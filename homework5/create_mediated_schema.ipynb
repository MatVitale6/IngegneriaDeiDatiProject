{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd>=2.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore con il file sources/AmbitionBox.csv usando encoding utf-8: 'utf-8' codec can't decode byte 0xe9 in position 3: invalid continuation byte\n",
      "Schema unificato salvato in  'output_other.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carica un file CSV, XLS, JSON o JSONL e restituisce un DataFrame con le colonne \n",
    "    'name', 'category', 'address', 'city', 'country', 'yearFoundation', 'founders', 'link',\n",
    "    'rank', 'market_cap', 'employees', 'ceo', 'assets', 'profit', 'sales', 'revenue', 'telephone',\n",
    "    'iban', 'sic_code', 'facebook'.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "            elif file_path.endswith(('.xls', '.xlsx')):\n",
    "                try:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore con il file {file_path} (Excel) usando encoding {encoding}: {e}\")\n",
    "                    continue\n",
    "            elif file_path.endswith('.json'):\n",
    "                with open(file_path, 'r', encoding=encoding) as f:\n",
    "                    data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    df = pd.DataFrame(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    df = pd.DataFrame([data])\n",
    "                else:\n",
    "                    raise ValueError(f\"Formato del JSON non supportato in {file_path}\")\n",
    "            elif file_path.endswith('.jsonl'):\n",
    "                df = pd.read_json(file_path, lines=True)\n",
    "            else:\n",
    "                raise ValueError(\"Formato non supportato\")\n",
    "            \n",
    "            # Inizializzazione dei valori come NaN\n",
    "            name_value = np.nan\n",
    "            category_value = np.nan\n",
    "            address_value = np.nan\n",
    "            city_value = np.nan\n",
    "            country_value = np.nan\n",
    "            year_foundation_value = np.nan\n",
    "            founders_value = np.nan\n",
    "            link_value = np.nan\n",
    "            rank_value = np.nan\n",
    "            market_cap_value = np.nan\n",
    "            employees_value = np.nan\n",
    "            ceo_value = np.nan\n",
    "            assets_value = np.nan\n",
    "            profit_value = np.nan\n",
    "            sales_value = np.nan\n",
    "            revenue_value = np.nan\n",
    "            telephone_value = np.nan\n",
    "            iban_value = np.nan\n",
    "            sic_code_value = np.nan\n",
    "            facebook_value = np.nan\n",
    "\n",
    "            # Mappatura colonne esistenti\n",
    "            name_columns = [\"Name\", \"name\", \"Company\", \"BRAND NAME\"]\n",
    "            category_columns = [\"category\", \"Sector\", \"Area of Activity\", \"nature_of_business\", \"company_business\", \"industry\", \"CATEGORY\", \"Industry\"]\n",
    "            address_columns = [\"address\", \"Address Name\", \"Address\"]\n",
    "            city_columns = [\"city\", \"City\", \"headquarters_region_city\", \"headquarters\", \"location\", \"Headquarter\"]\n",
    "            country_columns = [\"country\", \"Country\", \"headquarters_country\", \"headquarters\", \"Headquarter\", \"Headquarters\"]\n",
    "            foundation_columns = [\"company_creation_date\", \"founded\", \"Foundation Year\", \"Founded\"]\n",
    "            founders_columns = [\"founders\"]\n",
    "            link_columns = [\"URL\", \"company_website\", \"website\", \"link\"]\n",
    "\n",
    "            # Mappatura nuovi campi\n",
    "            rank_columns = [\"world_rank\", \"rank\"]\n",
    "            market_cap_columns = [\"market_cap\", \"Market Value\"]\n",
    "            employees_columns = [\"number_of_employees\", \"employees\", \"size\"]\n",
    "            ceo_columns = [\"ceo\"]\n",
    "            assets_columns = [\"total_assets_usd\", \"Assets\"]\n",
    "            profit_columns = [\"Profit\"]\n",
    "            sales_columns = [\"Sales\"]\n",
    "            revenue_columns = [\"annual_revenue_in_usd\", \"revenue\"]\n",
    "            telephone_columns = [\"telephone\"]\n",
    "            iban_columns = [\"national\"]\n",
    "            sic_code_columns = [\"sic_code\"]\n",
    "            facebook_columns = [\"Facebook\"]\n",
    "\n",
    "            # Estrazione dei valori per ciascuna colonna\n",
    "            for col in name_columns:\n",
    "                if col in df.columns:\n",
    "                    name_value = df[col].astype(str).str.strip()\n",
    "                    break\n",
    "\n",
    "            for col in category_columns:\n",
    "                if col in df.columns:\n",
    "                    category_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in address_columns:\n",
    "                if col in df.columns:\n",
    "                    address_value = df[col]\n",
    "                    if col == \"address\":\n",
    "                        address_value = address_value.str.split(',').str[0]  # Primo valore prima della virgola\n",
    "                    break\n",
    "\n",
    "            for col in city_columns:\n",
    "                if col in df.columns:\n",
    "                    city_value = df[col]\n",
    "                    if col in [\"Headquarter\", \"headquarters\"]:\n",
    "                        city_value = city_value.str.split(',').str[1]\n",
    "                    break\n",
    "\n",
    "            for col in country_columns:\n",
    "                if col in df.columns:\n",
    "                    country_value = df[col]\n",
    "                    if col in [\"headquarters\", \"Headquarter\"]:\n",
    "                        country_value = country_value.str.split(',').str[2]\n",
    "                    break\n",
    "            \n",
    "            for col in foundation_columns:\n",
    "                if col in df.columns:\n",
    "                    year_foundation_value = df[col]\n",
    "                    break\n",
    "            \n",
    "            for col in founders_columns:\n",
    "                if col in df.columns:\n",
    "                    founders_value = df[col]\n",
    "                    break\n",
    "            \n",
    "            for col in link_columns:\n",
    "                if col in df.columns:\n",
    "                    link_value = df[col]\n",
    "                    break\n",
    "\n",
    "            # Estrazione dei nuovi campi\n",
    "            for col in rank_columns:\n",
    "                if col in df.columns:\n",
    "                    rank_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in market_cap_columns:\n",
    "                if col in df.columns:\n",
    "                    market_cap_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in employees_columns:\n",
    "                if col in df.columns:\n",
    "                    employees_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in ceo_columns:\n",
    "                if col in df.columns:\n",
    "                    ceo_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in assets_columns:\n",
    "                if col in df.columns:\n",
    "                    assets_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in profit_columns:\n",
    "                if col in df.columns:\n",
    "                    profit_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in sales_columns:\n",
    "                if col in df.columns:\n",
    "                    sales_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in revenue_columns:\n",
    "                if col in df.columns:\n",
    "                    revenue_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in telephone_columns:\n",
    "                if col in df.columns:\n",
    "                    telephone_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in iban_columns:\n",
    "                if col in df.columns:\n",
    "                    iban_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in sic_code_columns:\n",
    "                if col in df.columns:\n",
    "                    sic_code_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in facebook_columns:\n",
    "                if col in df.columns:\n",
    "                    facebook_value = df[col]\n",
    "                    break\n",
    "            \n",
    "            # Creazione del DataFrame con i valori estratti\n",
    "            result_df = pd.DataFrame({\n",
    "                \"name\": name_value, \n",
    "                \"category\": category_value, \n",
    "                \"address\": address_value, \n",
    "                \"city\": city_value, \n",
    "                \"country\": country_value,\n",
    "                \"yearFoundation\": year_foundation_value,\n",
    "                \"founders\": founders_value,\n",
    "                \"link\": link_value,\n",
    "                \"rank\": rank_value,\n",
    "                \"market_cap\": market_cap_value,\n",
    "                \"employees\": employees_value,\n",
    "                \"ceo\": ceo_value,\n",
    "                \"assets\": assets_value,\n",
    "                \"profit\": profit_value,\n",
    "                \"sales\": sales_value,\n",
    "                \"revenue\": revenue_value,\n",
    "                \"telephone\": telephone_value,\n",
    "                \"iban\": iban_value,\n",
    "                \"sic_code\": sic_code_value,\n",
    "                \"facebook\": facebook_value\n",
    "            }, index=range(len(df)))\n",
    "            \n",
    "            return result_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Errore con il file {file_path} usando encoding {encoding}: {e}\")\n",
    "    \n",
    "    print(f\"Impossibile caricare il file {file_path} con i codici di encoding disponibili.\")\n",
    "    return pd.DataFrame(columns=[\"name\", \"category\", \"address\", \"city\", \"country\", \"yearFoundation\", \"founders\", \"link\", \"rank\", \"market_cap\", \"employees\", \"ceo\", \"assets\", \"profit\", \"sales\", \"revenue\", \"telephone\", \"iban\", \"sic_code\", \"facebook\"])\n",
    "\n",
    "# Cartella contenente i file\n",
    "source_folder = \"sources/\"\n",
    "\n",
    "# Ottieni la lista dei file nella cartella source\n",
    "file_list = [os.path.join(source_folder, file) for file in os.listdir(source_folder) \n",
    "             if file.endswith(('.csv', '.xls', '.xlsx', '.json', '.jsonl'))]\n",
    "\n",
    "# Separare i file in due gruppi\n",
    "wissel_files = [file for file in file_list if os.path.basename(file) in [\n",
    "    \"wissel-rappresentanti-ariregister.rik.ee.csv\", \"wissel-partners-ariregister.rik.ee.csv\"]]\n",
    "other_files = [file for file in file_list if file not in wissel_files]\n",
    "\n",
    "# Creare DataFrame\n",
    "other_df = pd.concat([load_data(file) for file in other_files], ignore_index=True)\n",
    "\n",
    "# Salvare i risultati\n",
    "other_df.to_csv(\"output_other.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Schema unificato salvato in  'output_other.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema unificato salvato in 'output_wissel.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carica un file CSV, XLS, JSON o JSONL e restituisce un DataFrame con le colonne \n",
    "    'name', 'category', 'address', 'city', 'country', 'yearFoundation', 'founders', 'link',\n",
    "    'rank', 'market_cap', 'employees', 'ceo', 'assets', 'profit', 'sales', 'revenue', 'telephone',\n",
    "    'iban', 'sic_code', 'facebook'.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "            elif file_path.endswith(('.xls', '.xlsx')):\n",
    "                try:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore con il file {file_path} (Excel) usando encoding {encoding}: {e}\")\n",
    "                    continue\n",
    "            elif file_path.endswith('.json'):\n",
    "                with open(file_path, 'r', encoding=encoding) as f:\n",
    "                    data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    df = pd.DataFrame(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    df = pd.DataFrame([data])\n",
    "                else:\n",
    "                    raise ValueError(f\"Formato del JSON non supportato in {file_path}\")\n",
    "            elif file_path.endswith('.jsonl'):\n",
    "                df = pd.read_json(file_path, lines=True)\n",
    "            else:\n",
    "                raise ValueError(\"Formato non supportato\")\n",
    "            \n",
    "            # Mappatura colonne\n",
    "            idAzienda_columns = [\"ID azienda\"]\n",
    "            nameEmployee_columns = [\"Name\"]\n",
    "            code_columns = [\"Code\"]\n",
    "            role_columns = [\"Role\"]\n",
    "            startDate_columns = [\"Start Date\"]\n",
    "            participation_columns = [\"Participation\"]\n",
    "            contribution_columns = [\"Contribution\"]\n",
    "\n",
    "            # Inizializzazione dei valori come NaN\n",
    "            idAzienda_value = np.nan\n",
    "            nameEmployee_value = np.nan\n",
    "            code_value = np.nan\n",
    "            role_value = np.nan\n",
    "            startDate_value = np.nan\n",
    "            participation_value = np.nan\n",
    "            contribution_value = np.nan\n",
    "\n",
    "            # Estrazione dei valori per ciascuna colonna \n",
    "            if any(col in df.columns for col in idAzienda_columns):\n",
    "                idAzienda_value = df[idAzienda_columns[0]] if idAzienda_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in nameEmployee_columns):\n",
    "                nameEmployee_value = df[nameEmployee_columns[0]].astype(str).str.strip() if nameEmployee_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in code_columns):\n",
    "                code_value = df[code_columns[0]] if code_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in role_columns):\n",
    "                role_value = df[role_columns[0]] if role_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in startDate_columns):\n",
    "                startDate_value = df[startDate_columns[0]] if startDate_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in participation_columns):\n",
    "                participation_value = df[participation_columns[0]] if participation_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in contribution_columns):\n",
    "                contribution_value = df[contribution_columns[0]] if contribution_columns[0] in df.columns else np.nan\n",
    "\n",
    "            # Creazione del DataFrame con i valori estratti\n",
    "            result_df = pd.DataFrame({\n",
    "                \"idAzienda\": idAzienda_value, \n",
    "                \"nameEmployee\": nameEmployee_value, \n",
    "                \"code\": code_value, \n",
    "                \"role\": role_value, \n",
    "                \"startDate\": startDate_value,\n",
    "                \"participation\": participation_value,\n",
    "                \"contribution\": contribution_value,\n",
    "            })\n",
    "            \n",
    "            return result_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Errore con il file {file_path} usando encoding {encoding}: {e}\")\n",
    "    \n",
    "    print(f\"Impossibile caricare il file {file_path} con i codici di encoding disponibili.\")\n",
    "    return pd.DataFrame(columns=[\"idAzienda\", \"nameEmployee\", \"code\", \"role\", \"startDate\", \"partecipation\", \"contribution\"])\n",
    "\n",
    "# Cartella contenente i file\n",
    "source_folder = \"sources/\"\n",
    "\n",
    "# Ottieni la lista dei file nella cartella source\n",
    "file_list = [os.path.join(source_folder, file) for file in os.listdir(source_folder) \n",
    "             if file.endswith(('.csv', '.xls', '.xlsx', '.json', '.jsonl'))]\n",
    "\n",
    "# Separare i file in due gruppi\n",
    "wissel_files = [file for file in file_list if os.path.basename(file) in [\n",
    "    \"wissel-rappresentanti-ariregister.rik.ee.csv\", \"wissel-partners-ariregister.rik.ee.csv\"]]\n",
    "\n",
    "# Creare DataFrame\n",
    "wissel_df = pd.concat([load_data(file) for file in wissel_files], ignore_index=True)\n",
    "\n",
    "# Salvare i risultati\n",
    "wissel_df.to_csv(\"output_wissel.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Schema unificato salvato in 'output_wissel.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi dei dati estratti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di righe nel file: 76808\n",
      "Numero di duplicati per 'name': 13837\n",
      "Numero di duplicati per 'link': 35042\n",
      "Numero di duplicati considerando insieme 'name' e 'link': 7181\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funzione per normalizzare i valori\n",
    "def normalize_string(s):\n",
    "    # Converti tutto in minuscolo\n",
    "    s = str(s).lower()\n",
    "    # Rimuovi spazi extra all'inizio e alla fine\n",
    "    s = s.strip()\n",
    "    # Sostituire più spazi consecutivi con uno solo\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "# Carica il file CSV\n",
    "file_path = \"output_other_sorted.csv\"\n",
    "other_df = pd.read_csv(file_path)\n",
    "\n",
    "# Conta il numero totale di righe nel DataFrame\n",
    "total_rows = len(other_df)\n",
    "print(f\"Numero totale di righe nel file: {total_rows}\")\n",
    "\n",
    "# Applica la normalizzazione alle colonne 'name' e 'link'\n",
    "columns_to_normalize = [\"name\", \"link\"]\n",
    "\n",
    "for col in columns_to_normalize:\n",
    "    if col in other_df.columns:\n",
    "        other_df[col] = other_df[col].apply(normalize_string)\n",
    "\n",
    "# Conta il numero di duplicati per la colonna 'name'\n",
    "duplicates_name_count = other_df.duplicated(subset=[\"name\"]).sum()\n",
    "print(f\"Numero di duplicati per 'name': {duplicates_name_count}\")\n",
    "\n",
    "# Conta il numero di duplicati per la colonna 'link'\n",
    "duplicates_link_count = other_df.duplicated(subset=[\"link\"]).sum()\n",
    "print(f\"Numero di duplicati per 'link': {duplicates_link_count}\")\n",
    "\n",
    "# Conta il numero di duplicati considerando insieme 'name' e 'link'\n",
    "duplicates_combined_count = other_df.duplicated(subset=[\"name\", \"link\"]).sum()\n",
    "print(f\"Numero di duplicati considerando insieme 'name' e 'link': {duplicates_combined_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di righe nel file: 2196\n",
      "Numero di duplicati per 'nameEmployee': 903\n",
      "File ordinato e normalizzato salvato come 'output_wissel_sorted.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funzione per normalizzare i valori\n",
    "def normalize_string(s):\n",
    "    # Converti tutto in minuscolo\n",
    "    s = str(s).lower()\n",
    "    # Rimuovi spazi extra all'inizio e alla fine\n",
    "    s = s.strip()\n",
    "    # Sostituire più spazi consecutivi con uno solo\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "# Carica il file CSV\n",
    "file_path = \"output_wissel.csv\"\n",
    "wissel_df = pd.read_csv(file_path)\n",
    "\n",
    "# Conta il numero totale di righe nel DataFrame\n",
    "total_rows = len(wissel_df)\n",
    "print(f\"Numero totale di righe nel file: {total_rows}\")\n",
    "\n",
    "# Controlla se la colonna 'nameEmployee' esiste nel DataFrame\n",
    "if 'nameEmployee' in wissel_df.columns:\n",
    "    # Normalizza i valori nella colonna 'nameEmployee'\n",
    "    wissel_df['nameEmployee'] = wissel_df['nameEmployee'].apply(normalize_string)\n",
    "    \n",
    "    # Ordina il DataFrame sulla base della colonna 'nameEmployee'\n",
    "    wissel_df = wissel_df.sort_values(by=\"nameEmployee\")\n",
    "    \n",
    "    # Conta il numero di duplicati nella colonna 'nameEmployee'\n",
    "    duplicates_nameEmployee_count = wissel_df.duplicated(subset=[\"nameEmployee\"]).sum()\n",
    "    print(f\"Numero di duplicati per 'nameEmployee': {duplicates_nameEmployee_count}\")\n",
    "\n",
    "    # Salvare il file ordinato e normalizzato\n",
    "    wissel_df.to_csv(\"output_wissel_sorted.csv\", index=False, encoding='utf-8')\n",
    "    print(\"File ordinato e normalizzato salvato come 'output_wissel_sorted.csv'\")\n",
    "else:\n",
    "    print(\"La colonna 'nameEmployee' non è presente nel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
