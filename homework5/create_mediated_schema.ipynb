{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd>=2.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore con il file sources/AmbitionBox.csv usando encoding utf-8: 'utf-8' codec can't decode byte 0xe9 in position 3: invalid continuation byte\n",
      "Schema unificato salvato in 'output_wissel.csv' e 'output_other.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carica un file CSV, XLS, JSON o JSONL e restituisce un DataFrame con le colonne 'name', 'category', 'address', 'city', 'country'.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                # Prova a leggere il file CSV con encoding\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "            elif file_path.endswith(('.xls', '.xlsx')):\n",
    "                # Gestione dei file Excel\n",
    "                try:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore con il file {file_path} (Excel) usando encoding {encoding}: {e}\")\n",
    "                    continue\n",
    "            elif file_path.endswith('.json'):\n",
    "                # Gestione dei file JSON\n",
    "                with open(file_path, 'r', encoding=encoding) as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Verifica la struttura dei dati nel JSON\n",
    "                if isinstance(data, list):\n",
    "                    df = pd.DataFrame(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    # In caso di dizionario, estrai i dati necessari e crea il DataFrame\n",
    "                    df = pd.DataFrame([data])\n",
    "                else:\n",
    "                    # Se i dati non sono né una lista né un dizionario, non possiamo trattarli correttamente\n",
    "                    raise ValueError(f\"Formato del JSON non supportato in {file_path}\")\n",
    "                \n",
    "            elif file_path.endswith('.jsonl'):\n",
    "                # Gestione dei file JSONL\n",
    "                df = pd.read_json(file_path, lines=True)\n",
    "            else:\n",
    "                raise ValueError(\"Formato non supportato\")\n",
    "            \n",
    "            # Inizializzazione dei valori come NaN\n",
    "            name_value = np.nan\n",
    "            category_value = np.nan\n",
    "            address_value = np.nan\n",
    "            city_value = np.nan\n",
    "            country_value = np.nan\n",
    "\n",
    "            # Trova il primo campo per \"name\", \"category\", \"address\", \"city\" e \"country\"\n",
    "            name_columns = [\"Name\", \"name\", \"Company\", \"BRAND NAME\"]\n",
    "            category_columns = [\"category\", \"Area of Activity\", \"company_business\", \"industry\", \"CATEGORY\", \"Industry\"]\n",
    "            address_columns = [\"address\", \"Address Name\", \"Address\"]\n",
    "            city_columns = [\"city\",\"City\",\"headquarters_region_city\", \"headquarters\", \"location\", \"Headquarter\"]\n",
    "            country_columns = [\"country\", \"Country\", \"headquarters_country\", \"headquarters\",\"Headquarter\"]\n",
    "\n",
    "            for col in name_columns:\n",
    "                if col in df.columns:\n",
    "                    name_value = df[col].astype(str).str.strip()  # Mantieni come nel file\n",
    "                    break\n",
    "\n",
    "            for col in category_columns:\n",
    "                if col in df.columns:\n",
    "                    category_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in address_columns:\n",
    "                if col in df.columns:\n",
    "                    address_value = df[col]\n",
    "                    if col == \"address\":\n",
    "                        address_value = address_value.str.split(',').str[0]  # Primo valore prima della virgola\n",
    "                    break\n",
    "\n",
    "            for col in city_columns:\n",
    "                if col in df.columns:\n",
    "                    # Se city è in address (contenuto in \"location_columns\" come \"address\")\n",
    "                    city_value = df[col]\n",
    "                    if col == \"address\":\n",
    "                        address_split = city_value.str.split(',')\n",
    "                        if address_split.str.len() > 2:  # Se ci sono almeno 3 valori separati da virgola\n",
    "                            city_value = address_split.str[2]  # Prendi il terzo valore\n",
    "                        else:\n",
    "                            city_value = np.nan  # Se non ci sono abbastanza valori, lascia NaN\n",
    "                    elif col in [\"Headquarter\", \"headquarters\"]:\n",
    "                        city_value = city_value.str.split(',').str[1]  # Primo valore prima della virgola\n",
    "                    break\n",
    "\n",
    "            for col in country_columns:\n",
    "               if col in df.columns:\n",
    "                country_value = df[col]\n",
    "                if col in [\"headquarters\", \"Headquarter\"]:\n",
    "                   country_value = country_value.str.split(',').str[2]  # Prendi il terzo valore dopo la virgola\n",
    "                break\n",
    "\n",
    "            # Crea il DataFrame con i valori estratti\n",
    "            result_df = pd.DataFrame({\n",
    "                \"name\": name_value, \n",
    "                \"category\": category_value, \n",
    "                \"address\": address_value, \n",
    "                \"city\": city_value, \n",
    "                \"country\": country_value\n",
    "            }, index=range(len(df)))\n",
    "            \n",
    "            return result_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Errore con il file {file_path} usando encoding {encoding}: {e}\")\n",
    "    \n",
    "    # Se non riusciamo a caricare il file\n",
    "    print(f\"Impossibile caricare il file {file_path} con i codici di encoding disponibili.\")\n",
    "    return pd.DataFrame(columns=[\"name\", \"category\", \"address\", \"city\", \"country\"])\n",
    "\n",
    "# Cartella contenente i file\n",
    "source_folder = \"sources/\"\n",
    "\n",
    "# Ottieni la lista dei file nella cartella source\n",
    "file_list = [os.path.join(source_folder, file) for file in os.listdir(source_folder) \n",
    "             if file.endswith(('.csv', '.xls', '.xlsx', '.json', '.jsonl'))]\n",
    "\n",
    "# Separare i file in due gruppi\n",
    "wissel_files = [file for file in file_list if os.path.basename(file) in [\n",
    "    \"wissel-rappresentanti-ariregister.rik.ee.csv\", \"wissel-partners-ariregister.rik.ee.csv\"]]\n",
    "other_files = [file for file in file_list if file not in wissel_files]\n",
    "\n",
    "# Creare due DataFrame separati\n",
    "wissel_df = pd.concat([load_data(file) for file in wissel_files], ignore_index=True)\n",
    "other_df = pd.concat([load_data(file) for file in other_files], ignore_index=True)\n",
    "\n",
    "# Salvare i risultati in due CSV separati\n",
    "wissel_df.to_csv(\"output_wissel.csv\", index=False, encoding='utf-8')\n",
    "other_df.to_csv(\"output_other.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Schema unificato salvato in 'output_wissel.csv' e 'output_other.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
