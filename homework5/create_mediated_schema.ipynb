{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd>=2.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore con il file sources/AmbitionBox.csv usando encoding utf-8: 'utf-8' codec can't decode byte 0xe9 in position 3: invalid continuation byte\n",
      "Schema unificato salvato in  'output_other.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carica un file CSV, XLS, JSON o JSONL e restituisce un DataFrame con le colonne \n",
    "    'name', 'category', 'address', 'city', 'country', 'yearFoundation', 'founders', 'link',\n",
    "    'rank', 'market_cap', 'employees', 'ceo', 'assets', 'profit', 'sales', 'revenue', 'telephone',\n",
    "    'iban', 'sic_code', 'facebook'.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "            elif file_path.endswith(('.xls', '.xlsx')):\n",
    "                try:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore con il file {file_path} (Excel) usando encoding {encoding}: {e}\")\n",
    "                    continue\n",
    "            elif file_path.endswith('.json'):\n",
    "                with open(file_path, 'r', encoding=encoding) as f:\n",
    "                    data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    df = pd.DataFrame(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    df = pd.DataFrame([data])\n",
    "                else:\n",
    "                    raise ValueError(f\"Formato del JSON non supportato in {file_path}\")\n",
    "            elif file_path.endswith('.jsonl'):\n",
    "                df = pd.read_json(file_path, lines=True)\n",
    "            else:\n",
    "                raise ValueError(\"Formato non supportato\")\n",
    "            \n",
    "            # Inizializzazione dei valori come NaN\n",
    "            code_azienda_value = np.nan #hhid\n",
    "            name_value = np.nan\n",
    "            category_value = np.nan\n",
    "            sector_value = np.nan\n",
    "            address_value = np.nan\n",
    "            postal_code_value = np.nan  #va gestito\n",
    "            city_value = np.nan\n",
    "            country_value = np.nan\n",
    "            county_position_value = np.nan  \n",
    "            continent_value = np.nan \n",
    "            year_foundation_value = np.nan\n",
    "            year_legal_form_value = np.nan\n",
    "            year_data_joined_value = np.nan\n",
    "            founders_value = np.nan\n",
    "            link_value = np.nan\n",
    "            rank_value = np.nan\n",
    "            rank_2010_value = np.nan\n",
    "            market_cap_value = np.nan\n",
    "            employees_value = np.nan\n",
    "            ceo_value = np.nan\n",
    "            assets_value = np.nan\n",
    "            profit_value = np.nan\n",
    "            sales_value = np.nan\n",
    "            revenue_value = np.nan\n",
    "            telephone_value = np.nan\n",
    "            partita_iva_value = np.nan\n",
    "            hhid_value = np.nan\n",
    "            sic_code_value = np.nan\n",
    "            facebook_value = np.nan\n",
    "            twitter_value = np.nan\n",
    "            pinterest_value = np.nan\n",
    "            instagram_value= np.nan\n",
    "            capital_value = np.nan\n",
    "            deletion_date_value=np.nan\n",
    "            emtak_code_value = np.nan\n",
    "            nace_code_value = np.nan\n",
    "            source_value = np.nan\n",
    "            annual_net_income_in_usd_value = np.nan\n",
    "            annual_results_for_year_ending_value = np.nan\n",
    "            total_liabilities_in_usd_value = np.nan\n",
    "            total_equity_in_usd_value = np.nan\n",
    "            company_status_value = np.nan\n",
    "            company_type = np.nan\n",
    "            valuetion_value = np.nan\n",
    "            investors_value = np.nan\n",
    "            total_raised_value = np.nan\n",
    "            share_price_value = np.nan\n",
    "            change_1_day_value = np.nan\n",
    "            change_1_year_value = np.nan\n",
    "            main_market_value = np.nan\n",
    "            ownership_value = np.nan\n",
    "            note_value = np.nan\n",
    "\n",
    "\n",
    "            # Mappatura colonne esistenti\n",
    "            code_azienda_columns = [\"ID azienda\", \"ID\", \"id\", \"company_number\"]\n",
    "            name_columns = [\"Name\", \"name\", \"Company\", \"BRAND NAME\"]\n",
    "            category_columns = [\"category\", \"Area of Activity\", \"nature_of_business\", \"company_business\", \"industry\", \"CATEGORY\", \"Industry\"]\n",
    "            sector_columns = [\"Sector\"]\n",
    "            address_columns = [\"address\", \"Address Name\", \"Address\"]\n",
    "            city_columns = [\"city\", \"City\", \"headquarters_region_city\", \"headquarters\", \"location\", \"Headquarter\"]\n",
    "            country_columns = [\"country\", \"Country\", \"headquarters_country\", \"headquarters\", \"Headquarter\", \"Headquarters\"]\n",
    "            county_position_columns = [\"headquarters_sub_region\"]\n",
    "            continent_columns = [\"-\theadquarters_continent\"]\n",
    "            foundation_columns = [\"company_creation_date\", \"founded\", \"Foundation Year\", \"Founded\"]\n",
    "            year_legal_form_columns = [\"Legal form\"]\n",
    "            year_data_joined_columns = [\"dateJoined\"]\n",
    "            founders_columns = [\"founders\"]\n",
    "            link_columns = [\"URL\", \"company_website\", \"website\", \"link\"]\n",
    "\n",
    "            # Mappatura nuovi campi\n",
    "            rank_columns = [\"world_rank\", \"rank\"]\n",
    "            market_cap_columns = [\"market_cap\", \"Market Value\"]\n",
    "            employees_columns = [\"number_of_employees\", \"employees\", \"size\"]\n",
    "            ceo_columns = [\"ceo\"]\n",
    "            assets_columns = [\"total_assets_usd\", \"Assets\"]\n",
    "            profit_columns = [\"Profit\"]\n",
    "            sales_columns = [\"Sales\"]\n",
    "            revenue_columns = [\"annual_revenue_in_usd\", \"revenue\"]\n",
    "            telephone_columns = [\"telephone\"]\n",
    "            partita_iva_columns = [\"national\"]\n",
    "            sic_code_columns = [\"sic_code\"]\n",
    "            facebook_columns = [\"Facebook\"]\n",
    "            instagram_colums = [\"Instagram\"]\n",
    "            \n",
    "\n",
    "            # Estrazione dei valori per ciascuna colonna\n",
    "            for col in code_azienda_columns:\n",
    "                if col in df.columns:\n",
    "                    code_azienda_value= df[col].astype(str).str.strip()\n",
    "                    break\n",
    "            \n",
    "            for col in name_columns:\n",
    "                if col in df.columns:\n",
    "                    name_value = df[col].astype(str).str.strip()\n",
    "                    break\n",
    "\n",
    "            for col in category_columns:\n",
    "                if col in df.columns:\n",
    "                    category_value = df[col]\n",
    "                    break\n",
    "            for col in sector_columns:\n",
    "                if col in df.columns:\n",
    "                    sector_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in address_columns:\n",
    "                if col in df.columns:\n",
    "                    address_value = df[col]\n",
    "                    if col == \"address\":\n",
    "                        address_value = address_value.str.split(',').str[0]  # Primo valore prima della virgola\n",
    "                    break\n",
    "\n",
    "            for col in city_columns:\n",
    "                if col in df.columns:\n",
    "                    city_value = df[col]\n",
    "                    if col in [\"Headquarter\", \"headquarters\"]:\n",
    "                        city_value = city_value.str.split(',').str[1]\n",
    "                    break\n",
    "\n",
    "            for col in country_columns:\n",
    "                if col in df.columns:\n",
    "                    country_value = df[col]\n",
    "                    if col in [\"headquarters\", \"Headquarter\"]:\n",
    "                        country_value = country_value.str.split(',').str[2]\n",
    "                    break\n",
    "            \n",
    "            for col in foundation_columns:\n",
    "                if col in df.columns:\n",
    "                    year_foundation_value = df[col]\n",
    "                    break\n",
    "            \n",
    "            for col in founders_columns:\n",
    "                if col in df.columns:\n",
    "                    founders_value = df[col]\n",
    "                    break\n",
    "            \n",
    "            for col in link_columns:\n",
    "                if col in df.columns:\n",
    "                    link_value = df[col]\n",
    "                    break\n",
    "\n",
    "            # Estrazione dei nuovi campi\n",
    "            for col in rank_columns:\n",
    "                if col in df.columns:\n",
    "                    rank_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in market_cap_columns:\n",
    "                if col in df.columns:\n",
    "                    market_cap_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in employees_columns:\n",
    "                if col in df.columns:\n",
    "                    employees_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in ceo_columns:\n",
    "                if col in df.columns:\n",
    "                    ceo_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in assets_columns:\n",
    "                if col in df.columns:\n",
    "                    assets_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in profit_columns:\n",
    "                if col in df.columns:\n",
    "                    profit_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in sales_columns:\n",
    "                if col in df.columns:\n",
    "                    sales_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in revenue_columns:\n",
    "                if col in df.columns:\n",
    "                    revenue_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in telephone_columns:\n",
    "                if col in df.columns:\n",
    "                    telephone_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in partita_iva_columns:\n",
    "                if col in df.columns:\n",
    "                    partita_iva_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in sic_code_columns:\n",
    "                if col in df.columns:\n",
    "                    sic_code_value = df[col]\n",
    "                    break\n",
    "\n",
    "            for col in facebook_columns:\n",
    "                if col in df.columns:\n",
    "                    facebook_value = df[col]\n",
    "                    break\n",
    "            \n",
    "            # Creazione del DataFrame con i valori estratti\n",
    "            result_df = pd.DataFrame({\n",
    "                \"code azienda\": code_azienda_value,\n",
    "                \"name\": name_value, \n",
    "                \"category\": category_value, \n",
    "                \"sector\": sector_value,\n",
    "                \"address\": address_value, \n",
    "                \"city\": city_value, \n",
    "                \"country\": country_value,\n",
    "                \"yearFoundation\": year_foundation_value,\n",
    "                \"founders\": founders_value,\n",
    "                \"link\": link_value,\n",
    "                \"rank\": rank_value,\n",
    "                \"market_cap\": market_cap_value,\n",
    "                \"employees\": employees_value,\n",
    "                \"ceo\": ceo_value,\n",
    "                \"assets\": assets_value,\n",
    "                \"profit\": profit_value,\n",
    "                \"sales\": sales_value,\n",
    "                \"revenue\": revenue_value,\n",
    "                \"telephone\": telephone_value,\n",
    "                \"partita iva\": partita_iva_value,\n",
    "                \"sic_code\": sic_code_value,\n",
    "                \"facebook\": facebook_value\n",
    "            }, index=range(len(df)))\n",
    "            \n",
    "            return result_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Errore con il file {file_path} usando encoding {encoding}: {e}\")\n",
    "    \n",
    "    print(f\"Impossibile caricare il file {file_path} con i codici di encoding disponibili.\")\n",
    "    return pd.DataFrame(columns=[\"code azienda\",\"name\", \"category\",\"sector\", \"address\", \"city\", \"country\", \"yearFoundation\", \"founders\", \"link\", \"rank\", \"market_cap\", \"employees\", \"ceo\", \"assets\", \"profit\", \"sales\", \"revenue\", \"telephone\", \"partita_iva\", \"sic_code\", \"facebook\"])\n",
    "\n",
    "# Cartella contenente i file\n",
    "source_folder = \"sources/\"\n",
    "\n",
    "# Ottieni la lista dei file nella cartella source\n",
    "file_list = [os.path.join(source_folder, file) for file in os.listdir(source_folder) \n",
    "             if file.endswith(('.csv', '.xls', '.xlsx', '.json', '.jsonl'))]\n",
    "\n",
    "# Separare i file in due gruppi\n",
    "wissel_files = [file for file in file_list if os.path.basename(file) in [\n",
    "    \"wissel-rappresentanti-ariregister.rik.ee.csv\", \"wissel-partners-ariregister.rik.ee.csv\"]]\n",
    "other_files = [file for file in file_list if file not in wissel_files]\n",
    "\n",
    "# Creare DataFrame\n",
    "other_df = pd.concat([load_data(file) for file in other_files], ignore_index=True)\n",
    "\n",
    "# Salvare i risultati\n",
    "other_df.to_csv(\"output_other.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Schema unificato salvato in  'output_other.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema unificato salvato in 'output_wissel.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carica un file CSV, XLS, JSON o JSONL e restituisce un DataFrame con le colonne \n",
    "    'name', 'category', 'address', 'city', 'country', 'yearFoundation', 'founders', 'link',\n",
    "    'rank', 'market_cap', 'employees', 'ceo', 'assets', 'profit', 'sales', 'revenue', 'telephone',\n",
    "    'iban', 'sic_code', 'facebook'.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "            elif file_path.endswith(('.xls', '.xlsx')):\n",
    "                try:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore con il file {file_path} (Excel) usando encoding {encoding}: {e}\")\n",
    "                    continue\n",
    "            elif file_path.endswith('.json'):\n",
    "                with open(file_path, 'r', encoding=encoding) as f:\n",
    "                    data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    df = pd.DataFrame(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    df = pd.DataFrame([data])\n",
    "                else:\n",
    "                    raise ValueError(f\"Formato del JSON non supportato in {file_path}\")\n",
    "            elif file_path.endswith('.jsonl'):\n",
    "                df = pd.read_json(file_path, lines=True)\n",
    "            else:\n",
    "                raise ValueError(\"Formato non supportato\")\n",
    "            \n",
    "            # Mappatura colonne\n",
    "            idAzienda_columns = [\"ID azienda\"]\n",
    "            nameEmployee_columns = [\"Name\"]\n",
    "            code_columns = [\"Code\"]\n",
    "            role_columns = [\"Role\"]\n",
    "            startDate_columns = [\"Start Date\"]\n",
    "            participation_columns = [\"Participation\"]\n",
    "            contribution_columns = [\"Contribution\"]\n",
    "\n",
    "            # Inizializzazione dei valori come NaN\n",
    "            idAzienda_value = np.nan\n",
    "            nameEmployee_value = np.nan\n",
    "            code_value = np.nan\n",
    "            role_value = np.nan\n",
    "            startDate_value = np.nan\n",
    "            participation_value = np.nan\n",
    "            contribution_value = np.nan\n",
    "\n",
    "            # Estrazione dei valori per ciascuna colonna \n",
    "            if any(col in df.columns for col in idAzienda_columns):\n",
    "                idAzienda_value = df[idAzienda_columns[0]] if idAzienda_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in nameEmployee_columns):\n",
    "                nameEmployee_value = df[nameEmployee_columns[0]].astype(str).str.strip() if nameEmployee_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in code_columns):\n",
    "                code_value = df[code_columns[0]] if code_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in role_columns):\n",
    "                role_value = df[role_columns[0]] if role_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in startDate_columns):\n",
    "                startDate_value = df[startDate_columns[0]] if startDate_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in participation_columns):\n",
    "                participation_value = df[participation_columns[0]] if participation_columns[0] in df.columns else np.nan\n",
    "\n",
    "            if any(col in df.columns for col in contribution_columns):\n",
    "                contribution_value = df[contribution_columns[0]] if contribution_columns[0] in df.columns else np.nan\n",
    "\n",
    "            # Creazione del DataFrame con i valori estratti\n",
    "            result_df = pd.DataFrame({\n",
    "                \"idAzienda\": idAzienda_value, \n",
    "                \"nameEmployee\": nameEmployee_value, \n",
    "                \"code\": code_value, \n",
    "                \"role\": role_value, \n",
    "                \"startDate\": startDate_value,\n",
    "                \"participation\": participation_value,\n",
    "                \"contribution\": contribution_value,\n",
    "            })\n",
    "            \n",
    "            return result_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Errore con il file {file_path} usando encoding {encoding}: {e}\")\n",
    "    \n",
    "    print(f\"Impossibile caricare il file {file_path} con i codici di encoding disponibili.\")\n",
    "    return pd.DataFrame(columns=[\"idAzienda\", \"nameEmployee\", \"code\", \"role\", \"startDate\", \"partecipation\", \"contribution\"])\n",
    "\n",
    "# Cartella contenente i file\n",
    "source_folder = \"sources/\"\n",
    "\n",
    "# Ottieni la lista dei file nella cartella source\n",
    "file_list = [os.path.join(source_folder, file) for file in os.listdir(source_folder) \n",
    "             if file.endswith(('.csv', '.xls', '.xlsx', '.json', '.jsonl'))]\n",
    "\n",
    "# Separare i file in due gruppi\n",
    "wissel_files = [file for file in file_list if os.path.basename(file) in [\n",
    "    \"wissel-rappresentanti-ariregister.rik.ee.csv\", \"wissel-partners-ariregister.rik.ee.csv\"]]\n",
    "\n",
    "# Creare DataFrame\n",
    "wissel_df = pd.concat([load_data(file) for file in wissel_files], ignore_index=True)\n",
    "\n",
    "# Salvare i risultati\n",
    "wissel_df.to_csv(\"output_wissel.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Schema unificato salvato in 'output_wissel.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi dei dati estratti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di righe nel file: 76808\n",
      "                                             name  \\\n",
      "0                \"all about me\" full stop limited   \n",
      "1  \"q\" (chester green) management company limited   \n",
      "2                                          #sinob   \n",
      "3                      'all aboard' shops limited   \n",
      "4                'q' accountancy services limited   \n",
      "\n",
      "                                            category address city  country  \\\n",
      "0  82990 - other business support service activit...     NaN  NaN      NaN   \n",
      "1              98000 - residents property management     NaN  NaN      NaN   \n",
      "2                                             retail     NaN  NaN  germany   \n",
      "3  88990 - other social work activities without a...     NaN  NaN      NaN   \n",
      "4         69201 - accounting and auditing activities     NaN  NaN      NaN   \n",
      "\n",
      "      yearFoundation founders                   link rank market_cap  \\\n",
      "0     13 august 2018      NaN                    NaN  NaN        NaN   \n",
      "1  27 september 2007      NaN                    NaN  NaN        NaN   \n",
      "2               2015      NaN  https://www.sinob.de/  NaN        NaN   \n",
      "3     4 january 1991      NaN                    NaN  NaN        NaN   \n",
      "4      21 april 1994      NaN                    NaN  NaN        NaN   \n",
      "\n",
      "  employees  ceo assets profit sales revenue telephone  iban sic_code facebook  \n",
      "0       NaN  NaN    NaN    NaN   NaN     NaN       NaN   NaN      NaN      NaN  \n",
      "1       NaN  NaN    NaN    NaN   NaN     NaN       NaN   NaN      NaN      NaN  \n",
      "2        14  NaN    NaN    NaN   NaN    4.95       NaN   NaN      NaN      NaN  \n",
      "3       NaN  NaN    NaN    NaN   NaN     NaN       NaN   NaN      NaN      NaN  \n",
      "4       NaN  NaN    NaN    NaN   NaN     NaN       NaN   NaN      NaN      NaN  \n",
      "Numero di duplicati per 'name': 13837\n",
      "Numero di duplicati per 'category': 71850\n",
      "Numero di duplicati per 'address': 68062\n",
      "Numero di duplicati per 'city': 75100\n",
      "Numero di duplicati per 'country': 75616\n",
      "Numero di duplicati per 'yearFoundation': 72705\n",
      "Numero di duplicati per 'founders': 76421\n",
      "Numero di duplicati per 'link': 35042\n",
      "Numero di duplicati per 'rank': 61938\n",
      "Numero di duplicati per 'market_cap': 58033\n",
      "Numero di duplicati per 'employees': 67016\n",
      "Numero di duplicati per 'ceo': 66257\n",
      "Numero di duplicati per 'assets': 75011\n",
      "Numero di duplicati per 'profit': 75421\n",
      "Numero di duplicati per 'sales': 75208\n",
      "Numero di duplicati per 'revenue': 67594\n",
      "Numero di duplicati per 'telephone': 71624\n",
      "Numero di duplicati per 'iban': 76807\n",
      "Numero di duplicati per 'sic_code': 76641\n",
      "Numero di duplicati per 'facebook': 75969\n",
      "Numero di duplicati considerando insieme 'name' e 'link': 7181\n",
      "File normalizzato salvato come 'output_other_normalized.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funzione per normalizzare i valori\n",
    "def normalize_string(s):\n",
    "    if pd.isna(s) or not s:\n",
    "        return s  # Se il valore è NaN o vuoto, non lo modificare\n",
    "    # Converti tutto in minuscolo\n",
    "    s = str(s).lower()\n",
    "    # Rimuovi spazi extra all'inizio e alla fine\n",
    "    s = s.strip()\n",
    "    # Sostituire più spazi consecutivi con uno solo\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "# Carica il file CSV\n",
    "file_path = \"output_other_sorted.csv\"\n",
    "other_df = pd.read_csv(file_path)\n",
    "\n",
    "# Conta il numero totale di righe nel DataFrame\n",
    "total_rows = len(other_df)\n",
    "print(f\"Numero totale di righe nel file: {total_rows}\")\n",
    "\n",
    "# Lista di colonne da normalizzare\n",
    "columns_to_normalize = [\n",
    "    \"name\", \"category\", \"address\", \"city\", \"country\", \"yearFoundation\", \n",
    "    \"founders\", \"link\", \"rank\", \"market_cap\", \"employees\", \"ceo\", \n",
    "    \"assets\", \"profit\", \"sales\", \"revenue\", \"telephone\", \"iban\", \n",
    "    \"sic_code\", \"facebook\"\n",
    "]\n",
    "\n",
    "# Applica la normalizzazione a tutte le colonne indicate\n",
    "for col in columns_to_normalize:\n",
    "    if col in other_df.columns:\n",
    "        other_df[col] = other_df[col].apply(normalize_string)\n",
    "\n",
    "# Stampa un esempio per verificare la normalizzazione\n",
    "print(other_df.head())\n",
    "\n",
    "# Conta il numero di duplicati per ciascuna colonna\n",
    "for col in columns_to_normalize:\n",
    "    if col in other_df.columns:\n",
    "        duplicates_count = other_df.duplicated(subset=[col]).sum()\n",
    "        print(f\"Numero di duplicati per '{col}': {duplicates_count}\")\n",
    "        \n",
    "# Conta il numero di duplicati considerando insieme 'name' e 'link'\n",
    "duplicates_combined_count = other_df.duplicated(subset=[\"name\", \"link\"]).sum()\n",
    "print(f\"Numero di duplicati considerando insieme 'name' e 'link': {duplicates_combined_count}\")\n",
    "\n",
    "# Salvare il DataFrame normalizzato\n",
    "other_df.to_csv(\"output_other_normalized.csv\", index=False, encoding='utf-8')\n",
    "print(\"File normalizzato salvato come 'output_other_normalized.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di righe nel file: 2196\n",
      "Numero di duplicati per 'nameEmployee': 903\n",
      "File ordinato e normalizzato salvato come 'output_wissel_sorted.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funzione per normalizzare i valori\n",
    "def normalize_string(s):\n",
    "    # Converti tutto in minuscolo\n",
    "    s = str(s).lower()\n",
    "    # Rimuovi spazi extra all'inizio e alla fine\n",
    "    s = s.strip()\n",
    "    # Sostituire più spazi consecutivi con uno solo\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "# Carica il file CSV\n",
    "file_path = \"output_wissel.csv\"\n",
    "wissel_df = pd.read_csv(file_path)\n",
    "\n",
    "# Conta il numero totale di righe nel DataFrame\n",
    "total_rows = len(wissel_df)\n",
    "print(f\"Numero totale di righe nel file: {total_rows}\")\n",
    "\n",
    "# Controlla se la colonna 'nameEmployee' esiste nel DataFrame\n",
    "if 'nameEmployee' in wissel_df.columns:\n",
    "    # Normalizza i valori nella colonna 'nameEmployee'\n",
    "    wissel_df['nameEmployee'] = wissel_df['nameEmployee'].apply(normalize_string)\n",
    "    \n",
    "    # Ordina il DataFrame sulla base della colonna 'nameEmployee'\n",
    "    wissel_df = wissel_df.sort_values(by=\"nameEmployee\")\n",
    "    \n",
    "    # Conta il numero di duplicati nella colonna 'nameEmployee'\n",
    "    duplicates_nameEmployee_count = wissel_df.duplicated(subset=[\"nameEmployee\"]).sum()\n",
    "    print(f\"Numero di duplicati per 'nameEmployee': {duplicates_nameEmployee_count}\")\n",
    "\n",
    "    # Salvare il file ordinato e normalizzato\n",
    "    wissel_df.to_csv(\"output_wissel_sorted.csv\", index=False, encoding='utf-8')\n",
    "    print(\"File ordinato e normalizzato salvato come 'output_wissel_sorted.csv'\")\n",
    "else:\n",
    "    print(\"La colonna 'nameEmployee' non è presente nel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
