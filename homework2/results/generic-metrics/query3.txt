Query: accuracy comparison for federated learning models

Table: 2308.11217:S2.T1
Caption: TABLE I: Comparison of Federated Learning in Small Model Era and Large Model Era
References: TableÂ I makes the comparison between traditional federated learning(i.e., in small model era) and that in big model era. Traditional federated learning jointly train a global model from scratch for the purpose of enhance model accuracy within a predefined application scenarios. Nowadays, federated learning aims at a domain-specific model based on the foundational intelligence of a general large model. Since the application target and generation method of intelligent product have been fundamentally changed in big model era, federated learning faces new challenges to tackled.

-----------------------------------------

Table: 2311.00959:S4.T3
Caption: TABLE III: Comparison of Accuracy Distribution of Different Federated Learning Algorithms
References: the q-FFL algorithm and  Î± ğ›¼ \alpha -FedAvg algorithm are selected for comparison with the algorithm proposed in this paper. In order to exclude the influence of irrelevant factors, the number of clients involved in the computation in each round of aggregation is set to 10 in this paper. The learning rates of Synthetic, Vehicle, and Sent140 are 0.1, 0.01, and 0.03, respectively, and the batch sizes of Synthetic, Vehicle, and Sent140 are 10, 64, and 32. The number of local iterations  E ğ¸ E  is fixed to 1. The accuracy of the final model is tested on each participantâ€™s local dataset by conducting several sets of experiments with the above dataset, and the frequency distribution histogram is constructed by counting the customers whose values fall into the corresponding intervals. Table 3 further shows the performance of each comparison algorithm on the dataset, including the average accuracy, the worst performing (10%) in the category accuracy, the best performing (10%) accuracy in the category, and the variance of the fairness metric used to measure the model. From the analysis of the experimental results, it is obtained that the algorithm DQFFL proposed in this paper achieves good performance before optimizing the model performance and fairness. The average accuracy of DQFFL on the Synthetic dataset rate decreases by 1.6% compared to FedAvg, but reduces fairness by 40% by adjusting the performance of the worst and best performing clients. From the Vehicle, Sent140 dataset performance, DQFFL compared to other comparison algorithms, the algorithm further reduces the variance by boosting the accuracy and average accuracy of the worst performing clients in the category at the expense of the accuracy of the best performing clients in the category, taking into account the performance of reinforcement federated learning on fairness in a comprehensive manner.

-----------------------------------------

Table: 2304.12889:S5.T4
Caption: TABLE IV: Comparison of machine learning model accuracy in federated learning process when using normal CPU and SGX
References: Table IV shows the results of testing our framework to see the effect when we apply the machine learning model in a federated way inside the enclave and standard CPU. In this experiment, all the datasets have 28x28 pixels and 128 batch size. We ran the experiment with 50 training iterations. The experimental results show that the differences in the accuracy of the proposed methodology and two benchmark methods proposed in [14] and [15]. Initially, we record the accuracies of our proposed method with and without SGX. The accuracies of the aforementioned methods are obtained by applying various CNN models on different datasets. According to the results, the accuracies are reduced by 2.2% to 2.9% when SGX is used. Later, we measure the accuracies of Myelin[14] and Chiron[15] with and without SGX. Results show that accuracies of the Myelin and Chiron are lower than our proposed method. Moreover, the accuracies of Myelin and Chiron are reduced around 5.1% and 7.4% with SGX, respectively. Hence, our method has better accuracy compared to Myelin and Chiron.

-----------------------------------------

Table: 2404.13946:S5.T4
Caption: TABLE IV: Performance comparison of federated learning backdoor model
References: Table IV shows the performance comparison of each federated learning backdoor model under different datasets, where Clean F-Model is a federated learning model trained on normal datasets. The ASR of DBA performs poorly on the CIFAR10 and GTSRB datasets, 98.64% and 96.85%, respectively. After changing the trigger size, the ASR of DBA on the MS-Celeb-1M dataset can reach 99.69%. The BA of DBA is quite different from that of each baseline model, and the average difference between the three datasets is reduced by about 5%-10%.

-----------------------------------------

Table: 2310.09444:S5.T1
Caption: Table 1: Comparison of federated learning methods (Local, FedMHA, FedAvg [17], FedAvg ResNet [22], FedBN [14], FedProx [11]) under different levels of data heterogeneity represented by varying Î±LDAsubscriptğ›¼LDA\alpha_{\text{LDA}} values. The average accuracies were calculated after 5 rounds of federated learning.
References: Table 1 provides a comparison of various federated learning methods, including our proposed FedMHA method, under different heterogeneity levels, represented by varying Î±LDAsubscriptğ›¼LDA\alpha_{\mathrm{LDA}} values. The table highlights the average accuracies achieved after 5 rounds of federated learning.A detailed analysis of these results reveals that while all models generally improve their performance as the Î±LDAsubscriptğ›¼LDA\alpha_{\mathrm{LDA}} value increases (corresponding to a more homogeneous data distribution), the FedMHA outperforms all other models, particularly in low Î±LDAsubscriptğ›¼LDA\alpha_{\mathrm{LDA}} values.

-----------------------------------------

Table: 2303.11745:S2.T5
Caption: TABLE V: Accuracy of the federated deep learning approach (CNN) for binary classification and multi-classification in federated model performance with Non-IID data.
References: Table V presents the accuracy results of the federated deep learning approach (CNN) for binary classification and multi-classification in federated model performance with the Non-IID data and different numbers of honest clients Khsubscriptğ¾â„K_{h} and malicious clients Kmsubscriptğ¾ğ‘šK_{m}. When the number of honest clients is less than the number of malicious clients (i.e., Kh=3subscriptğ¾â„3K_{h}=3 and Km=7subscriptğ¾ğ‘š7K_{m}=7), we can observe that in each round, the accuracy results are affected in each round and give negative results until it reaches 30.04%.

-----------------------------------------

Table: 2401.07234:S2.T2
Caption: Table 2: Comparison of Federated Learning studies on heterogeneous data.
References: One of the primary challenges in federated learning is data heterogeneity (non-IID data). The most common non-IID data settings can be categorised into three types, quantity imbalance, class imbalance and feature imbalance[13]. TableÂ 2 summaries of existing federated learning approaches on non-IID data. The majority of prior research on simulating non-IID data primarily centers around class imbalance and feature imbalance. Many studies proposed various averaging methods to address the performance degradation caused by these imbalances[37][38][39]. There have been relatively few investigations into quantity imbalance. One example in this area is the work by Chung et al., who proposed FedISM to address quantity imbalance issue and improve the performance degradation caused by quantity skew[40]. Certain studies have attempted to assess the impact of quantity imbalance on model performance[41][42]. However, these studies have typically limited their analysis to comparing federated models in non-IID scenarios with either centralised models or federated models in IID scenarios. Additionally, these investigations have often only experimented with one or two imbalanced scenarios. Our work bridges this research gap, standing out as the pioneering effort in conducting comprehensive experiments involving three distinct model architectures and three datasets. Its primary aim is to explore the impact of quantity imbalances in federated learning. This is achieved through comparisons among federated, local, and centralised models across varying client numbers and data distributions.

-----------------------------------------

Table: 2303.11745:S2.T4
Caption: TABLE IV: Accuracy of the federated deep learning approach (CNN) for binary classification and multi-classification in federated model performance with IID data and different numbers of honest clients Khsubscriptğ¾â„K_{h} and malicious clients Kmsubscriptğ¾ğ‘šK_{m}.
References: TableÂ IV presents the classification report of the accuracy of deep learning for binary classification and multi-classification under different deep learning approaches, namely, DNN, RNN, and CNN in centralized model performance with the attack rate Î±ğ›¼\alpha =[0%,40%,50%,60%]absentpercent0percent40percent50percent60=[0\%,40\%,50\%,60\%] (i.e., Poisoning Attack). With binary classification, the accuracy of the DNN classifier is decreased from 100% to 95.50%, while with multi-classification, the accuracy is decreased from 93.01% to 21.76%. We observe that intrusion detection models based on the deep learning classifiers (i.e., CNN, RNN, DNN) are more affected by multi-classification than binary classification. Table IV presents the accuracy results of the federated deep learning approach (CNN) for binary classification and multi-classification in federated model performance with the IID data and different numbers of honest clients Khsubscriptğ¾â„K_{h} and malicious clients Kmsubscriptğ¾ğ‘šK_{m}. When the number of honest clients is higher than the number of malicious clients (i.e., [Kh=10subscriptğ¾â„10K_{h}=10 and Km=0subscriptğ¾ğ‘š0K_{m}=0], [Kh=7subscriptğ¾â„7K_{h}=7 and Km=3subscriptğ¾ğ‘š3K_{m}=3]), we can observe that in each round, the accuracy results increases until it reaches 94.93% and 100% with multi-classification and binary classification, respectively. Therefore, when the number of honest clients is less than the number of malicious clients (i.e., Kh=3subscriptğ¾â„3K_{h}=3 and Km=7subscriptğ¾ğ‘š7K_{m}=7), we can observe that the accuracy results are affected in each round and give negative results until it reaches 85.98% with multi-classification.

-----------------------------------------

Table: 2404.09443:S4.T2
Caption: Table 2: Comparison of clustering algorithm in terms of accuracy for use in our federated learning algorithm.
References: We evaluated our proposed model in terms of clustering. Specifically, we introduced several clustering algorithms, including K-means [32], random clustering, and the proposed CRC, for use in our learning algorithm and compared their performance. For CRC, Î±ğ›¼\alpha was set to 0.7. Additionally, we assumed that features from feature extractors are shared and concatenated for K-means. The results are presented in Table 2. Here, â€˜baselineâ€™ refers to the average accuracy result across all clients. The table illustrates that only the proposed algorithm was able to improve performance compared to the average of clients. In terms of clustering algorithm comparison, the proposed CRC achieved the best performance, achieving 17.5% higher accuracy compared to K-means even though features and class label information are not shared among clients.

-----------------------------------------

Table: 2203.08176:S3.T3
Caption: TABLE III: Performance comparisons with other federated learning methods on several datasets
References: Table III demonstrates a comparison amongst our method and the most related studies investigating the effectiveness of federated learning frameworks for embedded edge intelligence. Here, we have classified these methods based on their objectives: personlized, label in server, label in user, and the model type. In order to be able to accurately compare our results with selected methods, we chose similar pre-processing steps. Most of these works focus on federated learning, where users collaborate to generate a global model. These methods are not performing well, having lower average Kappa or F1 scores (as seen in Table III). While SemiPFL use FCNN which is simpler and faster to train than the more complex architectures such as CNN and LSTM, it outperforms them all in terms of respective average F1 and Kappa values.  SemiPFL performs better than recent semi-personalized work [67, 39, 66, 33, 38, 31], and earlier federated learning methods [12, 37, 9]. It also has a more relaxed attribute regarding the need for labeled data on the user side.

-----------------------------------------
