Query: f1 and accuracy on CIFAR-10 classification

Table: 2405.04765:S5.T2
Caption: Table 2. Classification accuracy (%), consumed FLOPS and peak memory for CIFAR-10/100. 
References: Accuracy and FLOPs Analysis.
Table 2 shows the maximum accuracy and FLOPs for all federated pruning baselines under an extreme non-IID scenario where β=0.1𝛽0.1\beta=0.1. The training curves for CIFAR-10 are shown in Figure 1. Note that “NTK-Ori” represents the result on real data and “NTK-Rand” represents that on randomly generated data. We denote epoch as “ep” in tables. Since the time coefficient is required to implement PruneFL, we omit PruneFL for the ResNet-20 model as the source code of FedDST or PruneFL does not support the corresponding time coefficient.
The sparsity of all experiments is initialized to 80%percent8080\%.
We use the FLOPs to evaluate whether local devices suffer
from intensive computation overhead, thus showing the efficiency of the federated learning algorithm. Classification Accuracy Improvements.
Since the performance in Table 2 and Figure 1 show that 111 local epoch and “NTK-Rand” both maximize the global performance, we set the local training epoch as 111 and utilize “NTK-Rand” for the following experiments.
We denote the vanilla BP-Free method in (Feng et al., 2023) as Vanilla-BAFFLE and our method as NTK-BAFFLE. It is worth mentioning that the BP-Free training for FL is currently not competitive with the backpropagation-based FL as the estimated gradients are not as accurate as the true gradients. Therefore, we focus on how many improvements our method can achieve.
Table 3 displays the maximum accuracy comparison between NTK-BAFFLE and Vanilla-BAFFLE on the CIFAR-10 dataset with a sparsity of 90%percent9090\%. Note that the number of local training epochs is set to 1. For experiments on the two datasets, the NTK-BAFFLE consistently outperforms the vanilla BAFFLE regarding classification accuracy. For instance, the maximum accuracy is boosted by 4.62%percent4.624.62\%, 6.35%percent6.356.35\%, and 3.8%percent3.83.8\% on LeNet when setting K𝐾K to 50, 100, and 200, respectively. Figure 2 shows the learning curve against communication rounds given different values of K𝐾K. It’s clear that NTK-BAFFLE performs better than the Vanilla-BAFFLE method on various settings of K𝐾K.
Figure 3 presents the learning curves from the perspective of accuracy versus FLOPs. The first row shows the results on LeNet, and the second row shows that on ResNet-20.

-----------------------------------------

Table: 2409.06067:S3.T2
Caption: Table 2. Top-1 classification accuracy(%) on CIFAR-10-LT and CIFAR-100-LT datasets with different FL methods, where th results are referred in (Shang et al., 2022; Shi et al., 2023). The best results are marked in bold.
References: Results for CIFAR-10/100-LT are presented in Table 2, where we evaluate the performance of our CLIP2FL against a range of FL approaches on both CIFAR-10-LT and CIFAR-100-LT datasets. Notably, MLLM-FL outperforms other methods in terms of classification accuracy on both datasets. Specifically, at an Imbalance Factor (IF) of 100, which presents a severe imbalance, MLLM shows an improvement of 2.12% and 1.94% in classification accuracy over CLIP2FL for CIFAR-10-LT and CIFAR-100-LT, respectively. Under the condition of IF = 50 or 10, MLLM still manages to enhance performance by around 1%. This underscores MLLM-FL’s effectiveness and its outperforms over competing methods to deal with heterogeous and long-tailed distributions.

-----------------------------------------

Table: 2302.00903:S5.T9
Caption: TABLE IX: Investigation of heterogeneous class distribution ({40%,50%,60%}percent40percent50percent60\{40\%,50\%,60\%\}) in terms of accuracy and F1 score on CIFAR-100 [23] when setting T=10𝑇10T=10. 
References: In order to discuss how heterogeneous class distribution across local clients affects performance, as presented in Table IX, we conduct extensive experiments in terms of accuracy and F1 score on CIFAR-100 dataset [23]. Specifically, we consider different settings of data heterogeneity via randomly assigning {40%,50%,60%}percent40percent50percent60\{40\%,50\%,60\%\} categories from the label space of current learning task to local clients. From Table IX, we conclude that the proposed LGA model achieves significant performance improvement about 3.6%∼6.6%similar-topercent3.6percent6.63.6\%\sim 6.6\% in terms of averaged accuracy and F1 score under different settings of heterogeneous class distributions across local clients, when compared with our conference version (i.e., GLFC [10]). It validates the effectiveness of our model to tackle local and global forgetting on old categories brought by heterogeneous class imbalance across local clients. Although the increase of data heterogeneity at local side degrades the performance of proposed model, our LGA model still achieves better performance to tackle large data heterogeneity brought by Non-IID class imbalance across local clients when compared with GLFC [10]. Table IX also illustrates superiority and effectiveness of the ameliorated proxy server to tackle global catastrophic forgetting on old categories.

-----------------------------------------

Table: 2405.06413:S4.T6
Caption: TABLE VI: Ablation study on three classification datasets Fasion-MNIST, CIFAR-10, and CIFAR-100 with I​F=10,α=0.5formulae-sequence𝐼𝐹10𝛼0.5IF=10,\alpha=0.5. 
References: Our ablation studies for MuPFL meticulously evaluate the individual and combined effects of BAVD, ACMU, and PKCF on classification tasks. As shown in  table   VI , each module independently improves CIFAR-10 accuracy by upwards of 10%. The combined use of ACMU and BAVD contributes to an additional 4% increase in CIFAR-100 accuracy by leveraging activation maps to discern crucial feature patterns. The integration of PKCF builds on this foundation, further elevating CIFAR-100 accuracy by more than 6%, highlighting the compound efficacy of these components in our framework. The advantages of adaptive clustering over predetermined cluster counts are underscored in  table   V . Training with a static number of clusters leads to subpar results across various models with 90.46% on FashionMNIST when  κ = 4 𝜅 4 \kappa=4  and  α = 0.5 𝛼 0.5 \alpha=0.5 , whereas adaptive clustering surpasses these by margins reaching 2.67%, validating the approach of customizing cluster sizes to the nuances of local model features for enhanced performance and underscoring the efficacy of ACMU across various classification datasets and different non-i.i.d scenarios.

-----------------------------------------

Table: 2305.00771:S4.T4
Caption: Table 4: Analysis of Loss function: classification accuracy on CINIC-10 (the number of clients: 10). 
References: First, we compare our proposed FedoSSL methods with the baseline methods over three benchmark datasets.
The classification accuracy on CIFAR-10, CIFAR-100 and CININ-10 dataset are listed in Table  LABEL:tab:small_fl .
It should be noted that the overall unseen accuracy (AU.) is not always a weighted average of locally unseen accuracy (LU.) and globally unseen accuracy (GU.). Because sometimes most samples of a locally unseen class and most samples of a globally unseen class will be classified in the same label, in this case, when calculating overall unseen accuracy, we have to choose another label (i.e., with the second largest number of samples) for one of those two classes. From the results, it can be observed that our proposed FedoSSL provides superior performance of overall classification accuracy than baselines and the locally trained versions (i.e., Local-O, Local-N) over all three datasets. In most cases, FedoSSL maintains robust performance on seen classes and locally unseen classes. On globally unseen classes and overall unseen classes, FedoSSL achieves remarkable performance gains. For example, for globally unseen classes, FedoSSL outperforms the best baselines by 11.72% on CIFAR-10, 11.10% on CIFAR-100 and 13.52% on CINIC-10. For overall unseen classes, FedoSSL outperforms the best baselines by 14.76% on CIFAR-10 and 15.07% on CINIC-10.
Moreover, we prove that the performance gap between locally and globally unseen classes on FedoSSL has significantly reduced when compared with other methods, i.e., there is a 47% gap between locally and globally unseen classes in Fed-AO, while FedoSSL reduces this gap to 31% on CIFAR-10.

-----------------------------------------

Table: 2110.10302:A1.T10
Caption: Table 10: 
(Non-IID data) CIFAR-100 classification results of FedLAMA with different ϕitalic-ϕ\phi settings.

References: In this section, we provide extra experimental results with extensive hyper-parameter settings.
We fix the number of clients to  128 128 128  and use a local batch size of  32 32 32  in all the experiments.
The gradual learning rate warm-up ( Goyal et al. [ 2017 ] ) is applied to the first 10 epochs.
Overall, the learning curve charts and the validation accuracy tables deliver the key insight that FedLAMA achieves a comparable convergence speed to the periodic full aggregation with the base interval ( τ 𝜏 \tau ’) while having the communication cost that is similar to the periodic full aggregation with the increased interval ( ϕ ​ τ ′ italic-ϕ superscript 𝜏 ′ \phi\tau^{\prime} ). Artificial Data Heterogeneity  – For CIFAR-10 and CIFAR-100, we artificially generate the heterogeneous data distribution using Dirichlet’s distribution.
The concentration coefficient  α 𝛼 \alpha  is set to  0.1 0.1 0.1 ,  0.5 0.5 0.5 , and  1.0 1.0 1.0  to evaluate the performance of FedLAMA across a variety of degree of data heterogeneity.
Note that the small concentration coefficient represents the highly heterogeneous numbers of local samples across clients as well as the balance of the samples across the labels.
We used the data distribution source code provided by FedML ( He et al. [ 2020 ] ). CIFAR-10  –
Figure  4  shows the full learning curves for IID and non-IID CIFAR-10 datasets.
The hyper-parameter settings correspond to Table  4  and  1 .
First, as the aggregation interval increases from  6 6 6  to  24 24 24 , FedAvg suffers from the slower convergence, and it results in achieving a lower validation accuracy, regardless of the data distribution.
In contrast, FedLAMA learning curves are marginally affected by the increased aggregation interval.
Table  6  and  7  show the CIFAR-10 classification performance of FedLAMA across different  ϕ italic-ϕ \phi  settings.
As expected, the accuracy is reduced as  ϕ italic-ϕ \phi  increases.
The IID and non-IID data settings show the common trend.
Depending on the system network bandwidth,  ϕ italic-ϕ \phi  can be tuned to be an appropriate value.
When  ϕ = 2 italic-ϕ 2 \phi=2 , the accuracy is almost the same as or even slightly higher than FedAvg accuracy.
If the network bandwidth is limited, one can increase  ϕ italic-ϕ \phi  and slightly increase the epoch budget to achieve a good accuracy.
Table  8  shows the CIFAR-10 accuracy across different  τ ′ superscript 𝜏 ′ \tau^{\prime}  settings.
We see that the accuracy is significantly dropped as  τ ′ superscript 𝜏 ′ \tau^{\prime}  increases. CIFAR-100  –
Figure  5  shows the learning curves for IID and non-IID CIFAR-100 datasets.
Likely to CIFAR-10 results, FedAvg learning curves are strongly affected as the aggregation interval increases from  6 6 6  to  24 24 24  while FedLAMA learning curves are not strongly affected.
Table  9  and  10  show the CIFAR-100 classification performance of FedLAMA across different  ϕ italic-ϕ \phi  settings.
FedLAMA achieves a comparable accuracy to FedAvg with a short aggregation interval, even when the degree of data heterogeneity is extreamly high ( 25 % percent 25 25\%  device sampling and Direchlet’s coefficient of  0.1 0.1 0.1 ).
Table  11  shows the FedAvg accuracy with different  τ ′ superscript 𝜏 ′ \tau^{\prime}  settings.
Under the strongly heterogeneous data distributions, FedAvg with a large aggregation interval ( τ ≥ 12 𝜏 12 \tau\geq 12 ) do not achieve a reasonable accuracy. FEMNIST  –
Figure  6  shows the learning curves of CNN training.
Likely to the previous two datasets, the periodic full aggregation suffers from the slower convergence as the aggregation interval increases.
FedLAMA learning curves are not much affected by the increased aggregation interval, and it results in achieving a higher validation accuracy after the same number of iterations.
Table  12  shows the FEMNIST classification performance of FedLAMA across different  ϕ italic-ϕ \phi  settings.
FedLAMA achieves a similar accuracy to the baseline (FedAvg with  τ ′ = 10 superscript 𝜏 ′ 10 \tau^{\prime}=10 ) even when using a large interval increase factor  ϕ ≥ 4 italic-ϕ 4 \phi\geq 4 .
These results demonstrate the effectiveness of the proposed layer-wise adaptive model aggregation method on the problems with heterogeneous data distributions.

-----------------------------------------

Table: 2110.10302:A1.T7
Caption: Table 7: 
(Non-IID data) CIFAR-10 classification results of FedLAMA with different ϕitalic-ϕ\phi settings.

References: In this section, we provide extra experimental results with extensive hyper-parameter settings.
We fix the number of clients to  128 128 128  and use a local batch size of  32 32 32  in all the experiments.
The gradual learning rate warm-up ( Goyal et al. [ 2017 ] ) is applied to the first 10 epochs.
Overall, the learning curve charts and the validation accuracy tables deliver the key insight that FedLAMA achieves a comparable convergence speed to the periodic full aggregation with the base interval ( τ 𝜏 \tau ’) while having the communication cost that is similar to the periodic full aggregation with the increased interval ( ϕ ​ τ ′ italic-ϕ superscript 𝜏 ′ \phi\tau^{\prime} ). Artificial Data Heterogeneity  – For CIFAR-10 and CIFAR-100, we artificially generate the heterogeneous data distribution using Dirichlet’s distribution.
The concentration coefficient  α 𝛼 \alpha  is set to  0.1 0.1 0.1 ,  0.5 0.5 0.5 , and  1.0 1.0 1.0  to evaluate the performance of FedLAMA across a variety of degree of data heterogeneity.
Note that the small concentration coefficient represents the highly heterogeneous numbers of local samples across clients as well as the balance of the samples across the labels.
We used the data distribution source code provided by FedML ( He et al. [ 2020 ] ). CIFAR-10  –
Figure  4  shows the full learning curves for IID and non-IID CIFAR-10 datasets.
The hyper-parameter settings correspond to Table  4  and  1 .
First, as the aggregation interval increases from  6 6 6  to  24 24 24 , FedAvg suffers from the slower convergence, and it results in achieving a lower validation accuracy, regardless of the data distribution.
In contrast, FedLAMA learning curves are marginally affected by the increased aggregation interval.
Table  6  and  7  show the CIFAR-10 classification performance of FedLAMA across different  ϕ italic-ϕ \phi  settings.
As expected, the accuracy is reduced as  ϕ italic-ϕ \phi  increases.
The IID and non-IID data settings show the common trend.
Depending on the system network bandwidth,  ϕ italic-ϕ \phi  can be tuned to be an appropriate value.
When  ϕ = 2 italic-ϕ 2 \phi=2 , the accuracy is almost the same as or even slightly higher than FedAvg accuracy.
If the network bandwidth is limited, one can increase  ϕ italic-ϕ \phi  and slightly increase the epoch budget to achieve a good accuracy.
Table  8  shows the CIFAR-10 accuracy across different  τ ′ superscript 𝜏 ′ \tau^{\prime}  settings.
We see that the accuracy is significantly dropped as  τ ′ superscript 𝜏 ′ \tau^{\prime}  increases. CIFAR-100  –
Figure  5  shows the learning curves for IID and non-IID CIFAR-100 datasets.
Likely to CIFAR-10 results, FedAvg learning curves are strongly affected as the aggregation interval increases from  6 6 6  to  24 24 24  while FedLAMA learning curves are not strongly affected.
Table  9  and  10  show the CIFAR-100 classification performance of FedLAMA across different  ϕ italic-ϕ \phi  settings.
FedLAMA achieves a comparable accuracy to FedAvg with a short aggregation interval, even when the degree of data heterogeneity is extreamly high ( 25 % percent 25 25\%  device sampling and Direchlet’s coefficient of  0.1 0.1 0.1 ).
Table  11  shows the FedAvg accuracy with different  τ ′ superscript 𝜏 ′ \tau^{\prime}  settings.
Under the strongly heterogeneous data distributions, FedAvg with a large aggregation interval ( τ ≥ 12 𝜏 12 \tau\geq 12 ) do not achieve a reasonable accuracy. FEMNIST  –
Figure  6  shows the learning curves of CNN training.
Likely to the previous two datasets, the periodic full aggregation suffers from the slower convergence as the aggregation interval increases.
FedLAMA learning curves are not much affected by the increased aggregation interval, and it results in achieving a higher validation accuracy after the same number of iterations.
Table  12  shows the FEMNIST classification performance of FedLAMA across different  ϕ italic-ϕ \phi  settings.
FedLAMA achieves a similar accuracy to the baseline (FedAvg with  τ ′ = 10 superscript 𝜏 ′ 10 \tau^{\prime}=10 ) even when using a large interval increase factor  ϕ ≥ 4 italic-ϕ 4 \phi\geq 4 .
These results demonstrate the effectiveness of the proposed layer-wise adaptive model aggregation method on the problems with heterogeneous data distributions.

-----------------------------------------

Table: 2110.10302:A1.T6
Caption: Table 6: 
(IID data) CIFAR-10 classification results of FedLAMA with different ϕitalic-ϕ\phi settings.

References: CIFAR-10 –
Figure 4 shows the full learning curves for IID and non-IID CIFAR-10 datasets.
The hyper-parameter settings correspond to Table 4 and 1.
First, as the aggregation interval increases from 666 to 242424, FedAvg suffers from the slower convergence, and it results in achieving a lower validation accuracy, regardless of the data distribution.
In contrast, FedLAMA learning curves are marginally affected by the increased aggregation interval.
Table 6 and 7 show the CIFAR-10 classification performance of FedLAMA across different ϕitalic-ϕ\phi settings.
As expected, the accuracy is reduced as ϕitalic-ϕ\phi increases.
The IID and non-IID data settings show the common trend.
Depending on the system network bandwidth, ϕitalic-ϕ\phi can be tuned to be an appropriate value.
When ϕ=2italic-ϕ2\phi=2, the accuracy is almost the same as or even slightly higher than FedAvg accuracy.
If the network bandwidth is limited, one can increase ϕitalic-ϕ\phi and slightly increase the epoch budget to achieve a good accuracy.
Table 8 shows the CIFAR-10 accuracy across different τ′superscript𝜏′\tau^{\prime} settings.
We see that the accuracy is significantly dropped as τ′superscript𝜏′\tau^{\prime} increases.

-----------------------------------------

Table: 2110.10302:S6.T1
Caption: Table 1: 
(IID data) CIFAR-10 classification results. The number of workers is 128 and the local batch size is 32 in all the experiments. The epoch budget is 300300300.

References: Experimental Results with IID Data –
We first present CIFAR-10 and CIFAR-100 classification results under IID data settings.
Table 1 and 2 show the CIFAR-10 and CIFAR-100 results, respectively.
Note that the learning rate is individually tuned for each setting using a grid search, and we report the best settings.
In both tables, the first row shows the performance of FedAvg with a short interval τ′=6superscript𝜏′6\tau^{\prime}=6.
As the interval increases, FedAvg significantly loses the accuracy while the communication cost is proportionally reduced.
FedLAMA achieves a comparable accuracy to FedAvg with τ′=6superscript𝜏′6\tau^{\prime}=6 while its communication cost is similar to that of FedAvg with ϕ​τ′italic-ϕsuperscript𝜏′\phi\tau^{\prime}.
These results demonstrate that Algorithm 2 effectively finds the layer-wise interval settings that maximize the communication cost reduction while minimizing the model discrepancy increase. CIFAR-100 –
Figure 5 shows the learning curves for IID and non-IID CIFAR-100 datasets.
Likely to CIFAR-10 results, FedAvg learning curves are strongly affected as the aggregation interval increases from 666 to 242424 while FedLAMA learning curves are not strongly affected.
Table 9 and 10 show the CIFAR-100 classification performance of FedLAMA across different ϕitalic-ϕ\phi settings.
FedLAMA achieves a comparable accuracy to FedAvg with a short aggregation interval, even when the degree of data heterogeneity is extreamly high (25%percent2525\% device sampling and Direchlet’s coefficient of 0.10.10.1).
Table 11 shows the FedAvg accuracy with different τ′superscript𝜏′\tau^{\prime} settings.
Under the strongly heterogeneous data distributions, FedAvg with a large aggregation interval (τ≥12𝜏12\tau\geq 12) do not achieve a reasonable accuracy. FEMNIST –
Figure 6 shows the learning curves of CNN training.
Likely to the previous two datasets, the periodic full aggregation suffers from the slower convergence as the aggregation interval increases.
FedLAMA learning curves are not much affected by the increased aggregation interval, and it results in achieving a higher validation accuracy after the same number of iterations.
Table 12 shows the FEMNIST classification performance of FedLAMA across different ϕitalic-ϕ\phi settings.
FedLAMA achieves a similar accuracy to the baseline (FedAvg with τ′=10superscript𝜏′10\tau^{\prime}=10) even when using a large interval increase factor ϕ≥4italic-ϕ4\phi\geq 4.
These results demonstrate the effectiveness of the proposed layer-wise adaptive model aggregation method on the problems with heterogeneous data distributions.

-----------------------------------------

Table: 2010.10030:S4.T1
Caption: TABLE I: CNN architecture for image classification on MNIST and CIFAR-10.
References: Here we evaluate the performance of the proposed analog FEEL algorithm with no CSI available at the wireless devices.
We are particularly interested in investigating the impact of the number of PS antennas on the performance.
We perform image classification on MNIST [44] and CIFAR-10 datasets [45] using ADAM optimizer [46].
We train different convolutional neural networks (CNNs) whose architectures are described in Table I.
The performance is measured as the accuracy with respect to the test dataset, known as the test accuracy, versus the global iteration count, t𝑡t. In Fig. 3, we illustrate the convergence rate of the proposed analog FEEL algorithm, presented in Corollary 1, for the setting considered in Fig. 2, i.e., training on CIFAR-10 with iid distributed local datasets, for K∈{M,2​M,5​M,10​M,2​M2}𝐾𝑀2𝑀5𝑀10𝑀2superscript𝑀2K\in\{M,2M,5M,10M,2M^{2}\}.
The CNN for training on CIFAR-10, whose architecture is provided in Table I, has d=307498𝑑307498d=307498 parameters, and we have M=20𝑀20M=20 and σz2=σh2=1superscriptsubscript𝜎𝑧2superscriptsubscript𝜎ℎ21\sigma_{z}^{2}=\sigma_{h}^{2}=1.
We set μ=1𝜇1\mu=1, L=5𝐿5L=5, G2=Γ=1superscript𝐺2Γ1G^{2}=\Gamma=1, ‖𝜽​(0)−𝜽∗‖22=103superscriptsubscriptnorm𝜽0superscript𝜽22superscript103\left\|\boldsymbol{\theta}(0)-\boldsymbol{\theta}^{*}\right\|_{2}^{2}=10^{3}.
We consider a decreasing learning rate η​(t)=1μ​τ​(10−4​t+1)𝜂𝑡1𝜇𝜏superscript104𝑡1\eta(t)=\frac{1}{\mu\tau(10^{-4}t+1)}, and αt=1+10−3​tsubscript𝛼𝑡1superscript103𝑡\alpha_{t}=1+10^{-3}t, t∈[T]𝑡delimited-[]𝑇t\in[T].
We also consider the convergence rate of the error-free shared link scenario given as follows:

-----------------------------------------
