{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_claims(file_path):\n",
    "    \"\"\"Parses the claims file and extracts specifications, metrics, and values.\"\"\"\n",
    "    claims = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            match = re.match(r'Claim \\d+: \\|\\{(.*?)\\}, (.*?), (.*?)\\|', line)\n",
    "            if match:\n",
    "                specifications_raw, metric, value = match.groups()\n",
    "                specifications = re.findall(r'\\|([^|]+), ([^|]+)\\|', specifications_raw)\n",
    "                claims.append({\n",
    "                    'specifications': {k.strip().lower(): v.strip() for k, v in specifications},\n",
    "                    'metric': metric.strip(),\n",
    "                    'value': value.strip()\n",
    "                })\n",
    "            else:\n",
    "                print(f'Warning: could not parse line \"{line.strip()}\" in {file_path}')\n",
    "    return claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_claims(claims):\n",
    "    \"\"\"Profiles the claims data and computes distributions.\"\"\"\n",
    "    name_distribution = defaultdict(int)\n",
    "    value_distribution = defaultdict(lambda: defaultdict(int))\n",
    "    metric_distribution = defaultdict(int)\n",
    "\n",
    "    for claim in claims:\n",
    "        for name, value in claim['specifications'].items():\n",
    "            name_distribution[name] += 1\n",
    "            value_distribution[name][value] += 1\n",
    "        metric_distribution[claim['metric']] += 1\n",
    "\n",
    "    return name_distribution, value_distribution, metric_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_profiling_to_csv_and_log(name_distribution, value_distribution, metric_distribution, output_filename):\n",
    "    \"\"\"Saves the profiling results and log to a CSV.\"\"\"\n",
    "    with open(output_filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write distributions of 'name'\n",
    "        writer.writerow(['Distributions of name in specifications'])\n",
    "        writer.writerow(['Name', 'Occurences'])\n",
    "        for name, count in sorted(name_distribution.items()):\n",
    "            writer.writerow([name, count])\n",
    "\n",
    "        # Write distributions of 'values'\n",
    "        writer.writerow([])  # Blank row for separation\n",
    "        writer.writerow(['Distributions of values for each name of each specification'])\n",
    "        writer.writerow(['Name', 'Value', 'Occurrences'])\n",
    "        for name, values in sorted(value_distribution.items()):\n",
    "            for value, occurrences in values.items():\n",
    "                writer.writerow([name, value, occurrences])\n",
    "\n",
    "        # Write distributions of metrics\n",
    "        writer.writerow([])  # Blank row for separation\n",
    "        writer.writerow(['Distributions of metrics'])\n",
    "        writer.writerow(['Metric', 'Occurences'])\n",
    "        for metric, count in sorted(metric_distribution.items()):\n",
    "            writer.writerow([metric, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling results saved to consegna/profilings/ground_truth.csv\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'ground_truth'\n",
    "output_file = 'consegna/profilings/ground_truth.csv'\n",
    "\n",
    "# Parse claims\n",
    "claims = []\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_file = os.path.join(input_dir, filename)\n",
    "    claims.append(parse_claims(input_file))\n",
    "\n",
    "claims = [claim for sublist in claims for claim in sublist]\n",
    "\n",
    "# Profile claims\n",
    "name_distribution, value_distribution, metric_distribution = profile_claims(claims)\n",
    "\n",
    "save_profiling_to_csv_and_log(name_distribution, value_distribution, metric_distribution, output_file)\n",
    "print(f\"Profiling results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
