{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def parse_claims(claims):\n",
    "    \"\"\"\n",
    "    Estrai specifiche, nomi e metriche dalle claim.\n",
    "    \"\"\"\n",
    "    specifications = []\n",
    "    names = []\n",
    "    metrics = []\n",
    "\n",
    "    for claim in claims:\n",
    "        # Match the pattern |{Specification, Name} Metric: Value|\n",
    "        match = re.match(r\"claim \\d+\\|\\{([^,]+), ([^}]+)\\} ([^:]+): (.+)\\|\", claim)\n",
    "        if match:\n",
    "            specification, name, metric, value = match.groups()\n",
    "            specifications.append(specification)\n",
    "            names.append(name)\n",
    "            metrics.append(metric)\n",
    "\n",
    "    return specifications, names, metrics\n",
    "\n",
    "def create_profiling(specifications, names, metrics, filename):\n",
    "    \"\"\"\n",
    "    Crea il profiling delle distribuzioni e salva i risultati in un CSV.\n",
    "    \"\"\"\n",
    "    # Conta le distribuzioni\n",
    "    spec_distribution = Counter(specifications)\n",
    "    name_distribution = Counter(names)\n",
    "    metric_distribution = Counter(metrics)\n",
    "\n",
    "    # Crea un dataframe per salvare i risultati\n",
    "    profiling_data = []\n",
    "\n",
    "    # Aggiungi specifiche al profiling\n",
    "    for spec, count in spec_distribution.items():\n",
    "        profiling_data.append({\"Key\": f\"Specification: {spec}\", \"Count\": count})\n",
    "\n",
    "    # Aggiungi nomi al profiling\n",
    "    for name, count in name_distribution.items():\n",
    "        profiling_data.append({\"Key\": f\"Name: {name}\", \"Count\": count})\n",
    "\n",
    "    # Aggiungi metriche al profiling\n",
    "    for metric, count in metric_distribution.items():\n",
    "        profiling_data.append({\"Key\": f\"Metric: {metric}\", \"Count\": count})\n",
    "\n",
    "    # Crea un DataFrame\n",
    "    profiling_df = pd.DataFrame(profiling_data)\n",
    "\n",
    "    # Salva i risultati in un file CSV\n",
    "    profiling_df.to_csv(filename, index=False)\n",
    "\n",
    "    return spec_distribution, name_distribution, metric_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuzione delle Specifiche:\n",
      "Models: 30\n",
      "Discriminators: 42\n",
      "\n",
      "Distribuzione dei Nomi:\n",
      "EXALT Baseline: 3\n",
      "ZSEC-gpt4turbo: 3\n",
      "ZSEC-gpt4o: 3\n",
      "MBCAWF: 3\n",
      "MIAWF-3444built on ZSEC-gpt4o and Ensemble-9: 3\n",
      "MIAWF-5555built on MIAWF-4 (which is built on MIAWF-3 and Ensemble-8) and Ensemble-8: 3\n",
      "Ensemble-9666Ensemble of 9 models (see Table3in AppendixB): 3\n",
      "Ensemble-8777Ensemble of 8 models (see Table3in AppendixB): 3\n",
      "Ensemble-17888Ensemble of 17 models (see Table3in AppendixB): 3\n",
      "Ensemble-19999Ensemble of 19 models (see Table3in AppendixB): 3\n",
      "CodeLlama-13B: 6\n",
      "GPT-3.5-Turbo: 6\n",
      "CodeLlama-13B-FT: 6\n",
      "CodeLlama-13BE: 6\n",
      "GPT-3.5-TurboE: 6\n",
      "CodeLlama-13B-FTE: 6\n",
      "Oracle Simulation (œÑ=1.0ùúè1.0\\tau=1.0): 6\n",
      "\n",
      "Distribuzione delle Metriche:\n",
      "F1-score: 10\n",
      "Precision: 10\n",
      "Recall: 10\n",
      "Spider (Greedy Gen = 62.3) Re-ranking: 7\n",
      "Spider (Greedy Gen = 62.3) Iter. Correct.: 7\n",
      "Spider (Greedy Gen = 62.3) Tree Search: 7\n",
      "Bird (Greedy Gen = 16.0) Re-ranking: 7\n",
      "Bird (Greedy Gen = 16.0) Iter. Correct.: 7\n",
      "Bird (Greedy Gen = 16.0) Tree Search: 7\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Leggi le claim dal file claims_test.txt\n",
    "    with open('claims_test.txt', 'r') as file:\n",
    "        claims = file.readlines()\n",
    "\n",
    "    # Estrai le informazioni dalle claim\n",
    "    specifications, names, metrics = parse_claims(claims)\n",
    "\n",
    "    # Nome del file CSV\n",
    "    filename = \"NAME_PROFILING.csv\"\n",
    "\n",
    "    # Crea il profiling e ottieni le distribuzioni\n",
    "    spec_distribution, name_distribution, metric_distribution = create_profiling(specifications, names, metrics, filename)\n",
    "\n",
    "    # Stampa le distribuzioni\n",
    "    print(\"Distribuzione delle Specifiche:\")\n",
    "    for spec, count in spec_distribution.items():\n",
    "        print(f\"{spec}: {count}\")\n",
    "\n",
    "    print(\"\\nDistribuzione dei Nomi:\")\n",
    "    for name, count in name_distribution.items():\n",
    "        print(f\"{name}: {count}\")\n",
    "\n",
    "    print(\"\\nDistribuzione delle Metriche:\")\n",
    "    for metric, count in metric_distribution.items():\n",
    "        print(f\"{metric}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
