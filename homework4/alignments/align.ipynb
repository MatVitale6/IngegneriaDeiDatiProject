{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PROFILING_DIR = '../consegna/profilings/GPT-4o'\n",
    "INPUT_DIR = '../consegna/LLMAGENTS_CLAIMS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load profilings csv into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22136\\772492641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvalue_profilings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPROFILING_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VALUE_PROFILING.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvalue_profilings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_profilings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_profilings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "value_profilings = pd.read_csv(os.path.join(PROFILING_DIR, 'VALUE_PROFILING.csv'))\n",
    "value_profilings = value_profilings.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "print(value_profilings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load claim and convert it to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_as_df(filename):\n",
    "    with open(os.path.join(INPUT_DIR, filename), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    rows = []\n",
    "    for key, entry in json_data.items():\n",
    "        row = {}\n",
    "        row['claim_id'] = key\n",
    "        # Extract specifications\n",
    "        for spec_key, spec in entry[\"specifications\"].items():\n",
    "            row[spec[\"name\"]] = spec[\"value\"]\n",
    "        # Add measure and outcome\n",
    "        row[\"Measure\"] = entry[\"Measure\"]\n",
    "        row[\"Outcome\"] = entry[\"Outcome\"]\n",
    "        rows.append(row)\n",
    "    claim_df = pd.DataFrame(rows)\n",
    "    filename = filename.replace(\"_claims.json\",\"\")\n",
    "    claim_df['paper_id'] = filename.split('_')[0]\n",
    "    claim_df['table_id'] = filename.split('_')[1]\n",
    "    return claim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reassign values in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   claim_id     Model Name Setting     Task     Measure Outcome    paper_id  \\\n",
      "0         0  GPT-3.5-turbo    Zero  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "1         1  GPT-3.5-turbo     Few  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "2         2       Claude-2    Zero  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "3         3       Claude-2     Few  OpenAGI  CLIP Score  0.2543  2304.04370   \n",
      "4         4          GPT-4    Zero  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "5         5          GPT-4     Few  OpenAGI  CLIP Score  0.3055  2304.04370   \n",
      "6         6  GPT-3.5-turbo    Zero  OpenAGI  BERT Score  0.1914  2304.04370   \n",
      "7         7  GPT-3.5-turbo     Few  OpenAGI  BERT Score   0.382  2304.04370   \n",
      "8         8       Claude-2    Zero  OpenAGI  BERT Score  0.2111  2304.04370   \n",
      "9         9       Claude-2     Few  OpenAGI  BERT Score  0.5038  2304.04370   \n",
      "10       10          GPT-4    Zero  OpenAGI  BERT Score  0.2076  2304.04370   \n",
      "11       11          GPT-4     Few  OpenAGI  BERT Score  0.6307  2304.04370   \n",
      "12       12  GPT-3.5-turbo    Zero  OpenAGI   ViT Score  0.2437  2304.04370   \n",
      "13       13  GPT-3.5-turbo     Few  OpenAGI   ViT Score  0.7497  2304.04370   \n",
      "14       14       Claude-2    Zero  OpenAGI   ViT Score  0.4082  2304.04370   \n",
      "15       15       Claude-2     Few  OpenAGI   ViT Score  0.5416  2304.04370   \n",
      "16       16          GPT-4    Zero  OpenAGI   ViT Score  0.5058  2304.04370   \n",
      "17       17          GPT-4     Few  OpenAGI   ViT Score   0.648  2304.04370   \n",
      "18       18  GPT-3.5-turbo    Zero  OpenAGI     Overall   0.145  2304.04370   \n",
      "19       19  GPT-3.5-turbo     Few  OpenAGI     Overall  0.3772  2304.04370   \n",
      "20       20       Claude-2    Zero  OpenAGI     Overall  0.2064  2304.04370   \n",
      "21       21       Claude-2     Few  OpenAGI     Overall  0.4332  2304.04370   \n",
      "22       22          GPT-4    Zero  OpenAGI     Overall  0.2378  2304.04370   \n",
      "23       23          GPT-4     Few  OpenAGI     Overall  0.5281  2304.04370   \n",
      "\n",
      "   table_id  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "5         1  \n",
      "6         1  \n",
      "7         1  \n",
      "8         1  \n",
      "9         1  \n",
      "10        1  \n",
      "11        1  \n",
      "12        1  \n",
      "13        1  \n",
      "14        1  \n",
      "15        1  \n",
      "16        1  \n",
      "17        1  \n",
      "18        1  \n",
      "19        1  \n",
      "20        1  \n",
      "21        1  \n",
      "22        1  \n",
      "23        1  \n",
      "   claim_id     Model Name      Setting     Task     Measure Outcome  \\\n",
      "0         0  Flan-T5-Large         Zero  OpenAGI  CLIP Score     0.0   \n",
      "1         1  Flan-T5-Large          Few  OpenAGI  CLIP Score     0.0   \n",
      "2         2  Flan-T5-Large  Fine-tuning  OpenAGI  CLIP Score     0.0   \n",
      "3         3  Flan-T5-Large         RLTF  OpenAGI  CLIP Score     0.0   \n",
      "4         4      Vicuna-7B         Zero  OpenAGI  CLIP Score     0.0   \n",
      "5         5      Vicuna-7B          Few  OpenAGI  CLIP Score     0.0   \n",
      "6         6      Vicuna-7B  Fine-tuning  OpenAGI  CLIP Score     0.0   \n",
      "7         7      Vicuna-7B         RLTF  OpenAGI  CLIP Score     0.0   \n",
      "8         8    LLaMA-2-13B         Zero  OpenAGI  CLIP Score     0.0   \n",
      "9         9    LLaMA-2-13B          Few  OpenAGI  CLIP Score  0.0612   \n",
      "10       10    LLaMA-2-13B  Fine-tuning  OpenAGI  CLIP Score  0.0608   \n",
      "11       11    LLaMA-2-13B         RLTF  OpenAGI  CLIP Score   0.122   \n",
      "12       12  Flan-T5-Large         Zero  OpenAGI  BERT Score     0.0   \n",
      "13       13  Flan-T5-Large          Few  OpenAGI  BERT Score  0.2488   \n",
      "14       14  Flan-T5-Large  Fine-tuning  OpenAGI  BERT Score     0.0   \n",
      "15       15  Flan-T5-Large         RLTF  OpenAGI  BERT Score  0.0655   \n",
      "16       16      Vicuna-7B         Zero  OpenAGI  BERT Score  0.0513   \n",
      "17       17      Vicuna-7B          Few  OpenAGI  BERT Score     0.0   \n",
      "18       18      Vicuna-7B  Fine-tuning  OpenAGI  BERT Score  0.1212   \n",
      "19       19      Vicuna-7B         RLTF  OpenAGI  BERT Score  0.1756   \n",
      "20       20    LLaMA-2-13B         Zero  OpenAGI  BERT Score  0.0986   \n",
      "21       21    LLaMA-2-13B          Few  OpenAGI  BERT Score  0.2281   \n",
      "22       22    LLaMA-2-13B  Fine-tuning  OpenAGI  BERT Score   0.157   \n",
      "23       23    LLaMA-2-13B         RLTF  OpenAGI  BERT Score  0.2401   \n",
      "24       24  Flan-T5-Large         Zero  OpenAGI   ViT Score     0.0   \n",
      "25       25  Flan-T5-Large          Few  OpenAGI   ViT Score     0.0   \n",
      "26       26  Flan-T5-Large  Fine-tuning  OpenAGI   ViT Score  0.6316   \n",
      "27       27  Flan-T5-Large         RLTF  OpenAGI   ViT Score  0.6978   \n",
      "28       28      Vicuna-7B         Zero  OpenAGI   ViT Score  0.1704   \n",
      "29       29      Vicuna-7B          Few  OpenAGI   ViT Score  0.4285   \n",
      "30       30      Vicuna-7B  Fine-tuning  OpenAGI   ViT Score  0.5507   \n",
      "31       31      Vicuna-7B         RLTF  OpenAGI   ViT Score    0.73   \n",
      "32       32    LLaMA-2-13B         Zero  OpenAGI   ViT Score  0.3614   \n",
      "33       33    LLaMA-2-13B          Few  OpenAGI   ViT Score  0.2558   \n",
      "34       34    LLaMA-2-13B  Fine-tuning  OpenAGI   ViT Score  0.6723   \n",
      "35       35    LLaMA-2-13B         RLTF  OpenAGI   ViT Score  0.7584   \n",
      "36       36  Flan-T5-Large         Zero  OpenAGI     Overall     0.0   \n",
      "37       37  Flan-T5-Large          Few  OpenAGI     Overall  0.0829   \n",
      "38       38  Flan-T5-Large  Fine-tuning  OpenAGI     Overall  0.2105   \n",
      "39       39  Flan-T5-Large         RLTF  OpenAGI     Overall  0.2544   \n",
      "40       40      Vicuna-7B         Zero  OpenAGI     Overall  0.0739   \n",
      "41       41      Vicuna-7B          Few  OpenAGI     Overall  0.1428   \n",
      "42       42      Vicuna-7B  Fine-tuning  OpenAGI     Overall  0.2239   \n",
      "43       43      Vicuna-7B         RLTF  OpenAGI     Overall  0.3018   \n",
      "44       44    LLaMA-2-13B         Zero  OpenAGI     Overall  0.1533   \n",
      "45       45    LLaMA-2-13B          Few  OpenAGI     Overall  0.1817   \n",
      "46       46    LLaMA-2-13B  Fine-tuning  OpenAGI     Overall  0.2967   \n",
      "47       47    LLaMA-2-13B         RLTF  OpenAGI     Overall  0.3735   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2304.04370        2  \n",
      "1   2304.04370        2  \n",
      "2   2304.04370        2  \n",
      "3   2304.04370        2  \n",
      "4   2304.04370        2  \n",
      "5   2304.04370        2  \n",
      "6   2304.04370        2  \n",
      "7   2304.04370        2  \n",
      "8   2304.04370        2  \n",
      "9   2304.04370        2  \n",
      "10  2304.04370        2  \n",
      "11  2304.04370        2  \n",
      "12  2304.04370        2  \n",
      "13  2304.04370        2  \n",
      "14  2304.04370        2  \n",
      "15  2304.04370        2  \n",
      "16  2304.04370        2  \n",
      "17  2304.04370        2  \n",
      "18  2304.04370        2  \n",
      "19  2304.04370        2  \n",
      "20  2304.04370        2  \n",
      "21  2304.04370        2  \n",
      "22  2304.04370        2  \n",
      "23  2304.04370        2  \n",
      "24  2304.04370        2  \n",
      "25  2304.04370        2  \n",
      "26  2304.04370        2  \n",
      "27  2304.04370        2  \n",
      "28  2304.04370        2  \n",
      "29  2304.04370        2  \n",
      "30  2304.04370        2  \n",
      "31  2304.04370        2  \n",
      "32  2304.04370        2  \n",
      "33  2304.04370        2  \n",
      "34  2304.04370        2  \n",
      "35  2304.04370        2  \n",
      "36  2304.04370        2  \n",
      "37  2304.04370        2  \n",
      "38  2304.04370        2  \n",
      "39  2304.04370        2  \n",
      "40  2304.04370        2  \n",
      "41  2304.04370        2  \n",
      "42  2304.04370        2  \n",
      "43  2304.04370        2  \n",
      "44  2304.04370        2  \n",
      "45  2304.04370        2  \n",
      "46  2304.04370        2  \n",
      "47  2304.04370        2  \n",
      "   claim_id          Model    Prompt                                Task  \\\n",
      "0         0  GPT-3.5-turbo  Prompt-1  zero-shot task-solving performance   \n",
      "1         1  GPT-3.5-turbo  Prompt-1  zero-shot task-solving performance   \n",
      "2         2  GPT-3.5-turbo  Prompt-2  zero-shot task-solving performance   \n",
      "3         3  GPT-3.5-turbo  Prompt-2  zero-shot task-solving performance   \n",
      "4         4  GPT-3.5-turbo  Prompt-2  zero-shot task-solving performance   \n",
      "..      ...            ...       ...                                 ...   \n",
      "63       63          GPT-4  Prompt-1  zero-shot task-solving performance   \n",
      "64       64          GPT-4  Prompt-1  zero-shot task-solving performance   \n",
      "65       65          GPT-4  Prompt-2  zero-shot task-solving performance   \n",
      "66       66          GPT-4  Prompt-2  zero-shot task-solving performance   \n",
      "67       67          GPT-4  Prompt-2  zero-shot task-solving performance   \n",
      "\n",
      "       Measure Outcome    paper_id table_id  \n",
      "0   CLIP Score  0.2106  2304.04370        3  \n",
      "1   CLIP Score  0.0702  2304.04370        3  \n",
      "2   CLIP Score  0.3013  2304.04370        3  \n",
      "3   CLIP Score   0.271  2304.04370        3  \n",
      "4   CLIP Score  0.1907  2304.04370        3  \n",
      "..         ...     ...         ...      ...  \n",
      "63     Overall  0.5497  2304.04370        3  \n",
      "64     Overall  0.3299  2304.04370        3  \n",
      "65     Overall  0.5595  2304.04370        3  \n",
      "66     Overall  0.5565  2304.04370        3  \n",
      "67     Overall  0.3717  2304.04370        3  \n",
      "\n",
      "[68 rows x 8 columns]\n",
      "  claim_id      Model    Dataset                               Task  \\\n",
      "0        0        CoT  ToolBench  solution ranking on complex tasks   \n",
      "1        1      CoT@3  ToolBench  solution ranking on complex tasks   \n",
      "2        2  Reflexion  ToolBench  solution ranking on complex tasks   \n",
      "3        3        BFS  ToolBench  solution ranking on complex tasks   \n",
      "4        4        DFS  ToolBench  solution ranking on complex tasks   \n",
      "5        5      DFSDT  ToolBench  solution ranking on complex tasks   \n",
      "6        6   RaDAgent  ToolBench  solution ranking on complex tasks   \n",
      "\n",
      "         Measure Outcome    paper_id table_id  \n",
      "0  Pass Rate (%)    16.6  2308.12519        1  \n",
      "1  Pass Rate (%)    31.2  2308.12519        1  \n",
      "2  Pass Rate (%)    26.6  2308.12519        1  \n",
      "3  Pass Rate (%)    38.0  2308.12519        1  \n",
      "4  Pass Rate (%)   45.58  2308.12519        1  \n",
      "5  Pass Rate (%)    50.2  2308.12519        1  \n",
      "6  Pass Rate (%)   61.92  2308.12519        1  \n",
      "  claim_id         Model    Dataset                               Task  \\\n",
      "0        0         CoT@3  ToolBench  solution ranking on complex tasks   \n",
      "1        1     Reflexion  ToolBench  solution ranking on complex tasks   \n",
      "2        2           BFS  ToolBench  solution ranking on complex tasks   \n",
      "3        3         DFSDT  ToolBench  solution ranking on complex tasks   \n",
      "4        4      RaDAgent  ToolBench  solution ranking on complex tasks   \n",
      "5        5  Rand. Select  ToolBench  solution ranking on complex tasks   \n",
      "6        6    Elo Select  ToolBench  solution ranking on complex tasks   \n",
      "\n",
      "      Measure Outcome    paper_id table_id  \n",
      "0  Pref. Rank    3.45  2308.12519        2  \n",
      "1  Pref. Rank    3.48  2308.12519        2  \n",
      "2  Pref. Rank    3.25  2308.12519        2  \n",
      "3  Pref. Rank    2.91  2308.12519        2  \n",
      "4  Pref. Rank     N/A  2308.12519        2  \n",
      "5  Pref. Rank    3.24  2308.12519        2  \n",
      "6  Pref. Rank    2.19  2308.12519        2  \n",
      "   claim_id    Method    Dataset  \\\n",
      "0         0     CoT@3  ToolBench   \n",
      "1         1     CoT@3  ToolBench   \n",
      "2         2     CoT@3  ToolBench   \n",
      "3         3     CoT@3  ToolBench   \n",
      "4         4     CoT@3  ToolBench   \n",
      "5         5     CoT@3  ToolBench   \n",
      "6         6       BFS  ToolBench   \n",
      "7         7       BFS  ToolBench   \n",
      "8         8       BFS  ToolBench   \n",
      "9         9       BFS  ToolBench   \n",
      "10       10       BFS  ToolBench   \n",
      "11       11       BFS  ToolBench   \n",
      "12       12     DFSDT  ToolBench   \n",
      "13       13     DFSDT  ToolBench   \n",
      "14       14     DFSDT  ToolBench   \n",
      "15       15     DFSDT  ToolBench   \n",
      "16       16     DFSDT  ToolBench   \n",
      "17       17     DFSDT  ToolBench   \n",
      "18       18  RaDAgent  ToolBench   \n",
      "19       19  RaDAgent  ToolBench   \n",
      "20       20  RaDAgent  ToolBench   \n",
      "21       21  RaDAgent  ToolBench   \n",
      "22       22  RaDAgent  ToolBench   \n",
      "23       23  RaDAgent  ToolBench   \n",
      "\n",
      "                                                 Task  \\\n",
      "0   analyzing common failure reasons in decision-m...   \n",
      "1   analyzing common failure reasons in decision-m...   \n",
      "2   analyzing common failure reasons in decision-m...   \n",
      "3   analyzing common failure reasons in decision-m...   \n",
      "4   analyzing common failure reasons in decision-m...   \n",
      "5   analyzing common failure reasons in decision-m...   \n",
      "6   analyzing common failure reasons in decision-m...   \n",
      "7   analyzing common failure reasons in decision-m...   \n",
      "8   analyzing common failure reasons in decision-m...   \n",
      "9   analyzing common failure reasons in decision-m...   \n",
      "10  analyzing common failure reasons in decision-m...   \n",
      "11  analyzing common failure reasons in decision-m...   \n",
      "12  analyzing common failure reasons in decision-m...   \n",
      "13  analyzing common failure reasons in decision-m...   \n",
      "14  analyzing common failure reasons in decision-m...   \n",
      "15  analyzing common failure reasons in decision-m...   \n",
      "16  analyzing common failure reasons in decision-m...   \n",
      "17  analyzing common failure reasons in decision-m...   \n",
      "18  analyzing common failure reasons in decision-m...   \n",
      "19  analyzing common failure reasons in decision-m...   \n",
      "20  analyzing common failure reasons in decision-m...   \n",
      "21  analyzing common failure reasons in decision-m...   \n",
      "22  analyzing common failure reasons in decision-m...   \n",
      "23  analyzing common failure reasons in decision-m...   \n",
      "\n",
      "                        Measure Outcome    paper_id table_id  \n",
      "0       Hallucinated Tool Ratio    14.2  2308.12519        3  \n",
      "1   Hallucinated Tool Fix Ratio    25.4  2308.12519        3  \n",
      "2         Tool Call Error Ratio    41.2  2308.12519        3  \n",
      "3     Tool Call Error Fix Ratio    14.8  2308.12519        3  \n",
      "4              Unavailable Tool     2.0  2308.12519        3  \n",
      "5              Decision Failure    52.5  2308.12519        3  \n",
      "6       Hallucinated Tool Ratio    18.8  2308.12519        3  \n",
      "7   Hallucinated Tool Fix Ratio    25.5  2308.12519        3  \n",
      "8         Tool Call Error Ratio    50.8  2308.12519        3  \n",
      "9     Tool Call Error Fix Ratio    31.1  2308.12519        3  \n",
      "10             Unavailable Tool     2.6  2308.12519        3  \n",
      "11             Decision Failure    48.6  2308.12519        3  \n",
      "12      Hallucinated Tool Ratio    31.5  2308.12519        3  \n",
      "13  Hallucinated Tool Fix Ratio    38.9  2308.12519        3  \n",
      "14        Tool Call Error Ratio    62.5  2308.12519        3  \n",
      "15    Tool Call Error Fix Ratio    41.0  2308.12519        3  \n",
      "16             Unavailable Tool     3.0  2308.12519        3  \n",
      "17             Decision Failure    26.4  2308.12519        3  \n",
      "18      Hallucinated Tool Ratio    42.1  2308.12519        3  \n",
      "19  Hallucinated Tool Fix Ratio    53.3  2308.12519        3  \n",
      "20        Tool Call Error Ratio    62.3  2308.12519        3  \n",
      "21    Tool Call Error Fix Ratio    54.0  2308.12519        3  \n",
      "22             Unavailable Tool     3.0  2308.12519        3  \n",
      "23             Decision Failure    14.8  2308.12519        3  \n",
      "   claim_id      Model          Method   Dataset  \\\n",
      "0         0  PaLM-540B        CoT [61]  HotpotQA   \n",
      "1         1  PaLM-540B     CoT-SC [55]  HotpotQA   \n",
      "2         2  PaLM-540B      ReAct [65]  HotpotQA   \n",
      "3         3  PaLM-540B  ReAct → CoT-SC  HotpotQA   \n",
      "4         4  GPT3-175B           ReAct  HotpotQA   \n",
      "5         5   PaLM-62B    ReAct-Tuning  HotpotQA   \n",
      "6         6   PaLM-62B      CoT-Tuning  HotpotQA   \n",
      "7         7    PaLM-8B    ReAct-Tuning  HotpotQA   \n",
      "8         8    PaLM-8B      CoT-Tuning  HotpotQA   \n",
      "9         9   LLaMA-7B    ReAct-Tuning  HotpotQA   \n",
      "10       10   LLaMA-7B             LTC  HotpotQA   \n",
      "\n",
      "                                Task   Measure Outcome    paper_id table_id  \n",
      "0   evaluating EM scores on HotpotQA  EM score    29.4  2310.01444        2  \n",
      "1   evaluating EM scores on HotpotQA  EM score    33.4  2310.01444        2  \n",
      "2   evaluating EM scores on HotpotQA  EM score    27.4  2310.01444        2  \n",
      "3   evaluating EM scores on HotpotQA  EM score    35.1  2310.01444        2  \n",
      "4   evaluating EM scores on HotpotQA  EM score    30.8  2310.01444        2  \n",
      "5   evaluating EM scores on HotpotQA  EM score    32.6  2310.01444        2  \n",
      "6   evaluating EM scores on HotpotQA  EM score    25.2  2310.01444        2  \n",
      "7   evaluating EM scores on HotpotQA  EM score    25.0  2310.01444        2  \n",
      "8   evaluating EM scores on HotpotQA  EM score    14.1  2310.01444        2  \n",
      "9   evaluating EM scores on HotpotQA  EM score    28.1  2310.01444        2  \n",
      "10  evaluating EM scores on HotpotQA  EM score    33.2  2310.01444        2  \n",
      "  claim_id Method    Dataset                                     Task  \\\n",
      "0        0    ICL      GSM8k  evaluating token usage in input prompts   \n",
      "1        1    ICL  Hotpot-QA  evaluating token usage in input prompts   \n",
      "2        2    ICL   Alfworld  evaluating token usage in input prompts   \n",
      "3        3    LTC      GSM8k  evaluating token usage in input prompts   \n",
      "4        4    LTC  Hotpot-QA  evaluating token usage in input prompts   \n",
      "5        5    LTC   Alfworld  evaluating token usage in input prompts   \n",
      "\n",
      "       Measure Outcome    paper_id table_id  \n",
      "0  Token Count     836  2310.01444        4  \n",
      "1  Token Count    1937  2310.01444        4  \n",
      "2  Token Count    1744  2310.01444        4  \n",
      "3  Token Count     107  2310.01444        4  \n",
      "4  Token Count     167  2310.01444        4  \n",
      "5  Token Count     189  2310.01444        4  \n",
      "    claim_id LLM-Backend Method                          Task Shot Type  \\\n",
      "0          0      PaLM-2     IO  Shortest-path Reasoning Task    0-shot   \n",
      "1          1      PaLM-2     IO  Shortest-path Reasoning Task    0-shot   \n",
      "2          2      PaLM-2     IO  Shortest-path Reasoning Task    0-shot   \n",
      "3          3      PaLM-2     IO  Shortest-path Reasoning Task    1-shot   \n",
      "4          4      PaLM-2     IO  Shortest-path Reasoning Task    1-shot   \n",
      "..       ...         ...    ...                           ...       ...   \n",
      "121      121       GPT-4     TP  Shortest-path Reasoning Task    1-shot   \n",
      "122      122       GPT-4     TP  Shortest-path Reasoning Task    1-shot   \n",
      "123      123       GPT-4     TP  Shortest-path Reasoning Task    5-shot   \n",
      "124      124       GPT-4     TP  Shortest-path Reasoning Task    5-shot   \n",
      "125      125       GPT-4     TP  Shortest-path Reasoning Task    5-shot   \n",
      "\n",
      "    Metric Index Measure Outcome    paper_id table_id  \n",
      "0              1      OR    0.14  2310.03965        1  \n",
      "1              2      FR    0.37  2310.03965        1  \n",
      "2              3     OLR    0.62  2310.03965        1  \n",
      "3              1      OR    0.28  2310.03965        1  \n",
      "4              2      FR    0.48  2310.03965        1  \n",
      "..           ...     ...     ...         ...      ...  \n",
      "121            2      FR     1.0  2310.03965        1  \n",
      "122            3     OLR    0.04  2310.03965        1  \n",
      "123            1      OR    0.86  2310.03965        1  \n",
      "124            2      FR     1.0  2310.03965        1  \n",
      "125            3     OLR    0.05  2310.03965        1  \n",
      "\n",
      "[126 rows x 10 columns]\n",
      "   claim_id LLM-Backend Method                   Task         Measure  \\\n",
      "0         0     GPT-3.5     IO  Creative Writing Task  Coherent Score   \n",
      "1         1     GPT-3.5     IO  Creative Writing Task      User Study   \n",
      "2         2       GPT-4     IO  Creative Writing Task  Coherent Score   \n",
      "3         3       GPT-4     IO  Creative Writing Task      User Study   \n",
      "4         4     GPT-3.5    CoT  Creative Writing Task  Coherent Score   \n",
      "5         5     GPT-3.5    CoT  Creative Writing Task      User Study   \n",
      "6         6       GPT-4    CoT  Creative Writing Task  Coherent Score   \n",
      "7         7       GPT-4    CoT  Creative Writing Task      User Study   \n",
      "8         8     GPT-3.5    ToT  Creative Writing Task  Coherent Score   \n",
      "9         9     GPT-3.5    ToT  Creative Writing Task      User Study   \n",
      "10       10       GPT-4    ToT  Creative Writing Task  Coherent Score   \n",
      "11       11       GPT-4    ToT  Creative Writing Task      User Study   \n",
      "12       12     GPT-3.5     TP  Creative Writing Task  Coherent Score   \n",
      "13       13     GPT-3.5     TP  Creative Writing Task      User Study   \n",
      "14       14       GPT-4     TP  Creative Writing Task  Coherent Score   \n",
      "15       15       GPT-4     TP  Creative Writing Task      User Study   \n",
      "\n",
      "          Outcome    paper_id table_id  \n",
      "0   6.087 ± 2.229  2310.03965        2  \n",
      "1             14%  2310.03965        2  \n",
      "2   6.193 ± 1.953  2310.03965        2  \n",
      "3              7%  2310.03965        2  \n",
      "4   6.654 ± 2.201  2310.03965        2  \n",
      "5             21%  2310.03965        2  \n",
      "6   6.927 ± 1.508  2310.03965        2  \n",
      "7             15%  2310.03965        2  \n",
      "8   6.856 ± 1.975  2310.03965        2  \n",
      "9             26%  2310.03965        2  \n",
      "10  7.684 ± 1.141  2310.03965        2  \n",
      "11            33%  2310.03965        2  \n",
      "12  7.000 ± 1.783  2310.03965        2  \n",
      "13            39%  2310.03965        2  \n",
      "14  7.989 ± 1.453  2310.03965        2  \n",
      "15            45%  2310.03965        2  \n",
      "   claim_id         Model Dataset                      Task Measure Outcome  \\\n",
      "0         0  CodeLlama-7B  Spider       text-to-SQL parsing     Acc    54.0   \n",
      "1         1  CodeLlama-7B  Spider       text-to-SQL parsing      F1    37.1   \n",
      "2         2  CodeLlama-7B  Spider       text-to-SQL parsing     H@1    56.0   \n",
      "3         3  CodeLlama-7B  Spider       text-to-SQL parsing     MRR    62.3   \n",
      "4         4  CodeLlama-7B    Bird  discrimination abilities     Acc    44.6   \n",
      "..      ...           ...     ...                       ...     ...     ...   \n",
      "67       67   GPT-4-Turbo    Bird  discrimination abilities     MRR    23.0   \n",
      "68       68   GPT-4-Turbo   GSM8K  discrimination abilities     Acc    93.8   \n",
      "69       69   GPT-4-Turbo   GSM8K  discrimination abilities      F1    91.1   \n",
      "70       70   GPT-4-Turbo   GSM8K  discrimination abilities     H@1    59.8   \n",
      "71       71   GPT-4-Turbo   GSM8K  discrimination abilities     MRR    61.6   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2402.10890        1  \n",
      "1   2402.10890        1  \n",
      "2   2402.10890        1  \n",
      "3   2402.10890        1  \n",
      "4   2402.10890        1  \n",
      "..         ...      ...  \n",
      "67  2402.10890        1  \n",
      "68  2402.10890        1  \n",
      "69  2402.10890        1  \n",
      "70  2402.10890        1  \n",
      "71  2402.10890        1  \n",
      "\n",
      "[72 rows x 8 columns]\n",
      "   claim_id             Model Dataset  \\\n",
      "0         0     CodeLlama-13B  Spider   \n",
      "1         1     CodeLlama-13B  Spider   \n",
      "2         2     CodeLlama-13B  Spider   \n",
      "3         3     CodeLlama-13B  Spider   \n",
      "4         4     CodeLlama-13B    Bird   \n",
      "5         5     CodeLlama-13B    Bird   \n",
      "6         6     CodeLlama-13B    Bird   \n",
      "7         7     CodeLlama-13B    Bird   \n",
      "8         8     CodeLlama-13B   GSM8K   \n",
      "9         9     CodeLlama-13B   GSM8K   \n",
      "10       10     CodeLlama-13B   GSM8K   \n",
      "11       11     CodeLlama-13B   GSM8K   \n",
      "12       12     GPT-3.5-Turbo  Spider   \n",
      "13       13     GPT-3.5-Turbo  Spider   \n",
      "14       14     GPT-3.5-Turbo  Spider   \n",
      "15       15     GPT-3.5-Turbo  Spider   \n",
      "16       16     GPT-3.5-Turbo    Bird   \n",
      "17       17     GPT-3.5-Turbo    Bird   \n",
      "18       18     GPT-3.5-Turbo    Bird   \n",
      "19       19     GPT-3.5-Turbo    Bird   \n",
      "20       20     GPT-3.5-Turbo   GSM8K   \n",
      "21       21     GPT-3.5-Turbo   GSM8K   \n",
      "22       22     GPT-3.5-Turbo   GSM8K   \n",
      "23       23     GPT-3.5-Turbo   GSM8K   \n",
      "24       24  CodeLlama-13B-FT  Spider   \n",
      "25       25  CodeLlama-13B-FT  Spider   \n",
      "26       26  CodeLlama-13B-FT  Spider   \n",
      "27       27  CodeLlama-13B-FT  Spider   \n",
      "28       28  CodeLlama-13B-FT    Bird   \n",
      "29       29  CodeLlama-13B-FT    Bird   \n",
      "30       30  CodeLlama-13B-FT    Bird   \n",
      "31       31  CodeLlama-13B-FT    Bird   \n",
      "32       32  CodeLlama-13B-FT   GSM8K   \n",
      "33       33  CodeLlama-13B-FT   GSM8K   \n",
      "34       34  CodeLlama-13B-FT   GSM8K   \n",
      "35       35  CodeLlama-13B-FT   GSM8K   \n",
      "\n",
      "                                                Task   Measure Outcome  \\\n",
      "0                            discrimination accuracy  Accuracy    58.2   \n",
      "1   discrimination accuracy with Executability Check  Accuracy    78.7   \n",
      "2      discrimination accuracy with Execution Result  Accuracy    83.6   \n",
      "3                discrimination accuracy Improvement      Gain    25.4   \n",
      "4                            discrimination accuracy  Accuracy    49.4   \n",
      "5   discrimination accuracy with Executability Check  Accuracy    78.8   \n",
      "6      discrimination accuracy with Execution Result  Accuracy    79.6   \n",
      "7                discrimination accuracy Improvement      Gain    30.2   \n",
      "8                            discrimination accuracy  Accuracy    62.2   \n",
      "9   discrimination accuracy with Executability Check  Accuracy    64.5   \n",
      "10     discrimination accuracy with Execution Result  Accuracy    70.6   \n",
      "11               discrimination accuracy Improvement      Gain     8.4   \n",
      "12                           discrimination accuracy  Accuracy    67.0   \n",
      "13  discrimination accuracy with Executability Check  Accuracy    84.8   \n",
      "14     discrimination accuracy with Execution Result  Accuracy    90.0   \n",
      "15               discrimination accuracy Improvement      Gain    23.0   \n",
      "16                           discrimination accuracy  Accuracy    64.3   \n",
      "17  discrimination accuracy with Executability Check  Accuracy    86.3   \n",
      "18     discrimination accuracy with Execution Result  Accuracy    89.2   \n",
      "19               discrimination accuracy Improvement      Gain    24.9   \n",
      "20                           discrimination accuracy  Accuracy    72.1   \n",
      "21  discrimination accuracy with Executability Check  Accuracy    73.2   \n",
      "22     discrimination accuracy with Execution Result  Accuracy    76.5   \n",
      "23               discrimination accuracy Improvement      Gain     4.4   \n",
      "24                           discrimination accuracy  Accuracy    69.7   \n",
      "25  discrimination accuracy with Executability Check  Accuracy    83.6   \n",
      "26     discrimination accuracy with Execution Result  Accuracy    88.5   \n",
      "27               discrimination accuracy Improvement      Gain    18.8   \n",
      "28                           discrimination accuracy  Accuracy    62.1   \n",
      "29  discrimination accuracy with Executability Check  Accuracy    82.2   \n",
      "30     discrimination accuracy with Execution Result  Accuracy    85.1   \n",
      "31               discrimination accuracy Improvement      Gain    23.0   \n",
      "32                           discrimination accuracy  Accuracy     nan   \n",
      "33  discrimination accuracy with Executability Check  Accuracy     nan   \n",
      "34     discrimination accuracy with Execution Result  Accuracy     nan   \n",
      "35               discrimination accuracy Improvement      Gain     nan   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2402.10890        2  \n",
      "1   2402.10890        2  \n",
      "2   2402.10890        2  \n",
      "3   2402.10890        2  \n",
      "4   2402.10890        2  \n",
      "5   2402.10890        2  \n",
      "6   2402.10890        2  \n",
      "7   2402.10890        2  \n",
      "8   2402.10890        2  \n",
      "9   2402.10890        2  \n",
      "10  2402.10890        2  \n",
      "11  2402.10890        2  \n",
      "12  2402.10890        2  \n",
      "13  2402.10890        2  \n",
      "14  2402.10890        2  \n",
      "15  2402.10890        2  \n",
      "16  2402.10890        2  \n",
      "17  2402.10890        2  \n",
      "18  2402.10890        2  \n",
      "19  2402.10890        2  \n",
      "20  2402.10890        2  \n",
      "21  2402.10890        2  \n",
      "22  2402.10890        2  \n",
      "23  2402.10890        2  \n",
      "24  2402.10890        2  \n",
      "25  2402.10890        2  \n",
      "26  2402.10890        2  \n",
      "27  2402.10890        2  \n",
      "28  2402.10890        2  \n",
      "29  2402.10890        2  \n",
      "30  2402.10890        2  \n",
      "31  2402.10890        2  \n",
      "32  2402.10890        2  \n",
      "33  2402.10890        2  \n",
      "34  2402.10890        2  \n",
      "35  2402.10890        2  \n",
      "   claim_id         Discriminator Dataset       Planning Method  \\\n",
      "0         0         CodeLlama-13B  Spider            Re-ranking   \n",
      "1         1         CodeLlama-13B  Spider  Iterative Correction   \n",
      "2         2         CodeLlama-13B  Spider           Tree Search   \n",
      "3         3         CodeLlama-13B  Spider     Advanced Planning   \n",
      "4         4         GPT-3.5-Turbo    Bird            Re-ranking   \n",
      "5         5         GPT-3.5-Turbo    Bird  Iterative Correction   \n",
      "6         6         GPT-3.5-Turbo    Bird           Tree Search   \n",
      "7         7         GPT-3.5-Turbo    Bird     Advanced Planning   \n",
      "8         8      CodeLlama-13B-FT  Spider            Re-ranking   \n",
      "9         9      CodeLlama-13B-FT  Spider  Iterative Correction   \n",
      "10       10      CodeLlama-13B-FT  Spider           Tree Search   \n",
      "11       11      CodeLlama-13B-FT  Spider     Advanced Planning   \n",
      "12       12     CodeLlama-13B (E)    Bird            Re-ranking   \n",
      "13       13     CodeLlama-13B (E)    Bird  Iterative Correction   \n",
      "14       14     CodeLlama-13B (E)    Bird           Tree Search   \n",
      "15       15     CodeLlama-13B (E)    Bird     Advanced Planning   \n",
      "16       16     GPT-3.5-Turbo (E)  Spider            Re-ranking   \n",
      "17       17     GPT-3.5-Turbo (E)  Spider  Iterative Correction   \n",
      "18       18     GPT-3.5-Turbo (E)  Spider           Tree Search   \n",
      "19       19     GPT-3.5-Turbo (E)  Spider     Advanced Planning   \n",
      "20       20  CodeLlama-13B-FT (E)    Bird            Re-ranking   \n",
      "21       21  CodeLlama-13B-FT (E)    Bird  Iterative Correction   \n",
      "22       22  CodeLlama-13B-FT (E)    Bird           Tree Search   \n",
      "23       23  CodeLlama-13B-FT (E)    Bird     Advanced Planning   \n",
      "\n",
      "                   Task   Measure Outcome    paper_id table_id  \n",
      "0   text-to-SQL parsing  Accuracy    57.5  2402.10890        3  \n",
      "1   text-to-SQL parsing  Accuracy    51.7  2402.10890        3  \n",
      "2   text-to-SQL parsing  Accuracy    55.5  2402.10890        3  \n",
      "3   text-to-SQL parsing  Accuracy     nan  2402.10890        3  \n",
      "4   text-to-SQL parsing  Accuracy    13.3  2402.10890        3  \n",
      "5   text-to-SQL parsing  Accuracy    13.3  2402.10890        3  \n",
      "6   text-to-SQL parsing  Accuracy    13.3  2402.10890        3  \n",
      "7   text-to-SQL parsing  Accuracy     nan  2402.10890        3  \n",
      "8   text-to-SQL parsing  Accuracy    61.5  2402.10890        3  \n",
      "9   text-to-SQL parsing  Accuracy    51.7  2402.10890        3  \n",
      "10  text-to-SQL parsing  Accuracy    56.0  2402.10890        3  \n",
      "11  text-to-SQL parsing  Accuracy    67.5  2402.10890        3  \n",
      "12  text-to-SQL parsing  Accuracy    14.3  2402.10890        3  \n",
      "13  text-to-SQL parsing  Accuracy    13.0  2402.10890        3  \n",
      "14  text-to-SQL parsing  Accuracy    13.0  2402.10890        3  \n",
      "15  text-to-SQL parsing  Accuracy    23.7  2402.10890        3  \n",
      "16  text-to-SQL parsing  Accuracy    65.5  2402.10890        3  \n",
      "17  text-to-SQL parsing  Accuracy    62.0  2402.10890        3  \n",
      "18  text-to-SQL parsing  Accuracy    62.5  2402.10890        3  \n",
      "19  text-to-SQL parsing  Accuracy    70.3  2402.10890        3  \n",
      "20  text-to-SQL parsing  Accuracy    21.0  2402.10890        3  \n",
      "21  text-to-SQL parsing  Accuracy    24.3  2402.10890        3  \n",
      "22  text-to-SQL parsing  Accuracy    22.7  2402.10890        3  \n",
      "23  text-to-SQL parsing  Accuracy    26.3  2402.10890        3  \n",
      "   claim_id        Attack Method         Model Dataset  \\\n",
      "0         0        Combination-1       GPT-3.5     DAN   \n",
      "1         1        Combination-1    Vicuna-13b     DAN   \n",
      "2         2        Combination-1   LLaMA-2-70b     DAN   \n",
      "3         3        Combination-1  mixtral-8x7b     DAN   \n",
      "4         4     Prefix Injection       GPT-3.5     DAN   \n",
      "5         5     Prefix Injection    Vicuna-13b     DAN   \n",
      "6         6     Prefix Injection   LLaMA-2-70b     DAN   \n",
      "7         7     Prefix Injection  mixtral-8x7b     DAN   \n",
      "8         8  Refusal Suppression       GPT-3.5     DAN   \n",
      "9         9  Refusal Suppression    Vicuna-13b     DAN   \n",
      "10       10  Refusal Suppression   LLaMA-2-70b     DAN   \n",
      "11       11  Refusal Suppression  mixtral-8x7b     DAN   \n",
      "12       12        Combination-2       GPT-3.5     DAN   \n",
      "13       13        Combination-2    Vicuna-13b     DAN   \n",
      "14       14        Combination-2   LLaMA-2-70b     DAN   \n",
      "15       15        Combination-2  mixtral-8x7b     DAN   \n",
      "16       16                  AIM       GPT-3.5     DAN   \n",
      "17       17                  AIM    Vicuna-13b     DAN   \n",
      "18       18                  AIM   LLaMA-2-70b     DAN   \n",
      "19       19                  AIM  mixtral-8x7b     DAN   \n",
      "20       20                  N/A       GPT-3.5     DAN   \n",
      "21       21                  N/A    Vicuna-13b     DAN   \n",
      "22       22                  N/A   LLaMA-2-70b     DAN   \n",
      "23       23                  N/A  mixtral-8x7b     DAN   \n",
      "\n",
      "                              Task Measure Outcome    paper_id table_id  \n",
      "0   Attack Success Rate Evaluation     ASR   55.74  2403.04783        1  \n",
      "1   Attack Success Rate Evaluation     ASR   57.18  2403.04783        1  \n",
      "2   Attack Success Rate Evaluation     ASR    4.87  2403.04783        1  \n",
      "3   Attack Success Rate Evaluation     ASR   40.77  2403.04783        1  \n",
      "4   Attack Success Rate Evaluation     ASR   34.36  2403.04783        1  \n",
      "5   Attack Success Rate Evaluation     ASR   51.03  2403.04783        1  \n",
      "6   Attack Success Rate Evaluation     ASR    6.41  2403.04783        1  \n",
      "7   Attack Success Rate Evaluation     ASR   49.23  2403.04783        1  \n",
      "8   Attack Success Rate Evaluation     ASR   29.74  2403.04783        1  \n",
      "9   Attack Success Rate Evaluation     ASR   51.54  2403.04783        1  \n",
      "10  Attack Success Rate Evaluation     ASR    5.13  2403.04783        1  \n",
      "11  Attack Success Rate Evaluation     ASR   31.28  2403.04783        1  \n",
      "12  Attack Success Rate Evaluation     ASR   36.41  2403.04783        1  \n",
      "13  Attack Success Rate Evaluation     ASR    3.85  2403.04783        1  \n",
      "14  Attack Success Rate Evaluation     ASR    2.05  2403.04783        1  \n",
      "15  Attack Success Rate Evaluation     ASR    1.03  2403.04783        1  \n",
      "16  Attack Success Rate Evaluation     ASR     0.0  2403.04783        1  \n",
      "17  Attack Success Rate Evaluation     ASR   64.87  2403.04783        1  \n",
      "18  Attack Success Rate Evaluation     ASR    7.18  2403.04783        1  \n",
      "19  Attack Success Rate Evaluation     ASR   58.72  2403.04783        1  \n",
      "20  Attack Success Rate Evaluation     ASR    2.82  2403.04783        1  \n",
      "21  Attack Success Rate Evaluation     ASR    8.72  2403.04783        1  \n",
      "22  Attack Success Rate Evaluation     ASR    0.51  2403.04783        1  \n",
      "23  Attack Success Rate Evaluation     ASR    7.95  2403.04783        1  \n",
      "  claim_id     Agent Configuration Dataset                               Task  \\\n",
      "0        0      Single Agent (CoT)     N/A  Defense Using Multi-Agent Systems   \n",
      "1        1      Single Agent (CoT)     N/A  Defense Using Multi-Agent Systems   \n",
      "2        2                3 Agents     N/A  Defense Using Multi-Agent Systems   \n",
      "3        3                3 Agents     N/A  Defense Using Multi-Agent Systems   \n",
      "4        4  4 Agents w/ LlamaGuard     N/A  Defense Using Multi-Agent Systems   \n",
      "5        5  4 Agents w/ LlamaGuard     N/A  Defense Using Multi-Agent Systems   \n",
      "\n",
      "  Measure Outcome    paper_id table_id  \n",
      "0     FPR   17.16  2403.04783        4  \n",
      "1     ASR   10.87  2403.04783        4  \n",
      "2     FPR   37.32  2403.04783        4  \n",
      "3     ASR    3.13  2403.04783        4  \n",
      "4     FPR     6.8  2403.04783        4  \n",
      "5     ASR   11.08  2403.04783        4  \n",
      "   claim_id           Model       Dataset               Task    Measure  \\\n",
      "0         0  EXALT Baseline  Test Dataset  Emotion Detection   F1-score   \n",
      "1         1  EXALT Baseline  Test Dataset  Emotion Detection  Precision   \n",
      "2         2  EXALT Baseline  Test Dataset  Emotion Detection     Recall   \n",
      "3         3  ZSEC-gpt4turbo  Test Dataset  Emotion Detection   F1-score   \n",
      "4         4  ZSEC-gpt4turbo  Test Dataset  Emotion Detection  Precision   \n",
      "5         5  ZSEC-gpt4turbo  Test Dataset  Emotion Detection     Recall   \n",
      "6         6      ZSEC-gpt4o  Test Dataset  Emotion Detection   F1-score   \n",
      "7         7      ZSEC-gpt4o  Test Dataset  Emotion Detection  Precision   \n",
      "8         8      ZSEC-gpt4o  Test Dataset  Emotion Detection     Recall   \n",
      "9         9          MBCAWF  Test Dataset  Emotion Detection   F1-score   \n",
      "10       10          MBCAWF  Test Dataset  Emotion Detection  Precision   \n",
      "11       11          MBCAWF  Test Dataset  Emotion Detection     Recall   \n",
      "12       12         MIAWF-3  Test Dataset  Emotion Detection   F1-score   \n",
      "13       13         MIAWF-3  Test Dataset  Emotion Detection  Precision   \n",
      "14       14         MIAWF-3  Test Dataset  Emotion Detection     Recall   \n",
      "15       15         MIAWF-5  Test Dataset  Emotion Detection   F1-score   \n",
      "16       16         MIAWF-5  Test Dataset  Emotion Detection  Precision   \n",
      "17       17         MIAWF-5  Test Dataset  Emotion Detection     Recall   \n",
      "18       18      Ensemble-9  Test Dataset  Emotion Detection   F1-score   \n",
      "19       19      Ensemble-9  Test Dataset  Emotion Detection  Precision   \n",
      "20       20      Ensemble-9  Test Dataset  Emotion Detection     Recall   \n",
      "21       21      Ensemble-8  Test Dataset  Emotion Detection   F1-score   \n",
      "22       22      Ensemble-8  Test Dataset  Emotion Detection  Precision   \n",
      "23       23      Ensemble-8  Test Dataset  Emotion Detection     Recall   \n",
      "24       24     Ensemble-17  Test Dataset  Emotion Detection   F1-score   \n",
      "25       25     Ensemble-17  Test Dataset  Emotion Detection  Precision   \n",
      "26       26     Ensemble-17  Test Dataset  Emotion Detection     Recall   \n",
      "27       27     Ensemble-19  Test Dataset  Emotion Detection   F1-score   \n",
      "28       28     Ensemble-19  Test Dataset  Emotion Detection  Precision   \n",
      "29       29     Ensemble-19  Test Dataset  Emotion Detection     Recall   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0     0.43  2405.17129        1  \n",
      "1     0.43  2405.17129        1  \n",
      "2     0.44  2405.17129        1  \n",
      "3     0.55  2405.17129        1  \n",
      "4     0.55  2405.17129        1  \n",
      "5     0.58  2405.17129        1  \n",
      "6     0.57  2405.17129        1  \n",
      "7     0.56  2405.17129        1  \n",
      "8      0.6  2405.17129        1  \n",
      "9     0.56  2405.17129        1  \n",
      "10    0.56  2405.17129        1  \n",
      "11    0.59  2405.17129        1  \n",
      "12    0.59  2405.17129        1  \n",
      "13    0.59  2405.17129        1  \n",
      "14    0.61  2405.17129        1  \n",
      "15     0.6  2405.17129        1  \n",
      "16    0.59  2405.17129        1  \n",
      "17    0.62  2405.17129        1  \n",
      "18    0.59  2405.17129        1  \n",
      "19    0.59  2405.17129        1  \n",
      "20    0.61  2405.17129        1  \n",
      "21     0.6  2405.17129        1  \n",
      "22     0.6  2405.17129        1  \n",
      "23    0.62  2405.17129        1  \n",
      "24     0.6  2405.17129        1  \n",
      "25     0.6  2405.17129        1  \n",
      "26    0.62  2405.17129        1  \n",
      "27     0.6  2405.17129        1  \n",
      "28     0.6  2405.17129        1  \n",
      "29    0.62  2405.17129        1  \n",
      "   claim_id Emotion Label        Model               Task    Measure Outcome  \\\n",
      "0         0          Love  Ensemble-19  Emotion Detection   F1-score    0.47   \n",
      "1         1          Love  Ensemble-19  Emotion Detection  Precision    0.55   \n",
      "2         2          Love  Ensemble-19  Emotion Detection     Recall    0.41   \n",
      "3         3          Love  Ensemble-19  Emotion Detection    Support     190   \n",
      "4         4           Joy  Ensemble-19  Emotion Detection   F1-score    0.63   \n",
      "5         5           Joy  Ensemble-19  Emotion Detection  Precision    0.55   \n",
      "6         6           Joy  Ensemble-19  Emotion Detection     Recall    0.74   \n",
      "7         7           Joy  Ensemble-19  Emotion Detection    Support     433   \n",
      "8         8         Anger  Ensemble-19  Emotion Detection   F1-score    0.73   \n",
      "9         9         Anger  Ensemble-19  Emotion Detection  Precision    0.76   \n",
      "10       10         Anger  Ensemble-19  Emotion Detection     Recall     0.7   \n",
      "11       11         Anger  Ensemble-19  Emotion Detection    Support     614   \n",
      "12       12          Fear  Ensemble-19  Emotion Detection   F1-score    0.53   \n",
      "13       13          Fear  Ensemble-19  Emotion Detection  Precision    0.44   \n",
      "14       14          Fear  Ensemble-19  Emotion Detection     Recall    0.68   \n",
      "15       15          Fear  Ensemble-19  Emotion Detection    Support      77   \n",
      "16       16       Sadness  Ensemble-19  Emotion Detection   F1-score    0.55   \n",
      "17       17       Sadness  Ensemble-19  Emotion Detection  Precision    0.56   \n",
      "18       18       Sadness  Ensemble-19  Emotion Detection     Recall    0.54   \n",
      "19       19       Sadness  Ensemble-19  Emotion Detection    Support     270   \n",
      "20       20       Neutral  Ensemble-19  Emotion Detection   F1-score    0.72   \n",
      "21       21       Neutral  Ensemble-19  Emotion Detection  Precision    0.76   \n",
      "22       22       Neutral  Ensemble-19  Emotion Detection     Recall    0.68   \n",
      "23       23       Neutral  Ensemble-19  Emotion Detection    Support     916   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2405.17129        4  \n",
      "1   2405.17129        4  \n",
      "2   2405.17129        4  \n",
      "3   2405.17129        4  \n",
      "4   2405.17129        4  \n",
      "5   2405.17129        4  \n",
      "6   2405.17129        4  \n",
      "7   2405.17129        4  \n",
      "8   2405.17129        4  \n",
      "9   2405.17129        4  \n",
      "10  2405.17129        4  \n",
      "11  2405.17129        4  \n",
      "12  2405.17129        4  \n",
      "13  2405.17129        4  \n",
      "14  2405.17129        4  \n",
      "15  2405.17129        4  \n",
      "16  2405.17129        4  \n",
      "17  2405.17129        4  \n",
      "18  2405.17129        4  \n",
      "19  2405.17129        4  \n",
      "20  2405.17129        4  \n",
      "21  2405.17129        4  \n",
      "22  2405.17129        4  \n",
      "23  2405.17129        4  \n",
      "   claim_id                   Model       Dataset Task    Measure Outcome  \\\n",
      "0         0  ZeroShot (gpt-4-turbo)  Test Dataset  N/A   F1-score  0.5459   \n",
      "1         1  ZeroShot (gpt-4-turbo)  Test Dataset  N/A  Precision  0.5539   \n",
      "2         2  ZeroShot (gpt-4-turbo)  Test Dataset  N/A     Recall  0.5682   \n",
      "3         3  ZeroShot (gpt-4-turbo)  Test Dataset  N/A       Acc.  0.6028   \n",
      "4         4       ZeroShot (gpt-4o)  Test Dataset  N/A   F1-score  0.5732   \n",
      "5         5       ZeroShot (gpt-4o)  Test Dataset  N/A  Precision  0.5685   \n",
      "6         6       ZeroShot (gpt-4o)  Test Dataset  N/A     Recall  0.5813   \n",
      "7         7       ZeroShot (gpt-4o)  Test Dataset  N/A       Acc.  0.6164   \n",
      "8         8            ZSE (gpt-4o)  Test Dataset  N/A   F1-score  0.5723   \n",
      "9         9            ZSE (gpt-4o)  Test Dataset  N/A  Precision  0.5664   \n",
      "10       10            ZSE (gpt-4o)  Test Dataset  N/A     Recall   0.589   \n",
      "11       11            ZSE (gpt-4o)  Test Dataset  N/A       Acc.  0.6232   \n",
      "12       12           ZSEC (gpt-4o)  Test Dataset  N/A   F1-score  0.5726   \n",
      "13       13           ZSEC (gpt-4o)  Test Dataset  N/A  Precision  0.5631   \n",
      "14       14           ZSEC (gpt-4o)  Test Dataset  N/A     Recall  0.5953   \n",
      "15       15           ZSEC (gpt-4o)  Test Dataset  N/A       Acc.   0.624   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2405.17129        5  \n",
      "1   2405.17129        5  \n",
      "2   2405.17129        5  \n",
      "3   2405.17129        5  \n",
      "4   2405.17129        5  \n",
      "5   2405.17129        5  \n",
      "6   2405.17129        5  \n",
      "7   2405.17129        5  \n",
      "8   2405.17129        5  \n",
      "9   2405.17129        5  \n",
      "10  2405.17129        5  \n",
      "11  2405.17129        5  \n",
      "12  2405.17129        5  \n",
      "13  2405.17129        5  \n",
      "14  2405.17129        5  \n",
      "15  2405.17129        5  \n",
      "   claim_id                      Dataset Evaluation Level          Method  \\\n",
      "0         0  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "1         1  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "2         2  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "3         3  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "4         4  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "5         5  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "6         6  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "7         7  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "8         8  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "9         9  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "10       10  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "11       11  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "12       12  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "13       13  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "14       14  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "15       15  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "16       16  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "17       17  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "18       18  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "19       19  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "20       20  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "21       21  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "22       22  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "23       23  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "24       24  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "25       25  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "26       26  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "27       27  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "28       28  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "29       29  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "30       30  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "31       31  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "\n",
      "   Measure Outcome    paper_id table_id  \n",
      "0     Acc.   75.54  2406.03075        2  \n",
      "1        R   90.40  2406.03075        2  \n",
      "2        P   80.00  2406.03075        2  \n",
      "3       F1   84.88  2406.03075        2  \n",
      "4     Acc.   69.53  2406.03075        2  \n",
      "5        R   81.36  2406.03075        2  \n",
      "6        P   79.12  2406.03075        2  \n",
      "7       F1   80.23  2406.03075        2  \n",
      "8     Acc.   74.25  2406.03075        2  \n",
      "9        R   73.45  2406.03075        2  \n",
      "10       P   90.91  2406.03075        2  \n",
      "11      F1   81.25  2406.03075        2  \n",
      "12    Acc.   77.68  2406.03075        2  \n",
      "13       R   80.79  2406.03075        2  \n",
      "14       P   88.82  2406.03075        2  \n",
      "15      F1   84.62  2406.03075        2  \n",
      "16    Acc.   54.00  2406.03075        2  \n",
      "17       R   60.87  2406.03075        2  \n",
      "18       P   50.00  2406.03075        2  \n",
      "19      F1   54.90  2406.03075        2  \n",
      "20    Acc.   54.00  2406.03075        2  \n",
      "21       R   47.83  2406.03075        2  \n",
      "22       P   50.00  2406.03075        2  \n",
      "23      F1   48.89  2406.03075        2  \n",
      "24    Acc.   64.00  2406.03075        2  \n",
      "25       R   43.48  2406.03075        2  \n",
      "26       P   66.67  2406.03075        2  \n",
      "27      F1   52.63  2406.03075        2  \n",
      "28    Acc.   72.00  2406.03075        2  \n",
      "29       R   52.17  2406.03075        2  \n",
      "30       P   80.00  2406.03075        2  \n",
      "31      F1   63.15  2406.03075        2  \n",
      "   claim_id                     Dataset           Task    Method Measure  \\\n",
      "0         0  HaluEval Li et al. (2023a)             QA  HaluEval    Acc.   \n",
      "1         1  HaluEval Li et al. (2023a)             QA  HaluEval       R   \n",
      "2         2  HaluEval Li et al. (2023a)             QA  HaluEval       P   \n",
      "3         3  HaluEval Li et al. (2023a)             QA  HaluEval      F1   \n",
      "4         4  HaluEval Li et al. (2023a)             QA   FACTOOL    Acc.   \n",
      "5         5  HaluEval Li et al. (2023a)             QA   FACTOOL       R   \n",
      "6         6  HaluEval Li et al. (2023a)             QA   FACTOOL       P   \n",
      "7         7  HaluEval Li et al. (2023a)             QA   FACTOOL      F1   \n",
      "8         8  HaluEval Li et al. (2023a)             QA      Ours    Acc.   \n",
      "9         9  HaluEval Li et al. (2023a)             QA      Ours       R   \n",
      "10       10  HaluEval Li et al. (2023a)             QA      Ours       P   \n",
      "11       11  HaluEval Li et al. (2023a)             QA      Ours      F1   \n",
      "12       12  HaluEval Li et al. (2023a)  Summarization  HaluEval    Acc.   \n",
      "13       13  HaluEval Li et al. (2023a)  Summarization  HaluEval       R   \n",
      "14       14  HaluEval Li et al. (2023a)  Summarization  HaluEval       P   \n",
      "15       15  HaluEval Li et al. (2023a)  Summarization  HaluEval      F1   \n",
      "16       16  HaluEval Li et al. (2023a)  Summarization   FACTOOL    Acc.   \n",
      "17       17  HaluEval Li et al. (2023a)  Summarization   FACTOOL       R   \n",
      "18       18  HaluEval Li et al. (2023a)  Summarization   FACTOOL       P   \n",
      "19       19  HaluEval Li et al. (2023a)  Summarization   FACTOOL      F1   \n",
      "20       20  HaluEval Li et al. (2023a)  Summarization      Ours    Acc.   \n",
      "21       21  HaluEval Li et al. (2023a)  Summarization      Ours       R   \n",
      "22       22  HaluEval Li et al. (2023a)  Summarization      Ours       P   \n",
      "23       23  HaluEval Li et al. (2023a)  Summarization      Ours      F1   \n",
      "24       24  HaluEval Li et al. (2023a)       Dialogue  HaluEval    Acc.   \n",
      "25       25  HaluEval Li et al. (2023a)       Dialogue  HaluEval       R   \n",
      "26       26  HaluEval Li et al. (2023a)       Dialogue  HaluEval       P   \n",
      "27       27  HaluEval Li et al. (2023a)       Dialogue  HaluEval      F1   \n",
      "28       28  HaluEval Li et al. (2023a)       Dialogue   FACTOOL    Acc.   \n",
      "29       29  HaluEval Li et al. (2023a)       Dialogue   FACTOOL       R   \n",
      "30       30  HaluEval Li et al. (2023a)       Dialogue   FACTOOL       P   \n",
      "31       31  HaluEval Li et al. (2023a)       Dialogue   FACTOOL      F1   \n",
      "32       32  HaluEval Li et al. (2023a)       Dialogue      Ours    Acc.   \n",
      "33       33  HaluEval Li et al. (2023a)       Dialogue      Ours       R   \n",
      "34       34  HaluEval Li et al. (2023a)       Dialogue      Ours       P   \n",
      "35       35  HaluEval Li et al. (2023a)       Dialogue      Ours      F1   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0    56.00  2406.03075        3  \n",
      "1    77.33  2406.03075        3  \n",
      "2    54.21  2406.03075        3  \n",
      "3    63.74  2406.03075        3  \n",
      "4    67.33  2406.03075        3  \n",
      "5    86.67  2406.03075        3  \n",
      "6    62.50  2406.03075        3  \n",
      "7    72.63  2406.03075        3  \n",
      "8    70.67  2406.03075        3  \n",
      "9    82.67  2406.03075        3  \n",
      "10   66.67  2406.03075        3  \n",
      "11   73.81  2406.03075        3  \n",
      "12   58.00  2406.03075        3  \n",
      "13   100.0  2406.03075        3  \n",
      "14   54.35  2406.03075        3  \n",
      "15   70.42  2406.03075        3  \n",
      "16   64.00  2406.03075        3  \n",
      "17   48.00  2406.03075        3  \n",
      "18   70.59  2406.03075        3  \n",
      "19   57.14  2406.03075        3  \n",
      "20   70.00  2406.03075        3  \n",
      "21   64.00  2406.03075        3  \n",
      "22   72.73  2406.03075        3  \n",
      "23   68.09  2406.03075        3  \n",
      "24   68.00  2406.03075        3  \n",
      "25   75.71  2406.03075        3  \n",
      "26   63.10  2406.03075        3  \n",
      "27   68.83  2406.03075        3  \n",
      "28   74.67  2406.03075        3  \n",
      "29   70.00  2406.03075        3  \n",
      "30   74,24  2406.03075        3  \n",
      "31   72.06  2406.03075        3  \n",
      "32   76.00  2406.03075        3  \n",
      "33   62.86  2406.03075        3  \n",
      "34   81.48  2406.03075        3  \n",
      "35   70.97  2406.03075        3  \n",
      "   claim_id                     Dataset Task Samples          Method Measure  \\\n",
      "0         0  HaluEval Li et al. (2023a)   QA      80  Always Skeptic    Acc.   \n",
      "1         1  HaluEval Li et al. (2023a)   QA      80  Always Skeptic       R   \n",
      "2         2  HaluEval Li et al. (2023a)   QA      80  Always Skeptic       P   \n",
      "3         3  HaluEval Li et al. (2023a)   QA      80  Always Skeptic      F1   \n",
      "4         4  HaluEval Li et al. (2023a)   QA      80    Always Trust    Acc.   \n",
      "5         5  HaluEval Li et al. (2023a)   QA      80    Always Trust       R   \n",
      "6         6  HaluEval Li et al. (2023a)   QA      80    Always Trust       P   \n",
      "7         7  HaluEval Li et al. (2023a)   QA      80    Always Trust      F1   \n",
      "8         8  HaluEval Li et al. (2023a)   QA      80      True→Trust    Acc.   \n",
      "9         9  HaluEval Li et al. (2023a)   QA      80      True→Trust       R   \n",
      "10       10  HaluEval Li et al. (2023a)   QA      80      True→Trust       P   \n",
      "11       11  HaluEval Li et al. (2023a)   QA      80      True→Trust      F1   \n",
      "12       12  HaluEval Li et al. (2023a)   QA      80    True→Skeptic    Acc.   \n",
      "13       13  HaluEval Li et al. (2023a)   QA      80    True→Skeptic       R   \n",
      "14       14  HaluEval Li et al. (2023a)   QA      80    True→Skeptic       P   \n",
      "15       15  HaluEval Li et al. (2023a)   QA      80    True→Skeptic      F1   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0    65.00  2406.03075        4  \n",
      "1    84.21  2406.03075        4  \n",
      "2    59.26  2406.03075        4  \n",
      "3    69.57  2406.03075        4  \n",
      "4    68.75  2406.03075        4  \n",
      "5    84.21  2406.03075        4  \n",
      "6    62.75  2406.03075        4  \n",
      "7    71.91  2406.03075        4  \n",
      "8    67.50  2406.03075        4  \n",
      "9    89.47  2406.03075        4  \n",
      "10   60.71  2406.03075        4  \n",
      "11   72.34  2406.03075        4  \n",
      "12   70.00  2406.03075        4  \n",
      "13   86.84  2406.03075        4  \n",
      "14   63.46  2406.03075        4  \n",
      "15   73.33  2406.03075        4  \n",
      "  claim_id                          Model Dataset                    Task  \\\n",
      "0        0                  Speech-GPT3.5     N/A  Performance evaluation   \n",
      "1        1                  Speech-GPT3.5     N/A  Performance evaluation   \n",
      "2        2                PerceptiveAgent     N/A  Performance evaluation   \n",
      "3        3                PerceptiveAgent     N/A  Performance evaluation   \n",
      "4        4  PerceptiveAgent -w/o captions     N/A  Performance evaluation   \n",
      "5        5  PerceptiveAgent -w/o captions     N/A  Performance evaluation   \n",
      "\n",
      "     Measure      Outcome    paper_id table_id  \n",
      "0  BERTScore  53.03±10.20  2406.12707        1  \n",
      "1   Accuracy         0.74  2406.12707        1  \n",
      "2  BERTScore   54.36±9.25  2406.12707        1  \n",
      "3   Accuracy        21.89  2406.12707        1  \n",
      "4  BERTScore            -  2406.12707        1  \n",
      "5   Accuracy        16.53  2406.12707        1  \n",
      "  claim_id                          Model       Dataset  \\\n",
      "0        0                  Speech-GPT3.5  TextroSpeech   \n",
      "1        1                  Speech-GPT3.5  TextroSpeech   \n",
      "2        2                PerceptiveAgent  TextroSpeech   \n",
      "3        3                PerceptiveAgent  TextroSpeech   \n",
      "4        4  PerceptiveAgent -w/o captions  TextroSpeech   \n",
      "5        5  PerceptiveAgent -w/o captions  TextroSpeech   \n",
      "\n",
      "                                    Task    Measure      Outcome    paper_id  \\\n",
      "0  Generalization Performance Evaluation  BERTScore  53.03±10.20  2406.12707   \n",
      "1  Generalization Performance Evaluation   Accuracy         0.74  2406.12707   \n",
      "2  Generalization Performance Evaluation  BERTScore   54.36±9.25  2406.12707   \n",
      "3  Generalization Performance Evaluation   Accuracy        21.89  2406.12707   \n",
      "4  Generalization Performance Evaluation  BERTScore            -  2406.12707   \n",
      "5  Generalization Performance Evaluation   Accuracy        16.53  2406.12707   \n",
      "\n",
      "  table_id  \n",
      "0        2  \n",
      "1        2  \n",
      "2        2  \n",
      "3        2  \n",
      "4        2  \n",
      "5        2  \n",
      "   claim_id Attribute  Gender                           Task    Measure  \\\n",
      "0         0   Emotion    Male  Speech Captioning Performance  Precision   \n",
      "1         1   Emotion    Male  Speech Captioning Performance     Recall   \n",
      "2         2   Emotion    Male  Speech Captioning Performance   F1-score   \n",
      "3         3   Emotion  Female  Speech Captioning Performance  Precision   \n",
      "4         4   Emotion  Female  Speech Captioning Performance     Recall   \n",
      "5         5   Emotion  Female  Speech Captioning Performance   F1-score   \n",
      "6         6     Pitch    Male  Speech Captioning Performance  Precision   \n",
      "7         7     Pitch    Male  Speech Captioning Performance     Recall   \n",
      "8         8     Pitch    Male  Speech Captioning Performance   F1-score   \n",
      "9         9     Pitch  Female  Speech Captioning Performance  Precision   \n",
      "10       10     Pitch  Female  Speech Captioning Performance     Recall   \n",
      "11       11     Pitch  Female  Speech Captioning Performance   F1-score   \n",
      "12       12    Energy    Male  Speech Captioning Performance  Precision   \n",
      "13       13    Energy    Male  Speech Captioning Performance     Recall   \n",
      "14       14    Energy    Male  Speech Captioning Performance   F1-score   \n",
      "15       15    Energy  Female  Speech Captioning Performance  Precision   \n",
      "16       16    Energy  Female  Speech Captioning Performance     Recall   \n",
      "17       17    Energy  Female  Speech Captioning Performance   F1-score   \n",
      "18       18     Speed    Male  Speech Captioning Performance  Precision   \n",
      "19       19     Speed    Male  Speech Captioning Performance     Recall   \n",
      "20       20     Speed    Male  Speech Captioning Performance   F1-score   \n",
      "21       21     Speed  Female  Speech Captioning Performance  Precision   \n",
      "22       22     Speed  Female  Speech Captioning Performance     Recall   \n",
      "23       23     Speed  Female  Speech Captioning Performance   F1-score   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0     84.3  2406.12707        3  \n",
      "1     85.4  2406.12707        3  \n",
      "2     84.2  2406.12707        3  \n",
      "3     87.4  2406.12707        3  \n",
      "4     85.5  2406.12707        3  \n",
      "5     86.0  2406.12707        3  \n",
      "6     88.2  2406.12707        3  \n",
      "7     82.8  2406.12707        3  \n",
      "8     85.3  2406.12707        3  \n",
      "9     84.8  2406.12707        3  \n",
      "10    71.0  2406.12707        3  \n",
      "11    75.9  2406.12707        3  \n",
      "12    74.4  2406.12707        3  \n",
      "13    60.0  2406.12707        3  \n",
      "14    65.0  2406.12707        3  \n",
      "15    71.2  2406.12707        3  \n",
      "16    54.9  2406.12707        3  \n",
      "17    60.9  2406.12707        3  \n",
      "18    46.4  2406.12707        3  \n",
      "19    43.1  2406.12707        3  \n",
      "20    44.6  2406.12707        3  \n",
      "21    48.0  2406.12707        3  \n",
      "22    30.6  2406.12707        3  \n",
      "23    37.3  2406.12707        3  \n",
      "   claim_id                        task query_budget           Method  \\\n",
      "0         0  Jailbreak general-use LLMs           40             PAIR   \n",
      "1         1  Jailbreak general-use LLMs           40             PAIR   \n",
      "2         2  Jailbreak general-use LLMs           40             PAIR   \n",
      "3         3  Jailbreak general-use LLMs           40             PAIR   \n",
      "4         4  Jailbreak general-use LLMs           40             PAIR   \n",
      "5         5  Jailbreak general-use LLMs           40             PAIR   \n",
      "6         6  Jailbreak general-use LLMs           40             PAIR   \n",
      "7         7  Jailbreak general-use LLMs           40             PAIR   \n",
      "8         8  Jailbreak general-use LLMs           40             PAIR   \n",
      "9         9  Jailbreak general-use LLMs           40             PAIR   \n",
      "10       10  Jailbreak general-use LLMs           40             PAIR   \n",
      "11       11  Jailbreak general-use LLMs           40             PAIR   \n",
      "12       12  Jailbreak general-use LLMs           40              TAP   \n",
      "13       13  Jailbreak general-use LLMs           40              TAP   \n",
      "14       14  Jailbreak general-use LLMs           40              TAP   \n",
      "15       15  Jailbreak general-use LLMs           40              TAP   \n",
      "16       16  Jailbreak general-use LLMs           40              TAP   \n",
      "17       17  Jailbreak general-use LLMs           40              TAP   \n",
      "18       18  Jailbreak general-use LLMs           40              TAP   \n",
      "19       19  Jailbreak general-use LLMs           40              TAP   \n",
      "20       20  Jailbreak general-use LLMs           40              TAP   \n",
      "21       21  Jailbreak general-use LLMs           40              TAP   \n",
      "22       22  Jailbreak general-use LLMs           40              TAP   \n",
      "23       23  Jailbreak general-use LLMs           40              TAP   \n",
      "24       24  Jailbreak general-use LLMs           40              PAP   \n",
      "25       25  Jailbreak general-use LLMs           40              PAP   \n",
      "26       26  Jailbreak general-use LLMs           40              PAP   \n",
      "27       27  Jailbreak general-use LLMs           40              PAP   \n",
      "28       28  Jailbreak general-use LLMs           40              PAP   \n",
      "29       29  Jailbreak general-use LLMs           40              PAP   \n",
      "30       30  Jailbreak general-use LLMs           40              PAP   \n",
      "31       31  Jailbreak general-use LLMs           40              PAP   \n",
      "32       32  Jailbreak general-use LLMs           40              PAP   \n",
      "33       33  Jailbreak general-use LLMs           40              PAP   \n",
      "34       34  Jailbreak general-use LLMs           40              PAP   \n",
      "35       35  Jailbreak general-use LLMs           40              PAP   \n",
      "36       36  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "37       37  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "38       38  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "39       39  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "40       40  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "41       41  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "42       42  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "43       43  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "44       44  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "45       45  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "46       46  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "47       47  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "48       48  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "49       49  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "50       50  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "51       51  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "52       52  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "53       53  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "54       54  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "55       55  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "56       56  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "57       57  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "58       58  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "59       59  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "\n",
      "                 Model Measure Outcome    paper_id table_id  \n",
      "0       Vicuna-7b-v1.5     ASR      94  2407.16667        1  \n",
      "1       Vicuna-7b-v1.5     ANQ    6.72  2407.16667        1  \n",
      "2   LLaMa-2-7b-chat-hf     ASR      46  2407.16667        1  \n",
      "3   LLaMa-2-7b-chat-hf     ANQ   19.74  2407.16667        1  \n",
      "4   GPT-3.5-turbo-1106     ASR      64  2407.16667        1  \n",
      "5   GPT-3.5-turbo-1106     ANQ   13.25  2407.16667        1  \n",
      "6   GPT-4-1106-preview     ASR      74  2407.16667        1  \n",
      "7   GPT-4-1106-preview     ANQ    9.73  2407.16667        1  \n",
      "8           Gemini-Pro     ASR      94  2407.16667        1  \n",
      "9           Gemini-Pro     ANQ    7.75  2407.16667        1  \n",
      "10   Claude-3.5-sonnet     ASR      38  2407.16667        1  \n",
      "11   Claude-3.5-sonnet     ANQ   17.05  2407.16667        1  \n",
      "12      Vicuna-7b-v1.5     ASR      90  2407.16667        1  \n",
      "13      Vicuna-7b-v1.5     ANQ    4.58  2407.16667        1  \n",
      "14  LLaMa-2-7b-chat-hf     ASR      48  2407.16667        1  \n",
      "15  LLaMa-2-7b-chat-hf     ANQ   13.25  2407.16667        1  \n",
      "16  GPT-3.5-turbo-1106     ASR      36  2407.16667        1  \n",
      "17  GPT-3.5-turbo-1106     ANQ    9.67  2407.16667        1  \n",
      "18  GPT-4-1106-preview     ASR      62  2407.16667        1  \n",
      "19  GPT-4-1106-preview     ANQ    9.36  2407.16667        1  \n",
      "20          Gemini-Pro     ASR      86  2407.16667        1  \n",
      "21          Gemini-Pro     ANQ    6.21  2407.16667        1  \n",
      "22   Claude-3.5-sonnet     ASR      22  2407.16667        1  \n",
      "23   Claude-3.5-sonnet     ANQ      13  2407.16667        1  \n",
      "24      Vicuna-7b-v1.5     ASR      94  2407.16667        1  \n",
      "25      Vicuna-7b-v1.5     ANQ    4.15  2407.16667        1  \n",
      "26  LLaMa-2-7b-chat-hf     ASR      58  2407.16667        1  \n",
      "27  LLaMa-2-7b-chat-hf     ANQ   13.86  2407.16667        1  \n",
      "28  GPT-3.5-turbo-1106     ASR      58  2407.16667        1  \n",
      "29  GPT-3.5-turbo-1106     ANQ     9.1  2407.16667        1  \n",
      "30  GPT-4-1106-preview     ASR      92  2407.16667        1  \n",
      "31  GPT-4-1106-preview     ANQ    5.63  2407.16667        1  \n",
      "32          Gemini-Pro     ASR      96  2407.16667        1  \n",
      "33          Gemini-Pro     ANQ     2.1  2407.16667        1  \n",
      "34   Claude-3.5-sonnet     ASR      16  2407.16667        1  \n",
      "35   Claude-3.5-sonnet     ANQ   11.75  2407.16667        1  \n",
      "36      Vicuna-7b-v1.5     ASR     100  2407.16667        1  \n",
      "37      Vicuna-7b-v1.5     ANQ     1.2  2407.16667        1  \n",
      "38  LLaMa-2-7b-chat-hf     ASR      62  2407.16667        1  \n",
      "39  LLaMa-2-7b-chat-hf     ANQ   17.26  2407.16667        1  \n",
      "40  GPT-3.5-turbo-1106     ASR      50  2407.16667        1  \n",
      "41  GPT-3.5-turbo-1106     ANQ   15.04  2407.16667        1  \n",
      "42  GPT-4-1106-preview     ASR      12  2407.16667        1  \n",
      "43  GPT-4-1106-preview     ANQ    9.17  2407.16667        1  \n",
      "44          Gemini-Pro     ASR      98  2407.16667        1  \n",
      "45          Gemini-Pro     ANQ   2.306  2407.16667        1  \n",
      "46   Claude-3.5-sonnet     ASR       0  2407.16667        1  \n",
      "47   Claude-3.5-sonnet     ANQ     N/A  2407.16667        1  \n",
      "48      Vicuna-7b-v1.5     ASR     100  2407.16667        1  \n",
      "49      Vicuna-7b-v1.5     ANQ    2.68  2407.16667        1  \n",
      "50  LLaMa-2-7b-chat-hf     ASR      92  2407.16667        1  \n",
      "51  LLaMa-2-7b-chat-hf     ANQ    6.89  2407.16667        1  \n",
      "52  GPT-3.5-turbo-1106     ASR      96  2407.16667        1  \n",
      "53  GPT-3.5-turbo-1106     ANQ    5.73  2407.16667        1  \n",
      "54  GPT-4-1106-preview     ASR     100  2407.16667        1  \n",
      "55  GPT-4-1106-preview     ANQ    3.76  2407.16667        1  \n",
      "56          Gemini-Pro     ASR     100  2407.16667        1  \n",
      "57          Gemini-Pro     ANQ    3.76  2407.16667        1  \n",
      "58   Claude-3.5-sonnet     ASR      74  2407.16667        1  \n",
      "59   Claude-3.5-sonnet     ANQ    9.54  2407.16667        1  \n",
      "  claim_id                                        task               model  \\\n",
      "0        0  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "1        1  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "2        2  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "3        3  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "4        4  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "5        5  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "6        6  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "7        7  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "8        8  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "9        9  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "\n",
      "  query_budget Memory Capacity  Measure Outcome    paper_id table_id  \n",
      "0         same               0  ASR (%)      60  2407.16667        3  \n",
      "1         same               1  ASR (%)      52  2407.16667        3  \n",
      "2         same              10  ASR (%)      76  2407.16667        3  \n",
      "3         same              25  ASR (%)      92  2407.16667        3  \n",
      "4         same              50  ASR (%)      72  2407.16667        3  \n",
      "5         same               0      ANQ    6.05  2407.16667        3  \n",
      "6         same               1      ANQ    4.63  2407.16667        3  \n",
      "7         same              10      ANQ    3.57  2407.16667        3  \n",
      "8         same              25      ANQ    4.65  2407.16667        3  \n",
      "9         same              50      ANQ    3.53  2407.16667        3  \n",
      "  claim_id                                           task               model  \\\n",
      "0        0  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "1        1  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "2        2  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "3        3  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "4        4  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "5        5  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "6        6  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "7        7  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "\n",
      "  Memory Tag Configuration  Measure Outcome    paper_id table_id  \n",
      "0                  Default  ASR (%)      92  2407.16667        4  \n",
      "1                  w/o Cat  ASR (%)      88  2407.16667        4  \n",
      "2                  w/o Que  ASR (%)      92  2407.16667        4  \n",
      "3            w/o Cat & Que  ASR (%)      92  2407.16667        4  \n",
      "4                  Default      ANQ    4.65  2407.16667        4  \n",
      "5                  w/o Cat      ANQ    5.31  2407.16667        4  \n",
      "6                  w/o Que      ANQ     6.3  2407.16667        4  \n",
      "7            w/o Cat & Que      ANQ       9  2407.16667        4  \n",
      "   claim_id   Method Dataset Measure Outcome    paper_id table_id\n",
      "0         0      Pop   ML-1M     N@1    0.26  2407.17115        2\n",
      "1         1      Pop   ML-1M     N@5    0.60  2407.17115        2\n",
      "2         2      Pop   ML-1M    N@10    0.63  2407.17115        2\n",
      "3         3      Pop   Games     N@1    0.39  2407.17115        2\n",
      "4         4      Pop   Games     N@5    0.61  2407.17115        2\n",
      "5         5      Pop   Games    N@10    0.67  2407.17115        2\n",
      "6         6      Pop  Lastfm     N@1    0.78  2407.17115        2\n",
      "7         7      Pop  Lastfm     N@5    0.86  2407.17115        2\n",
      "8         8      Pop  Lastfm    N@10    0.88  2407.17115        2\n",
      "9         9    BPRMF   ML-1M     N@1    0.44  2407.17115        2\n",
      "10       10    BPRMF   ML-1M     N@5    0.71  2407.17115        2\n",
      "11       11    BPRMF   ML-1M    N@10    0.74  2407.17115        2\n",
      "12       12    BPRMF   Games     N@1    0.57  2407.17115        2\n",
      "13       13    BPRMF   Games     N@5    0.75  2407.17115        2\n",
      "14       14    BPRMF   Games    N@10    0.78  2407.17115        2\n",
      "15       15    BPRMF  Lastfm     N@1    0.71  2407.17115        2\n",
      "16       16    BPRMF  Lastfm     N@5    0.80  2407.17115        2\n",
      "17       17    BPRMF  Lastfm    N@10    0.84  2407.17115        2\n",
      "18       18   SASRec   ML-1M     N@1    0.68  2407.17115        2\n",
      "19       19   SASRec   ML-1M     N@5    0.84  2407.17115        2\n",
      "20       20   SASRec   ML-1M    N@10    0.85  2407.17115        2\n",
      "21       21   SASRec   Games     N@1    0.69  2407.17115        2\n",
      "22       22   SASRec   Games     N@5    0.83  2407.17115        2\n",
      "23       23   SASRec   Games    N@10    0.85  2407.17115        2\n",
      "24       24   SASRec  Lastfm     N@1    0.81  2407.17115        2\n",
      "25       25   SASRec  Lastfm     N@5    0.88  2407.17115        2\n",
      "26       26   SASRec  Lastfm    N@10    0.89  2407.17115        2\n",
      "27       27     BM25   ML-1M     N@1    0.08  2407.17115        2\n",
      "28       28     BM25   ML-1M     N@5    0.20  2407.17115        2\n",
      "29       29     BM25   ML-1M    N@10    0.43  2407.17115        2\n",
      "30       30     BM25   Games     N@1    0.27  2407.17115        2\n",
      "31       31     BM25   Games     N@5    0.45  2407.17115        2\n",
      "32       32     BM25   Games    N@10    0.57  2407.17115        2\n",
      "33       33     BM25  Lastfm     N@1     N/A  2407.17115        2\n",
      "34       34     BM25  Lastfm     N@5     N/A  2407.17115        2\n",
      "35       35     BM25  Lastfm    N@10     N/A  2407.17115        2\n",
      "36       36  UniSRec   ML-1M     N@1    0.12  2407.17115        2\n",
      "37       37  UniSRec   ML-1M     N@5    0.35  2407.17115        2\n",
      "38       38  UniSRec   ML-1M    N@10    0.47  2407.17115        2\n",
      "39       39  UniSRec   Games     N@1    0.25  2407.17115        2\n",
      "40       40  UniSRec   Games     N@5    0.45  2407.17115        2\n",
      "41       41  UniSRec   Games    N@10    0.56  2407.17115        2\n",
      "42       42  UniSRec  Lastfm     N@1     N/A  2407.17115        2\n",
      "43       43  UniSRec  Lastfm     N@5     N/A  2407.17115        2\n",
      "44       44  UniSRec  Lastfm    N@10     N/A  2407.17115        2\n",
      "45       45   VQ-Rec   ML-1M     N@1    0.10  2407.17115        2\n",
      "46       46   VQ-Rec   ML-1M     N@5    0.33  2407.17115        2\n",
      "47       47   VQ-Rec   ML-1M    N@10    0.47  2407.17115        2\n",
      "48       48   VQ-Rec   Games     N@1    0.14  2407.17115        2\n",
      "49       49   VQ-Rec   Games     N@5    0.33  2407.17115        2\n",
      "50       50   VQ-Rec   Games    N@10    0.48  2407.17115        2\n",
      "51       51   VQ-Rec  Lastfm     N@1     N/A  2407.17115        2\n",
      "52       52   VQ-Rec  Lastfm     N@5     N/A  2407.17115        2\n",
      "53       53   VQ-Rec  Lastfm    N@10     N/A  2407.17115        2\n",
      "   claim_id          Method Dataset Metric                              Task  \\\n",
      "0         0  Manual prompts   ML-1M    N@1  Enhancing Recommendation Ability   \n",
      "1         1  Manual prompts   ML-1M    N@5  Enhancing Recommendation Ability   \n",
      "2         2  Manual prompts   ML-1M   N@10  Enhancing Recommendation Ability   \n",
      "3         3  Manual prompts   Games    N@1  Enhancing Recommendation Ability   \n",
      "4         4  Manual prompts   Games    N@5  Enhancing Recommendation Ability   \n",
      "..      ...             ...     ...    ...                               ...   \n",
      "58       58             RPP   Games    N@5  Enhancing Recommendation Ability   \n",
      "59       59             RPP   Games   N@10  Enhancing Recommendation Ability   \n",
      "60       60             RPP  Lastfm    N@1  Enhancing Recommendation Ability   \n",
      "61       61             RPP  Lastfm    N@5  Enhancing Recommendation Ability   \n",
      "62       62             RPP  Lastfm   N@10  Enhancing Recommendation Ability   \n",
      "\n",
      "    Measure    Outcome    paper_id table_id  \n",
      "0   Outcome  0.03±0.02  2407.17115        4  \n",
      "1   Outcome  0.35±0.01  2407.17115        4  \n",
      "2   Outcome  0.41±0.01  2407.17115        4  \n",
      "3   Outcome  0.04±0.01  2407.17115        4  \n",
      "4   Outcome  0.30±0.02  2407.17115        4  \n",
      "..      ...        ...         ...      ...  \n",
      "58  Outcome  0.82±0.03  2407.17115        4  \n",
      "59  Outcome  0.85±0.02  2407.17115        4  \n",
      "60  Outcome  0.87±0.01  2407.17115        4  \n",
      "61  Outcome  0.89±0.01  2407.17115        4  \n",
      "62  Outcome  0.91±0.01  2407.17115        4  \n",
      "\n",
      "[63 rows x 9 columns]\n",
      "   claim_id                    Task          Method Dataset Measure Outcome  \\\n",
      "0         0  Ablation study on RPP+  Manual prompts   ML-1M     N@1    0.03   \n",
      "1         1  Ablation study on RPP+  Manual prompts   ML-1M     N@5    0.35   \n",
      "2         2  Ablation study on RPP+  Manual prompts   ML-1M    N@10    0.41   \n",
      "3         3  Ablation study on RPP+  Manual prompts   Games     N@1    0.04   \n",
      "4         4  Ablation study on RPP+  Manual prompts   Games     N@5    0.36   \n",
      "..      ...                     ...             ...     ...     ...     ...   \n",
      "58       58  Ablation study on RPP+            RPP+   Games     N@5    0.87   \n",
      "59       59  Ablation study on RPP+            RPP+   Games    N@10    0.91   \n",
      "60       60  Ablation study on RPP+            RPP+  Lastfm     N@1    0.93   \n",
      "61       61  Ablation study on RPP+            RPP+  Lastfm     N@5    0.94   \n",
      "62       62  Ablation study on RPP+            RPP+  Lastfm    N@10    0.95   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2407.17115        5  \n",
      "1   2407.17115        5  \n",
      "2   2407.17115        5  \n",
      "3   2407.17115        5  \n",
      "4   2407.17115        5  \n",
      "..         ...      ...  \n",
      "58  2407.17115        5  \n",
      "59  2407.17115        5  \n",
      "60  2407.17115        5  \n",
      "61  2407.17115        5  \n",
      "62  2407.17115        5  \n",
      "\n",
      "[63 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "claims_df = []\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    df = load_json_as_df(filename)\n",
    "    print(df)\n",
    "    claims_df.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alignment_name_schema.json', 'r') as file:\n",
    "    align_name = json.load(file)\n",
    "\n",
    "with open('alignment_values_schema.json', 'r') as file:\n",
    "    align_value = json.load(file)\n",
    "\n",
    "aligned_df = pd.DataFrame(columns=align_name.keys())\n",
    "\n",
    "excluded_columns = ['outcome', 'table_id', 'paper_id', 'claim_id']\n",
    "\n",
    "for claim_df in claims_df:\n",
    "    for _, row in claim_df.iterrows():\n",
    "        aligned_row = {key: None for key in align_name.keys()}\n",
    "        aligned_row[\"outcome\"] = row[\"Outcome\"]\n",
    "        aligned_row[\"table_id\"] = row[\"table_id\"]\n",
    "        aligned_row[\"paper_id\"] = row[\"paper_id\"]\n",
    "        aligned_row[\"claim_id\"] = row[\"claim_id\"]\n",
    "        for name_key, name_values in align_name.items():\n",
    "            for col in [c for c in claim_df.columns if c not in excluded_columns]:\n",
    "                if row[col].lower() in name_values:\n",
    "                    for value_key, value_value in align_value.items():\n",
    "                        if value_value is not None and row[col].lower() in value_value:\n",
    "                            aligned_row[name_key] = value_key\n",
    "                            break\n",
    "                        else:\n",
    "                            aligned_row[name_key] = row[col]\n",
    "        aligned_df = pd.concat([aligned_df, pd.DataFrame([aligned_row])], ignore_index=True)\n",
    "\n",
    "aligned_df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON pe paulo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_spec_id(filename, claim_id, flag):\n",
    "    with open(os.path.join(INPUT_DIR, filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for key, value in data[claim_id]['specifications'].items():\n",
    "        if value['value'] == flag:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constr_filename(paper_id, table_id):\n",
    "    return f'{paper_id}_{table_id}_claims.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aligned_names': {'agent configuration': ['2403.04783_4_0_0', '2403.04783_4_1_0', '2403.04783_4_2_0', '2403.04783_4_3_0', '2403.04783_4_4_0', '2403.04783_4_5_0'], 'attack method': ['2403.04783_1_0_0', '2403.04783_1_1_0', '2403.04783_1_2_0', '2403.04783_1_3_0', '2403.04783_1_4_0', '2403.04783_1_5_0', '2403.04783_1_6_0', '2403.04783_1_7_0', '2403.04783_1_8_0', '2403.04783_1_9_0', '2403.04783_1_10_0', '2403.04783_1_11_0', '2403.04783_1_12_0', '2403.04783_1_13_0', '2403.04783_1_14_0', '2403.04783_1_15_0', '2403.04783_1_16_0', '2403.04783_1_17_0', '2403.04783_1_18_0', '2403.04783_1_19_0'], 'attribute': ['2406.12707_3_0_0', '2406.12707_3_1_0', '2406.12707_3_2_0', '2406.12707_3_3_0', '2406.12707_3_4_0', '2406.12707_3_5_0', '2406.12707_3_6_0', '2406.12707_3_7_0', '2406.12707_3_8_0', '2406.12707_3_9_0', '2406.12707_3_10_0', '2406.12707_3_11_0', '2406.12707_3_12_0', '2406.12707_3_13_0', '2406.12707_3_14_0', '2406.12707_3_15_0', '2406.12707_3_16_0', '2406.12707_3_17_0', '2406.12707_3_18_0', '2406.12707_3_19_0', '2406.12707_3_20_0', '2406.12707_3_21_0', '2406.12707_3_22_0', '2406.12707_3_23_0'], 'dataset': ['2308.12519_1_0_1', '2308.12519_1_1_1', '2308.12519_1_2_1', '2308.12519_1_3_1', '2308.12519_1_4_1', '2308.12519_1_5_1', '2308.12519_1_6_1', '2308.12519_2_0_1', '2308.12519_2_1_1', '2308.12519_2_2_1', '2308.12519_2_3_1', '2308.12519_2_4_1', '2308.12519_2_5_1', '2308.12519_2_6_1', '2308.12519_3_0_1', '2308.12519_3_1_1', '2308.12519_3_2_1', '2308.12519_3_3_1', '2308.12519_3_4_1', '2308.12519_3_5_1', '2308.12519_3_6_1', '2308.12519_3_7_1', '2308.12519_3_8_1', '2308.12519_3_9_1', '2308.12519_3_10_1', '2308.12519_3_11_1', '2308.12519_3_12_1', '2308.12519_3_13_1', '2308.12519_3_14_1', '2308.12519_3_15_1', '2308.12519_3_16_1', '2308.12519_3_17_1', '2308.12519_3_18_1', '2308.12519_3_19_1', '2308.12519_3_20_1', '2308.12519_3_21_1', '2308.12519_3_22_1', '2308.12519_3_23_1', '2310.01444_4_0_1', '2310.01444_4_1_1', '2310.01444_4_2_1', '2310.01444_4_3_1', '2310.01444_4_4_1', '2310.01444_4_5_1', '2402.10890_1_0_1', '2402.10890_1_1_1', '2402.10890_1_2_1', '2402.10890_1_3_1', '2402.10890_1_4_1', '2402.10890_1_5_1', '2402.10890_1_6_1', '2402.10890_1_7_1', '2402.10890_1_8_1', '2402.10890_1_9_1', '2402.10890_1_10_1', '2402.10890_1_11_1', '2402.10890_1_12_1', '2402.10890_1_13_1', '2402.10890_1_14_1', '2402.10890_1_15_1', '2402.10890_1_16_1', '2402.10890_1_17_1', '2402.10890_1_18_1', '2402.10890_1_19_1', '2402.10890_1_20_1', '2402.10890_1_21_1', '2402.10890_1_22_1', '2402.10890_1_23_1', '2402.10890_1_24_1', '2402.10890_1_25_1', '2402.10890_1_26_1', '2402.10890_1_27_1', '2402.10890_1_28_1', '2402.10890_1_29_1', '2402.10890_1_30_1', '2402.10890_1_31_1', '2402.10890_1_32_1', '2402.10890_1_33_1', '2402.10890_1_34_1', '2402.10890_1_35_1', '2402.10890_1_36_1', '2402.10890_1_37_1', '2402.10890_1_38_1', '2402.10890_1_39_1', '2402.10890_1_40_1', '2402.10890_1_41_1', '2402.10890_1_42_1', '2402.10890_1_43_1', '2402.10890_1_44_1', '2402.10890_1_45_1', '2402.10890_1_46_1', '2402.10890_1_47_1', '2402.10890_1_48_1', '2402.10890_1_49_1', '2402.10890_1_50_1', '2402.10890_1_51_1', '2402.10890_1_52_1', '2402.10890_1_53_1', '2402.10890_1_54_1', '2402.10890_1_55_1', '2402.10890_1_56_1', '2402.10890_1_57_1', '2402.10890_1_58_1', '2402.10890_1_59_1', '2402.10890_1_60_1', '2402.10890_1_61_1', '2402.10890_1_62_1', '2402.10890_1_63_1', '2402.10890_1_64_1', '2402.10890_1_65_1', '2402.10890_1_66_1', '2402.10890_1_67_1', '2402.10890_1_68_1', '2402.10890_1_69_1', '2402.10890_1_70_1', '2402.10890_1_71_1', '2402.10890_2_0_1', '2402.10890_2_1_1', '2402.10890_2_2_1', '2402.10890_2_3_1', '2402.10890_2_4_1', '2402.10890_2_5_1', '2402.10890_2_6_1', '2402.10890_2_7_1', '2402.10890_2_8_1', '2402.10890_2_9_1', '2402.10890_2_10_1', '2402.10890_2_11_1', '2402.10890_2_12_1', '2402.10890_2_13_1', '2402.10890_2_14_1', '2402.10890_2_15_1', '2402.10890_2_16_1', '2402.10890_2_17_1', '2402.10890_2_18_1', '2402.10890_2_19_1', '2402.10890_2_20_1', '2402.10890_2_21_1', '2402.10890_2_22_1', '2402.10890_2_23_1', '2402.10890_2_24_1', '2402.10890_2_25_1', '2402.10890_2_26_1', '2402.10890_2_27_1', '2402.10890_2_28_1', '2402.10890_2_29_1', '2402.10890_2_30_1', '2402.10890_2_31_1', '2402.10890_2_32_1', '2402.10890_2_33_1', '2402.10890_2_34_1', '2402.10890_2_35_1', '2402.10890_3_0_1', '2402.10890_3_1_1', '2402.10890_3_2_1', '2402.10890_3_3_1', '2402.10890_3_4_1', '2402.10890_3_5_1', '2402.10890_3_6_1', '2402.10890_3_7_1', '2402.10890_3_8_1', '2402.10890_3_9_1', '2402.10890_3_10_1', '2402.10890_3_11_1', '2402.10890_3_12_1', '2402.10890_3_13_1', '2402.10890_3_14_1', '2402.10890_3_15_1', '2402.10890_3_16_1', '2402.10890_3_17_1', '2402.10890_3_18_1', '2402.10890_3_19_1', '2402.10890_3_20_1', '2402.10890_3_21_1', '2402.10890_3_22_1', '2402.10890_3_23_1', '2403.04783_1_0_2', '2403.04783_1_1_2', '2403.04783_1_2_2', '2403.04783_1_3_2', '2403.04783_1_4_2', '2403.04783_1_5_2', '2403.04783_1_6_2', '2403.04783_1_7_2', '2403.04783_1_8_2', '2403.04783_1_9_2', '2403.04783_1_10_2', '2403.04783_1_11_2', '2403.04783_1_12_2', '2403.04783_1_13_2', '2403.04783_1_14_2', '2403.04783_1_15_2', '2403.04783_1_16_2', '2403.04783_1_17_2', '2403.04783_1_18_2', '2403.04783_1_19_2', '2403.04783_1_20_2', '2403.04783_1_21_2', '2403.04783_1_22_2', '2403.04783_1_23_2', '2405.17129_1_0_1', '2405.17129_1_1_1', '2405.17129_1_2_1', '2405.17129_1_3_1', '2405.17129_1_4_1', '2405.17129_1_5_1', '2405.17129_1_6_1', '2405.17129_1_7_1', '2405.17129_1_8_1', '2405.17129_1_9_1', '2405.17129_1_10_1', '2405.17129_1_11_1', '2405.17129_1_12_1', '2405.17129_1_13_1', '2405.17129_1_14_1', '2405.17129_1_15_1', '2405.17129_1_16_1', '2405.17129_1_17_1', '2405.17129_1_18_1', '2405.17129_1_19_1', '2405.17129_1_20_1', '2405.17129_1_21_1', '2405.17129_1_22_1', '2405.17129_1_23_1', '2405.17129_1_24_1', '2405.17129_1_25_1', '2405.17129_1_26_1', '2405.17129_1_27_1', '2405.17129_1_28_1', '2405.17129_1_29_1', '2405.17129_5_0_1', '2405.17129_5_1_1', '2405.17129_5_2_1', '2405.17129_5_3_1', '2405.17129_5_4_1', '2405.17129_5_5_1', '2405.17129_5_6_1', '2405.17129_5_7_1', '2405.17129_5_8_1', '2405.17129_5_9_1', '2405.17129_5_10_1', '2405.17129_5_11_1', '2405.17129_5_12_1', '2405.17129_5_13_1', '2405.17129_5_14_1', '2405.17129_5_15_1', '2406.12707_2_0_1', '2406.12707_2_1_1', '2406.12707_2_2_1', '2406.12707_2_3_1', '2406.12707_2_4_1', '2406.12707_2_5_1', '2407.17115_2_0_1', '2407.17115_2_1_1', '2407.17115_2_2_1', '2407.17115_2_3_1', '2407.17115_2_4_1', '2407.17115_2_5_1', '2407.17115_2_6_1', '2407.17115_2_7_1', '2407.17115_2_8_1', '2407.17115_2_9_1', '2407.17115_2_10_1', '2407.17115_2_11_1', '2407.17115_2_12_1', '2407.17115_2_13_1', '2407.17115_2_14_1', '2407.17115_2_15_1', '2407.17115_2_16_1', '2407.17115_2_17_1', '2407.17115_2_18_1', '2407.17115_2_19_1', '2407.17115_2_20_1', '2407.17115_2_21_1', '2407.17115_2_22_1', '2407.17115_2_23_1', '2407.17115_2_24_1', '2407.17115_2_25_1', '2407.17115_2_26_1', '2407.17115_2_27_1', '2407.17115_2_28_1', '2407.17115_2_29_1', '2407.17115_2_30_1', '2407.17115_2_31_1', '2407.17115_2_32_1', '2407.17115_2_33_1', '2407.17115_2_34_1', '2407.17115_2_35_1', '2407.17115_2_36_1', '2407.17115_2_37_1', '2407.17115_2_38_1', '2407.17115_2_39_1', '2407.17115_2_40_1', '2407.17115_2_41_1', '2407.17115_2_42_1', '2407.17115_2_43_1', '2407.17115_2_44_1', '2407.17115_2_45_1', '2407.17115_2_46_1', '2407.17115_2_47_1', '2407.17115_2_48_1', '2407.17115_2_49_1', '2407.17115_2_50_1', '2407.17115_2_51_1', '2407.17115_2_52_1', '2407.17115_2_53_1', '2407.17115_4_0_1', '2407.17115_4_1_1', '2407.17115_4_2_1', '2407.17115_4_3_1', '2407.17115_4_4_1', '2407.17115_4_5_1', '2407.17115_4_6_1', '2407.17115_4_7_1', '2407.17115_4_8_1', '2407.17115_4_9_1', '2407.17115_4_10_1', '2407.17115_4_11_1', '2407.17115_4_12_1', '2407.17115_4_13_1', '2407.17115_4_14_1', '2407.17115_4_15_1', '2407.17115_4_16_1', '2407.17115_4_17_1', '2407.17115_4_18_1', '2407.17115_4_19_1', '2407.17115_4_20_1', '2407.17115_4_21_1', '2407.17115_4_22_1', '2407.17115_4_23_1', '2407.17115_4_24_1', '2407.17115_4_25_1', '2407.17115_4_26_1', '2407.17115_4_27_1', '2407.17115_4_28_1', '2407.17115_4_29_1', '2407.17115_4_30_1', '2407.17115_4_31_1', '2407.17115_4_32_1', '2407.17115_4_33_1', '2407.17115_4_34_1', '2407.17115_4_35_1', '2407.17115_4_36_1', '2407.17115_4_37_1', '2407.17115_4_38_1', '2407.17115_4_39_1', '2407.17115_4_40_1', '2407.17115_4_41_1', '2407.17115_4_42_1', '2407.17115_4_43_1', '2407.17115_4_44_1', '2407.17115_4_45_1', '2407.17115_4_46_1', '2407.17115_4_47_1', '2407.17115_4_48_1', '2407.17115_4_49_1', '2407.17115_4_50_1', '2407.17115_4_51_1', '2407.17115_4_52_1', '2407.17115_4_53_1', '2407.17115_4_54_1', '2407.17115_4_55_1', '2407.17115_4_56_1', '2407.17115_4_57_1', '2407.17115_4_58_1', '2407.17115_4_59_1', '2407.17115_4_60_1', '2407.17115_4_61_1', '2407.17115_4_62_1', '2407.17115_5_0_2', '2407.17115_5_1_2', '2407.17115_5_2_2', '2407.17115_5_3_2', '2407.17115_5_4_2', '2407.17115_5_5_2', '2407.17115_5_6_2', '2407.17115_5_7_2', '2407.17115_5_8_2', '2407.17115_5_9_2', '2407.17115_5_10_2', '2407.17115_5_11_2', '2407.17115_5_12_2', '2407.17115_5_13_2', '2407.17115_5_14_2', '2407.17115_5_15_2', '2407.17115_5_16_2', '2407.17115_5_17_2', '2407.17115_5_18_2', '2407.17115_5_19_2', '2407.17115_5_20_2', '2407.17115_5_21_2', '2407.17115_5_22_2', '2407.17115_5_23_2', '2407.17115_5_24_2', '2407.17115_5_25_2', '2407.17115_5_26_2', '2407.17115_5_27_2', '2407.17115_5_28_2', '2407.17115_5_29_2', '2407.17115_5_30_2', '2407.17115_5_31_2', '2407.17115_5_32_2', '2407.17115_5_33_2', '2407.17115_5_34_2', '2407.17115_5_35_2', '2407.17115_5_36_2', '2407.17115_5_37_2', '2407.17115_5_38_2', '2407.17115_5_39_2', '2407.17115_5_40_2', '2407.17115_5_41_2', '2407.17115_5_42_2', '2407.17115_5_43_2', '2407.17115_5_44_2', '2407.17115_5_45_2', '2407.17115_5_46_2', '2407.17115_5_47_2', '2407.17115_5_48_2', '2407.17115_5_49_2', '2407.17115_5_50_2', '2407.17115_5_51_2', '2407.17115_5_52_2', '2407.17115_5_53_2', '2407.17115_5_54_2', '2407.17115_5_55_2', '2407.17115_5_56_2', '2407.17115_5_57_2', '2407.17115_5_58_2', '2407.17115_5_59_2', '2407.17115_5_60_2', '2407.17115_5_61_2', '2407.17115_5_62_2'], 'emotion label': ['2405.17129_4_0_0', '2405.17129_4_1_0', '2405.17129_4_2_0', '2405.17129_4_3_0', '2405.17129_4_4_0', '2405.17129_4_5_0', '2405.17129_4_6_0', '2405.17129_4_7_0', '2405.17129_4_8_0', '2405.17129_4_9_0', '2405.17129_4_10_0', '2405.17129_4_11_0', '2405.17129_4_12_0', '2405.17129_4_13_0', '2405.17129_4_14_0', '2405.17129_4_15_0', '2405.17129_4_16_0', '2405.17129_4_17_0', '2405.17129_4_18_0', '2405.17129_4_19_0', '2405.17129_4_20_0', '2405.17129_4_21_0', '2405.17129_4_22_0', '2405.17129_4_23_0'], 'evaluation level': ['2406.03075_2_0_1', '2406.03075_2_1_1', '2406.03075_2_2_1', '2406.03075_2_3_1', '2406.03075_2_4_1', '2406.03075_2_5_1', '2406.03075_2_6_1', '2406.03075_2_7_1', '2406.03075_2_8_1', '2406.03075_2_9_1', '2406.03075_2_10_1', '2406.03075_2_11_1', '2406.03075_2_12_1', '2406.03075_2_13_1', '2406.03075_2_14_1', '2406.03075_2_15_1', '2406.03075_2_16_1', '2406.03075_2_17_1', '2406.03075_2_18_1', '2406.03075_2_19_1', '2406.03075_2_20_1', '2406.03075_2_21_1', '2406.03075_2_22_1', '2406.03075_2_23_1', '2406.03075_2_24_1', '2406.03075_2_25_1', '2406.03075_2_26_1', '2406.03075_2_27_1', '2406.03075_2_28_1', '2406.03075_2_29_1', '2406.03075_2_30_1', '2406.03075_2_31_1'], 'gender': ['2406.12707_3_0_1', '2406.12707_3_1_1', '2406.12707_3_2_1', '2406.12707_3_3_1', '2406.12707_3_4_1', '2406.12707_3_5_1', '2406.12707_3_6_1', '2406.12707_3_7_1', '2406.12707_3_8_1', '2406.12707_3_9_1', '2406.12707_3_10_1', '2406.12707_3_11_1', '2406.12707_3_12_1', '2406.12707_3_13_1', '2406.12707_3_14_1', '2406.12707_3_15_1', '2406.12707_3_16_1', '2406.12707_3_17_1', '2406.12707_3_18_1', '2406.12707_3_19_1', '2406.12707_3_20_1', '2406.12707_3_21_1', '2406.12707_3_22_1', '2406.12707_3_23_1'], 'memory capacity': ['2310.03965_1_0_4', '2310.03965_1_3_4', '2310.03965_1_6_4', '2310.03965_1_9_4', '2310.03965_1_12_4', '2310.03965_1_15_4', '2310.03965_1_18_4', '2310.03965_1_21_4', '2310.03965_1_24_4', '2310.03965_1_27_4', '2310.03965_1_30_4', '2310.03965_1_33_4', '2310.03965_1_36_4', '2310.03965_1_39_4', '2310.03965_1_42_4', '2310.03965_1_45_4', '2310.03965_1_48_4', '2310.03965_1_51_4', '2310.03965_1_54_4', '2310.03965_1_57_4', '2310.03965_1_60_4', '2310.03965_1_63_4', '2310.03965_1_66_4', '2310.03965_1_69_4', '2310.03965_1_72_4', '2310.03965_1_75_4', '2310.03965_1_78_4', '2310.03965_1_81_4', '2310.03965_1_84_4', '2310.03965_1_87_4', '2310.03965_1_90_4', '2310.03965_1_93_4', '2310.03965_1_96_4', '2310.03965_1_99_4', '2310.03965_1_102_4', '2310.03965_1_105_4', '2310.03965_1_108_4', '2310.03965_1_111_4', '2310.03965_1_114_4', '2310.03965_1_117_4', '2310.03965_1_120_4', '2310.03965_1_123_4', '2407.16667_3_0_3', '2407.16667_3_1_3', '2407.16667_3_2_3', '2407.16667_3_3_3', '2407.16667_3_4_3', '2407.16667_3_5_3', '2407.16667_3_6_3', '2407.16667_3_7_3', '2407.16667_3_8_3', '2407.16667_3_9_3'], 'memory tag configuration': ['2407.16667_4_0_2', '2407.16667_4_1_2', '2407.16667_4_2_2', '2407.16667_4_3_2', '2407.16667_4_4_2', '2407.16667_4_5_2', '2407.16667_4_6_2', '2407.16667_4_7_2'], 'method': ['2308.12519_1_0_0', '2308.12519_1_1_0', '2308.12519_1_3_0', '2308.12519_1_5_0', '2308.12519_1_6_0', '2308.12519_2_0_0', '2308.12519_2_2_0', '2308.12519_2_3_0', '2308.12519_2_4_0', '2308.12519_2_5_0', '2308.12519_2_6_0', '2308.12519_3_0_0', '2308.12519_3_1_0', '2308.12519_3_2_0', '2308.12519_3_3_0', '2308.12519_3_4_0', '2308.12519_3_5_0', '2308.12519_3_6_0', '2308.12519_3_7_0', '2308.12519_3_8_0', '2308.12519_3_9_0', '2308.12519_3_10_0', '2308.12519_3_11_0', '2308.12519_3_12_0', '2308.12519_3_13_0', '2308.12519_3_14_0', '2308.12519_3_15_0', '2308.12519_3_16_0', '2308.12519_3_17_0', '2308.12519_3_18_0', '2308.12519_3_19_0', '2308.12519_3_20_0', '2308.12519_3_21_0', '2308.12519_3_22_0', '2308.12519_3_23_0', '2310.01444_2_1_1', '2310.01444_2_2_1', '2310.01444_2_3_1', '2310.01444_2_4_1', '2310.01444_2_5_1', '2310.01444_2_6_1', '2310.01444_2_7_1', '2310.01444_2_8_1', '2310.01444_2_9_1', '2310.01444_2_10_1', '2310.01444_4_0_0', '2310.01444_4_1_0', '2310.01444_4_2_0', '2310.01444_4_3_0', '2310.01444_4_4_0', '2310.01444_4_5_0', '2310.03965_1_0_1', '2310.03965_1_1_1', '2310.03965_1_2_1', '2310.03965_1_3_1', '2310.03965_1_4_1', '2310.03965_1_5_1', '2310.03965_1_6_1', '2310.03965_1_7_1', '2310.03965_1_8_1', '2310.03965_1_9_1', '2310.03965_1_10_1', '2310.03965_1_11_1', '2310.03965_1_12_1', '2310.03965_1_13_1', '2310.03965_1_14_1', '2310.03965_1_15_1', '2310.03965_1_16_1', '2310.03965_1_17_1', '2310.03965_1_18_1', '2310.03965_1_19_1', '2310.03965_1_20_1', '2310.03965_1_21_1', '2310.03965_1_22_1', '2310.03965_1_23_1', '2310.03965_1_24_1', '2310.03965_1_25_1', '2310.03965_1_26_1', '2310.03965_1_27_1', '2310.03965_1_28_1', '2310.03965_1_29_1', '2310.03965_1_30_1', '2310.03965_1_31_1', '2310.03965_1_32_1', '2310.03965_1_33_1', '2310.03965_1_34_1', '2310.03965_1_35_1', '2310.03965_1_36_1', '2310.03965_1_37_1', '2310.03965_1_38_1', '2310.03965_1_39_1', '2310.03965_1_40_1', '2310.03965_1_41_1', '2310.03965_1_42_1', '2310.03965_1_43_1', '2310.03965_1_44_1', '2310.03965_1_45_1', '2310.03965_1_46_1', '2310.03965_1_47_1', '2310.03965_1_48_1', '2310.03965_1_49_1', '2310.03965_1_50_1', '2310.03965_1_51_1', '2310.03965_1_52_1', '2310.03965_1_53_1', '2310.03965_1_54_1', '2310.03965_1_55_1', '2310.03965_1_56_1', '2310.03965_1_57_1', '2310.03965_1_58_1', '2310.03965_1_59_1', '2310.03965_1_60_1', '2310.03965_1_61_1', '2310.03965_1_62_1', '2310.03965_1_63_1', '2310.03965_1_64_1', '2310.03965_1_65_1', '2310.03965_1_66_1', '2310.03965_1_67_1', '2310.03965_1_68_1', '2310.03965_1_69_1', '2310.03965_1_70_1', '2310.03965_1_71_1', '2310.03965_1_72_1', '2310.03965_1_73_1', '2310.03965_1_74_1', '2310.03965_1_75_1', '2310.03965_1_76_1', '2310.03965_1_77_1', '2310.03965_1_78_1', '2310.03965_1_79_1', '2310.03965_1_80_1', '2310.03965_1_81_1', '2310.03965_1_82_1', '2310.03965_1_83_1', '2310.03965_1_84_1', '2310.03965_1_85_1', '2310.03965_1_86_1', '2310.03965_1_87_1', '2310.03965_1_88_1', '2310.03965_1_89_1', '2310.03965_1_90_1', '2310.03965_1_91_1', '2310.03965_1_92_1', '2310.03965_1_93_1', '2310.03965_1_94_1', '2310.03965_1_95_1', '2310.03965_1_96_1', '2310.03965_1_97_1', '2310.03965_1_98_1', '2310.03965_1_99_1', '2310.03965_1_100_1', '2310.03965_1_101_1', '2310.03965_1_102_1', '2310.03965_1_103_1', '2310.03965_1_104_1', '2310.03965_1_105_1', '2310.03965_1_106_1', '2310.03965_1_107_1', '2310.03965_1_108_1', '2310.03965_1_109_1', '2310.03965_1_110_1', '2310.03965_1_111_1', '2310.03965_1_112_1', '2310.03965_1_113_1', '2310.03965_1_114_1', '2310.03965_1_115_1', '2310.03965_1_116_1', '2310.03965_1_117_1', '2310.03965_1_118_1', '2310.03965_1_119_1', '2310.03965_1_120_1', '2310.03965_1_121_1', '2310.03965_1_122_1', '2310.03965_1_123_1', '2310.03965_1_124_1', '2310.03965_1_125_1', '2310.03965_2_0_1', '2310.03965_2_1_1', '2310.03965_2_2_1', '2310.03965_2_3_1', '2310.03965_2_4_1', '2310.03965_2_5_1', '2310.03965_2_6_1', '2310.03965_2_7_1', '2310.03965_2_8_1', '2310.03965_2_9_1', '2310.03965_2_10_1', '2310.03965_2_11_1', '2310.03965_2_12_1', '2310.03965_2_13_1', '2310.03965_2_14_1', '2310.03965_2_15_1', '2406.03075_2_8_2', '2406.03075_2_9_2', '2406.03075_2_10_2', '2406.03075_2_11_2', '2406.03075_2_12_2', '2406.03075_2_13_2', '2406.03075_2_14_2', '2406.03075_2_15_2', '2406.03075_2_24_2', '2406.03075_2_25_2', '2406.03075_2_26_2', '2406.03075_2_27_2', '2406.03075_2_28_2', '2406.03075_2_29_2', '2406.03075_2_30_2', '2406.03075_2_31_2', '2406.03075_3_0_2', '2406.03075_3_1_2', '2406.03075_3_2_2', '2406.03075_3_3_2', '2406.03075_3_4_2', '2406.03075_3_5_2', '2406.03075_3_6_2', '2406.03075_3_7_2', '2406.03075_3_8_2', '2406.03075_3_9_2', '2406.03075_3_10_2', '2406.03075_3_11_2', '2406.03075_3_12_2', '2406.03075_3_13_2', '2406.03075_3_14_2', '2406.03075_3_15_2', '2406.03075_3_16_2', '2406.03075_3_17_2', '2406.03075_3_18_2', '2406.03075_3_19_2', '2406.03075_3_20_2', '2406.03075_3_21_2', '2406.03075_3_22_2', '2406.03075_3_23_2', '2406.03075_3_24_2', '2406.03075_3_25_2', '2406.03075_3_26_2', '2406.03075_3_27_2', '2406.03075_3_28_2', '2406.03075_3_29_2', '2406.03075_3_30_2', '2406.03075_3_31_2', '2406.03075_3_32_2', '2406.03075_3_33_2', '2406.03075_3_34_2', '2406.03075_3_35_2', '2406.03075_4_0_3', '2406.03075_4_1_3', '2406.03075_4_2_3', '2406.03075_4_3_3', '2406.03075_4_4_3', '2406.03075_4_5_3', '2406.03075_4_6_3', '2406.03075_4_7_3', '2406.03075_4_8_3', '2406.03075_4_9_3', '2406.03075_4_10_3', '2406.03075_4_11_3', '2406.03075_4_12_3', '2406.03075_4_13_3', '2406.03075_4_14_3', '2406.03075_4_15_3', '2407.16667_1_0_2', '2407.16667_1_1_2', '2407.16667_1_2_2', '2407.16667_1_3_2', '2407.16667_1_4_2', '2407.16667_1_5_2', '2407.16667_1_6_2', '2407.16667_1_7_2', '2407.16667_1_8_2', '2407.16667_1_9_2', '2407.16667_1_10_2', '2407.16667_1_11_2', '2407.16667_1_12_2', '2407.16667_1_13_2', '2407.16667_1_14_2', '2407.16667_1_15_2', '2407.16667_1_16_2', '2407.16667_1_17_2', '2407.16667_1_18_2', '2407.16667_1_19_2', '2407.16667_1_20_2', '2407.16667_1_21_2', '2407.16667_1_22_2', '2407.16667_1_23_2', '2407.16667_1_24_2', '2407.16667_1_25_2', '2407.16667_1_26_2', '2407.16667_1_27_2', '2407.16667_1_28_2', '2407.16667_1_29_2', '2407.16667_1_30_2', '2407.16667_1_31_2', '2407.16667_1_32_2', '2407.16667_1_33_2', '2407.16667_1_34_2', '2407.16667_1_35_2', '2407.16667_1_36_2', '2407.16667_1_37_2', '2407.16667_1_38_2', '2407.16667_1_39_2', '2407.16667_1_40_2', '2407.16667_1_41_2', '2407.16667_1_42_2', '2407.16667_1_43_2', '2407.16667_1_44_2', '2407.16667_1_45_2', '2407.16667_1_46_2', '2407.16667_1_47_2', '2407.16667_1_48_2', '2407.16667_1_49_2', '2407.16667_1_50_2', '2407.16667_1_51_2', '2407.16667_1_52_2', '2407.16667_1_53_2', '2407.16667_1_54_2', '2407.16667_1_55_2', '2407.16667_1_56_2', '2407.16667_1_57_2', '2407.16667_1_58_2', '2407.16667_1_59_2', '2407.17115_2_0_0', '2407.17115_2_1_0', '2407.17115_2_2_0', '2407.17115_2_3_0', '2407.17115_2_4_0', '2407.17115_2_5_0', '2407.17115_2_6_0', '2407.17115_2_7_0', '2407.17115_2_8_0', '2407.17115_2_9_0', '2407.17115_2_10_0', '2407.17115_2_11_0', '2407.17115_2_12_0', '2407.17115_2_13_0', '2407.17115_2_14_0', '2407.17115_2_15_0', '2407.17115_2_16_0', '2407.17115_2_17_0', '2407.17115_2_18_0', '2407.17115_2_19_0', '2407.17115_2_20_0', '2407.17115_2_21_0', '2407.17115_2_22_0', '2407.17115_2_23_0', '2407.17115_2_24_0', '2407.17115_2_25_0', '2407.17115_2_26_0', '2407.17115_2_27_0', '2407.17115_2_28_0', '2407.17115_2_29_0', '2407.17115_2_30_0', '2407.17115_2_31_0', '2407.17115_2_32_0', '2407.17115_2_33_0', '2407.17115_2_34_0', '2407.17115_2_35_0', '2407.17115_2_36_0', '2407.17115_2_37_0', '2407.17115_2_38_0', '2407.17115_2_39_0', '2407.17115_2_40_0', '2407.17115_2_41_0', '2407.17115_2_42_0', '2407.17115_2_43_0', '2407.17115_2_44_0', '2407.17115_2_45_0', '2407.17115_2_46_0', '2407.17115_2_47_0', '2407.17115_2_48_0', '2407.17115_2_49_0', '2407.17115_2_50_0', '2407.17115_2_51_0', '2407.17115_2_52_0', '2407.17115_2_53_0', '2407.17115_4_0_0', '2407.17115_4_1_0', '2407.17115_4_2_0', '2407.17115_4_3_0', '2407.17115_4_4_0', '2407.17115_4_5_0', '2407.17115_4_6_0', '2407.17115_4_7_0', '2407.17115_4_8_0', '2407.17115_4_9_0', '2407.17115_4_10_0', '2407.17115_4_11_0', '2407.17115_4_12_0', '2407.17115_4_13_0', '2407.17115_4_14_0', '2407.17115_4_15_0', '2407.17115_4_16_0', '2407.17115_4_17_0', '2407.17115_4_18_0', '2407.17115_4_19_0', '2407.17115_4_20_0', '2407.17115_4_21_0', '2407.17115_4_22_0', '2407.17115_4_23_0', '2407.17115_4_24_0', '2407.17115_4_25_0', '2407.17115_4_26_0', '2407.17115_4_27_0', '2407.17115_4_28_0', '2407.17115_4_29_0', '2407.17115_4_30_0', '2407.17115_4_31_0', '2407.17115_4_32_0', '2407.17115_4_33_0', '2407.17115_4_34_0', '2407.17115_4_35_0', '2407.17115_4_36_0', '2407.17115_4_37_0', '2407.17115_4_38_0', '2407.17115_4_39_0', '2407.17115_4_40_0', '2407.17115_4_41_0', '2407.17115_4_42_0', '2407.17115_4_43_0', '2407.17115_4_44_0', '2407.17115_4_45_0', '2407.17115_4_46_0', '2407.17115_4_47_0', '2407.17115_4_48_0', '2407.17115_4_49_0', '2407.17115_4_50_0', '2407.17115_4_51_0', '2407.17115_4_52_0', '2407.17115_4_53_0', '2407.17115_4_54_0', '2407.17115_4_55_0', '2407.17115_4_56_0', '2407.17115_4_57_0', '2407.17115_4_58_0', '2407.17115_4_59_0', '2407.17115_4_60_0', '2407.17115_4_61_0', '2407.17115_4_62_0', '2407.17115_5_0_1', '2407.17115_5_1_1', '2407.17115_5_2_1', '2407.17115_5_3_1', '2407.17115_5_4_1', '2407.17115_5_5_1', '2407.17115_5_6_1', '2407.17115_5_7_1', '2407.17115_5_8_1', '2407.17115_5_9_1', '2407.17115_5_10_1', '2407.17115_5_11_1', '2407.17115_5_12_1', '2407.17115_5_13_1', '2407.17115_5_14_1', '2407.17115_5_15_1', '2407.17115_5_16_1', '2407.17115_5_17_1', '2407.17115_5_36_1', '2407.17115_5_37_1', '2407.17115_5_38_1', '2407.17115_5_39_1', '2407.17115_5_40_1', '2407.17115_5_41_1', '2407.17115_5_42_1', '2407.17115_5_43_1', '2407.17115_5_44_1'], 'metric index': ['2310.03965_1_0_4', '2310.03965_1_1_4', '2310.03965_1_2_4', '2310.03965_1_3_4', '2310.03965_1_4_4', '2310.03965_1_5_4', '2310.03965_1_6_4', '2310.03965_1_7_4', '2310.03965_1_8_4', '2310.03965_1_9_4', '2310.03965_1_10_4', '2310.03965_1_11_4', '2310.03965_1_12_4', '2310.03965_1_13_4', '2310.03965_1_14_4', '2310.03965_1_15_4', '2310.03965_1_16_4', '2310.03965_1_17_4', '2310.03965_1_18_4', '2310.03965_1_19_4', '2310.03965_1_20_4', '2310.03965_1_21_4', '2310.03965_1_22_4', '2310.03965_1_23_4', '2310.03965_1_24_4', '2310.03965_1_25_4', '2310.03965_1_26_4', '2310.03965_1_27_4', '2310.03965_1_28_4', '2310.03965_1_29_4', '2310.03965_1_30_4', '2310.03965_1_31_4', '2310.03965_1_32_4', '2310.03965_1_33_4', '2310.03965_1_34_4', '2310.03965_1_35_4', '2310.03965_1_36_4', '2310.03965_1_37_4', '2310.03965_1_38_4', '2310.03965_1_39_4', '2310.03965_1_40_4', '2310.03965_1_41_4', '2310.03965_1_42_4', '2310.03965_1_43_4', '2310.03965_1_44_4', '2310.03965_1_45_4', '2310.03965_1_46_4', '2310.03965_1_47_4', '2310.03965_1_48_4', '2310.03965_1_49_4', '2310.03965_1_50_4', '2310.03965_1_51_4', '2310.03965_1_52_4', '2310.03965_1_53_4', '2310.03965_1_54_4', '2310.03965_1_55_4', '2310.03965_1_56_4', '2310.03965_1_57_4', '2310.03965_1_58_4', '2310.03965_1_59_4', '2310.03965_1_60_4', '2310.03965_1_61_4', '2310.03965_1_62_4', '2310.03965_1_63_4', '2310.03965_1_64_4', '2310.03965_1_65_4', '2310.03965_1_66_4', '2310.03965_1_67_4', '2310.03965_1_68_4', '2310.03965_1_69_4', '2310.03965_1_70_4', '2310.03965_1_71_4', '2310.03965_1_72_4', '2310.03965_1_73_4', '2310.03965_1_74_4', '2310.03965_1_75_4', '2310.03965_1_76_4', '2310.03965_1_77_4', '2310.03965_1_78_4', '2310.03965_1_79_4', '2310.03965_1_80_4', '2310.03965_1_81_4', '2310.03965_1_82_4', '2310.03965_1_83_4', '2310.03965_1_84_4', '2310.03965_1_85_4', '2310.03965_1_86_4', '2310.03965_1_87_4', '2310.03965_1_88_4', '2310.03965_1_89_4', '2310.03965_1_90_4', '2310.03965_1_91_4', '2310.03965_1_92_4', '2310.03965_1_93_4', '2310.03965_1_94_4', '2310.03965_1_95_4', '2310.03965_1_96_4', '2310.03965_1_97_4', '2310.03965_1_98_4', '2310.03965_1_99_4', '2310.03965_1_100_4', '2310.03965_1_101_4', '2310.03965_1_102_4', '2310.03965_1_103_4', '2310.03965_1_104_4', '2310.03965_1_105_4', '2310.03965_1_106_4', '2310.03965_1_107_4', '2310.03965_1_108_4', '2310.03965_1_109_4', '2310.03965_1_110_4', '2310.03965_1_111_4', '2310.03965_1_112_4', '2310.03965_1_113_4', '2310.03965_1_114_4', '2310.03965_1_115_4', '2310.03965_1_116_4', '2310.03965_1_117_4', '2310.03965_1_118_4', '2310.03965_1_119_4', '2310.03965_1_120_4', '2310.03965_1_121_4', '2310.03965_1_122_4', '2310.03965_1_123_4', '2310.03965_1_124_4', '2310.03965_1_125_4', '2407.16667_3_1_3', '2407.16667_3_6_3'], 'model': ['2304.04370_1_0_0', '2304.04370_1_1_0', '2304.04370_1_2_0', '2304.04370_1_3_0', '2304.04370_1_4_0', '2304.04370_1_5_0', '2304.04370_1_6_0', '2304.04370_1_7_0', '2304.04370_1_8_0', '2304.04370_1_9_0', '2304.04370_1_10_0', '2304.04370_1_11_0', '2304.04370_1_12_0', '2304.04370_1_13_0', '2304.04370_1_14_0', '2304.04370_1_15_0', '2304.04370_1_16_0', '2304.04370_1_17_0', '2304.04370_1_18_0', '2304.04370_1_19_0', '2304.04370_1_20_0', '2304.04370_1_21_0', '2304.04370_1_22_0', '2304.04370_1_23_0', '2304.04370_2_0_0', '2304.04370_2_1_0', '2304.04370_2_2_0', '2304.04370_2_3_0', '2304.04370_2_4_0', '2304.04370_2_5_0', '2304.04370_2_6_0', '2304.04370_2_7_0', '2304.04370_2_8_0', '2304.04370_2_9_0', '2304.04370_2_10_0', '2304.04370_2_11_0', '2304.04370_2_12_0', '2304.04370_2_13_0', '2304.04370_2_14_0', '2304.04370_2_15_0', '2304.04370_2_16_0', '2304.04370_2_17_0', '2304.04370_2_18_0', '2304.04370_2_19_0', '2304.04370_2_20_0', '2304.04370_2_21_0', '2304.04370_2_22_0', '2304.04370_2_23_0', '2304.04370_2_24_0', '2304.04370_2_25_0', '2304.04370_2_26_0', '2304.04370_2_27_0', '2304.04370_2_28_0', '2304.04370_2_29_0', '2304.04370_2_30_0', '2304.04370_2_31_0', '2304.04370_2_32_0', '2304.04370_2_33_0', '2304.04370_2_34_0', '2304.04370_2_35_0', '2304.04370_2_36_0', '2304.04370_2_37_0', '2304.04370_2_38_0', '2304.04370_2_39_0', '2304.04370_2_40_0', '2304.04370_2_41_0', '2304.04370_2_42_0', '2304.04370_2_43_0', '2304.04370_2_44_0', '2304.04370_2_45_0', '2304.04370_2_46_0', '2304.04370_2_47_0', '2304.04370_3_0_0', '2304.04370_3_1_0', '2304.04370_3_2_0', '2304.04370_3_3_0', '2304.04370_3_4_0', '2304.04370_3_5_0', '2304.04370_3_6_0', '2304.04370_3_7_0', '2304.04370_3_8_0', '2304.04370_3_9_0', '2304.04370_3_10_0', '2304.04370_3_11_0', '2304.04370_3_12_0', '2304.04370_3_13_0', '2304.04370_3_14_0', '2304.04370_3_15_0', '2304.04370_3_16_0', '2304.04370_3_17_0', '2304.04370_3_18_0', '2304.04370_3_19_0', '2304.04370_3_20_0', '2304.04370_3_21_0', '2304.04370_3_22_0', '2304.04370_3_23_0', '2304.04370_3_24_0', '2304.04370_3_25_0', '2304.04370_3_26_0', '2304.04370_3_27_0', '2304.04370_3_28_0', '2304.04370_3_29_0', '2304.04370_3_30_0', '2304.04370_3_31_0', '2304.04370_3_32_0', '2304.04370_3_33_0', '2304.04370_3_34_0', '2304.04370_3_35_0', '2304.04370_3_36_0', '2304.04370_3_37_0', '2304.04370_3_38_0', '2304.04370_3_39_0', '2304.04370_3_40_0', '2304.04370_3_41_0', '2304.04370_3_42_0', '2304.04370_3_43_0', '2304.04370_3_44_0', '2304.04370_3_45_0', '2304.04370_3_46_0', '2304.04370_3_47_0', '2304.04370_3_48_0', '2304.04370_3_49_0', '2304.04370_3_50_0', '2304.04370_3_51_0', '2304.04370_3_52_0', '2304.04370_3_53_0', '2304.04370_3_54_0', '2304.04370_3_55_0', '2304.04370_3_56_0', '2304.04370_3_57_0', '2304.04370_3_58_0', '2304.04370_3_59_0', '2304.04370_3_60_0', '2304.04370_3_61_0', '2304.04370_3_62_0', '2304.04370_3_63_0', '2304.04370_3_64_0', '2304.04370_3_65_0', '2304.04370_3_66_0', '2304.04370_3_67_0', '2310.01444_2_0_0', '2310.01444_2_1_0', '2310.01444_2_2_0', '2310.01444_2_3_0', '2310.01444_2_4_0', '2310.01444_2_5_0', '2310.01444_2_6_0', '2310.01444_2_7_0', '2310.01444_2_8_0', '2310.01444_2_9_0', '2310.01444_2_10_0', '2310.03965_1_0_0', '2310.03965_1_1_0', '2310.03965_1_2_0', '2310.03965_1_3_0', '2310.03965_1_4_0', '2310.03965_1_5_0', '2310.03965_1_6_0', '2310.03965_1_7_0', '2310.03965_1_8_0', '2310.03965_1_9_0', '2310.03965_1_10_0', '2310.03965_1_11_0', '2310.03965_1_12_0', '2310.03965_1_13_0', '2310.03965_1_14_0', '2310.03965_1_15_0', '2310.03965_1_16_0', '2310.03965_1_17_0', '2310.03965_1_18_0', '2310.03965_1_19_0', '2310.03965_1_20_0', '2310.03965_1_21_0', '2310.03965_1_22_0', '2310.03965_1_23_0', '2310.03965_1_24_0', '2310.03965_1_25_0', '2310.03965_1_26_0', '2310.03965_1_27_0', '2310.03965_1_28_0', '2310.03965_1_29_0', '2310.03965_1_30_0', '2310.03965_1_31_0', '2310.03965_1_32_0', '2310.03965_1_33_0', '2310.03965_1_34_0', '2310.03965_1_35_0', '2310.03965_1_36_0', '2310.03965_1_37_0', '2310.03965_1_38_0', '2310.03965_1_39_0', '2310.03965_1_40_0', '2310.03965_1_41_0', '2310.03965_1_42_0', '2310.03965_1_43_0', '2310.03965_1_44_0', '2310.03965_1_45_0', '2310.03965_1_46_0', '2310.03965_1_47_0', '2310.03965_1_48_0', '2310.03965_1_49_0', '2310.03965_1_50_0', '2310.03965_1_51_0', '2310.03965_1_52_0', '2310.03965_1_53_0', '2310.03965_1_54_0', '2310.03965_1_55_0', '2310.03965_1_56_0', '2310.03965_1_57_0', '2310.03965_1_58_0', '2310.03965_1_59_0', '2310.03965_1_60_0', '2310.03965_1_61_0', '2310.03965_1_62_0', '2310.03965_1_63_0', '2310.03965_1_64_0', '2310.03965_1_65_0', '2310.03965_1_66_0', '2310.03965_1_67_0', '2310.03965_1_68_0', '2310.03965_1_69_0', '2310.03965_1_70_0', '2310.03965_1_71_0', '2310.03965_1_72_0', '2310.03965_1_73_0', '2310.03965_1_74_0', '2310.03965_1_75_0', '2310.03965_1_76_0', '2310.03965_1_77_0', '2310.03965_1_78_0', '2310.03965_1_79_0', '2310.03965_1_80_0', '2310.03965_1_81_0', '2310.03965_1_82_0', '2310.03965_1_83_0', '2310.03965_1_84_0', '2310.03965_1_85_0', '2310.03965_1_86_0', '2310.03965_1_87_0', '2310.03965_1_88_0', '2310.03965_1_89_0', '2310.03965_1_90_0', '2310.03965_1_91_0', '2310.03965_1_92_0', '2310.03965_1_93_0', '2310.03965_1_94_0', '2310.03965_1_95_0', '2310.03965_1_96_0', '2310.03965_1_97_0', '2310.03965_1_98_0', '2310.03965_1_99_0', '2310.03965_1_100_0', '2310.03965_1_101_0', '2310.03965_1_102_0', '2310.03965_1_103_0', '2310.03965_1_104_0', '2310.03965_1_105_0', '2310.03965_1_106_0', '2310.03965_1_107_0', '2310.03965_1_108_0', '2310.03965_1_109_0', '2310.03965_1_110_0', '2310.03965_1_111_0', '2310.03965_1_112_0', '2310.03965_1_113_0', '2310.03965_1_114_0', '2310.03965_1_115_0', '2310.03965_1_116_0', '2310.03965_1_117_0', '2310.03965_1_118_0', '2310.03965_1_119_0', '2310.03965_1_120_0', '2310.03965_1_121_0', '2310.03965_1_122_0', '2310.03965_1_123_0', '2310.03965_1_124_0', '2310.03965_1_125_0', '2310.03965_2_0_0', '2310.03965_2_1_0', '2310.03965_2_2_0', '2310.03965_2_3_0', '2310.03965_2_4_0', '2310.03965_2_5_0', '2310.03965_2_6_0', '2310.03965_2_7_0', '2310.03965_2_8_0', '2310.03965_2_9_0', '2310.03965_2_10_0', '2310.03965_2_11_0', '2310.03965_2_12_0', '2310.03965_2_13_0', '2310.03965_2_14_0', '2310.03965_2_15_0', '2402.10890_1_0_0', '2402.10890_1_1_0', '2402.10890_1_2_0', '2402.10890_1_3_0', '2402.10890_1_4_0', '2402.10890_1_5_0', '2402.10890_1_6_0', '2402.10890_1_7_0', '2402.10890_1_8_0', '2402.10890_1_9_0', '2402.10890_1_10_0', '2402.10890_1_11_0', '2402.10890_1_12_0', '2402.10890_1_13_0', '2402.10890_1_14_0', '2402.10890_1_15_0', '2402.10890_1_16_0', '2402.10890_1_17_0', '2402.10890_1_18_0', '2402.10890_1_19_0', '2402.10890_1_20_0', '2402.10890_1_21_0', '2402.10890_1_22_0', '2402.10890_1_23_0', '2402.10890_1_24_0', '2402.10890_1_25_0', '2402.10890_1_26_0', '2402.10890_1_27_0', '2402.10890_1_28_0', '2402.10890_1_29_0', '2402.10890_1_30_0', '2402.10890_1_31_0', '2402.10890_1_32_0', '2402.10890_1_33_0', '2402.10890_1_34_0', '2402.10890_1_35_0', '2402.10890_1_36_0', '2402.10890_1_37_0', '2402.10890_1_38_0', '2402.10890_1_39_0', '2402.10890_1_40_0', '2402.10890_1_41_0', '2402.10890_1_42_0', '2402.10890_1_43_0', '2402.10890_1_44_0', '2402.10890_1_45_0', '2402.10890_1_46_0', '2402.10890_1_47_0', '2402.10890_1_48_0', '2402.10890_1_49_0', '2402.10890_1_50_0', '2402.10890_1_51_0', '2402.10890_1_52_0', '2402.10890_1_53_0', '2402.10890_1_54_0', '2402.10890_1_55_0', '2402.10890_1_56_0', '2402.10890_1_57_0', '2402.10890_1_58_0', '2402.10890_1_59_0', '2402.10890_1_60_0', '2402.10890_1_61_0', '2402.10890_1_62_0', '2402.10890_1_63_0', '2402.10890_1_64_0', '2402.10890_1_65_0', '2402.10890_1_66_0', '2402.10890_1_67_0', '2402.10890_1_68_0', '2402.10890_1_69_0', '2402.10890_1_70_0', '2402.10890_1_71_0', '2402.10890_2_0_0', '2402.10890_2_1_0', '2402.10890_2_2_0', '2402.10890_2_3_0', '2402.10890_2_4_0', '2402.10890_2_5_0', '2402.10890_2_6_0', '2402.10890_2_7_0', '2402.10890_2_8_0', '2402.10890_2_9_0', '2402.10890_2_10_0', '2402.10890_2_11_0', '2402.10890_2_12_0', '2402.10890_2_13_0', '2402.10890_2_14_0', '2402.10890_2_15_0', '2402.10890_2_16_0', '2402.10890_2_17_0', '2402.10890_2_18_0', '2402.10890_2_19_0', '2402.10890_2_20_0', '2402.10890_2_21_0', '2402.10890_2_22_0', '2402.10890_2_23_0', '2402.10890_2_24_0', '2402.10890_2_25_0', '2402.10890_2_26_0', '2402.10890_2_27_0', '2402.10890_2_28_0', '2402.10890_2_29_0', '2402.10890_2_30_0', '2402.10890_2_31_0', '2402.10890_2_32_0', '2402.10890_2_33_0', '2402.10890_2_34_0', '2402.10890_2_35_0', '2402.10890_3_0_0', '2402.10890_3_1_0', '2402.10890_3_2_0', '2402.10890_3_3_0', '2402.10890_3_4_0', '2402.10890_3_5_0', '2402.10890_3_6_0', '2402.10890_3_7_0', '2402.10890_3_8_0', '2402.10890_3_9_0', '2402.10890_3_10_0', '2402.10890_3_11_0', '2403.04783_1_0_1', '2403.04783_1_1_1', '2403.04783_1_2_1', '2403.04783_1_3_1', '2403.04783_1_4_1', '2403.04783_1_5_1', '2403.04783_1_6_1', '2403.04783_1_7_1', '2403.04783_1_8_1', '2403.04783_1_9_1', '2403.04783_1_10_1', '2403.04783_1_11_1', '2403.04783_1_12_1', '2403.04783_1_13_1', '2403.04783_1_14_1', '2403.04783_1_15_1', '2403.04783_1_16_1', '2403.04783_1_17_1', '2403.04783_1_18_1', '2403.04783_1_19_1', '2403.04783_1_20_1', '2403.04783_1_21_1', '2403.04783_1_22_1', '2403.04783_1_23_1', '2405.17129_1_0_0', '2405.17129_1_1_0', '2405.17129_1_2_0', '2405.17129_1_3_0', '2405.17129_1_4_0', '2405.17129_1_5_0', '2405.17129_1_9_0', '2405.17129_1_10_0', '2405.17129_1_11_0', '2405.17129_1_12_0', '2405.17129_1_13_0', '2405.17129_1_14_0', '2405.17129_1_15_0', '2405.17129_1_16_0', '2405.17129_1_17_0', '2405.17129_1_18_0', '2405.17129_1_19_0', '2405.17129_1_20_0', '2405.17129_1_21_0', '2405.17129_1_22_0', '2405.17129_1_23_0', '2405.17129_1_24_0', '2405.17129_1_25_0', '2405.17129_1_26_0', '2405.17129_1_27_0', '2405.17129_1_28_0', '2405.17129_1_29_0', '2405.17129_4_0_1', '2405.17129_4_1_1', '2405.17129_4_2_1', '2405.17129_4_3_1', '2405.17129_4_4_1', '2405.17129_4_5_1', '2405.17129_4_6_1', '2405.17129_4_7_1', '2405.17129_4_8_1', '2405.17129_4_9_1', '2405.17129_4_10_1', '2405.17129_4_11_1', '2405.17129_4_12_1', '2405.17129_4_13_1', '2405.17129_4_14_1', '2405.17129_4_15_1', '2405.17129_4_16_1', '2405.17129_4_17_1', '2405.17129_4_18_1', '2405.17129_4_19_1', '2405.17129_4_20_1', '2405.17129_4_21_1', '2405.17129_4_22_1', '2405.17129_4_23_1', '2405.17129_5_0_0', '2405.17129_5_1_0', '2405.17129_5_2_0', '2405.17129_5_3_0', '2405.17129_5_4_0', '2405.17129_5_5_0', '2405.17129_5_6_0', '2405.17129_5_7_0', '2405.17129_5_8_0', '2405.17129_5_9_0', '2405.17129_5_10_0', '2405.17129_5_11_0', '2405.17129_5_12_0', '2405.17129_5_13_0', '2405.17129_5_14_0', '2405.17129_5_15_0', '2406.12707_1_0_0', '2406.12707_1_1_0', '2406.12707_1_2_0', '2406.12707_1_3_0', '2406.12707_1_4_0', '2406.12707_1_5_0', '2406.12707_2_0_0', '2406.12707_2_1_0', '2406.12707_2_2_0', '2406.12707_2_3_0', '2406.12707_2_4_0', '2406.12707_2_5_0', '2407.16667_1_0_3', '2407.16667_1_1_3', '2407.16667_1_2_3', '2407.16667_1_3_3', '2407.16667_1_4_3', '2407.16667_1_5_3', '2407.16667_1_6_3', '2407.16667_1_7_3', '2407.16667_1_8_3', '2407.16667_1_9_3', '2407.16667_1_10_3', '2407.16667_1_11_3', '2407.16667_1_12_3', '2407.16667_1_13_3', '2407.16667_1_14_3', '2407.16667_1_15_3', '2407.16667_1_16_3', '2407.16667_1_17_3', '2407.16667_1_18_3', '2407.16667_1_19_3', '2407.16667_1_20_3', '2407.16667_1_21_3', '2407.16667_1_22_3', '2407.16667_1_23_3', '2407.16667_1_24_3', '2407.16667_1_25_3', '2407.16667_1_26_3', '2407.16667_1_27_3', '2407.16667_1_28_3', '2407.16667_1_29_3', '2407.16667_1_30_3', '2407.16667_1_31_3', '2407.16667_1_32_3', '2407.16667_1_33_3', '2407.16667_1_34_3', '2407.16667_1_35_3', '2407.16667_1_36_3', '2407.16667_1_37_3', '2407.16667_1_38_3', '2407.16667_1_39_3', '2407.16667_1_40_3', '2407.16667_1_41_3', '2407.16667_1_42_3', '2407.16667_1_43_3', '2407.16667_1_44_3', '2407.16667_1_45_3', '2407.16667_1_46_3', '2407.16667_1_47_3', '2407.16667_1_48_3', '2407.16667_1_49_3', '2407.16667_1_50_3', '2407.16667_1_51_3', '2407.16667_1_52_3', '2407.16667_1_53_3', '2407.16667_1_54_3', '2407.16667_1_55_3', '2407.16667_1_56_3', '2407.16667_1_57_3', '2407.16667_1_58_3', '2407.16667_1_59_3', '2407.16667_3_0_1', '2407.16667_3_1_1', '2407.16667_3_2_1', '2407.16667_3_3_1', '2407.16667_3_4_1', '2407.16667_3_5_1', '2407.16667_3_6_1', '2407.16667_3_7_1', '2407.16667_3_8_1', '2407.16667_3_9_1', '2407.16667_4_0_1', '2407.16667_4_1_1', '2407.16667_4_2_1', '2407.16667_4_3_1', '2407.16667_4_4_1', '2407.16667_4_5_1', '2407.16667_4_6_1', '2407.16667_4_7_1'], 'planning method': ['2402.10890_3_0_2', '2402.10890_3_1_2', '2402.10890_3_2_2', '2402.10890_3_3_2', '2402.10890_3_4_2', '2402.10890_3_5_2', '2402.10890_3_6_2', '2402.10890_3_7_2', '2402.10890_3_8_2', '2402.10890_3_9_2', '2402.10890_3_10_2', '2402.10890_3_11_2', '2402.10890_3_12_2', '2402.10890_3_13_2', '2402.10890_3_14_2', '2402.10890_3_15_2', '2402.10890_3_16_2', '2402.10890_3_17_2', '2402.10890_3_18_2', '2402.10890_3_19_2', '2402.10890_3_20_2', '2402.10890_3_21_2', '2402.10890_3_22_2', '2402.10890_3_23_2'], 'prompt': ['2304.04370_3_0_1', '2304.04370_3_1_1', '2304.04370_3_2_1', '2304.04370_3_3_1', '2304.04370_3_4_1', '2304.04370_3_5_1', '2304.04370_3_6_1', '2304.04370_3_7_1', '2304.04370_3_8_1', '2304.04370_3_9_1', '2304.04370_3_10_1', '2304.04370_3_11_1', '2304.04370_3_12_1', '2304.04370_3_13_1', '2304.04370_3_14_1', '2304.04370_3_15_1', '2304.04370_3_16_1', '2304.04370_3_17_1', '2304.04370_3_18_1', '2304.04370_3_19_1', '2304.04370_3_20_1', '2304.04370_3_21_1', '2304.04370_3_22_1', '2304.04370_3_23_1', '2304.04370_3_24_1', '2304.04370_3_25_1', '2304.04370_3_26_1', '2304.04370_3_27_1', '2304.04370_3_28_1', '2304.04370_3_29_1', '2304.04370_3_30_1', '2304.04370_3_31_1', '2304.04370_3_32_1', '2304.04370_3_33_1', '2304.04370_3_34_1', '2304.04370_3_35_1', '2304.04370_3_36_1', '2304.04370_3_37_1', '2304.04370_3_38_1', '2304.04370_3_39_1', '2304.04370_3_40_1', '2304.04370_3_41_1', '2304.04370_3_42_1', '2304.04370_3_43_1', '2304.04370_3_44_1', '2304.04370_3_45_1', '2304.04370_3_46_1', '2304.04370_3_47_1', '2304.04370_3_48_1', '2304.04370_3_49_1', '2304.04370_3_50_1', '2304.04370_3_51_1', '2304.04370_3_52_1', '2304.04370_3_53_1', '2304.04370_3_54_1', '2304.04370_3_55_1', '2304.04370_3_56_1', '2304.04370_3_57_1', '2304.04370_3_58_1', '2304.04370_3_59_1', '2304.04370_3_60_1', '2304.04370_3_61_1', '2304.04370_3_62_1', '2304.04370_3_63_1', '2304.04370_3_64_1', '2304.04370_3_65_1', '2304.04370_3_66_1', '2304.04370_3_67_1'], 'query_budget': ['2407.16667_1_0_1', '2407.16667_1_1_1', '2407.16667_1_2_1', '2407.16667_1_3_1', '2407.16667_1_4_1', '2407.16667_1_5_1', '2407.16667_1_6_1', '2407.16667_1_7_1', '2407.16667_1_8_1', '2407.16667_1_9_1', '2407.16667_1_10_1', '2407.16667_1_11_1', '2407.16667_1_12_1', '2407.16667_1_13_1', '2407.16667_1_14_1', '2407.16667_1_15_1', '2407.16667_1_16_1', '2407.16667_1_17_1', '2407.16667_1_18_1', '2407.16667_1_19_1', '2407.16667_1_20_1', '2407.16667_1_21_1', '2407.16667_1_22_1', '2407.16667_1_23_1', '2407.16667_1_24_1', '2407.16667_1_25_1', '2407.16667_1_26_1', '2407.16667_1_27_1', '2407.16667_1_28_1', '2407.16667_1_29_1', '2407.16667_1_30_1', '2407.16667_1_31_1', '2407.16667_1_32_1', '2407.16667_1_33_1', '2407.16667_1_34_1', '2407.16667_1_35_1', '2407.16667_1_36_1', '2407.16667_1_37_1', '2407.16667_1_38_1', '2407.16667_1_39_1', '2407.16667_1_40_1', '2407.16667_1_41_1', '2407.16667_1_42_1', '2407.16667_1_43_1', '2407.16667_1_44_1', '2407.16667_1_45_1', '2407.16667_1_46_1', '2407.16667_1_47_1', '2407.16667_1_48_1', '2407.16667_1_49_1', '2407.16667_1_50_1', '2407.16667_1_51_1', '2407.16667_1_52_1', '2407.16667_1_53_1', '2407.16667_1_54_1', '2407.16667_1_55_1', '2407.16667_1_56_1', '2407.16667_1_57_1', '2407.16667_1_58_1', '2407.16667_1_59_1', '2407.16667_3_0_2', '2407.16667_3_1_2', '2407.16667_3_2_2', '2407.16667_3_3_2', '2407.16667_3_4_2', '2407.16667_3_5_2', '2407.16667_3_6_2', '2407.16667_3_7_2', '2407.16667_3_8_2', '2407.16667_3_9_2'], 'samples': ['2406.03075_4_0_2', '2406.03075_4_1_2', '2406.03075_4_2_2', '2406.03075_4_3_2', '2406.03075_4_4_2', '2406.03075_4_5_2', '2406.03075_4_6_2', '2406.03075_4_7_2', '2406.03075_4_8_2', '2406.03075_4_9_2', '2406.03075_4_10_2', '2406.03075_4_11_2', '2406.03075_4_12_2', '2406.03075_4_13_2', '2406.03075_4_14_2', '2406.03075_4_15_2'], 'setting': ['2304.04370_1_0_1', '2304.04370_1_1_1', '2304.04370_1_2_1', '2304.04370_1_3_1', '2304.04370_1_4_1', '2304.04370_1_5_1', '2304.04370_1_6_1', '2304.04370_1_7_1', '2304.04370_1_8_1', '2304.04370_1_9_1', '2304.04370_1_10_1', '2304.04370_1_11_1', '2304.04370_1_12_1', '2304.04370_1_13_1', '2304.04370_1_14_1', '2304.04370_1_15_1', '2304.04370_1_16_1', '2304.04370_1_17_1', '2304.04370_1_18_1', '2304.04370_1_19_1', '2304.04370_1_20_1', '2304.04370_1_21_1', '2304.04370_1_22_1', '2304.04370_1_23_1', '2304.04370_2_0_1', '2304.04370_2_1_1', '2304.04370_2_2_1', '2304.04370_2_3_1', '2304.04370_2_4_1', '2304.04370_2_5_1', '2304.04370_2_6_1', '2304.04370_2_7_1', '2304.04370_2_8_1', '2304.04370_2_9_1', '2304.04370_2_10_1', '2304.04370_2_11_1', '2304.04370_2_12_1', '2304.04370_2_13_1', '2304.04370_2_14_1', '2304.04370_2_15_1', '2304.04370_2_16_1', '2304.04370_2_17_1', '2304.04370_2_18_1', '2304.04370_2_19_1', '2304.04370_2_20_1', '2304.04370_2_21_1', '2304.04370_2_22_1', '2304.04370_2_23_1', '2304.04370_2_24_1', '2304.04370_2_25_1', '2304.04370_2_26_1', '2304.04370_2_27_1', '2304.04370_2_28_1', '2304.04370_2_29_1', '2304.04370_2_30_1', '2304.04370_2_31_1', '2304.04370_2_32_1', '2304.04370_2_33_1', '2304.04370_2_34_1', '2304.04370_2_35_1', '2304.04370_2_36_1', '2304.04370_2_37_1', '2304.04370_2_38_1', '2304.04370_2_39_1', '2304.04370_2_40_1', '2304.04370_2_41_1', '2304.04370_2_42_1', '2304.04370_2_43_1', '2304.04370_2_44_1', '2304.04370_2_45_1', '2304.04370_2_46_1', '2304.04370_2_47_1'], 'shot type': ['2310.03965_1_0_3', '2310.03965_1_1_3', '2310.03965_1_2_3', '2310.03965_1_3_3', '2310.03965_1_4_3', '2310.03965_1_5_3', '2310.03965_1_6_3', '2310.03965_1_7_3', '2310.03965_1_8_3', '2310.03965_1_9_3', '2310.03965_1_10_3', '2310.03965_1_11_3', '2310.03965_1_12_3', '2310.03965_1_13_3', '2310.03965_1_14_3', '2310.03965_1_15_3', '2310.03965_1_16_3', '2310.03965_1_17_3', '2310.03965_1_18_3', '2310.03965_1_19_3', '2310.03965_1_20_3', '2310.03965_1_21_3', '2310.03965_1_22_3', '2310.03965_1_23_3', '2310.03965_1_24_3', '2310.03965_1_25_3', '2310.03965_1_26_3', '2310.03965_1_27_3', '2310.03965_1_28_3', '2310.03965_1_29_3', '2310.03965_1_30_3', '2310.03965_1_31_3', '2310.03965_1_32_3', '2310.03965_1_33_3', '2310.03965_1_34_3', '2310.03965_1_35_3', '2310.03965_1_36_3', '2310.03965_1_37_3', '2310.03965_1_38_3', '2310.03965_1_39_3', '2310.03965_1_40_3', '2310.03965_1_41_3', '2310.03965_1_42_3', '2310.03965_1_43_3', '2310.03965_1_44_3', '2310.03965_1_45_3', '2310.03965_1_46_3', '2310.03965_1_47_3', '2310.03965_1_48_3', '2310.03965_1_49_3', '2310.03965_1_50_3', '2310.03965_1_51_3', '2310.03965_1_52_3', '2310.03965_1_53_3', '2310.03965_1_54_3', '2310.03965_1_55_3', '2310.03965_1_56_3', '2310.03965_1_57_3', '2310.03965_1_58_3', '2310.03965_1_59_3', '2310.03965_1_60_3', '2310.03965_1_61_3', '2310.03965_1_62_3', '2310.03965_1_63_3', '2310.03965_1_64_3', '2310.03965_1_65_3', '2310.03965_1_66_3', '2310.03965_1_67_3', '2310.03965_1_68_3', '2310.03965_1_69_3', '2310.03965_1_70_3', '2310.03965_1_71_3', '2310.03965_1_72_3', '2310.03965_1_73_3', '2310.03965_1_74_3', '2310.03965_1_75_3', '2310.03965_1_76_3', '2310.03965_1_77_3', '2310.03965_1_78_3', '2310.03965_1_79_3', '2310.03965_1_80_3', '2310.03965_1_81_3', '2310.03965_1_82_3', '2310.03965_1_83_3', '2310.03965_1_84_3', '2310.03965_1_85_3', '2310.03965_1_86_3', '2310.03965_1_87_3', '2310.03965_1_88_3', '2310.03965_1_89_3', '2310.03965_1_90_3', '2310.03965_1_91_3', '2310.03965_1_92_3', '2310.03965_1_93_3', '2310.03965_1_94_3', '2310.03965_1_95_3', '2310.03965_1_96_3', '2310.03965_1_97_3', '2310.03965_1_98_3', '2310.03965_1_99_3', '2310.03965_1_100_3', '2310.03965_1_101_3', '2310.03965_1_102_3', '2310.03965_1_103_3', '2310.03965_1_104_3', '2310.03965_1_105_3', '2310.03965_1_106_3', '2310.03965_1_107_3', '2310.03965_1_108_3', '2310.03965_1_109_3', '2310.03965_1_110_3', '2310.03965_1_111_3', '2310.03965_1_112_3', '2310.03965_1_113_3', '2310.03965_1_114_3', '2310.03965_1_115_3', '2310.03965_1_116_3', '2310.03965_1_117_3', '2310.03965_1_118_3', '2310.03965_1_119_3', '2310.03965_1_120_3', '2310.03965_1_121_3', '2310.03965_1_122_3', '2310.03965_1_123_3', '2310.03965_1_124_3', '2310.03965_1_125_3'], 'task': ['2304.04370_1_0_2', '2304.04370_1_1_2', '2304.04370_1_2_2', '2304.04370_1_3_2', '2304.04370_1_4_2', '2304.04370_1_5_2', '2304.04370_1_6_2', '2304.04370_1_7_2', '2304.04370_1_8_2', '2304.04370_1_9_2', '2304.04370_1_10_2', '2304.04370_1_11_2', '2304.04370_1_12_2', '2304.04370_1_13_2', '2304.04370_1_14_2', '2304.04370_1_15_2', '2304.04370_1_16_2', '2304.04370_1_17_2', '2304.04370_1_18_2', '2304.04370_1_19_2', '2304.04370_1_20_2', '2304.04370_1_21_2', '2304.04370_1_22_2', '2304.04370_1_23_2', '2304.04370_2_0_2', '2304.04370_2_1_2', '2304.04370_2_2_2', '2304.04370_2_3_2', '2304.04370_2_4_2', '2304.04370_2_5_2', '2304.04370_2_6_2', '2304.04370_2_7_2', '2304.04370_2_8_2', '2304.04370_2_9_2', '2304.04370_2_10_2', '2304.04370_2_11_2', '2304.04370_2_12_2', '2304.04370_2_13_2', '2304.04370_2_14_2', '2304.04370_2_15_2', '2304.04370_2_16_2', '2304.04370_2_17_2', '2304.04370_2_18_2', '2304.04370_2_19_2', '2304.04370_2_20_2', '2304.04370_2_21_2', '2304.04370_2_22_2', '2304.04370_2_23_2', '2304.04370_2_24_2', '2304.04370_2_25_2', '2304.04370_2_26_2', '2304.04370_2_27_2', '2304.04370_2_28_2', '2304.04370_2_29_2', '2304.04370_2_30_2', '2304.04370_2_31_2', '2304.04370_2_32_2', '2304.04370_2_33_2', '2304.04370_2_34_2', '2304.04370_2_35_2', '2304.04370_2_36_2', '2304.04370_2_37_2', '2304.04370_2_38_2', '2304.04370_2_39_2', '2304.04370_2_40_2', '2304.04370_2_41_2', '2304.04370_2_42_2', '2304.04370_2_43_2', '2304.04370_2_44_2', '2304.04370_2_45_2', '2304.04370_2_46_2', '2304.04370_2_47_2', '2304.04370_3_0_2', '2304.04370_3_1_2', '2304.04370_3_2_2', '2304.04370_3_3_2', '2304.04370_3_4_2', '2304.04370_3_5_2', '2304.04370_3_6_2', '2304.04370_3_7_2', '2304.04370_3_8_2', '2304.04370_3_9_2', '2304.04370_3_10_2', '2304.04370_3_11_2', '2304.04370_3_12_2', '2304.04370_3_13_2', '2304.04370_3_14_2', '2304.04370_3_15_2', '2304.04370_3_16_2', '2304.04370_3_17_2', '2304.04370_3_18_2', '2304.04370_3_19_2', '2304.04370_3_20_2', '2304.04370_3_21_2', '2304.04370_3_22_2', '2304.04370_3_23_2', '2304.04370_3_24_2', '2304.04370_3_25_2', '2304.04370_3_26_2', '2304.04370_3_27_2', '2304.04370_3_28_2', '2304.04370_3_29_2', '2304.04370_3_30_2', '2304.04370_3_31_2', '2304.04370_3_32_2', '2304.04370_3_33_2', '2304.04370_3_34_2', '2304.04370_3_35_2', '2304.04370_3_36_2', '2304.04370_3_37_2', '2304.04370_3_38_2', '2304.04370_3_39_2', '2304.04370_3_40_2', '2304.04370_3_41_2', '2304.04370_3_42_2', '2304.04370_3_43_2', '2304.04370_3_44_2', '2304.04370_3_45_2', '2304.04370_3_46_2', '2304.04370_3_47_2', '2304.04370_3_48_2', '2304.04370_3_49_2', '2304.04370_3_50_2', '2304.04370_3_51_2', '2304.04370_3_52_2', '2304.04370_3_53_2', '2304.04370_3_54_2', '2304.04370_3_55_2', '2304.04370_3_56_2', '2304.04370_3_57_2', '2304.04370_3_58_2', '2304.04370_3_59_2', '2304.04370_3_60_2', '2304.04370_3_61_2', '2304.04370_3_62_2', '2304.04370_3_63_2', '2304.04370_3_64_2', '2304.04370_3_65_2', '2304.04370_3_66_2', '2304.04370_3_67_2', '2308.12519_1_0_2', '2308.12519_1_1_2', '2308.12519_1_2_2', '2308.12519_1_3_2', '2308.12519_1_4_2', '2308.12519_1_5_2', '2308.12519_1_6_2', '2308.12519_2_0_2', '2308.12519_2_1_2', '2308.12519_2_2_2', '2308.12519_2_3_2', '2308.12519_2_4_2', '2308.12519_2_5_2', '2308.12519_2_6_2', '2308.12519_3_0_2', '2308.12519_3_1_2', '2308.12519_3_2_2', '2308.12519_3_3_2', '2308.12519_3_4_2', '2308.12519_3_5_2', '2308.12519_3_6_2', '2308.12519_3_7_2', '2308.12519_3_8_2', '2308.12519_3_9_2', '2308.12519_3_10_2', '2308.12519_3_11_2', '2308.12519_3_12_2', '2308.12519_3_13_2', '2308.12519_3_14_2', '2308.12519_3_15_2', '2308.12519_3_16_2', '2308.12519_3_17_2', '2308.12519_3_18_2', '2308.12519_3_19_2', '2308.12519_3_20_2', '2308.12519_3_21_2', '2308.12519_3_22_2', '2308.12519_3_23_2', '2310.01444_2_0_3', '2310.01444_2_1_3', '2310.01444_2_2_3', '2310.01444_2_3_3', '2310.01444_2_4_3', '2310.01444_2_5_3', '2310.01444_2_6_3', '2310.01444_2_7_3', '2310.01444_2_8_3', '2310.01444_2_9_3', '2310.01444_2_10_3', '2310.01444_4_0_2', '2310.01444_4_1_2', '2310.01444_4_2_2', '2310.01444_4_3_2', '2310.01444_4_4_2', '2310.01444_4_5_2', '2310.03965_1_0_2', '2310.03965_1_1_2', '2310.03965_1_2_2', '2310.03965_1_3_2', '2310.03965_1_4_2', '2310.03965_1_5_2', '2310.03965_1_6_2', '2310.03965_1_7_2', '2310.03965_1_8_2', '2310.03965_1_9_2', '2310.03965_1_10_2', '2310.03965_1_11_2', '2310.03965_1_12_2', '2310.03965_1_13_2', '2310.03965_1_14_2', '2310.03965_1_15_2', '2310.03965_1_16_2', '2310.03965_1_17_2', '2310.03965_1_18_2', '2310.03965_1_19_2', '2310.03965_1_20_2', '2310.03965_1_21_2', '2310.03965_1_22_2', '2310.03965_1_23_2', '2310.03965_1_24_2', '2310.03965_1_25_2', '2310.03965_1_26_2', '2310.03965_1_27_2', '2310.03965_1_28_2', '2310.03965_1_29_2', '2310.03965_1_30_2', '2310.03965_1_31_2', '2310.03965_1_32_2', '2310.03965_1_33_2', '2310.03965_1_34_2', '2310.03965_1_35_2', '2310.03965_1_36_2', '2310.03965_1_37_2', '2310.03965_1_38_2', '2310.03965_1_39_2', '2310.03965_1_40_2', '2310.03965_1_41_2', '2310.03965_1_42_2', '2310.03965_1_43_2', '2310.03965_1_44_2', '2310.03965_1_45_2', '2310.03965_1_46_2', '2310.03965_1_47_2', '2310.03965_1_48_2', '2310.03965_1_49_2', '2310.03965_1_50_2', '2310.03965_1_51_2', '2310.03965_1_52_2', '2310.03965_1_53_2', '2310.03965_1_54_2', '2310.03965_1_55_2', '2310.03965_1_56_2', '2310.03965_1_57_2', '2310.03965_1_58_2', '2310.03965_1_59_2', '2310.03965_1_60_2', '2310.03965_1_61_2', '2310.03965_1_62_2', '2310.03965_1_63_2', '2310.03965_1_64_2', '2310.03965_1_65_2', '2310.03965_1_66_2', '2310.03965_1_67_2', '2310.03965_1_68_2', '2310.03965_1_69_2', '2310.03965_1_70_2', '2310.03965_1_71_2', '2310.03965_1_72_2', '2310.03965_1_73_2', '2310.03965_1_74_2', '2310.03965_1_75_2', '2310.03965_1_76_2', '2310.03965_1_77_2', '2310.03965_1_78_2', '2310.03965_1_79_2', '2310.03965_1_80_2', '2310.03965_1_81_2', '2310.03965_1_82_2', '2310.03965_1_83_2', '2310.03965_1_84_2', '2310.03965_1_85_2', '2310.03965_1_86_2', '2310.03965_1_87_2', '2310.03965_1_88_2', '2310.03965_1_89_2', '2310.03965_1_90_2', '2310.03965_1_91_2', '2310.03965_1_92_2', '2310.03965_1_93_2', '2310.03965_1_94_2', '2310.03965_1_95_2', '2310.03965_1_96_2', '2310.03965_1_97_2', '2310.03965_1_98_2', '2310.03965_1_99_2', '2310.03965_1_100_2', '2310.03965_1_101_2', '2310.03965_1_102_2', '2310.03965_1_103_2', '2310.03965_1_104_2', '2310.03965_1_105_2', '2310.03965_1_106_2', '2310.03965_1_107_2', '2310.03965_1_108_2', '2310.03965_1_109_2', '2310.03965_1_110_2', '2310.03965_1_111_2', '2310.03965_1_112_2', '2310.03965_1_113_2', '2310.03965_1_114_2', '2310.03965_1_115_2', '2310.03965_1_116_2', '2310.03965_1_117_2', '2310.03965_1_118_2', '2310.03965_1_119_2', '2310.03965_1_120_2', '2310.03965_1_121_2', '2310.03965_1_122_2', '2310.03965_1_123_2', '2310.03965_1_124_2', '2310.03965_1_125_2', '2310.03965_2_0_2', '2310.03965_2_1_2', '2310.03965_2_2_2', '2310.03965_2_3_2', '2310.03965_2_4_2', '2310.03965_2_5_2', '2310.03965_2_6_2', '2310.03965_2_7_2', '2310.03965_2_8_2', '2310.03965_2_9_2', '2310.03965_2_10_2', '2310.03965_2_11_2', '2310.03965_2_12_2', '2310.03965_2_13_2', '2310.03965_2_14_2', '2310.03965_2_15_2', '2402.10890_1_0_2', '2402.10890_1_1_2', '2402.10890_1_2_2', '2402.10890_1_3_2', '2402.10890_1_4_2', '2402.10890_1_5_2', '2402.10890_1_6_2', '2402.10890_1_7_2', '2402.10890_1_8_2', '2402.10890_1_9_2', '2402.10890_1_10_2', '2402.10890_1_11_2', '2402.10890_1_12_2', '2402.10890_1_13_2', '2402.10890_1_14_2', '2402.10890_1_15_2', '2402.10890_1_16_2', '2402.10890_1_17_2', '2402.10890_1_18_2', '2402.10890_1_19_2', '2402.10890_1_20_2', '2402.10890_1_21_2', '2402.10890_1_22_2', '2402.10890_1_23_2', '2402.10890_1_24_2', '2402.10890_1_25_2', '2402.10890_1_26_2', '2402.10890_1_27_2', '2402.10890_1_28_2', '2402.10890_1_29_2', '2402.10890_1_30_2', '2402.10890_1_31_2', '2402.10890_1_32_2', '2402.10890_1_33_2', '2402.10890_1_34_2', '2402.10890_1_35_2', '2402.10890_1_36_2', '2402.10890_1_37_2', '2402.10890_1_38_2', '2402.10890_1_39_2', '2402.10890_1_40_2', '2402.10890_1_41_2', '2402.10890_1_42_2', '2402.10890_1_43_2', '2402.10890_1_44_2', '2402.10890_1_45_2', '2402.10890_1_46_2', '2402.10890_1_47_2', '2402.10890_1_48_2', '2402.10890_1_49_2', '2402.10890_1_50_2', '2402.10890_1_51_2', '2402.10890_1_52_2', '2402.10890_1_53_2', '2402.10890_1_54_2', '2402.10890_1_55_2', '2402.10890_1_56_2', '2402.10890_1_57_2', '2402.10890_1_58_2', '2402.10890_1_59_2', '2402.10890_1_60_2', '2402.10890_1_61_2', '2402.10890_1_62_2', '2402.10890_1_63_2', '2402.10890_1_64_2', '2402.10890_1_65_2', '2402.10890_1_66_2', '2402.10890_1_67_2', '2402.10890_1_68_2', '2402.10890_1_69_2', '2402.10890_1_70_2', '2402.10890_1_71_2', '2402.10890_2_0_2', '2402.10890_2_1_2', '2402.10890_2_2_2', '2402.10890_2_3_2', '2402.10890_2_4_2', '2402.10890_2_5_2', '2402.10890_2_6_2', '2402.10890_2_7_2', '2402.10890_2_8_2', '2402.10890_2_9_2', '2402.10890_2_10_2', '2402.10890_2_11_2', '2402.10890_2_12_2', '2402.10890_2_13_2', '2402.10890_2_14_2', '2402.10890_2_15_2', '2402.10890_2_16_2', '2402.10890_2_17_2', '2402.10890_2_18_2', '2402.10890_2_19_2', '2402.10890_2_20_2', '2402.10890_2_21_2', '2402.10890_2_22_2', '2402.10890_2_23_2', '2402.10890_2_24_2', '2402.10890_2_25_2', '2402.10890_2_26_2', '2402.10890_2_27_2', '2402.10890_2_28_2', '2402.10890_2_29_2', '2402.10890_2_30_2', '2402.10890_2_31_2', '2402.10890_2_32_2', '2402.10890_2_33_2', '2402.10890_2_34_2', '2402.10890_2_35_2', '2402.10890_3_0_3', '2402.10890_3_1_3', '2402.10890_3_2_3', '2402.10890_3_3_3', '2402.10890_3_4_3', '2402.10890_3_5_3', '2402.10890_3_6_3', '2402.10890_3_7_3', '2402.10890_3_8_3', '2402.10890_3_9_3', '2402.10890_3_10_3', '2402.10890_3_11_3', '2402.10890_3_12_3', '2402.10890_3_13_3', '2402.10890_3_14_3', '2402.10890_3_15_3', '2402.10890_3_16_3', '2402.10890_3_17_3', '2402.10890_3_18_3', '2402.10890_3_19_3', '2402.10890_3_20_3', '2402.10890_3_21_3', '2402.10890_3_22_3', '2402.10890_3_23_3', '2403.04783_1_0_3', '2403.04783_1_1_3', '2403.04783_1_2_3', '2403.04783_1_3_3', '2403.04783_1_4_3', '2403.04783_1_5_3', '2403.04783_1_6_3', '2403.04783_1_7_3', '2403.04783_1_8_3', '2403.04783_1_9_3', '2403.04783_1_10_3', '2403.04783_1_11_3', '2403.04783_1_12_3', '2403.04783_1_13_3', '2403.04783_1_14_3', '2403.04783_1_15_3', '2403.04783_1_16_3', '2403.04783_1_17_3', '2403.04783_1_18_3', '2403.04783_1_19_3', '2403.04783_1_20_3', '2403.04783_1_21_3', '2403.04783_1_22_3', '2403.04783_1_23_3', '2403.04783_4_0_2', '2403.04783_4_1_2', '2403.04783_4_2_2', '2403.04783_4_3_2', '2403.04783_4_4_2', '2403.04783_4_5_2', '2405.17129_1_0_2', '2405.17129_1_1_2', '2405.17129_1_2_2', '2405.17129_1_3_2', '2405.17129_1_4_2', '2405.17129_1_5_2', '2405.17129_1_6_2', '2405.17129_1_7_2', '2405.17129_1_8_2', '2405.17129_1_9_2', '2405.17129_1_10_2', '2405.17129_1_11_2', '2405.17129_1_12_2', '2405.17129_1_13_2', '2405.17129_1_14_2', '2405.17129_1_15_2', '2405.17129_1_16_2', '2405.17129_1_17_2', '2405.17129_1_18_2', '2405.17129_1_19_2', '2405.17129_1_20_2', '2405.17129_1_21_2', '2405.17129_1_22_2', '2405.17129_1_23_2', '2405.17129_1_24_2', '2405.17129_1_25_2', '2405.17129_1_26_2', '2405.17129_1_27_2', '2405.17129_1_28_2', '2405.17129_1_29_2', '2405.17129_4_0_2', '2405.17129_4_1_2', '2405.17129_4_2_2', '2405.17129_4_3_2', '2405.17129_4_4_2', '2405.17129_4_5_2', '2405.17129_4_6_2', '2405.17129_4_7_2', '2405.17129_4_8_2', '2405.17129_4_9_2', '2405.17129_4_10_2', '2405.17129_4_11_2', '2405.17129_4_12_2', '2405.17129_4_13_2', '2405.17129_4_14_2', '2405.17129_4_15_2', '2405.17129_4_16_2', '2405.17129_4_17_2', '2405.17129_4_18_2', '2405.17129_4_19_2', '2405.17129_4_20_2', '2405.17129_4_21_2', '2405.17129_4_22_2', '2405.17129_4_23_2', '2406.03075_3_0_1', '2406.03075_3_1_1', '2406.03075_3_2_1', '2406.03075_3_3_1', '2406.03075_3_4_1', '2406.03075_3_5_1', '2406.03075_3_6_1', '2406.03075_3_7_1', '2406.03075_3_8_1', '2406.03075_3_9_1', '2406.03075_3_10_1', '2406.03075_3_11_1', '2406.03075_3_12_1', '2406.03075_3_13_1', '2406.03075_3_14_1', '2406.03075_3_15_1', '2406.03075_3_16_1', '2406.03075_3_17_1', '2406.03075_3_18_1', '2406.03075_3_19_1', '2406.03075_3_20_1', '2406.03075_3_21_1', '2406.03075_3_22_1', '2406.03075_3_23_1', '2406.03075_3_24_1', '2406.03075_3_25_1', '2406.03075_3_26_1', '2406.03075_3_27_1', '2406.03075_3_28_1', '2406.03075_3_29_1', '2406.03075_3_30_1', '2406.03075_3_31_1', '2406.03075_3_32_1', '2406.03075_3_33_1', '2406.03075_3_34_1', '2406.03075_3_35_1', '2406.03075_4_0_1', '2406.03075_4_1_1', '2406.03075_4_2_1', '2406.03075_4_3_1', '2406.03075_4_4_1', '2406.03075_4_5_1', '2406.03075_4_6_1', '2406.03075_4_7_1', '2406.03075_4_8_1', '2406.03075_4_9_1', '2406.03075_4_10_1', '2406.03075_4_11_1', '2406.03075_4_12_1', '2406.03075_4_13_1', '2406.03075_4_14_1', '2406.03075_4_15_1', '2406.12707_1_0_2', '2406.12707_1_1_2', '2406.12707_1_2_2', '2406.12707_1_3_2', '2406.12707_1_4_2', '2406.12707_1_5_2', '2406.12707_2_0_2', '2406.12707_2_1_2', '2406.12707_2_2_2', '2406.12707_2_3_2', '2406.12707_2_4_2', '2406.12707_2_5_2', '2406.12707_3_0_2', '2406.12707_3_1_2', '2406.12707_3_2_2', '2406.12707_3_3_2', '2406.12707_3_4_2', '2406.12707_3_5_2', '2406.12707_3_6_2', '2406.12707_3_7_2', '2406.12707_3_8_2', '2406.12707_3_9_2', '2406.12707_3_10_2', '2406.12707_3_11_2', '2406.12707_3_12_2', '2406.12707_3_13_2', '2406.12707_3_14_2', '2406.12707_3_15_2', '2406.12707_3_16_2', '2406.12707_3_17_2', '2406.12707_3_18_2', '2406.12707_3_19_2', '2406.12707_3_20_2', '2406.12707_3_21_2', '2406.12707_3_22_2', '2406.12707_3_23_2', '2407.16667_1_0_0', '2407.16667_1_1_0', '2407.16667_1_2_0', '2407.16667_1_3_0', '2407.16667_1_4_0', '2407.16667_1_5_0', '2407.16667_1_6_0', '2407.16667_1_7_0', '2407.16667_1_8_0', '2407.16667_1_9_0', '2407.16667_1_10_0', '2407.16667_1_11_0', '2407.16667_1_12_0', '2407.16667_1_13_0', '2407.16667_1_14_0', '2407.16667_1_15_0', '2407.16667_1_16_0', '2407.16667_1_17_0', '2407.16667_1_18_0', '2407.16667_1_19_0', '2407.16667_1_20_0', '2407.16667_1_21_0', '2407.16667_1_22_0', '2407.16667_1_23_0', '2407.16667_1_24_0', '2407.16667_1_25_0', '2407.16667_1_26_0', '2407.16667_1_27_0', '2407.16667_1_28_0', '2407.16667_1_29_0', '2407.16667_1_30_0', '2407.16667_1_31_0', '2407.16667_1_32_0', '2407.16667_1_33_0', '2407.16667_1_34_0', '2407.16667_1_35_0', '2407.16667_1_36_0', '2407.16667_1_37_0', '2407.16667_1_38_0', '2407.16667_1_39_0', '2407.16667_1_40_0', '2407.16667_1_41_0', '2407.16667_1_42_0', '2407.16667_1_43_0', '2407.16667_1_44_0', '2407.16667_1_45_0', '2407.16667_1_46_0', '2407.16667_1_47_0', '2407.16667_1_48_0', '2407.16667_1_49_0', '2407.16667_1_50_0', '2407.16667_1_51_0', '2407.16667_1_52_0', '2407.16667_1_53_0', '2407.16667_1_54_0', '2407.16667_1_55_0', '2407.16667_1_56_0', '2407.16667_1_57_0', '2407.16667_1_58_0', '2407.16667_1_59_0', '2407.16667_3_0_0', '2407.16667_3_1_0', '2407.16667_3_2_0', '2407.16667_3_3_0', '2407.16667_3_4_0', '2407.16667_3_5_0', '2407.16667_3_6_0', '2407.16667_3_7_0', '2407.16667_3_8_0', '2407.16667_3_9_0', '2407.16667_4_0_0', '2407.16667_4_1_0', '2407.16667_4_2_0', '2407.16667_4_3_0', '2407.16667_4_4_0', '2407.16667_4_5_0', '2407.16667_4_6_0', '2407.16667_4_7_0', '2407.17115_4_0_3', '2407.17115_4_1_3', '2407.17115_4_2_3', '2407.17115_4_3_3', '2407.17115_4_4_3', '2407.17115_4_5_3', '2407.17115_4_6_3', '2407.17115_4_7_3', '2407.17115_4_8_3', '2407.17115_4_9_3', '2407.17115_4_10_3', '2407.17115_4_11_3', '2407.17115_4_12_3', '2407.17115_4_13_3', '2407.17115_4_14_3', '2407.17115_4_15_3', '2407.17115_4_16_3', '2407.17115_4_17_3', '2407.17115_4_18_3', '2407.17115_4_19_3', '2407.17115_4_20_3', '2407.17115_4_21_3', '2407.17115_4_22_3', '2407.17115_4_23_3', '2407.17115_4_24_3', '2407.17115_4_25_3', '2407.17115_4_26_3', '2407.17115_4_27_3', '2407.17115_4_28_3', '2407.17115_4_29_3', '2407.17115_4_30_3', '2407.17115_4_31_3', '2407.17115_4_32_3', '2407.17115_4_33_3', '2407.17115_4_34_3', '2407.17115_4_35_3', '2407.17115_4_36_3', '2407.17115_4_37_3', '2407.17115_4_38_3', '2407.17115_4_39_3', '2407.17115_4_40_3', '2407.17115_4_41_3', '2407.17115_4_42_3', '2407.17115_4_43_3', '2407.17115_4_44_3', '2407.17115_4_45_3', '2407.17115_4_46_3', '2407.17115_4_47_3', '2407.17115_4_48_3', '2407.17115_4_49_3', '2407.17115_4_50_3', '2407.17115_4_51_3', '2407.17115_4_52_3', '2407.17115_4_53_3', '2407.17115_4_54_3', '2407.17115_4_55_3', '2407.17115_4_56_3', '2407.17115_4_57_3', '2407.17115_4_58_3', '2407.17115_4_59_3', '2407.17115_4_60_3', '2407.17115_4_61_3', '2407.17115_4_62_3', '2407.17115_5_0_0', '2407.17115_5_1_0', '2407.17115_5_2_0', '2407.17115_5_3_0', '2407.17115_5_4_0', '2407.17115_5_5_0', '2407.17115_5_6_0', '2407.17115_5_7_0', '2407.17115_5_8_0', '2407.17115_5_9_0', '2407.17115_5_10_0', '2407.17115_5_11_0', '2407.17115_5_12_0', '2407.17115_5_13_0', '2407.17115_5_14_0', '2407.17115_5_15_0', '2407.17115_5_16_0', '2407.17115_5_17_0', '2407.17115_5_18_0', '2407.17115_5_19_0', '2407.17115_5_20_0', '2407.17115_5_21_0', '2407.17115_5_22_0', '2407.17115_5_23_0', '2407.17115_5_24_0', '2407.17115_5_25_0', '2407.17115_5_26_0', '2407.17115_5_27_0', '2407.17115_5_28_0', '2407.17115_5_29_0', '2407.17115_5_30_0', '2407.17115_5_31_0', '2407.17115_5_32_0', '2407.17115_5_33_0', '2407.17115_5_34_0', '2407.17115_5_35_0', '2407.17115_5_36_0', '2407.17115_5_37_0', '2407.17115_5_38_0', '2407.17115_5_39_0', '2407.17115_5_40_0', '2407.17115_5_41_0', '2407.17115_5_42_0', '2407.17115_5_43_0', '2407.17115_5_44_0', '2407.17115_5_45_0', '2407.17115_5_46_0', '2407.17115_5_47_0', '2407.17115_5_48_0', '2407.17115_5_49_0', '2407.17115_5_50_0', '2407.17115_5_51_0', '2407.17115_5_52_0', '2407.17115_5_53_0', '2407.17115_5_54_0', '2407.17115_5_55_0', '2407.17115_5_56_0', '2407.17115_5_57_0', '2407.17115_5_58_0', '2407.17115_5_59_0', '2407.17115_5_60_0', '2407.17115_5_61_0', '2407.17115_5_62_0'], 'metrics': [], 'outcome': []}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "def build_json(df):\n",
    "    json_data = {}\n",
    "    name2spec = {}\n",
    "    for col in df.columns:\n",
    "        if col not in ['claim_id', 'table_id', 'paper_id', 'Outcome']:\n",
    "            nomi = []\n",
    "            for _,row in df.iterrows():\n",
    "                filename = constr_filename(row['paper_id'], row['table_id'])\n",
    "                spec_id = retrieve_spec_id(filename, row['claim_id'], row[col])\n",
    "                if (spec_id is not None):\n",
    "                    nomi.append(f\"{row['paper_id']}_{row['table_id']}_{row['claim_id']}_{spec_id}\")  \n",
    "            name2spec[col] = nomi\n",
    "        json_data['aligned_names'] = name2spec\n",
    "    return json_data\n",
    "\n",
    "pprint(build_json(aligned_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_from_json(json_data):\n",
    "    values_set = set()\n",
    "\n",
    "    def extract_values(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for value in obj.values():\n",
    "                extract_values(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract_values(item)\n",
    "        else:\n",
    "            values_set.add(obj)\n",
    "\n",
    "    extract_values(json_data)\n",
    "    return values_set\n",
    "\n",
    "# Load the JSON file\n",
    "with open('alignment_schema.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract values\n",
    "values_set = extract_values_from_json(json_data)\n",
    "sorted_list = sorted(list(values_set))\n",
    "output_dict = {key: None for key in sorted_list}\n",
    "\n",
    "\n",
    "output_file = \"alignment_values_schema.json\"\n",
    "with open(output_file, \"w\") as json_file:\n",
    "    json.dump(output_dict, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
