{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PROFILING_DIR = '../consegna/profilings/GPT-4o'\n",
    "INPUT_DIR = '../consegna/LLMAGENTS_CLAIMS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load profilings csv into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22136\\772492641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvalue_profilings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPROFILING_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VALUE_PROFILING.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvalue_profilings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_profilings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_profilings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\matte\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "value_profilings = pd.read_csv(os.path.join(PROFILING_DIR, 'VALUE_PROFILING.csv'))\n",
    "value_profilings = value_profilings.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "print(value_profilings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load claim and convert it to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_as_df(filename):\n",
    "    with open(os.path.join(INPUT_DIR, filename), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    rows = []\n",
    "    for key, entry in json_data.items():\n",
    "        row = {}\n",
    "        row['claim_id'] = key\n",
    "        # Extract specifications\n",
    "        for spec_key, spec in entry[\"specifications\"].items():\n",
    "            row[spec[\"name\"]] = spec[\"value\"]\n",
    "        # Add measure and outcome\n",
    "        row[\"Measure\"] = entry[\"Measure\"]\n",
    "        row[\"Outcome\"] = entry[\"Outcome\"]\n",
    "        rows.append(row)\n",
    "    claim_df = pd.DataFrame(rows)\n",
    "    filename = filename.replace(\"_claims.json\",\"\")\n",
    "    claim_df['paper_id'] = filename.split('_')[0]\n",
    "    claim_df['table_id'] = filename.split('_')[1]\n",
    "    return claim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reassign values in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   claim_id                     Dataset           Task    Method Measure  \\\n",
      "0         0  HaluEval Li et al. (2023a)             QA  HaluEval    Acc.   \n",
      "1         1  HaluEval Li et al. (2023a)             QA  HaluEval       R   \n",
      "2         2  HaluEval Li et al. (2023a)             QA  HaluEval       P   \n",
      "3         3  HaluEval Li et al. (2023a)             QA  HaluEval      F1   \n",
      "4         4  HaluEval Li et al. (2023a)             QA   FACTOOL    Acc.   \n",
      "5         5  HaluEval Li et al. (2023a)             QA   FACTOOL       R   \n",
      "6         6  HaluEval Li et al. (2023a)             QA   FACTOOL       P   \n",
      "7         7  HaluEval Li et al. (2023a)             QA   FACTOOL      F1   \n",
      "8         8  HaluEval Li et al. (2023a)             QA      Ours    Acc.   \n",
      "9         9  HaluEval Li et al. (2023a)             QA      Ours       R   \n",
      "10       10  HaluEval Li et al. (2023a)             QA      Ours       P   \n",
      "11       11  HaluEval Li et al. (2023a)             QA      Ours      F1   \n",
      "12       12  HaluEval Li et al. (2023a)  Summarization  HaluEval    Acc.   \n",
      "13       13  HaluEval Li et al. (2023a)  Summarization  HaluEval       R   \n",
      "14       14  HaluEval Li et al. (2023a)  Summarization  HaluEval       P   \n",
      "15       15  HaluEval Li et al. (2023a)  Summarization  HaluEval      F1   \n",
      "16       16  HaluEval Li et al. (2023a)  Summarization   FACTOOL    Acc.   \n",
      "17       17  HaluEval Li et al. (2023a)  Summarization   FACTOOL       R   \n",
      "18       18  HaluEval Li et al. (2023a)  Summarization   FACTOOL       P   \n",
      "19       19  HaluEval Li et al. (2023a)  Summarization   FACTOOL      F1   \n",
      "20       20  HaluEval Li et al. (2023a)  Summarization      Ours    Acc.   \n",
      "21       21  HaluEval Li et al. (2023a)  Summarization      Ours       R   \n",
      "22       22  HaluEval Li et al. (2023a)  Summarization      Ours       P   \n",
      "23       23  HaluEval Li et al. (2023a)  Summarization      Ours      F1   \n",
      "24       24  HaluEval Li et al. (2023a)       Dialogue  HaluEval    Acc.   \n",
      "25       25  HaluEval Li et al. (2023a)       Dialogue  HaluEval       R   \n",
      "26       26  HaluEval Li et al. (2023a)       Dialogue  HaluEval       P   \n",
      "27       27  HaluEval Li et al. (2023a)       Dialogue  HaluEval      F1   \n",
      "28       28  HaluEval Li et al. (2023a)       Dialogue   FACTOOL    Acc.   \n",
      "29       29  HaluEval Li et al. (2023a)       Dialogue   FACTOOL       R   \n",
      "30       30  HaluEval Li et al. (2023a)       Dialogue   FACTOOL       P   \n",
      "31       31  HaluEval Li et al. (2023a)       Dialogue   FACTOOL      F1   \n",
      "32       32  HaluEval Li et al. (2023a)       Dialogue      Ours    Acc.   \n",
      "33       33  HaluEval Li et al. (2023a)       Dialogue      Ours       R   \n",
      "34       34  HaluEval Li et al. (2023a)       Dialogue      Ours       P   \n",
      "35       35  HaluEval Li et al. (2023a)       Dialogue      Ours      F1   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0    56.00  2406.03075        3  \n",
      "1    77.33  2406.03075        3  \n",
      "2    54.21  2406.03075        3  \n",
      "3    63.74  2406.03075        3  \n",
      "4    67.33  2406.03075        3  \n",
      "5    86.67  2406.03075        3  \n",
      "6    62.50  2406.03075        3  \n",
      "7    72.63  2406.03075        3  \n",
      "8    70.67  2406.03075        3  \n",
      "9    82.67  2406.03075        3  \n",
      "10   66.67  2406.03075        3  \n",
      "11   73.81  2406.03075        3  \n",
      "12   58.00  2406.03075        3  \n",
      "13   100.0  2406.03075        3  \n",
      "14   54.35  2406.03075        3  \n",
      "15   70.42  2406.03075        3  \n",
      "16   64.00  2406.03075        3  \n",
      "17   48.00  2406.03075        3  \n",
      "18   70.59  2406.03075        3  \n",
      "19   57.14  2406.03075        3  \n",
      "20   70.00  2406.03075        3  \n",
      "21   64.00  2406.03075        3  \n",
      "22   72.73  2406.03075        3  \n",
      "23   68.09  2406.03075        3  \n",
      "24   68.00  2406.03075        3  \n",
      "25   75.71  2406.03075        3  \n",
      "26   63.10  2406.03075        3  \n",
      "27   68.83  2406.03075        3  \n",
      "28   74.67  2406.03075        3  \n",
      "29   70.00  2406.03075        3  \n",
      "30   74,24  2406.03075        3  \n",
      "31   72.06  2406.03075        3  \n",
      "32   76.00  2406.03075        3  \n",
      "33   62.86  2406.03075        3  \n",
      "34   81.48  2406.03075        3  \n",
      "35   70.97  2406.03075        3  \n",
      "   claim_id                        task query_budget           Method  \\\n",
      "0         0  Jailbreak general-use LLMs           40             PAIR   \n",
      "1         1  Jailbreak general-use LLMs           40             PAIR   \n",
      "2         2  Jailbreak general-use LLMs           40             PAIR   \n",
      "3         3  Jailbreak general-use LLMs           40             PAIR   \n",
      "4         4  Jailbreak general-use LLMs           40             PAIR   \n",
      "5         5  Jailbreak general-use LLMs           40             PAIR   \n",
      "6         6  Jailbreak general-use LLMs           40             PAIR   \n",
      "7         7  Jailbreak general-use LLMs           40             PAIR   \n",
      "8         8  Jailbreak general-use LLMs           40             PAIR   \n",
      "9         9  Jailbreak general-use LLMs           40             PAIR   \n",
      "10       10  Jailbreak general-use LLMs           40             PAIR   \n",
      "11       11  Jailbreak general-use LLMs           40             PAIR   \n",
      "12       12  Jailbreak general-use LLMs           40              TAP   \n",
      "13       13  Jailbreak general-use LLMs           40              TAP   \n",
      "14       14  Jailbreak general-use LLMs           40              TAP   \n",
      "15       15  Jailbreak general-use LLMs           40              TAP   \n",
      "16       16  Jailbreak general-use LLMs           40              TAP   \n",
      "17       17  Jailbreak general-use LLMs           40              TAP   \n",
      "18       18  Jailbreak general-use LLMs           40              TAP   \n",
      "19       19  Jailbreak general-use LLMs           40              TAP   \n",
      "20       20  Jailbreak general-use LLMs           40              TAP   \n",
      "21       21  Jailbreak general-use LLMs           40              TAP   \n",
      "22       22  Jailbreak general-use LLMs           40              TAP   \n",
      "23       23  Jailbreak general-use LLMs           40              TAP   \n",
      "24       24  Jailbreak general-use LLMs           40              PAP   \n",
      "25       25  Jailbreak general-use LLMs           40              PAP   \n",
      "26       26  Jailbreak general-use LLMs           40              PAP   \n",
      "27       27  Jailbreak general-use LLMs           40              PAP   \n",
      "28       28  Jailbreak general-use LLMs           40              PAP   \n",
      "29       29  Jailbreak general-use LLMs           40              PAP   \n",
      "30       30  Jailbreak general-use LLMs           40              PAP   \n",
      "31       31  Jailbreak general-use LLMs           40              PAP   \n",
      "32       32  Jailbreak general-use LLMs           40              PAP   \n",
      "33       33  Jailbreak general-use LLMs           40              PAP   \n",
      "34       34  Jailbreak general-use LLMs           40              PAP   \n",
      "35       35  Jailbreak general-use LLMs           40              PAP   \n",
      "36       36  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "37       37  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "38       38  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "39       39  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "40       40  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "41       41  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "42       42  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "43       43  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "44       44  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "45       45  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "46       46  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "47       47  Jailbreak general-use LLMs           40        GPTFuzzer   \n",
      "48       48  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "49       49  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "50       50  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "51       51  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "52       52  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "53       53  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "54       54  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "55       55  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "56       56  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "57       57  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "58       58  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "59       59  Jailbreak general-use LLMs           40  RedAgent (Ours)   \n",
      "\n",
      "                 Model Measure Outcome    paper_id table_id  \n",
      "0       Vicuna-7b-v1.5     ASR      94  2407.16667        1  \n",
      "1       Vicuna-7b-v1.5     ANQ    6.72  2407.16667        1  \n",
      "2   LLaMa-2-7b-chat-hf     ASR      46  2407.16667        1  \n",
      "3   LLaMa-2-7b-chat-hf     ANQ   19.74  2407.16667        1  \n",
      "4   GPT-3.5-turbo-1106     ASR      64  2407.16667        1  \n",
      "5   GPT-3.5-turbo-1106     ANQ   13.25  2407.16667        1  \n",
      "6   GPT-4-1106-preview     ASR      74  2407.16667        1  \n",
      "7   GPT-4-1106-preview     ANQ    9.73  2407.16667        1  \n",
      "8           Gemini-Pro     ASR      94  2407.16667        1  \n",
      "9           Gemini-Pro     ANQ    7.75  2407.16667        1  \n",
      "10   Claude-3.5-sonnet     ASR      38  2407.16667        1  \n",
      "11   Claude-3.5-sonnet     ANQ   17.05  2407.16667        1  \n",
      "12      Vicuna-7b-v1.5     ASR      90  2407.16667        1  \n",
      "13      Vicuna-7b-v1.5     ANQ    4.58  2407.16667        1  \n",
      "14  LLaMa-2-7b-chat-hf     ASR      48  2407.16667        1  \n",
      "15  LLaMa-2-7b-chat-hf     ANQ   13.25  2407.16667        1  \n",
      "16  GPT-3.5-turbo-1106     ASR      36  2407.16667        1  \n",
      "17  GPT-3.5-turbo-1106     ANQ    9.67  2407.16667        1  \n",
      "18  GPT-4-1106-preview     ASR      62  2407.16667        1  \n",
      "19  GPT-4-1106-preview     ANQ    9.36  2407.16667        1  \n",
      "20          Gemini-Pro     ASR      86  2407.16667        1  \n",
      "21          Gemini-Pro     ANQ    6.21  2407.16667        1  \n",
      "22   Claude-3.5-sonnet     ASR      22  2407.16667        1  \n",
      "23   Claude-3.5-sonnet     ANQ      13  2407.16667        1  \n",
      "24      Vicuna-7b-v1.5     ASR      94  2407.16667        1  \n",
      "25      Vicuna-7b-v1.5     ANQ    4.15  2407.16667        1  \n",
      "26  LLaMa-2-7b-chat-hf     ASR      58  2407.16667        1  \n",
      "27  LLaMa-2-7b-chat-hf     ANQ   13.86  2407.16667        1  \n",
      "28  GPT-3.5-turbo-1106     ASR      58  2407.16667        1  \n",
      "29  GPT-3.5-turbo-1106     ANQ     9.1  2407.16667        1  \n",
      "30  GPT-4-1106-preview     ASR      92  2407.16667        1  \n",
      "31  GPT-4-1106-preview     ANQ    5.63  2407.16667        1  \n",
      "32          Gemini-Pro     ASR      96  2407.16667        1  \n",
      "33          Gemini-Pro     ANQ     2.1  2407.16667        1  \n",
      "34   Claude-3.5-sonnet     ASR      16  2407.16667        1  \n",
      "35   Claude-3.5-sonnet     ANQ   11.75  2407.16667        1  \n",
      "36      Vicuna-7b-v1.5     ASR     100  2407.16667        1  \n",
      "37      Vicuna-7b-v1.5     ANQ     1.2  2407.16667        1  \n",
      "38  LLaMa-2-7b-chat-hf     ASR      62  2407.16667        1  \n",
      "39  LLaMa-2-7b-chat-hf     ANQ   17.26  2407.16667        1  \n",
      "40  GPT-3.5-turbo-1106     ASR      50  2407.16667        1  \n",
      "41  GPT-3.5-turbo-1106     ANQ   15.04  2407.16667        1  \n",
      "42  GPT-4-1106-preview     ASR      12  2407.16667        1  \n",
      "43  GPT-4-1106-preview     ANQ    9.17  2407.16667        1  \n",
      "44          Gemini-Pro     ASR      98  2407.16667        1  \n",
      "45          Gemini-Pro     ANQ   2.306  2407.16667        1  \n",
      "46   Claude-3.5-sonnet     ASR       0  2407.16667        1  \n",
      "47   Claude-3.5-sonnet     ANQ     N/A  2407.16667        1  \n",
      "48      Vicuna-7b-v1.5     ASR     100  2407.16667        1  \n",
      "49      Vicuna-7b-v1.5     ANQ    2.68  2407.16667        1  \n",
      "50  LLaMa-2-7b-chat-hf     ASR      92  2407.16667        1  \n",
      "51  LLaMa-2-7b-chat-hf     ANQ    6.89  2407.16667        1  \n",
      "52  GPT-3.5-turbo-1106     ASR      96  2407.16667        1  \n",
      "53  GPT-3.5-turbo-1106     ANQ    5.73  2407.16667        1  \n",
      "54  GPT-4-1106-preview     ASR     100  2407.16667        1  \n",
      "55  GPT-4-1106-preview     ANQ    3.76  2407.16667        1  \n",
      "56          Gemini-Pro     ASR     100  2407.16667        1  \n",
      "57          Gemini-Pro     ANQ    3.76  2407.16667        1  \n",
      "58   Claude-3.5-sonnet     ASR      74  2407.16667        1  \n",
      "59   Claude-3.5-sonnet     ANQ    9.54  2407.16667        1  \n",
      "   claim_id         Discriminator Dataset       Planning Method  \\\n",
      "0         0         CodeLlama-13B  Spider            Re-ranking   \n",
      "1         1         CodeLlama-13B  Spider  Iterative Correction   \n",
      "2         2         CodeLlama-13B  Spider           Tree Search   \n",
      "3         3         CodeLlama-13B  Spider     Advanced Planning   \n",
      "4         4         GPT-3.5-Turbo    Bird            Re-ranking   \n",
      "5         5         GPT-3.5-Turbo    Bird  Iterative Correction   \n",
      "6         6         GPT-3.5-Turbo    Bird           Tree Search   \n",
      "7         7         GPT-3.5-Turbo    Bird     Advanced Planning   \n",
      "8         8      CodeLlama-13B-FT  Spider            Re-ranking   \n",
      "9         9      CodeLlama-13B-FT  Spider  Iterative Correction   \n",
      "10       10      CodeLlama-13B-FT  Spider           Tree Search   \n",
      "11       11      CodeLlama-13B-FT  Spider     Advanced Planning   \n",
      "12       12     CodeLlama-13B (E)    Bird            Re-ranking   \n",
      "13       13     CodeLlama-13B (E)    Bird  Iterative Correction   \n",
      "14       14     CodeLlama-13B (E)    Bird           Tree Search   \n",
      "15       15     CodeLlama-13B (E)    Bird     Advanced Planning   \n",
      "16       16     GPT-3.5-Turbo (E)  Spider            Re-ranking   \n",
      "17       17     GPT-3.5-Turbo (E)  Spider  Iterative Correction   \n",
      "18       18     GPT-3.5-Turbo (E)  Spider           Tree Search   \n",
      "19       19     GPT-3.5-Turbo (E)  Spider     Advanced Planning   \n",
      "20       20  CodeLlama-13B-FT (E)    Bird            Re-ranking   \n",
      "21       21  CodeLlama-13B-FT (E)    Bird  Iterative Correction   \n",
      "22       22  CodeLlama-13B-FT (E)    Bird           Tree Search   \n",
      "23       23  CodeLlama-13B-FT (E)    Bird     Advanced Planning   \n",
      "\n",
      "                   Task   Measure Outcome    paper_id table_id  \n",
      "0   text-to-SQL parsing  Accuracy    57.5  2402.10890        3  \n",
      "1   text-to-SQL parsing  Accuracy    51.7  2402.10890        3  \n",
      "2   text-to-SQL parsing  Accuracy    55.5  2402.10890        3  \n",
      "3   text-to-SQL parsing  Accuracy     nan  2402.10890        3  \n",
      "4   text-to-SQL parsing  Accuracy    13.3  2402.10890        3  \n",
      "5   text-to-SQL parsing  Accuracy    13.3  2402.10890        3  \n",
      "6   text-to-SQL parsing  Accuracy    13.3  2402.10890        3  \n",
      "7   text-to-SQL parsing  Accuracy     nan  2402.10890        3  \n",
      "8   text-to-SQL parsing  Accuracy    61.5  2402.10890        3  \n",
      "9   text-to-SQL parsing  Accuracy    51.7  2402.10890        3  \n",
      "10  text-to-SQL parsing  Accuracy    56.0  2402.10890        3  \n",
      "11  text-to-SQL parsing  Accuracy    67.5  2402.10890        3  \n",
      "12  text-to-SQL parsing  Accuracy    14.3  2402.10890        3  \n",
      "13  text-to-SQL parsing  Accuracy    13.0  2402.10890        3  \n",
      "14  text-to-SQL parsing  Accuracy    13.0  2402.10890        3  \n",
      "15  text-to-SQL parsing  Accuracy    23.7  2402.10890        3  \n",
      "16  text-to-SQL parsing  Accuracy    65.5  2402.10890        3  \n",
      "17  text-to-SQL parsing  Accuracy    62.0  2402.10890        3  \n",
      "18  text-to-SQL parsing  Accuracy    62.5  2402.10890        3  \n",
      "19  text-to-SQL parsing  Accuracy    70.3  2402.10890        3  \n",
      "20  text-to-SQL parsing  Accuracy    21.0  2402.10890        3  \n",
      "21  text-to-SQL parsing  Accuracy    24.3  2402.10890        3  \n",
      "22  text-to-SQL parsing  Accuracy    22.7  2402.10890        3  \n",
      "23  text-to-SQL parsing  Accuracy    26.3  2402.10890        3  \n",
      "   claim_id                    Task          Method Dataset Measure Outcome  \\\n",
      "0         0  Ablation study on RPP+  Manual prompts   ML-1M     N@1    0.03   \n",
      "1         1  Ablation study on RPP+  Manual prompts   ML-1M     N@5    0.35   \n",
      "2         2  Ablation study on RPP+  Manual prompts   ML-1M    N@10    0.41   \n",
      "3         3  Ablation study on RPP+  Manual prompts   Games     N@1    0.04   \n",
      "4         4  Ablation study on RPP+  Manual prompts   Games     N@5    0.36   \n",
      "..      ...                     ...             ...     ...     ...     ...   \n",
      "58       58  Ablation study on RPP+            RPP+   Games     N@5    0.87   \n",
      "59       59  Ablation study on RPP+            RPP+   Games    N@10    0.91   \n",
      "60       60  Ablation study on RPP+            RPP+  Lastfm     N@1    0.93   \n",
      "61       61  Ablation study on RPP+            RPP+  Lastfm     N@5    0.94   \n",
      "62       62  Ablation study on RPP+            RPP+  Lastfm    N@10    0.95   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2407.17115        5  \n",
      "1   2407.17115        5  \n",
      "2   2407.17115        5  \n",
      "3   2407.17115        5  \n",
      "4   2407.17115        5  \n",
      "..         ...      ...  \n",
      "58  2407.17115        5  \n",
      "59  2407.17115        5  \n",
      "60  2407.17115        5  \n",
      "61  2407.17115        5  \n",
      "62  2407.17115        5  \n",
      "\n",
      "[63 rows x 8 columns]\n",
      "   claim_id Emotion Label        Model               Task    Measure Outcome  \\\n",
      "0         0          Love  Ensemble-19  Emotion Detection   F1-score    0.47   \n",
      "1         1          Love  Ensemble-19  Emotion Detection  Precision    0.55   \n",
      "2         2          Love  Ensemble-19  Emotion Detection     Recall    0.41   \n",
      "3         3          Love  Ensemble-19  Emotion Detection    Support     190   \n",
      "4         4           Joy  Ensemble-19  Emotion Detection   F1-score    0.63   \n",
      "5         5           Joy  Ensemble-19  Emotion Detection  Precision    0.55   \n",
      "6         6           Joy  Ensemble-19  Emotion Detection     Recall    0.74   \n",
      "7         7           Joy  Ensemble-19  Emotion Detection    Support     433   \n",
      "8         8         Anger  Ensemble-19  Emotion Detection   F1-score    0.73   \n",
      "9         9         Anger  Ensemble-19  Emotion Detection  Precision    0.76   \n",
      "10       10         Anger  Ensemble-19  Emotion Detection     Recall     0.7   \n",
      "11       11         Anger  Ensemble-19  Emotion Detection    Support     614   \n",
      "12       12          Fear  Ensemble-19  Emotion Detection   F1-score    0.53   \n",
      "13       13          Fear  Ensemble-19  Emotion Detection  Precision    0.44   \n",
      "14       14          Fear  Ensemble-19  Emotion Detection     Recall    0.68   \n",
      "15       15          Fear  Ensemble-19  Emotion Detection    Support      77   \n",
      "16       16       Sadness  Ensemble-19  Emotion Detection   F1-score    0.55   \n",
      "17       17       Sadness  Ensemble-19  Emotion Detection  Precision    0.56   \n",
      "18       18       Sadness  Ensemble-19  Emotion Detection     Recall    0.54   \n",
      "19       19       Sadness  Ensemble-19  Emotion Detection    Support     270   \n",
      "20       20       Neutral  Ensemble-19  Emotion Detection   F1-score    0.72   \n",
      "21       21       Neutral  Ensemble-19  Emotion Detection  Precision    0.76   \n",
      "22       22       Neutral  Ensemble-19  Emotion Detection     Recall    0.68   \n",
      "23       23       Neutral  Ensemble-19  Emotion Detection    Support     916   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2405.17129        4  \n",
      "1   2405.17129        4  \n",
      "2   2405.17129        4  \n",
      "3   2405.17129        4  \n",
      "4   2405.17129        4  \n",
      "5   2405.17129        4  \n",
      "6   2405.17129        4  \n",
      "7   2405.17129        4  \n",
      "8   2405.17129        4  \n",
      "9   2405.17129        4  \n",
      "10  2405.17129        4  \n",
      "11  2405.17129        4  \n",
      "12  2405.17129        4  \n",
      "13  2405.17129        4  \n",
      "14  2405.17129        4  \n",
      "15  2405.17129        4  \n",
      "16  2405.17129        4  \n",
      "17  2405.17129        4  \n",
      "18  2405.17129        4  \n",
      "19  2405.17129        4  \n",
      "20  2405.17129        4  \n",
      "21  2405.17129        4  \n",
      "22  2405.17129        4  \n",
      "23  2405.17129        4  \n",
      "   claim_id          Model    Prompt                                Task  \\\n",
      "0         0  GPT-3.5-turbo  Prompt-1  zero-shot task-solving performance   \n",
      "1         1  GPT-3.5-turbo  Prompt-1  zero-shot task-solving performance   \n",
      "2         2  GPT-3.5-turbo  Prompt-2  zero-shot task-solving performance   \n",
      "3         3  GPT-3.5-turbo  Prompt-2  zero-shot task-solving performance   \n",
      "4         4  GPT-3.5-turbo  Prompt-2  zero-shot task-solving performance   \n",
      "..      ...            ...       ...                                 ...   \n",
      "63       63          GPT-4  Prompt-1  zero-shot task-solving performance   \n",
      "64       64          GPT-4  Prompt-1  zero-shot task-solving performance   \n",
      "65       65          GPT-4  Prompt-2  zero-shot task-solving performance   \n",
      "66       66          GPT-4  Prompt-2  zero-shot task-solving performance   \n",
      "67       67          GPT-4  Prompt-2  zero-shot task-solving performance   \n",
      "\n",
      "       Measure Outcome    paper_id table_id  \n",
      "0   CLIP Score  0.2106  2304.04370        3  \n",
      "1   CLIP Score  0.0702  2304.04370        3  \n",
      "2   CLIP Score  0.3013  2304.04370        3  \n",
      "3   CLIP Score   0.271  2304.04370        3  \n",
      "4   CLIP Score  0.1907  2304.04370        3  \n",
      "..         ...     ...         ...      ...  \n",
      "63     Overall  0.5497  2304.04370        3  \n",
      "64     Overall  0.3299  2304.04370        3  \n",
      "65     Overall  0.5595  2304.04370        3  \n",
      "66     Overall  0.5565  2304.04370        3  \n",
      "67     Overall  0.3717  2304.04370        3  \n",
      "\n",
      "[68 rows x 8 columns]\n",
      "   claim_id LLM-Backend Method                   Task         Measure  \\\n",
      "0         0     GPT-3.5     IO  Creative Writing Task  Coherent Score   \n",
      "1         1     GPT-3.5     IO  Creative Writing Task      User Study   \n",
      "2         2       GPT-4     IO  Creative Writing Task  Coherent Score   \n",
      "3         3       GPT-4     IO  Creative Writing Task      User Study   \n",
      "4         4     GPT-3.5    CoT  Creative Writing Task  Coherent Score   \n",
      "5         5     GPT-3.5    CoT  Creative Writing Task      User Study   \n",
      "6         6       GPT-4    CoT  Creative Writing Task  Coherent Score   \n",
      "7         7       GPT-4    CoT  Creative Writing Task      User Study   \n",
      "8         8     GPT-3.5    ToT  Creative Writing Task  Coherent Score   \n",
      "9         9     GPT-3.5    ToT  Creative Writing Task      User Study   \n",
      "10       10       GPT-4    ToT  Creative Writing Task  Coherent Score   \n",
      "11       11       GPT-4    ToT  Creative Writing Task      User Study   \n",
      "12       12     GPT-3.5     TP  Creative Writing Task  Coherent Score   \n",
      "13       13     GPT-3.5     TP  Creative Writing Task      User Study   \n",
      "14       14       GPT-4     TP  Creative Writing Task  Coherent Score   \n",
      "15       15       GPT-4     TP  Creative Writing Task      User Study   \n",
      "\n",
      "          Outcome    paper_id table_id  \n",
      "0   6.087 ± 2.229  2310.03965        2  \n",
      "1             14%  2310.03965        2  \n",
      "2   6.193 ± 1.953  2310.03965        2  \n",
      "3              7%  2310.03965        2  \n",
      "4   6.654 ± 2.201  2310.03965        2  \n",
      "5             21%  2310.03965        2  \n",
      "6   6.927 ± 1.508  2310.03965        2  \n",
      "7             15%  2310.03965        2  \n",
      "8   6.856 ± 1.975  2310.03965        2  \n",
      "9             26%  2310.03965        2  \n",
      "10  7.684 ± 1.141  2310.03965        2  \n",
      "11            33%  2310.03965        2  \n",
      "12  7.000 ± 1.783  2310.03965        2  \n",
      "13            39%  2310.03965        2  \n",
      "14  7.989 ± 1.453  2310.03965        2  \n",
      "15            45%  2310.03965        2  \n",
      "   claim_id        Attack Method         Model Dataset  \\\n",
      "0         0        Combination-1       GPT-3.5     DAN   \n",
      "1         1        Combination-1    Vicuna-13b     DAN   \n",
      "2         2        Combination-1   LLaMA-2-70b     DAN   \n",
      "3         3        Combination-1  mixtral-8x7b     DAN   \n",
      "4         4     Prefix Injection       GPT-3.5     DAN   \n",
      "5         5     Prefix Injection    Vicuna-13b     DAN   \n",
      "6         6     Prefix Injection   LLaMA-2-70b     DAN   \n",
      "7         7     Prefix Injection  mixtral-8x7b     DAN   \n",
      "8         8  Refusal Suppression       GPT-3.5     DAN   \n",
      "9         9  Refusal Suppression    Vicuna-13b     DAN   \n",
      "10       10  Refusal Suppression   LLaMA-2-70b     DAN   \n",
      "11       11  Refusal Suppression  mixtral-8x7b     DAN   \n",
      "12       12        Combination-2       GPT-3.5     DAN   \n",
      "13       13        Combination-2    Vicuna-13b     DAN   \n",
      "14       14        Combination-2   LLaMA-2-70b     DAN   \n",
      "15       15        Combination-2  mixtral-8x7b     DAN   \n",
      "16       16                  AIM       GPT-3.5     DAN   \n",
      "17       17                  AIM    Vicuna-13b     DAN   \n",
      "18       18                  AIM   LLaMA-2-70b     DAN   \n",
      "19       19                  AIM  mixtral-8x7b     DAN   \n",
      "20       20                  N/A       GPT-3.5     DAN   \n",
      "21       21                  N/A    Vicuna-13b     DAN   \n",
      "22       22                  N/A   LLaMA-2-70b     DAN   \n",
      "23       23                  N/A  mixtral-8x7b     DAN   \n",
      "\n",
      "                              Task Measure Outcome    paper_id table_id  \n",
      "0   Attack Success Rate Evaluation     ASR   55.74  2403.04783        1  \n",
      "1   Attack Success Rate Evaluation     ASR   57.18  2403.04783        1  \n",
      "2   Attack Success Rate Evaluation     ASR    4.87  2403.04783        1  \n",
      "3   Attack Success Rate Evaluation     ASR   40.77  2403.04783        1  \n",
      "4   Attack Success Rate Evaluation     ASR   34.36  2403.04783        1  \n",
      "5   Attack Success Rate Evaluation     ASR   51.03  2403.04783        1  \n",
      "6   Attack Success Rate Evaluation     ASR    6.41  2403.04783        1  \n",
      "7   Attack Success Rate Evaluation     ASR   49.23  2403.04783        1  \n",
      "8   Attack Success Rate Evaluation     ASR   29.74  2403.04783        1  \n",
      "9   Attack Success Rate Evaluation     ASR   51.54  2403.04783        1  \n",
      "10  Attack Success Rate Evaluation     ASR    5.13  2403.04783        1  \n",
      "11  Attack Success Rate Evaluation     ASR   31.28  2403.04783        1  \n",
      "12  Attack Success Rate Evaluation     ASR   36.41  2403.04783        1  \n",
      "13  Attack Success Rate Evaluation     ASR    3.85  2403.04783        1  \n",
      "14  Attack Success Rate Evaluation     ASR    2.05  2403.04783        1  \n",
      "15  Attack Success Rate Evaluation     ASR    1.03  2403.04783        1  \n",
      "16  Attack Success Rate Evaluation     ASR     0.0  2403.04783        1  \n",
      "17  Attack Success Rate Evaluation     ASR   64.87  2403.04783        1  \n",
      "18  Attack Success Rate Evaluation     ASR    7.18  2403.04783        1  \n",
      "19  Attack Success Rate Evaluation     ASR   58.72  2403.04783        1  \n",
      "20  Attack Success Rate Evaluation     ASR    2.82  2403.04783        1  \n",
      "21  Attack Success Rate Evaluation     ASR    8.72  2403.04783        1  \n",
      "22  Attack Success Rate Evaluation     ASR    0.51  2403.04783        1  \n",
      "23  Attack Success Rate Evaluation     ASR    7.95  2403.04783        1  \n",
      "  claim_id                          Model Dataset                    Task  \\\n",
      "0        0                  Speech-GPT3.5     N/A  Performance evaluation   \n",
      "1        1                  Speech-GPT3.5     N/A  Performance evaluation   \n",
      "2        2                PerceptiveAgent     N/A  Performance evaluation   \n",
      "3        3                PerceptiveAgent     N/A  Performance evaluation   \n",
      "4        4  PerceptiveAgent -w/o captions     N/A  Performance evaluation   \n",
      "5        5  PerceptiveAgent -w/o captions     N/A  Performance evaluation   \n",
      "\n",
      "     Measure      Outcome    paper_id table_id  \n",
      "0  BERTScore  53.03±10.20  2406.12707        1  \n",
      "1   Accuracy         0.74  2406.12707        1  \n",
      "2  BERTScore   54.36±9.25  2406.12707        1  \n",
      "3   Accuracy        21.89  2406.12707        1  \n",
      "4  BERTScore            -  2406.12707        1  \n",
      "5   Accuracy        16.53  2406.12707        1  \n",
      "   claim_id     Model Name      Setting     Task     Measure Outcome  \\\n",
      "0         0  Flan-T5-Large         Zero  OpenAGI  CLIP Score     0.0   \n",
      "1         1  Flan-T5-Large          Few  OpenAGI  CLIP Score     0.0   \n",
      "2         2  Flan-T5-Large  Fine-tuning  OpenAGI  CLIP Score     0.0   \n",
      "3         3  Flan-T5-Large         RLTF  OpenAGI  CLIP Score     0.0   \n",
      "4         4      Vicuna-7B         Zero  OpenAGI  CLIP Score     0.0   \n",
      "5         5      Vicuna-7B          Few  OpenAGI  CLIP Score     0.0   \n",
      "6         6      Vicuna-7B  Fine-tuning  OpenAGI  CLIP Score     0.0   \n",
      "7         7      Vicuna-7B         RLTF  OpenAGI  CLIP Score     0.0   \n",
      "8         8    LLaMA-2-13B         Zero  OpenAGI  CLIP Score     0.0   \n",
      "9         9    LLaMA-2-13B          Few  OpenAGI  CLIP Score  0.0612   \n",
      "10       10    LLaMA-2-13B  Fine-tuning  OpenAGI  CLIP Score  0.0608   \n",
      "11       11    LLaMA-2-13B         RLTF  OpenAGI  CLIP Score   0.122   \n",
      "12       12  Flan-T5-Large         Zero  OpenAGI  BERT Score     0.0   \n",
      "13       13  Flan-T5-Large          Few  OpenAGI  BERT Score  0.2488   \n",
      "14       14  Flan-T5-Large  Fine-tuning  OpenAGI  BERT Score     0.0   \n",
      "15       15  Flan-T5-Large         RLTF  OpenAGI  BERT Score  0.0655   \n",
      "16       16      Vicuna-7B         Zero  OpenAGI  BERT Score  0.0513   \n",
      "17       17      Vicuna-7B          Few  OpenAGI  BERT Score     0.0   \n",
      "18       18      Vicuna-7B  Fine-tuning  OpenAGI  BERT Score  0.1212   \n",
      "19       19      Vicuna-7B         RLTF  OpenAGI  BERT Score  0.1756   \n",
      "20       20    LLaMA-2-13B         Zero  OpenAGI  BERT Score  0.0986   \n",
      "21       21    LLaMA-2-13B          Few  OpenAGI  BERT Score  0.2281   \n",
      "22       22    LLaMA-2-13B  Fine-tuning  OpenAGI  BERT Score   0.157   \n",
      "23       23    LLaMA-2-13B         RLTF  OpenAGI  BERT Score  0.2401   \n",
      "24       24  Flan-T5-Large         Zero  OpenAGI   ViT Score     0.0   \n",
      "25       25  Flan-T5-Large          Few  OpenAGI   ViT Score     0.0   \n",
      "26       26  Flan-T5-Large  Fine-tuning  OpenAGI   ViT Score  0.6316   \n",
      "27       27  Flan-T5-Large         RLTF  OpenAGI   ViT Score  0.6978   \n",
      "28       28      Vicuna-7B         Zero  OpenAGI   ViT Score  0.1704   \n",
      "29       29      Vicuna-7B          Few  OpenAGI   ViT Score  0.4285   \n",
      "30       30      Vicuna-7B  Fine-tuning  OpenAGI   ViT Score  0.5507   \n",
      "31       31      Vicuna-7B         RLTF  OpenAGI   ViT Score    0.73   \n",
      "32       32    LLaMA-2-13B         Zero  OpenAGI   ViT Score  0.3614   \n",
      "33       33    LLaMA-2-13B          Few  OpenAGI   ViT Score  0.2558   \n",
      "34       34    LLaMA-2-13B  Fine-tuning  OpenAGI   ViT Score  0.6723   \n",
      "35       35    LLaMA-2-13B         RLTF  OpenAGI   ViT Score  0.7584   \n",
      "36       36  Flan-T5-Large         Zero  OpenAGI     Overall     0.0   \n",
      "37       37  Flan-T5-Large          Few  OpenAGI     Overall  0.0829   \n",
      "38       38  Flan-T5-Large  Fine-tuning  OpenAGI     Overall  0.2105   \n",
      "39       39  Flan-T5-Large         RLTF  OpenAGI     Overall  0.2544   \n",
      "40       40      Vicuna-7B         Zero  OpenAGI     Overall  0.0739   \n",
      "41       41      Vicuna-7B          Few  OpenAGI     Overall  0.1428   \n",
      "42       42      Vicuna-7B  Fine-tuning  OpenAGI     Overall  0.2239   \n",
      "43       43      Vicuna-7B         RLTF  OpenAGI     Overall  0.3018   \n",
      "44       44    LLaMA-2-13B         Zero  OpenAGI     Overall  0.1533   \n",
      "45       45    LLaMA-2-13B          Few  OpenAGI     Overall  0.1817   \n",
      "46       46    LLaMA-2-13B  Fine-tuning  OpenAGI     Overall  0.2967   \n",
      "47       47    LLaMA-2-13B         RLTF  OpenAGI     Overall  0.3735   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2304.04370        2  \n",
      "1   2304.04370        2  \n",
      "2   2304.04370        2  \n",
      "3   2304.04370        2  \n",
      "4   2304.04370        2  \n",
      "5   2304.04370        2  \n",
      "6   2304.04370        2  \n",
      "7   2304.04370        2  \n",
      "8   2304.04370        2  \n",
      "9   2304.04370        2  \n",
      "10  2304.04370        2  \n",
      "11  2304.04370        2  \n",
      "12  2304.04370        2  \n",
      "13  2304.04370        2  \n",
      "14  2304.04370        2  \n",
      "15  2304.04370        2  \n",
      "16  2304.04370        2  \n",
      "17  2304.04370        2  \n",
      "18  2304.04370        2  \n",
      "19  2304.04370        2  \n",
      "20  2304.04370        2  \n",
      "21  2304.04370        2  \n",
      "22  2304.04370        2  \n",
      "23  2304.04370        2  \n",
      "24  2304.04370        2  \n",
      "25  2304.04370        2  \n",
      "26  2304.04370        2  \n",
      "27  2304.04370        2  \n",
      "28  2304.04370        2  \n",
      "29  2304.04370        2  \n",
      "30  2304.04370        2  \n",
      "31  2304.04370        2  \n",
      "32  2304.04370        2  \n",
      "33  2304.04370        2  \n",
      "34  2304.04370        2  \n",
      "35  2304.04370        2  \n",
      "36  2304.04370        2  \n",
      "37  2304.04370        2  \n",
      "38  2304.04370        2  \n",
      "39  2304.04370        2  \n",
      "40  2304.04370        2  \n",
      "41  2304.04370        2  \n",
      "42  2304.04370        2  \n",
      "43  2304.04370        2  \n",
      "44  2304.04370        2  \n",
      "45  2304.04370        2  \n",
      "46  2304.04370        2  \n",
      "47  2304.04370        2  \n",
      "   claim_id         Model Dataset                      Task Measure Outcome  \\\n",
      "0         0  CodeLlama-7B  Spider       text-to-SQL parsing     Acc    54.0   \n",
      "1         1  CodeLlama-7B  Spider       text-to-SQL parsing      F1    37.1   \n",
      "2         2  CodeLlama-7B  Spider       text-to-SQL parsing     H@1    56.0   \n",
      "3         3  CodeLlama-7B  Spider       text-to-SQL parsing     MRR    62.3   \n",
      "4         4  CodeLlama-7B    Bird  discrimination abilities     Acc    44.6   \n",
      "..      ...           ...     ...                       ...     ...     ...   \n",
      "67       67   GPT-4-Turbo    Bird  discrimination abilities     MRR    23.0   \n",
      "68       68   GPT-4-Turbo   GSM8K  discrimination abilities     Acc    93.8   \n",
      "69       69   GPT-4-Turbo   GSM8K  discrimination abilities      F1    91.1   \n",
      "70       70   GPT-4-Turbo   GSM8K  discrimination abilities     H@1    59.8   \n",
      "71       71   GPT-4-Turbo   GSM8K  discrimination abilities     MRR    61.6   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2402.10890        1  \n",
      "1   2402.10890        1  \n",
      "2   2402.10890        1  \n",
      "3   2402.10890        1  \n",
      "4   2402.10890        1  \n",
      "..         ...      ...  \n",
      "67  2402.10890        1  \n",
      "68  2402.10890        1  \n",
      "69  2402.10890        1  \n",
      "70  2402.10890        1  \n",
      "71  2402.10890        1  \n",
      "\n",
      "[72 rows x 8 columns]\n",
      "   claim_id   Method Dataset Measure Outcome    paper_id table_id\n",
      "0         0      Pop   ML-1M     N@1    0.26  2407.17115        2\n",
      "1         1      Pop   ML-1M     N@5    0.60  2407.17115        2\n",
      "2         2      Pop   ML-1M    N@10    0.63  2407.17115        2\n",
      "3         3      Pop   Games     N@1    0.39  2407.17115        2\n",
      "4         4      Pop   Games     N@5    0.61  2407.17115        2\n",
      "5         5      Pop   Games    N@10    0.67  2407.17115        2\n",
      "6         6      Pop  Lastfm     N@1    0.78  2407.17115        2\n",
      "7         7      Pop  Lastfm     N@5    0.86  2407.17115        2\n",
      "8         8      Pop  Lastfm    N@10    0.88  2407.17115        2\n",
      "9         9    BPRMF   ML-1M     N@1    0.44  2407.17115        2\n",
      "10       10    BPRMF   ML-1M     N@5    0.71  2407.17115        2\n",
      "11       11    BPRMF   ML-1M    N@10    0.74  2407.17115        2\n",
      "12       12    BPRMF   Games     N@1    0.57  2407.17115        2\n",
      "13       13    BPRMF   Games     N@5    0.75  2407.17115        2\n",
      "14       14    BPRMF   Games    N@10    0.78  2407.17115        2\n",
      "15       15    BPRMF  Lastfm     N@1    0.71  2407.17115        2\n",
      "16       16    BPRMF  Lastfm     N@5    0.80  2407.17115        2\n",
      "17       17    BPRMF  Lastfm    N@10    0.84  2407.17115        2\n",
      "18       18   SASRec   ML-1M     N@1    0.68  2407.17115        2\n",
      "19       19   SASRec   ML-1M     N@5    0.84  2407.17115        2\n",
      "20       20   SASRec   ML-1M    N@10    0.85  2407.17115        2\n",
      "21       21   SASRec   Games     N@1    0.69  2407.17115        2\n",
      "22       22   SASRec   Games     N@5    0.83  2407.17115        2\n",
      "23       23   SASRec   Games    N@10    0.85  2407.17115        2\n",
      "24       24   SASRec  Lastfm     N@1    0.81  2407.17115        2\n",
      "25       25   SASRec  Lastfm     N@5    0.88  2407.17115        2\n",
      "26       26   SASRec  Lastfm    N@10    0.89  2407.17115        2\n",
      "27       27     BM25   ML-1M     N@1    0.08  2407.17115        2\n",
      "28       28     BM25   ML-1M     N@5    0.20  2407.17115        2\n",
      "29       29     BM25   ML-1M    N@10    0.43  2407.17115        2\n",
      "30       30     BM25   Games     N@1    0.27  2407.17115        2\n",
      "31       31     BM25   Games     N@5    0.45  2407.17115        2\n",
      "32       32     BM25   Games    N@10    0.57  2407.17115        2\n",
      "33       33     BM25  Lastfm     N@1     N/A  2407.17115        2\n",
      "34       34     BM25  Lastfm     N@5     N/A  2407.17115        2\n",
      "35       35     BM25  Lastfm    N@10     N/A  2407.17115        2\n",
      "36       36  UniSRec   ML-1M     N@1    0.12  2407.17115        2\n",
      "37       37  UniSRec   ML-1M     N@5    0.35  2407.17115        2\n",
      "38       38  UniSRec   ML-1M    N@10    0.47  2407.17115        2\n",
      "39       39  UniSRec   Games     N@1    0.25  2407.17115        2\n",
      "40       40  UniSRec   Games     N@5    0.45  2407.17115        2\n",
      "41       41  UniSRec   Games    N@10    0.56  2407.17115        2\n",
      "42       42  UniSRec  Lastfm     N@1     N/A  2407.17115        2\n",
      "43       43  UniSRec  Lastfm     N@5     N/A  2407.17115        2\n",
      "44       44  UniSRec  Lastfm    N@10     N/A  2407.17115        2\n",
      "45       45   VQ-Rec   ML-1M     N@1    0.10  2407.17115        2\n",
      "46       46   VQ-Rec   ML-1M     N@5    0.33  2407.17115        2\n",
      "47       47   VQ-Rec   ML-1M    N@10    0.47  2407.17115        2\n",
      "48       48   VQ-Rec   Games     N@1    0.14  2407.17115        2\n",
      "49       49   VQ-Rec   Games     N@5    0.33  2407.17115        2\n",
      "50       50   VQ-Rec   Games    N@10    0.48  2407.17115        2\n",
      "51       51   VQ-Rec  Lastfm     N@1     N/A  2407.17115        2\n",
      "52       52   VQ-Rec  Lastfm     N@5     N/A  2407.17115        2\n",
      "53       53   VQ-Rec  Lastfm    N@10     N/A  2407.17115        2\n",
      "   claim_id           Model       Dataset               Task    Measure  \\\n",
      "0         0  EXALT Baseline  Test Dataset  Emotion Detection   F1-score   \n",
      "1         1  EXALT Baseline  Test Dataset  Emotion Detection  Precision   \n",
      "2         2  EXALT Baseline  Test Dataset  Emotion Detection     Recall   \n",
      "3         3  ZSEC-gpt4turbo  Test Dataset  Emotion Detection   F1-score   \n",
      "4         4  ZSEC-gpt4turbo  Test Dataset  Emotion Detection  Precision   \n",
      "5         5  ZSEC-gpt4turbo  Test Dataset  Emotion Detection     Recall   \n",
      "6         6      ZSEC-gpt4o  Test Dataset  Emotion Detection   F1-score   \n",
      "7         7      ZSEC-gpt4o  Test Dataset  Emotion Detection  Precision   \n",
      "8         8      ZSEC-gpt4o  Test Dataset  Emotion Detection     Recall   \n",
      "9         9          MBCAWF  Test Dataset  Emotion Detection   F1-score   \n",
      "10       10          MBCAWF  Test Dataset  Emotion Detection  Precision   \n",
      "11       11          MBCAWF  Test Dataset  Emotion Detection     Recall   \n",
      "12       12         MIAWF-3  Test Dataset  Emotion Detection   F1-score   \n",
      "13       13         MIAWF-3  Test Dataset  Emotion Detection  Precision   \n",
      "14       14         MIAWF-3  Test Dataset  Emotion Detection     Recall   \n",
      "15       15         MIAWF-5  Test Dataset  Emotion Detection   F1-score   \n",
      "16       16         MIAWF-5  Test Dataset  Emotion Detection  Precision   \n",
      "17       17         MIAWF-5  Test Dataset  Emotion Detection     Recall   \n",
      "18       18      Ensemble-9  Test Dataset  Emotion Detection   F1-score   \n",
      "19       19      Ensemble-9  Test Dataset  Emotion Detection  Precision   \n",
      "20       20      Ensemble-9  Test Dataset  Emotion Detection     Recall   \n",
      "21       21      Ensemble-8  Test Dataset  Emotion Detection   F1-score   \n",
      "22       22      Ensemble-8  Test Dataset  Emotion Detection  Precision   \n",
      "23       23      Ensemble-8  Test Dataset  Emotion Detection     Recall   \n",
      "24       24     Ensemble-17  Test Dataset  Emotion Detection   F1-score   \n",
      "25       25     Ensemble-17  Test Dataset  Emotion Detection  Precision   \n",
      "26       26     Ensemble-17  Test Dataset  Emotion Detection     Recall   \n",
      "27       27     Ensemble-19  Test Dataset  Emotion Detection   F1-score   \n",
      "28       28     Ensemble-19  Test Dataset  Emotion Detection  Precision   \n",
      "29       29     Ensemble-19  Test Dataset  Emotion Detection     Recall   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0     0.43  2405.17129        1  \n",
      "1     0.43  2405.17129        1  \n",
      "2     0.44  2405.17129        1  \n",
      "3     0.55  2405.17129        1  \n",
      "4     0.55  2405.17129        1  \n",
      "5     0.58  2405.17129        1  \n",
      "6     0.57  2405.17129        1  \n",
      "7     0.56  2405.17129        1  \n",
      "8      0.6  2405.17129        1  \n",
      "9     0.56  2405.17129        1  \n",
      "10    0.56  2405.17129        1  \n",
      "11    0.59  2405.17129        1  \n",
      "12    0.59  2405.17129        1  \n",
      "13    0.59  2405.17129        1  \n",
      "14    0.61  2405.17129        1  \n",
      "15     0.6  2405.17129        1  \n",
      "16    0.59  2405.17129        1  \n",
      "17    0.62  2405.17129        1  \n",
      "18    0.59  2405.17129        1  \n",
      "19    0.59  2405.17129        1  \n",
      "20    0.61  2405.17129        1  \n",
      "21     0.6  2405.17129        1  \n",
      "22     0.6  2405.17129        1  \n",
      "23    0.62  2405.17129        1  \n",
      "24     0.6  2405.17129        1  \n",
      "25     0.6  2405.17129        1  \n",
      "26    0.62  2405.17129        1  \n",
      "27     0.6  2405.17129        1  \n",
      "28     0.6  2405.17129        1  \n",
      "29    0.62  2405.17129        1  \n",
      "   claim_id                     Dataset Task Samples          Method Measure  \\\n",
      "0         0  HaluEval Li et al. (2023a)   QA      80  Always Skeptic    Acc.   \n",
      "1         1  HaluEval Li et al. (2023a)   QA      80  Always Skeptic       R   \n",
      "2         2  HaluEval Li et al. (2023a)   QA      80  Always Skeptic       P   \n",
      "3         3  HaluEval Li et al. (2023a)   QA      80  Always Skeptic      F1   \n",
      "4         4  HaluEval Li et al. (2023a)   QA      80    Always Trust    Acc.   \n",
      "5         5  HaluEval Li et al. (2023a)   QA      80    Always Trust       R   \n",
      "6         6  HaluEval Li et al. (2023a)   QA      80    Always Trust       P   \n",
      "7         7  HaluEval Li et al. (2023a)   QA      80    Always Trust      F1   \n",
      "8         8  HaluEval Li et al. (2023a)   QA      80      True→Trust    Acc.   \n",
      "9         9  HaluEval Li et al. (2023a)   QA      80      True→Trust       R   \n",
      "10       10  HaluEval Li et al. (2023a)   QA      80      True→Trust       P   \n",
      "11       11  HaluEval Li et al. (2023a)   QA      80      True→Trust      F1   \n",
      "12       12  HaluEval Li et al. (2023a)   QA      80    True→Skeptic    Acc.   \n",
      "13       13  HaluEval Li et al. (2023a)   QA      80    True→Skeptic       R   \n",
      "14       14  HaluEval Li et al. (2023a)   QA      80    True→Skeptic       P   \n",
      "15       15  HaluEval Li et al. (2023a)   QA      80    True→Skeptic      F1   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0    65.00  2406.03075        4  \n",
      "1    84.21  2406.03075        4  \n",
      "2    59.26  2406.03075        4  \n",
      "3    69.57  2406.03075        4  \n",
      "4    68.75  2406.03075        4  \n",
      "5    84.21  2406.03075        4  \n",
      "6    62.75  2406.03075        4  \n",
      "7    71.91  2406.03075        4  \n",
      "8    67.50  2406.03075        4  \n",
      "9    89.47  2406.03075        4  \n",
      "10   60.71  2406.03075        4  \n",
      "11   72.34  2406.03075        4  \n",
      "12   70.00  2406.03075        4  \n",
      "13   86.84  2406.03075        4  \n",
      "14   63.46  2406.03075        4  \n",
      "15   73.33  2406.03075        4  \n",
      "  claim_id Method    Dataset                                     Task  \\\n",
      "0        0    ICL      GSM8k  evaluating token usage in input prompts   \n",
      "1        1    ICL  Hotpot-QA  evaluating token usage in input prompts   \n",
      "2        2    ICL   Alfworld  evaluating token usage in input prompts   \n",
      "3        3    LTC      GSM8k  evaluating token usage in input prompts   \n",
      "4        4    LTC  Hotpot-QA  evaluating token usage in input prompts   \n",
      "5        5    LTC   Alfworld  evaluating token usage in input prompts   \n",
      "\n",
      "       Measure Outcome    paper_id table_id  \n",
      "0  Token Count     836  2310.01444        4  \n",
      "1  Token Count    1937  2310.01444        4  \n",
      "2  Token Count    1744  2310.01444        4  \n",
      "3  Token Count     107  2310.01444        4  \n",
      "4  Token Count     167  2310.01444        4  \n",
      "5  Token Count     189  2310.01444        4  \n",
      "   claim_id     Model Name Setting     Task     Measure Outcome    paper_id  \\\n",
      "0         0  GPT-3.5-turbo    Zero  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "1         1  GPT-3.5-turbo     Few  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "2         2       Claude-2    Zero  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "3         3       Claude-2     Few  OpenAGI  CLIP Score  0.2543  2304.04370   \n",
      "4         4          GPT-4    Zero  OpenAGI  CLIP Score     0.0  2304.04370   \n",
      "5         5          GPT-4     Few  OpenAGI  CLIP Score  0.3055  2304.04370   \n",
      "6         6  GPT-3.5-turbo    Zero  OpenAGI  BERT Score  0.1914  2304.04370   \n",
      "7         7  GPT-3.5-turbo     Few  OpenAGI  BERT Score   0.382  2304.04370   \n",
      "8         8       Claude-2    Zero  OpenAGI  BERT Score  0.2111  2304.04370   \n",
      "9         9       Claude-2     Few  OpenAGI  BERT Score  0.5038  2304.04370   \n",
      "10       10          GPT-4    Zero  OpenAGI  BERT Score  0.2076  2304.04370   \n",
      "11       11          GPT-4     Few  OpenAGI  BERT Score  0.6307  2304.04370   \n",
      "12       12  GPT-3.5-turbo    Zero  OpenAGI   ViT Score  0.2437  2304.04370   \n",
      "13       13  GPT-3.5-turbo     Few  OpenAGI   ViT Score  0.7497  2304.04370   \n",
      "14       14       Claude-2    Zero  OpenAGI   ViT Score  0.4082  2304.04370   \n",
      "15       15       Claude-2     Few  OpenAGI   ViT Score  0.5416  2304.04370   \n",
      "16       16          GPT-4    Zero  OpenAGI   ViT Score  0.5058  2304.04370   \n",
      "17       17          GPT-4     Few  OpenAGI   ViT Score   0.648  2304.04370   \n",
      "18       18  GPT-3.5-turbo    Zero  OpenAGI     Overall   0.145  2304.04370   \n",
      "19       19  GPT-3.5-turbo     Few  OpenAGI     Overall  0.3772  2304.04370   \n",
      "20       20       Claude-2    Zero  OpenAGI     Overall  0.2064  2304.04370   \n",
      "21       21       Claude-2     Few  OpenAGI     Overall  0.4332  2304.04370   \n",
      "22       22          GPT-4    Zero  OpenAGI     Overall  0.2378  2304.04370   \n",
      "23       23          GPT-4     Few  OpenAGI     Overall  0.5281  2304.04370   \n",
      "\n",
      "   table_id  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "5         1  \n",
      "6         1  \n",
      "7         1  \n",
      "8         1  \n",
      "9         1  \n",
      "10        1  \n",
      "11        1  \n",
      "12        1  \n",
      "13        1  \n",
      "14        1  \n",
      "15        1  \n",
      "16        1  \n",
      "17        1  \n",
      "18        1  \n",
      "19        1  \n",
      "20        1  \n",
      "21        1  \n",
      "22        1  \n",
      "23        1  \n",
      "   claim_id                      Dataset Evaluation Level          Method  \\\n",
      "0         0  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "1         1  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "2         2  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "3         3  Factool Chern et al. (2023)      Claim-Level  Self-Check (0)   \n",
      "4         4  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "5         5  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "6         6  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "7         7  Factool Chern et al. (2023)      Claim-Level  Self-Check (3)   \n",
      "8         8  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "9         9  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "10       10  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "11       11  Factool Chern et al. (2023)      Claim-Level         FACTOOL   \n",
      "12       12  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "13       13  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "14       14  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "15       15  Factool Chern et al. (2023)      Claim-Level      Our Method   \n",
      "16       16  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "17       17  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "18       18  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "19       19  Factool Chern et al. (2023)   Response-Level  Self-Check (0)   \n",
      "20       20  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "21       21  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "22       22  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "23       23  Factool Chern et al. (2023)   Response-Level  Self-Check (3)   \n",
      "24       24  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "25       25  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "26       26  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "27       27  Factool Chern et al. (2023)   Response-Level         FACTOOL   \n",
      "28       28  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "29       29  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "30       30  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "31       31  Factool Chern et al. (2023)   Response-Level      Our Method   \n",
      "\n",
      "   Measure Outcome    paper_id table_id  \n",
      "0     Acc.   75.54  2406.03075        2  \n",
      "1        R   90.40  2406.03075        2  \n",
      "2        P   80.00  2406.03075        2  \n",
      "3       F1   84.88  2406.03075        2  \n",
      "4     Acc.   69.53  2406.03075        2  \n",
      "5        R   81.36  2406.03075        2  \n",
      "6        P   79.12  2406.03075        2  \n",
      "7       F1   80.23  2406.03075        2  \n",
      "8     Acc.   74.25  2406.03075        2  \n",
      "9        R   73.45  2406.03075        2  \n",
      "10       P   90.91  2406.03075        2  \n",
      "11      F1   81.25  2406.03075        2  \n",
      "12    Acc.   77.68  2406.03075        2  \n",
      "13       R   80.79  2406.03075        2  \n",
      "14       P   88.82  2406.03075        2  \n",
      "15      F1   84.62  2406.03075        2  \n",
      "16    Acc.   54.00  2406.03075        2  \n",
      "17       R   60.87  2406.03075        2  \n",
      "18       P   50.00  2406.03075        2  \n",
      "19      F1   54.90  2406.03075        2  \n",
      "20    Acc.   54.00  2406.03075        2  \n",
      "21       R   47.83  2406.03075        2  \n",
      "22       P   50.00  2406.03075        2  \n",
      "23      F1   48.89  2406.03075        2  \n",
      "24    Acc.   64.00  2406.03075        2  \n",
      "25       R   43.48  2406.03075        2  \n",
      "26       P   66.67  2406.03075        2  \n",
      "27      F1   52.63  2406.03075        2  \n",
      "28    Acc.   72.00  2406.03075        2  \n",
      "29       R   52.17  2406.03075        2  \n",
      "30       P   80.00  2406.03075        2  \n",
      "31      F1   63.15  2406.03075        2  \n",
      "   claim_id Attribute  Gender                           Task    Measure  \\\n",
      "0         0   Emotion    Male  Speech Captioning Performance  Precision   \n",
      "1         1   Emotion    Male  Speech Captioning Performance     Recall   \n",
      "2         2   Emotion    Male  Speech Captioning Performance   F1-score   \n",
      "3         3   Emotion  Female  Speech Captioning Performance  Precision   \n",
      "4         4   Emotion  Female  Speech Captioning Performance     Recall   \n",
      "5         5   Emotion  Female  Speech Captioning Performance   F1-score   \n",
      "6         6     Pitch    Male  Speech Captioning Performance  Precision   \n",
      "7         7     Pitch    Male  Speech Captioning Performance     Recall   \n",
      "8         8     Pitch    Male  Speech Captioning Performance   F1-score   \n",
      "9         9     Pitch  Female  Speech Captioning Performance  Precision   \n",
      "10       10     Pitch  Female  Speech Captioning Performance     Recall   \n",
      "11       11     Pitch  Female  Speech Captioning Performance   F1-score   \n",
      "12       12    Energy    Male  Speech Captioning Performance  Precision   \n",
      "13       13    Energy    Male  Speech Captioning Performance     Recall   \n",
      "14       14    Energy    Male  Speech Captioning Performance   F1-score   \n",
      "15       15    Energy  Female  Speech Captioning Performance  Precision   \n",
      "16       16    Energy  Female  Speech Captioning Performance     Recall   \n",
      "17       17    Energy  Female  Speech Captioning Performance   F1-score   \n",
      "18       18     Speed    Male  Speech Captioning Performance  Precision   \n",
      "19       19     Speed    Male  Speech Captioning Performance     Recall   \n",
      "20       20     Speed    Male  Speech Captioning Performance   F1-score   \n",
      "21       21     Speed  Female  Speech Captioning Performance  Precision   \n",
      "22       22     Speed  Female  Speech Captioning Performance     Recall   \n",
      "23       23     Speed  Female  Speech Captioning Performance   F1-score   \n",
      "\n",
      "   Outcome    paper_id table_id  \n",
      "0     84.3  2406.12707        3  \n",
      "1     85.4  2406.12707        3  \n",
      "2     84.2  2406.12707        3  \n",
      "3     87.4  2406.12707        3  \n",
      "4     85.5  2406.12707        3  \n",
      "5     86.0  2406.12707        3  \n",
      "6     88.2  2406.12707        3  \n",
      "7     82.8  2406.12707        3  \n",
      "8     85.3  2406.12707        3  \n",
      "9     84.8  2406.12707        3  \n",
      "10    71.0  2406.12707        3  \n",
      "11    75.9  2406.12707        3  \n",
      "12    74.4  2406.12707        3  \n",
      "13    60.0  2406.12707        3  \n",
      "14    65.0  2406.12707        3  \n",
      "15    71.2  2406.12707        3  \n",
      "16    54.9  2406.12707        3  \n",
      "17    60.9  2406.12707        3  \n",
      "18    46.4  2406.12707        3  \n",
      "19    43.1  2406.12707        3  \n",
      "20    44.6  2406.12707        3  \n",
      "21    48.0  2406.12707        3  \n",
      "22    30.6  2406.12707        3  \n",
      "23    37.3  2406.12707        3  \n",
      "   claim_id          Method Dataset Metric                              Task  \\\n",
      "0         0  Manual prompts   ML-1M    N@1  Enhancing Recommendation Ability   \n",
      "1         1  Manual prompts   ML-1M    N@5  Enhancing Recommendation Ability   \n",
      "2         2  Manual prompts   ML-1M   N@10  Enhancing Recommendation Ability   \n",
      "3         3  Manual prompts   Games    N@1  Enhancing Recommendation Ability   \n",
      "4         4  Manual prompts   Games    N@5  Enhancing Recommendation Ability   \n",
      "..      ...             ...     ...    ...                               ...   \n",
      "58       58             RPP   Games    N@5  Enhancing Recommendation Ability   \n",
      "59       59             RPP   Games   N@10  Enhancing Recommendation Ability   \n",
      "60       60             RPP  Lastfm    N@1  Enhancing Recommendation Ability   \n",
      "61       61             RPP  Lastfm    N@5  Enhancing Recommendation Ability   \n",
      "62       62             RPP  Lastfm   N@10  Enhancing Recommendation Ability   \n",
      "\n",
      "    Measure    Outcome    paper_id table_id  \n",
      "0   Outcome  0.03±0.02  2407.17115        4  \n",
      "1   Outcome  0.35±0.01  2407.17115        4  \n",
      "2   Outcome  0.41±0.01  2407.17115        4  \n",
      "3   Outcome  0.04±0.01  2407.17115        4  \n",
      "4   Outcome  0.30±0.02  2407.17115        4  \n",
      "..      ...        ...         ...      ...  \n",
      "58  Outcome  0.82±0.03  2407.17115        4  \n",
      "59  Outcome  0.85±0.02  2407.17115        4  \n",
      "60  Outcome  0.87±0.01  2407.17115        4  \n",
      "61  Outcome  0.89±0.01  2407.17115        4  \n",
      "62  Outcome  0.91±0.01  2407.17115        4  \n",
      "\n",
      "[63 rows x 9 columns]\n",
      "  claim_id         Model    Dataset                               Task  \\\n",
      "0        0         CoT@3  ToolBench  solution ranking on complex tasks   \n",
      "1        1     Reflexion  ToolBench  solution ranking on complex tasks   \n",
      "2        2           BFS  ToolBench  solution ranking on complex tasks   \n",
      "3        3         DFSDT  ToolBench  solution ranking on complex tasks   \n",
      "4        4      RaDAgent  ToolBench  solution ranking on complex tasks   \n",
      "5        5  Rand. Select  ToolBench  solution ranking on complex tasks   \n",
      "6        6    Elo Select  ToolBench  solution ranking on complex tasks   \n",
      "\n",
      "      Measure Outcome    paper_id table_id  \n",
      "0  Pref. Rank    3.45  2308.12519        2  \n",
      "1  Pref. Rank    3.48  2308.12519        2  \n",
      "2  Pref. Rank    3.25  2308.12519        2  \n",
      "3  Pref. Rank    2.91  2308.12519        2  \n",
      "4  Pref. Rank     N/A  2308.12519        2  \n",
      "5  Pref. Rank    3.24  2308.12519        2  \n",
      "6  Pref. Rank    2.19  2308.12519        2  \n",
      "  claim_id                                           task               model  \\\n",
      "0        0  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "1        1  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "2        2  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "3        3  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "4        4  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "5        5  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "6        6  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "7        7  Impact of Memory Tags on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "\n",
      "  Memory Tag Configuration  Measure Outcome    paper_id table_id  \n",
      "0                  Default  ASR (%)      92  2407.16667        4  \n",
      "1                  w/o Cat  ASR (%)      88  2407.16667        4  \n",
      "2                  w/o Que  ASR (%)      92  2407.16667        4  \n",
      "3            w/o Cat & Que  ASR (%)      92  2407.16667        4  \n",
      "4                  Default      ANQ    4.65  2407.16667        4  \n",
      "5                  w/o Cat      ANQ    5.31  2407.16667        4  \n",
      "6                  w/o Que      ANQ     6.3  2407.16667        4  \n",
      "7            w/o Cat & Que      ANQ       9  2407.16667        4  \n",
      "  claim_id     Agent Configuration Dataset                               Task  \\\n",
      "0        0      Single Agent (CoT)     N/A  Defense Using Multi-Agent Systems   \n",
      "1        1      Single Agent (CoT)     N/A  Defense Using Multi-Agent Systems   \n",
      "2        2                3 Agents     N/A  Defense Using Multi-Agent Systems   \n",
      "3        3                3 Agents     N/A  Defense Using Multi-Agent Systems   \n",
      "4        4  4 Agents w/ LlamaGuard     N/A  Defense Using Multi-Agent Systems   \n",
      "5        5  4 Agents w/ LlamaGuard     N/A  Defense Using Multi-Agent Systems   \n",
      "\n",
      "  Measure Outcome    paper_id table_id  \n",
      "0     FPR   17.16  2403.04783        4  \n",
      "1     ASR   10.87  2403.04783        4  \n",
      "2     FPR   37.32  2403.04783        4  \n",
      "3     ASR    3.13  2403.04783        4  \n",
      "4     FPR     6.8  2403.04783        4  \n",
      "5     ASR   11.08  2403.04783        4  \n",
      "  claim_id                          Model       Dataset  \\\n",
      "0        0                  Speech-GPT3.5  TextroSpeech   \n",
      "1        1                  Speech-GPT3.5  TextroSpeech   \n",
      "2        2                PerceptiveAgent  TextroSpeech   \n",
      "3        3                PerceptiveAgent  TextroSpeech   \n",
      "4        4  PerceptiveAgent -w/o captions  TextroSpeech   \n",
      "5        5  PerceptiveAgent -w/o captions  TextroSpeech   \n",
      "\n",
      "                                    Task    Measure      Outcome    paper_id  \\\n",
      "0  Generalization Performance Evaluation  BERTScore  53.03±10.20  2406.12707   \n",
      "1  Generalization Performance Evaluation   Accuracy         0.74  2406.12707   \n",
      "2  Generalization Performance Evaluation  BERTScore   54.36±9.25  2406.12707   \n",
      "3  Generalization Performance Evaluation   Accuracy        21.89  2406.12707   \n",
      "4  Generalization Performance Evaluation  BERTScore            -  2406.12707   \n",
      "5  Generalization Performance Evaluation   Accuracy        16.53  2406.12707   \n",
      "\n",
      "  table_id  \n",
      "0        2  \n",
      "1        2  \n",
      "2        2  \n",
      "3        2  \n",
      "4        2  \n",
      "5        2  \n",
      "  claim_id                                        task               model  \\\n",
      "0        0  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "1        1  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "2        2  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "3        3  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "4        4  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "5        5  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "6        6  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "7        7  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "8        8  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "9        9  Impact of Capacity on RedAgent performance  GPT-3.5-turbo-1106   \n",
      "\n",
      "  query_budget Memory Capacity  Measure Outcome    paper_id table_id  \n",
      "0         same               0  ASR (%)      60  2407.16667        3  \n",
      "1         same               1  ASR (%)      52  2407.16667        3  \n",
      "2         same              10  ASR (%)      76  2407.16667        3  \n",
      "3         same              25  ASR (%)      92  2407.16667        3  \n",
      "4         same              50  ASR (%)      72  2407.16667        3  \n",
      "5         same               0      ANQ    6.05  2407.16667        3  \n",
      "6         same               1      ANQ    4.63  2407.16667        3  \n",
      "7         same              10      ANQ    3.57  2407.16667        3  \n",
      "8         same              25      ANQ    4.65  2407.16667        3  \n",
      "9         same              50      ANQ    3.53  2407.16667        3  \n",
      "   claim_id                   Model       Dataset Task    Measure Outcome  \\\n",
      "0         0  ZeroShot (gpt-4-turbo)  Test Dataset  N/A   F1-score  0.5459   \n",
      "1         1  ZeroShot (gpt-4-turbo)  Test Dataset  N/A  Precision  0.5539   \n",
      "2         2  ZeroShot (gpt-4-turbo)  Test Dataset  N/A     Recall  0.5682   \n",
      "3         3  ZeroShot (gpt-4-turbo)  Test Dataset  N/A       Acc.  0.6028   \n",
      "4         4       ZeroShot (gpt-4o)  Test Dataset  N/A   F1-score  0.5732   \n",
      "5         5       ZeroShot (gpt-4o)  Test Dataset  N/A  Precision  0.5685   \n",
      "6         6       ZeroShot (gpt-4o)  Test Dataset  N/A     Recall  0.5813   \n",
      "7         7       ZeroShot (gpt-4o)  Test Dataset  N/A       Acc.  0.6164   \n",
      "8         8            ZSE (gpt-4o)  Test Dataset  N/A   F1-score  0.5723   \n",
      "9         9            ZSE (gpt-4o)  Test Dataset  N/A  Precision  0.5664   \n",
      "10       10            ZSE (gpt-4o)  Test Dataset  N/A     Recall   0.589   \n",
      "11       11            ZSE (gpt-4o)  Test Dataset  N/A       Acc.  0.6232   \n",
      "12       12           ZSEC (gpt-4o)  Test Dataset  N/A   F1-score  0.5726   \n",
      "13       13           ZSEC (gpt-4o)  Test Dataset  N/A  Precision  0.5631   \n",
      "14       14           ZSEC (gpt-4o)  Test Dataset  N/A     Recall  0.5953   \n",
      "15       15           ZSEC (gpt-4o)  Test Dataset  N/A       Acc.   0.624   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2405.17129        5  \n",
      "1   2405.17129        5  \n",
      "2   2405.17129        5  \n",
      "3   2405.17129        5  \n",
      "4   2405.17129        5  \n",
      "5   2405.17129        5  \n",
      "6   2405.17129        5  \n",
      "7   2405.17129        5  \n",
      "8   2405.17129        5  \n",
      "9   2405.17129        5  \n",
      "10  2405.17129        5  \n",
      "11  2405.17129        5  \n",
      "12  2405.17129        5  \n",
      "13  2405.17129        5  \n",
      "14  2405.17129        5  \n",
      "15  2405.17129        5  \n",
      "   claim_id    Method    Dataset  \\\n",
      "0         0     CoT@3  ToolBench   \n",
      "1         1     CoT@3  ToolBench   \n",
      "2         2     CoT@3  ToolBench   \n",
      "3         3     CoT@3  ToolBench   \n",
      "4         4     CoT@3  ToolBench   \n",
      "5         5     CoT@3  ToolBench   \n",
      "6         6       BFS  ToolBench   \n",
      "7         7       BFS  ToolBench   \n",
      "8         8       BFS  ToolBench   \n",
      "9         9       BFS  ToolBench   \n",
      "10       10       BFS  ToolBench   \n",
      "11       11       BFS  ToolBench   \n",
      "12       12     DFSDT  ToolBench   \n",
      "13       13     DFSDT  ToolBench   \n",
      "14       14     DFSDT  ToolBench   \n",
      "15       15     DFSDT  ToolBench   \n",
      "16       16     DFSDT  ToolBench   \n",
      "17       17     DFSDT  ToolBench   \n",
      "18       18  RaDAgent  ToolBench   \n",
      "19       19  RaDAgent  ToolBench   \n",
      "20       20  RaDAgent  ToolBench   \n",
      "21       21  RaDAgent  ToolBench   \n",
      "22       22  RaDAgent  ToolBench   \n",
      "23       23  RaDAgent  ToolBench   \n",
      "\n",
      "                                                 Task  \\\n",
      "0   analyzing common failure reasons in decision-m...   \n",
      "1   analyzing common failure reasons in decision-m...   \n",
      "2   analyzing common failure reasons in decision-m...   \n",
      "3   analyzing common failure reasons in decision-m...   \n",
      "4   analyzing common failure reasons in decision-m...   \n",
      "5   analyzing common failure reasons in decision-m...   \n",
      "6   analyzing common failure reasons in decision-m...   \n",
      "7   analyzing common failure reasons in decision-m...   \n",
      "8   analyzing common failure reasons in decision-m...   \n",
      "9   analyzing common failure reasons in decision-m...   \n",
      "10  analyzing common failure reasons in decision-m...   \n",
      "11  analyzing common failure reasons in decision-m...   \n",
      "12  analyzing common failure reasons in decision-m...   \n",
      "13  analyzing common failure reasons in decision-m...   \n",
      "14  analyzing common failure reasons in decision-m...   \n",
      "15  analyzing common failure reasons in decision-m...   \n",
      "16  analyzing common failure reasons in decision-m...   \n",
      "17  analyzing common failure reasons in decision-m...   \n",
      "18  analyzing common failure reasons in decision-m...   \n",
      "19  analyzing common failure reasons in decision-m...   \n",
      "20  analyzing common failure reasons in decision-m...   \n",
      "21  analyzing common failure reasons in decision-m...   \n",
      "22  analyzing common failure reasons in decision-m...   \n",
      "23  analyzing common failure reasons in decision-m...   \n",
      "\n",
      "                        Measure Outcome    paper_id table_id  \n",
      "0       Hallucinated Tool Ratio    14.2  2308.12519        3  \n",
      "1   Hallucinated Tool Fix Ratio    25.4  2308.12519        3  \n",
      "2         Tool Call Error Ratio    41.2  2308.12519        3  \n",
      "3     Tool Call Error Fix Ratio    14.8  2308.12519        3  \n",
      "4              Unavailable Tool     2.0  2308.12519        3  \n",
      "5              Decision Failure    52.5  2308.12519        3  \n",
      "6       Hallucinated Tool Ratio    18.8  2308.12519        3  \n",
      "7   Hallucinated Tool Fix Ratio    25.5  2308.12519        3  \n",
      "8         Tool Call Error Ratio    50.8  2308.12519        3  \n",
      "9     Tool Call Error Fix Ratio    31.1  2308.12519        3  \n",
      "10             Unavailable Tool     2.6  2308.12519        3  \n",
      "11             Decision Failure    48.6  2308.12519        3  \n",
      "12      Hallucinated Tool Ratio    31.5  2308.12519        3  \n",
      "13  Hallucinated Tool Fix Ratio    38.9  2308.12519        3  \n",
      "14        Tool Call Error Ratio    62.5  2308.12519        3  \n",
      "15    Tool Call Error Fix Ratio    41.0  2308.12519        3  \n",
      "16             Unavailable Tool     3.0  2308.12519        3  \n",
      "17             Decision Failure    26.4  2308.12519        3  \n",
      "18      Hallucinated Tool Ratio    42.1  2308.12519        3  \n",
      "19  Hallucinated Tool Fix Ratio    53.3  2308.12519        3  \n",
      "20        Tool Call Error Ratio    62.3  2308.12519        3  \n",
      "21    Tool Call Error Fix Ratio    54.0  2308.12519        3  \n",
      "22             Unavailable Tool     3.0  2308.12519        3  \n",
      "23             Decision Failure    14.8  2308.12519        3  \n",
      "    claim_id LLM-Backend Method                          Task Shot Type  \\\n",
      "0          0      PaLM-2     IO  Shortest-path Reasoning Task    0-shot   \n",
      "1          1      PaLM-2     IO  Shortest-path Reasoning Task    0-shot   \n",
      "2          2      PaLM-2     IO  Shortest-path Reasoning Task    0-shot   \n",
      "3          3      PaLM-2     IO  Shortest-path Reasoning Task    1-shot   \n",
      "4          4      PaLM-2     IO  Shortest-path Reasoning Task    1-shot   \n",
      "..       ...         ...    ...                           ...       ...   \n",
      "121      121       GPT-4     TP  Shortest-path Reasoning Task    1-shot   \n",
      "122      122       GPT-4     TP  Shortest-path Reasoning Task    1-shot   \n",
      "123      123       GPT-4     TP  Shortest-path Reasoning Task    5-shot   \n",
      "124      124       GPT-4     TP  Shortest-path Reasoning Task    5-shot   \n",
      "125      125       GPT-4     TP  Shortest-path Reasoning Task    5-shot   \n",
      "\n",
      "    Metric Index Measure Outcome    paper_id table_id  \n",
      "0              1      OR    0.14  2310.03965        1  \n",
      "1              2      FR    0.37  2310.03965        1  \n",
      "2              3     OLR    0.62  2310.03965        1  \n",
      "3              1      OR    0.28  2310.03965        1  \n",
      "4              2      FR    0.48  2310.03965        1  \n",
      "..           ...     ...     ...         ...      ...  \n",
      "121            2      FR     1.0  2310.03965        1  \n",
      "122            3     OLR    0.04  2310.03965        1  \n",
      "123            1      OR    0.86  2310.03965        1  \n",
      "124            2      FR     1.0  2310.03965        1  \n",
      "125            3     OLR    0.05  2310.03965        1  \n",
      "\n",
      "[126 rows x 10 columns]\n",
      "  claim_id      Model    Dataset                               Task  \\\n",
      "0        0        CoT  ToolBench  solution ranking on complex tasks   \n",
      "1        1      CoT@3  ToolBench  solution ranking on complex tasks   \n",
      "2        2  Reflexion  ToolBench  solution ranking on complex tasks   \n",
      "3        3        BFS  ToolBench  solution ranking on complex tasks   \n",
      "4        4        DFS  ToolBench  solution ranking on complex tasks   \n",
      "5        5      DFSDT  ToolBench  solution ranking on complex tasks   \n",
      "6        6   RaDAgent  ToolBench  solution ranking on complex tasks   \n",
      "\n",
      "         Measure Outcome    paper_id table_id  \n",
      "0  Pass Rate (%)    16.6  2308.12519        1  \n",
      "1  Pass Rate (%)    31.2  2308.12519        1  \n",
      "2  Pass Rate (%)    26.6  2308.12519        1  \n",
      "3  Pass Rate (%)    38.0  2308.12519        1  \n",
      "4  Pass Rate (%)   45.58  2308.12519        1  \n",
      "5  Pass Rate (%)    50.2  2308.12519        1  \n",
      "6  Pass Rate (%)   61.92  2308.12519        1  \n",
      "   claim_id      Model          Method   Dataset  \\\n",
      "0         0  PaLM-540B        CoT [61]  HotpotQA   \n",
      "1         1  PaLM-540B     CoT-SC [55]  HotpotQA   \n",
      "2         2  PaLM-540B      ReAct [65]  HotpotQA   \n",
      "3         3  PaLM-540B  ReAct → CoT-SC  HotpotQA   \n",
      "4         4  GPT3-175B           ReAct  HotpotQA   \n",
      "5         5   PaLM-62B    ReAct-Tuning  HotpotQA   \n",
      "6         6   PaLM-62B      CoT-Tuning  HotpotQA   \n",
      "7         7    PaLM-8B    ReAct-Tuning  HotpotQA   \n",
      "8         8    PaLM-8B      CoT-Tuning  HotpotQA   \n",
      "9         9   LLaMA-7B    ReAct-Tuning  HotpotQA   \n",
      "10       10   LLaMA-7B             LTC  HotpotQA   \n",
      "\n",
      "                                Task   Measure Outcome    paper_id table_id  \n",
      "0   evaluating EM scores on HotpotQA  EM score    29.4  2310.01444        2  \n",
      "1   evaluating EM scores on HotpotQA  EM score    33.4  2310.01444        2  \n",
      "2   evaluating EM scores on HotpotQA  EM score    27.4  2310.01444        2  \n",
      "3   evaluating EM scores on HotpotQA  EM score    35.1  2310.01444        2  \n",
      "4   evaluating EM scores on HotpotQA  EM score    30.8  2310.01444        2  \n",
      "5   evaluating EM scores on HotpotQA  EM score    32.6  2310.01444        2  \n",
      "6   evaluating EM scores on HotpotQA  EM score    25.2  2310.01444        2  \n",
      "7   evaluating EM scores on HotpotQA  EM score    25.0  2310.01444        2  \n",
      "8   evaluating EM scores on HotpotQA  EM score    14.1  2310.01444        2  \n",
      "9   evaluating EM scores on HotpotQA  EM score    28.1  2310.01444        2  \n",
      "10  evaluating EM scores on HotpotQA  EM score    33.2  2310.01444        2  \n",
      "   claim_id             Model Dataset  \\\n",
      "0         0     CodeLlama-13B  Spider   \n",
      "1         1     CodeLlama-13B  Spider   \n",
      "2         2     CodeLlama-13B  Spider   \n",
      "3         3     CodeLlama-13B  Spider   \n",
      "4         4     CodeLlama-13B    Bird   \n",
      "5         5     CodeLlama-13B    Bird   \n",
      "6         6     CodeLlama-13B    Bird   \n",
      "7         7     CodeLlama-13B    Bird   \n",
      "8         8     CodeLlama-13B   GSM8K   \n",
      "9         9     CodeLlama-13B   GSM8K   \n",
      "10       10     CodeLlama-13B   GSM8K   \n",
      "11       11     CodeLlama-13B   GSM8K   \n",
      "12       12     GPT-3.5-Turbo  Spider   \n",
      "13       13     GPT-3.5-Turbo  Spider   \n",
      "14       14     GPT-3.5-Turbo  Spider   \n",
      "15       15     GPT-3.5-Turbo  Spider   \n",
      "16       16     GPT-3.5-Turbo    Bird   \n",
      "17       17     GPT-3.5-Turbo    Bird   \n",
      "18       18     GPT-3.5-Turbo    Bird   \n",
      "19       19     GPT-3.5-Turbo    Bird   \n",
      "20       20     GPT-3.5-Turbo   GSM8K   \n",
      "21       21     GPT-3.5-Turbo   GSM8K   \n",
      "22       22     GPT-3.5-Turbo   GSM8K   \n",
      "23       23     GPT-3.5-Turbo   GSM8K   \n",
      "24       24  CodeLlama-13B-FT  Spider   \n",
      "25       25  CodeLlama-13B-FT  Spider   \n",
      "26       26  CodeLlama-13B-FT  Spider   \n",
      "27       27  CodeLlama-13B-FT  Spider   \n",
      "28       28  CodeLlama-13B-FT    Bird   \n",
      "29       29  CodeLlama-13B-FT    Bird   \n",
      "30       30  CodeLlama-13B-FT    Bird   \n",
      "31       31  CodeLlama-13B-FT    Bird   \n",
      "32       32  CodeLlama-13B-FT   GSM8K   \n",
      "33       33  CodeLlama-13B-FT   GSM8K   \n",
      "34       34  CodeLlama-13B-FT   GSM8K   \n",
      "35       35  CodeLlama-13B-FT   GSM8K   \n",
      "\n",
      "                                                Task   Measure Outcome  \\\n",
      "0                            discrimination accuracy  Accuracy    58.2   \n",
      "1   discrimination accuracy with Executability Check  Accuracy    78.7   \n",
      "2      discrimination accuracy with Execution Result  Accuracy    83.6   \n",
      "3                discrimination accuracy Improvement      Gain    25.4   \n",
      "4                            discrimination accuracy  Accuracy    49.4   \n",
      "5   discrimination accuracy with Executability Check  Accuracy    78.8   \n",
      "6      discrimination accuracy with Execution Result  Accuracy    79.6   \n",
      "7                discrimination accuracy Improvement      Gain    30.2   \n",
      "8                            discrimination accuracy  Accuracy    62.2   \n",
      "9   discrimination accuracy with Executability Check  Accuracy    64.5   \n",
      "10     discrimination accuracy with Execution Result  Accuracy    70.6   \n",
      "11               discrimination accuracy Improvement      Gain     8.4   \n",
      "12                           discrimination accuracy  Accuracy    67.0   \n",
      "13  discrimination accuracy with Executability Check  Accuracy    84.8   \n",
      "14     discrimination accuracy with Execution Result  Accuracy    90.0   \n",
      "15               discrimination accuracy Improvement      Gain    23.0   \n",
      "16                           discrimination accuracy  Accuracy    64.3   \n",
      "17  discrimination accuracy with Executability Check  Accuracy    86.3   \n",
      "18     discrimination accuracy with Execution Result  Accuracy    89.2   \n",
      "19               discrimination accuracy Improvement      Gain    24.9   \n",
      "20                           discrimination accuracy  Accuracy    72.1   \n",
      "21  discrimination accuracy with Executability Check  Accuracy    73.2   \n",
      "22     discrimination accuracy with Execution Result  Accuracy    76.5   \n",
      "23               discrimination accuracy Improvement      Gain     4.4   \n",
      "24                           discrimination accuracy  Accuracy    69.7   \n",
      "25  discrimination accuracy with Executability Check  Accuracy    83.6   \n",
      "26     discrimination accuracy with Execution Result  Accuracy    88.5   \n",
      "27               discrimination accuracy Improvement      Gain    18.8   \n",
      "28                           discrimination accuracy  Accuracy    62.1   \n",
      "29  discrimination accuracy with Executability Check  Accuracy    82.2   \n",
      "30     discrimination accuracy with Execution Result  Accuracy    85.1   \n",
      "31               discrimination accuracy Improvement      Gain    23.0   \n",
      "32                           discrimination accuracy  Accuracy     nan   \n",
      "33  discrimination accuracy with Executability Check  Accuracy     nan   \n",
      "34     discrimination accuracy with Execution Result  Accuracy     nan   \n",
      "35               discrimination accuracy Improvement      Gain     nan   \n",
      "\n",
      "      paper_id table_id  \n",
      "0   2402.10890        2  \n",
      "1   2402.10890        2  \n",
      "2   2402.10890        2  \n",
      "3   2402.10890        2  \n",
      "4   2402.10890        2  \n",
      "5   2402.10890        2  \n",
      "6   2402.10890        2  \n",
      "7   2402.10890        2  \n",
      "8   2402.10890        2  \n",
      "9   2402.10890        2  \n",
      "10  2402.10890        2  \n",
      "11  2402.10890        2  \n",
      "12  2402.10890        2  \n",
      "13  2402.10890        2  \n",
      "14  2402.10890        2  \n",
      "15  2402.10890        2  \n",
      "16  2402.10890        2  \n",
      "17  2402.10890        2  \n",
      "18  2402.10890        2  \n",
      "19  2402.10890        2  \n",
      "20  2402.10890        2  \n",
      "21  2402.10890        2  \n",
      "22  2402.10890        2  \n",
      "23  2402.10890        2  \n",
      "24  2402.10890        2  \n",
      "25  2402.10890        2  \n",
      "26  2402.10890        2  \n",
      "27  2402.10890        2  \n",
      "28  2402.10890        2  \n",
      "29  2402.10890        2  \n",
      "30  2402.10890        2  \n",
      "31  2402.10890        2  \n",
      "32  2402.10890        2  \n",
      "33  2402.10890        2  \n",
      "34  2402.10890        2  \n",
      "35  2402.10890        2  \n"
     ]
    }
   ],
   "source": [
    "claims_df = []\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    df = load_json_as_df(filename)\n",
    "    print(df)\n",
    "    claims_df.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2406.03075_3_0 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_0 value: Acc.\n",
      "2406.03075_3_1 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_1 value: R\n",
      "2406.03075_3_2 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_3 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_3 value: F1\n",
      "2406.03075_3_4 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_4 value: Acc.\n",
      "2406.03075_3_5 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_5 value: R\n",
      "2406.03075_3_6 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_7 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_7 value: F1\n",
      "2406.03075_3_8 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_8 value: Acc.\n",
      "2406.03075_3_9 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_9 value: R\n",
      "2406.03075_3_10 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_11 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_11 value: F1\n",
      "2406.03075_3_12 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_12 value: Acc.\n",
      "2406.03075_3_13 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_13 value: R\n",
      "2406.03075_3_14 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_15 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_15 value: F1\n",
      "2406.03075_3_16 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_16 value: Acc.\n",
      "2406.03075_3_17 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_17 value: R\n",
      "2406.03075_3_18 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_19 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_19 value: F1\n",
      "2406.03075_3_20 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_20 value: Acc.\n",
      "2406.03075_3_21 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_21 value: R\n",
      "2406.03075_3_22 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_23 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_23 value: F1\n",
      "2406.03075_3_24 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_24 value: Acc.\n",
      "2406.03075_3_25 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_25 value: R\n",
      "2406.03075_3_26 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_27 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_27 value: F1\n",
      "2406.03075_3_28 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_28 value: Acc.\n",
      "2406.03075_3_29 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_29 value: R\n",
      "2406.03075_3_30 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_31 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_31 value: F1\n",
      "2406.03075_3_32 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_32 value: Acc.\n",
      "2406.03075_3_33 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_33 value: R\n",
      "2406.03075_3_34 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_35 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_3_35 value: F1\n",
      "2402.10890_3_12 value: CodeLlama-13B (E)\n",
      "2402.10890_3_13 value: CodeLlama-13B (E)\n",
      "2402.10890_3_14 value: CodeLlama-13B (E)\n",
      "2402.10890_3_15 value: CodeLlama-13B (E)\n",
      "2402.10890_3_16 value: GPT-3.5-Turbo (E)\n",
      "2402.10890_3_17 value: GPT-3.5-Turbo (E)\n",
      "2402.10890_3_18 value: GPT-3.5-Turbo (E)\n",
      "2402.10890_3_19 value: GPT-3.5-Turbo (E)\n",
      "2402.10890_3_20 value: CodeLlama-13B-FT (E)\n",
      "2402.10890_3_21 value: CodeLlama-13B-FT (E)\n",
      "2402.10890_3_22 value: CodeLlama-13B-FT (E)\n",
      "2402.10890_3_23 value: CodeLlama-13B-FT (E)\n",
      "2407.17115_5_18 value: Role-playing+\n",
      "2407.17115_5_19 value: Role-playing+\n",
      "2407.17115_5_20 value: Role-playing+\n",
      "2407.17115_5_21 value: Role-playing+\n",
      "2407.17115_5_22 value: Role-playing+\n",
      "2407.17115_5_23 value: Role-playing+\n",
      "2407.17115_5_24 value: Role-playing+\n",
      "2407.17115_5_25 value: Role-playing+\n",
      "2407.17115_5_26 value: Role-playing+\n",
      "2407.17115_5_27 value: History records+\n",
      "2407.17115_5_28 value: History records+\n",
      "2407.17115_5_29 value: History records+\n",
      "2407.17115_5_30 value: History records+\n",
      "2407.17115_5_31 value: History records+\n",
      "2407.17115_5_32 value: History records+\n",
      "2407.17115_5_33 value: History records+\n",
      "2407.17115_5_34 value: History records+\n",
      "2407.17115_5_35 value: History records+\n",
      "2407.17115_5_45 value: Output format+\n",
      "2407.17115_5_46 value: Output format+\n",
      "2407.17115_5_47 value: Output format+\n",
      "2407.17115_5_48 value: Output format+\n",
      "2407.17115_5_49 value: Output format+\n",
      "2407.17115_5_50 value: Output format+\n",
      "2407.17115_5_51 value: Output format+\n",
      "2407.17115_5_52 value: Output format+\n",
      "2407.17115_5_53 value: Output format+\n",
      "2407.17115_5_54 value: RPP+\n",
      "2407.17115_5_55 value: RPP+\n",
      "2407.17115_5_56 value: RPP+\n",
      "2407.17115_5_57 value: RPP+\n",
      "2407.17115_5_58 value: RPP+\n",
      "2407.17115_5_59 value: RPP+\n",
      "2407.17115_5_60 value: RPP+\n",
      "2407.17115_5_61 value: RPP+\n",
      "2407.17115_5_62 value: RPP+\n",
      "2406.12707_1_0 value: BERTScore\n",
      "2406.12707_1_2 value: BERTScore\n",
      "2406.12707_1_4 value: BERTScore\n",
      "2402.10890_1_0 value: Acc\n",
      "2402.10890_1_1 value: F1\n",
      "2402.10890_1_4 value: Acc\n",
      "2402.10890_1_5 value: F1\n",
      "2402.10890_1_8 value: Acc\n",
      "2402.10890_1_9 value: F1\n",
      "2402.10890_1_12 value: Acc\n",
      "2402.10890_1_13 value: F1\n",
      "2402.10890_1_16 value: Acc\n",
      "2402.10890_1_17 value: F1\n",
      "2402.10890_1_20 value: Acc\n",
      "2402.10890_1_21 value: F1\n",
      "2402.10890_1_24 value: Acc\n",
      "2402.10890_1_25 value: F1\n",
      "2402.10890_1_28 value: Acc\n",
      "2402.10890_1_29 value: F1\n",
      "2402.10890_1_32 value: Acc\n",
      "2402.10890_1_33 value: F1\n",
      "2402.10890_1_36 value: Acc\n",
      "2402.10890_1_37 value: F1\n",
      "2402.10890_1_40 value: Acc\n",
      "2402.10890_1_41 value: F1\n",
      "2402.10890_1_44 value: Acc\n",
      "2402.10890_1_45 value: F1\n",
      "2402.10890_1_48 value: Acc\n",
      "2402.10890_1_49 value: F1\n",
      "2402.10890_1_52 value: Acc\n",
      "2402.10890_1_53 value: F1\n",
      "2402.10890_1_56 value: Acc\n",
      "2402.10890_1_57 value: F1\n",
      "2402.10890_1_60 value: Acc\n",
      "2402.10890_1_61 value: F1\n",
      "2402.10890_1_64 value: Acc\n",
      "2402.10890_1_65 value: F1\n",
      "2402.10890_1_68 value: Acc\n",
      "2402.10890_1_69 value: F1\n",
      "2405.17129_1_6 value: ZSEC-gpt4o\n",
      "2405.17129_1_7 value: ZSEC-gpt4o\n",
      "2405.17129_1_8 value: ZSEC-gpt4o\n",
      "2406.03075_4_0 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_0 value: Acc.\n",
      "2406.03075_4_1 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_1 value: R\n",
      "2406.03075_4_2 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_3 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_3 value: F1\n",
      "2406.03075_4_4 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_4 value: Acc.\n",
      "2406.03075_4_5 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_5 value: R\n",
      "2406.03075_4_6 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_7 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_7 value: F1\n",
      "2406.03075_4_8 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_8 value: Acc.\n",
      "2406.03075_4_9 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_9 value: R\n",
      "2406.03075_4_10 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_11 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_11 value: F1\n",
      "2406.03075_4_12 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_12 value: Acc.\n",
      "2406.03075_4_13 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_13 value: R\n",
      "2406.03075_4_14 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_15 value: HaluEval Li et al. (2023a)\n",
      "2406.03075_4_15 value: F1\n",
      "2406.03075_2_0 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_0 value: Self-Check (0)\n",
      "2406.03075_2_0 value: Acc.\n",
      "2406.03075_2_1 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_1 value: Self-Check (0)\n",
      "2406.03075_2_1 value: R\n",
      "2406.03075_2_2 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_2 value: Self-Check (0)\n",
      "2406.03075_2_3 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_3 value: Self-Check (0)\n",
      "2406.03075_2_3 value: F1\n",
      "2406.03075_2_4 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_4 value: Self-Check (3)\n",
      "2406.03075_2_4 value: Acc.\n",
      "2406.03075_2_5 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_5 value: Self-Check (3)\n",
      "2406.03075_2_5 value: R\n",
      "2406.03075_2_6 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_6 value: Self-Check (3)\n",
      "2406.03075_2_7 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_7 value: Self-Check (3)\n",
      "2406.03075_2_7 value: F1\n",
      "2406.03075_2_8 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_8 value: Acc.\n",
      "2406.03075_2_9 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_9 value: R\n",
      "2406.03075_2_10 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_11 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_11 value: F1\n",
      "2406.03075_2_12 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_12 value: Acc.\n",
      "2406.03075_2_13 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_13 value: R\n",
      "2406.03075_2_14 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_15 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_15 value: F1\n",
      "2406.03075_2_16 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_16 value: Self-Check (0)\n",
      "2406.03075_2_16 value: Acc.\n",
      "2406.03075_2_17 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_17 value: Self-Check (0)\n",
      "2406.03075_2_17 value: R\n",
      "2406.03075_2_18 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_18 value: Self-Check (0)\n",
      "2406.03075_2_19 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_19 value: Self-Check (0)\n",
      "2406.03075_2_19 value: F1\n",
      "2406.03075_2_20 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_20 value: Self-Check (3)\n",
      "2406.03075_2_20 value: Acc.\n",
      "2406.03075_2_21 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_21 value: Self-Check (3)\n",
      "2406.03075_2_21 value: R\n",
      "2406.03075_2_22 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_22 value: Self-Check (3)\n",
      "2406.03075_2_23 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_23 value: Self-Check (3)\n",
      "2406.03075_2_23 value: F1\n",
      "2406.03075_2_24 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_24 value: Acc.\n",
      "2406.03075_2_25 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_25 value: R\n",
      "2406.03075_2_26 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_27 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_27 value: F1\n",
      "2406.03075_2_28 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_28 value: Acc.\n",
      "2406.03075_2_29 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_29 value: R\n",
      "2406.03075_2_30 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_31 value: Factool Chern et al. (2023)\n",
      "2406.03075_2_31 value: F1\n",
      "2406.12707_2_0 value: BERTScore\n",
      "2406.12707_2_2 value: BERTScore\n",
      "2406.12707_2_4 value: BERTScore\n",
      "2405.17129_5_3 value: Acc.\n",
      "2405.17129_5_7 value: Acc.\n",
      "2405.17129_5_11 value: Acc.\n",
      "2405.17129_5_15 value: Acc.\n",
      "2310.01444_2_0 value: HotpotQA\n",
      "2310.01444_2_0 value: CoT [61]\n",
      "2310.01444_2_1 value: HotpotQA\n",
      "2310.01444_2_2 value: HotpotQA\n",
      "2310.01444_2_3 value: HotpotQA\n",
      "2310.01444_2_4 value: HotpotQA\n",
      "2310.01444_2_5 value: HotpotQA\n",
      "2310.01444_2_6 value: HotpotQA\n",
      "2310.01444_2_7 value: HotpotQA\n",
      "2310.01444_2_8 value: HotpotQA\n",
      "2310.01444_2_9 value: HotpotQA\n",
      "2310.01444_2_10 value: HotpotQA\n"
     ]
    }
   ],
   "source": [
    "with open('alignment_name_schema.json', 'r') as file:\n",
    "    align_name = json.load(file)\n",
    "\n",
    "with open('alignment_values_schema.json', 'r') as file:\n",
    "    align_value = json.load(file)\n",
    "\n",
    "aligned_df = pd.DataFrame(columns=align_name.keys())\n",
    "\n",
    "excluded_columns = ['outcome', 'table_id', 'paper_id', 'claim_id']\n",
    "\n",
    "for claim_df in claims_df:\n",
    "    for _, row in claim_df.iterrows():\n",
    "        aligned_row = {key: None for key in align_name.keys()}\n",
    "        aligned_row[\"outcome\"] = row[\"Outcome\"]\n",
    "        aligned_row[\"table_id\"] = row[\"table_id\"]\n",
    "        aligned_row[\"paper_id\"] = row[\"paper_id\"]\n",
    "        aligned_row[\"claim_id\"] = row[\"claim_id\"]\n",
    "        for name_key, name_values in align_name.items():\n",
    "            for col in [c for c in claim_df.columns if c not in excluded_columns]:\n",
    "                if row[col].lower() in name_values:\n",
    "                    for value_key, value_value in align_value.items():\n",
    "                        if value_value is not None and row[col].lower() in value_value:\n",
    "                            aligned_row[name_key] = value_key\n",
    "                            print(f\"{aligned_row[\"paper_id\"]}_{aligned_row[\"table_id\"]}_{aligned_row[\"claim_id\"]} value: {row[col]}\")\n",
    "                            break\n",
    "                        else:\n",
    "                            aligned_row[name_key] = row[col]\n",
    "        aligned_df = pd.concat([aligned_df, pd.DataFrame([aligned_row])], ignore_index=True)\n",
    "\n",
    "aligned_df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON pe paulo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_spec_id(filename, claim_id, flag):\n",
    "    with open(os.path.join(INPUT_DIR, filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for key, value in data[claim_id]['specifications'].items():\n",
    "        if value['value'] == flag:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constr_filename(paper_id, table_id):\n",
    "    return f'{paper_id}_{table_id}_claims.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_json_name(df):\n",
    "    json_data = {}\n",
    "    name2spec = {}\n",
    "    for col in df.columns:\n",
    "        if col not in ['claim_id', 'table_id', 'paper_id', 'Outcome']:\n",
    "            nomi = []\n",
    "            for _,row in df.iterrows():\n",
    "                filename = constr_filename(row['paper_id'], row['table_id'])\n",
    "                spec_id = retrieve_spec_id(filename, row['claim_id'], row[col])\n",
    "                if (spec_id is not None):\n",
    "                    nomi.append(f\"{row['paper_id']}_{row['table_id']}_{row['claim_id']}_{spec_id}\")  \n",
    "            name2spec[col] = nomi\n",
    "        json_data['aligned_names'] = name2spec\n",
    "    return json_data\n",
    "\n",
    "json_data = build_json_name(aligned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "files = \"\"\" \n",
    "2406.03075_3_0 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_0 Acc.\n",
    "2406.03075_3_1 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_1 R\n",
    "2406.03075_3_2 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_3 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_3 F1\n",
    "2406.03075_3_4 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_4 Acc.\n",
    "2406.03075_3_5 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_5 R\n",
    "2406.03075_3_6 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_7 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_7 F1\n",
    "2406.03075_3_8 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_8 Acc.\n",
    "2406.03075_3_9 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_9 R\n",
    "2406.03075_3_10 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_11 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_11 F1\n",
    "2406.03075_3_12 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_12 Acc.\n",
    "2406.03075_3_13 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_13 R\n",
    "2406.03075_3_14 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_15 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_15 F1\n",
    "2406.03075_3_16 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_16 Acc.\n",
    "2406.03075_3_17 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_17 R\n",
    "2406.03075_3_18 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_19 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_19 F1\n",
    "2406.03075_3_20 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_20 Acc.\n",
    "2406.03075_3_21 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_21 R\n",
    "2406.03075_3_22 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_23 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_23 F1\n",
    "2406.03075_3_24 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_24 Acc.\n",
    "2406.03075_3_25 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_25 R\n",
    "2406.03075_3_26 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_27 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_27 F1\n",
    "2406.03075_3_28 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_28 Acc.\n",
    "2406.03075_3_29 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_29 R\n",
    "2406.03075_3_30 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_31 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_31 F1\n",
    "2406.03075_3_32 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_32 Acc.\n",
    "2406.03075_3_33 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_33 R\n",
    "2406.03075_3_34 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_35 HaluEval Li et al. (2023a)\n",
    "2406.03075_3_35 F1\n",
    "2402.10890_3_12 CodeLlama-13B (E)\n",
    "2402.10890_3_13 CodeLlama-13B (E)\n",
    "2402.10890_3_14 CodeLlama-13B (E)\n",
    "2402.10890_3_15 CodeLlama-13B (E)\n",
    "2402.10890_3_16 GPT-3.5-Turbo (E)\n",
    "2402.10890_3_17 GPT-3.5-Turbo (E)\n",
    "2402.10890_3_18 GPT-3.5-Turbo (E)\n",
    "2402.10890_3_19 GPT-3.5-Turbo (E)\n",
    "2402.10890_3_20 CodeLlama-13B-FT (E)\n",
    "2402.10890_3_21 CodeLlama-13B-FT (E)\n",
    "2402.10890_3_22 CodeLlama-13B-FT (E)\n",
    "2402.10890_3_23 CodeLlama-13B-FT (E)\n",
    "2407.17115_5_18 Role-playing+\n",
    "2407.17115_5_19 Role-playing+\n",
    "2407.17115_5_20 Role-playing+\n",
    "2407.17115_5_21 Role-playing+\n",
    "2407.17115_5_22 Role-playing+\n",
    "2407.17115_5_23 Role-playing+\n",
    "2407.17115_5_24 Role-playing+\n",
    "2407.17115_5_25 Role-playing+\n",
    "2407.17115_5_26 Role-playing+\n",
    "2407.17115_5_27 History records+\n",
    "2407.17115_5_28 History records+\n",
    "2407.17115_5_29 History records+\n",
    "2407.17115_5_30 History records+\n",
    "2407.17115_5_31 History records+\n",
    "2407.17115_5_32 History records+\n",
    "2407.17115_5_33 History records+\n",
    "2407.17115_5_34 History records+\n",
    "2407.17115_5_35 History records+\n",
    "2407.17115_5_45 Output format+\n",
    "2407.17115_5_46 Output format+\n",
    "2407.17115_5_47 Output format+\n",
    "2407.17115_5_48 Output format+\n",
    "2407.17115_5_49 Output format+\n",
    "2407.17115_5_50 Output format+\n",
    "2407.17115_5_51 Output format+\n",
    "2407.17115_5_52 Output format+\n",
    "2407.17115_5_53 Output format+\n",
    "2407.17115_5_54 RPP+\n",
    "2407.17115_5_55 RPP+\n",
    "2407.17115_5_56 RPP+\n",
    "2407.17115_5_57 RPP+\n",
    "2407.17115_5_58 RPP+\n",
    "2407.17115_5_59 RPP+\n",
    "2407.17115_5_60 RPP+\n",
    "2407.17115_5_61 RPP+\n",
    "2407.17115_5_62 RPP+\n",
    "2406.12707_1_0 BERTScore\n",
    "2406.12707_1_2 BERTScore\n",
    "2406.12707_1_4 BERTScore\n",
    "2402.10890_1_0 Acc\n",
    "2402.10890_1_1 F1\n",
    "2402.10890_1_4 Acc\n",
    "2402.10890_1_5 F1\n",
    "2402.10890_1_8 Acc\n",
    "2402.10890_1_9 F1\n",
    "2402.10890_1_12 Acc\n",
    "2402.10890_1_13 F1\n",
    "2402.10890_1_16 Acc\n",
    "2402.10890_1_17 F1\n",
    "2402.10890_1_20 Acc\n",
    "2402.10890_1_21 F1\n",
    "2402.10890_1_24 Acc\n",
    "2402.10890_1_25 F1\n",
    "2402.10890_1_28 Acc\n",
    "2402.10890_1_29 F1\n",
    "2402.10890_1_32 Acc\n",
    "2402.10890_1_33 F1\n",
    "2402.10890_1_36 Acc\n",
    "2402.10890_1_37 F1\n",
    "2402.10890_1_40 Acc\n",
    "2402.10890_1_41 F1\n",
    "2402.10890_1_44 Acc\n",
    "2402.10890_1_45 F1\n",
    "2402.10890_1_48 Acc\n",
    "2402.10890_1_49 F1\n",
    "2402.10890_1_52 Acc\n",
    "2402.10890_1_53 F1\n",
    "2402.10890_1_56 Acc\n",
    "2402.10890_1_57 F1\n",
    "2402.10890_1_60 Acc\n",
    "2402.10890_1_61 F1\n",
    "2402.10890_1_64 Acc\n",
    "2402.10890_1_65 F1\n",
    "2402.10890_1_68 Acc\n",
    "2402.10890_1_69 F1\n",
    "2405.17129_1_6 ZSEC-gpt4o\n",
    "2405.17129_1_7 ZSEC-gpt4o\n",
    "2405.17129_1_8 ZSEC-gpt4o\n",
    "2406.03075_4_0 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_0 Acc.\n",
    "2406.03075_4_1 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_1 R\n",
    "2406.03075_4_2 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_3 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_3 F1\n",
    "2406.03075_4_4 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_4 Acc.\n",
    "2406.03075_4_5 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_5 R\n",
    "2406.03075_4_6 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_7 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_7 F1\n",
    "2406.03075_4_8 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_8 Acc.\n",
    "2406.03075_4_9 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_9 R\n",
    "2406.03075_4_10 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_11 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_11 F1\n",
    "2406.03075_4_12 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_12 Acc.\n",
    "2406.03075_4_13 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_13 R\n",
    "2406.03075_4_14 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_15 HaluEval Li et al. (2023a)\n",
    "2406.03075_4_15 F1\n",
    "2406.03075_2_0 Factool Chern et al. (2023)\n",
    "2406.03075_2_0 Self-Check (0)\n",
    "2406.03075_2_0 Acc.\n",
    "2406.03075_2_1 Factool Chern et al. (2023)\n",
    "2406.03075_2_1 Self-Check (0)\n",
    "2406.03075_2_1 R\n",
    "2406.03075_2_2 Factool Chern et al. (2023)\n",
    "2406.03075_2_2 Self-Check (0)\n",
    "2406.03075_2_3 Factool Chern et al. (2023)\n",
    "2406.03075_2_3 Self-Check (0)\n",
    "2406.03075_2_3 F1\n",
    "2406.03075_2_4 Factool Chern et al. (2023)\n",
    "2406.03075_2_4 Self-Check (3)\n",
    "2406.03075_2_4 Acc.\n",
    "2406.03075_2_5 Factool Chern et al. (2023)\n",
    "2406.03075_2_5 Self-Check (3)\n",
    "2406.03075_2_5 R\n",
    "2406.03075_2_6 Factool Chern et al. (2023)\n",
    "2406.03075_2_6 Self-Check (3)\n",
    "2406.03075_2_7 Factool Chern et al. (2023)\n",
    "2406.03075_2_7 Self-Check (3)\n",
    "2406.03075_2_7 F1\n",
    "2406.03075_2_8 Factool Chern et al. (2023)\n",
    "2406.03075_2_8 Acc.\n",
    "2406.03075_2_9 Factool Chern et al. (2023)\n",
    "2406.03075_2_9 R\n",
    "2406.03075_2_10 Factool Chern et al. (2023)\n",
    "2406.03075_2_11 Factool Chern et al. (2023)\n",
    "2406.03075_2_11 F1\n",
    "2406.03075_2_12 Factool Chern et al. (2023)\n",
    "2406.03075_2_12 Acc.\n",
    "2406.03075_2_13 Factool Chern et al. (2023)\n",
    "2406.03075_2_13 R\n",
    "2406.03075_2_14 Factool Chern et al. (2023)\n",
    "2406.03075_2_15 Factool Chern et al. (2023)\n",
    "2406.03075_2_15 F1\n",
    "2406.03075_2_16 Factool Chern et al. (2023)\n",
    "2406.03075_2_16 Self-Check (0)\n",
    "2406.03075_2_16 Acc.\n",
    "2406.03075_2_17 Factool Chern et al. (2023)\n",
    "2406.03075_2_17 Self-Check (0)\n",
    "2406.03075_2_17 R\n",
    "2406.03075_2_18 Factool Chern et al. (2023)\n",
    "2406.03075_2_18 Self-Check (0)\n",
    "2406.03075_2_19 Factool Chern et al. (2023)\n",
    "2406.03075_2_19 Self-Check (0)\n",
    "2406.03075_2_19 F1\n",
    "2406.03075_2_20 Factool Chern et al. (2023)\n",
    "2406.03075_2_20 Self-Check (3)\n",
    "2406.03075_2_20 Acc.\n",
    "2406.03075_2_21 Factool Chern et al. (2023)\n",
    "2406.03075_2_21 Self-Check (3)\n",
    "2406.03075_2_21 R\n",
    "2406.03075_2_22 Factool Chern et al. (2023)\n",
    "2406.03075_2_22 Self-Check (3)\n",
    "2406.03075_2_23 Factool Chern et al. (2023)\n",
    "2406.03075_2_23 Self-Check (3)\n",
    "2406.03075_2_23 F1\n",
    "2406.03075_2_24 Factool Chern et al. (2023)\n",
    "2406.03075_2_24 Acc.\n",
    "2406.03075_2_25 Factool Chern et al. (2023)\n",
    "2406.03075_2_25 R\n",
    "2406.03075_2_26 Factool Chern et al. (2023)\n",
    "2406.03075_2_27 Factool Chern et al. (2023)\n",
    "2406.03075_2_27 F1\n",
    "2406.03075_2_28 Factool Chern et al. (2023)\n",
    "2406.03075_2_28 Acc.\n",
    "2406.03075_2_29 Factool Chern et al. (2023)\n",
    "2406.03075_2_29 R\n",
    "2406.03075_2_30 Factool Chern et al. (2023)\n",
    "2406.03075_2_31 Factool Chern et al. (2023)\n",
    "2406.03075_2_31 F1\n",
    "2406.12707_2_0 BERTScore\n",
    "2406.12707_2_2 BERTScore\n",
    "2406.12707_2_4 BERTScore\n",
    "2405.17129_5_3 Acc.\n",
    "2405.17129_5_7 Acc.\n",
    "2405.17129_5_11 Acc.\n",
    "2405.17129_5_15 Acc.\n",
    "2310.01444_2_0 HotpotQA\n",
    "2310.01444_2_0 CoT [61]\n",
    "2310.01444_2_1 HotpotQA\n",
    "2310.01444_2_2 HotpotQA\n",
    "2310.01444_2_3 HotpotQA\n",
    "2310.01444_2_4 HotpotQA\n",
    "2310.01444_2_5 HotpotQA\n",
    "2310.01444_2_6 HotpotQA\n",
    "2310.01444_2_7 HotpotQA\n",
    "2310.01444_2_8 HotpotQA\n",
    "2310.01444_2_9 HotpotQA\n",
    "2310.01444_2_10 HotpotQA\n",
    "\"\"\"\n",
    "value2filename = {}\n",
    "for line in files.split('\\n'):\n",
    "    match = re.match(r\"^(\\S+)\\s(.+)$\", line)\n",
    "    if match:\n",
    "        base, value = match.groups()\n",
    "        filename = constr_filename(base.split('_')[0], base.split('_')[1])\n",
    "        spec_id = retrieve_spec_id(filename, base.split('_')[2], value)\n",
    "        if value.lower().strip() not in value2filename.keys():\n",
    "            value2filename[value.lower()] = []\n",
    "        if spec_id is not None:\n",
    "            value2filename[value.lower()].append(f\"{base}_{spec_id}\")\n",
    "        else:\n",
    "            value2filename[value.lower()].append(f\"{base}_measure\")\n",
    "\n",
    "value2filename_good = {}\n",
    "for key_1, value_1 in value2filename.items():\n",
    "    for key_2, value_2 in align_value.items():\n",
    "        if value_2 is not None and key_1 in value_2:\n",
    "            value2filename_good[key_2] = value_1\n",
    "\n",
    "json_data['aligned_values'] = value2filename_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task3.json', 'w') as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_from_json(json_data):\n",
    "    values_set = set()\n",
    "\n",
    "    def extract_values(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for value in obj.values():\n",
    "                extract_values(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract_values(item)\n",
    "        else:\n",
    "            values_set.add(obj)\n",
    "\n",
    "    extract_values(json_data)\n",
    "    return values_set\n",
    "\n",
    "# Load the JSON file\n",
    "with open('alignment_schema.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract values\n",
    "values_set = extract_values_from_json(json_data)\n",
    "sorted_list = sorted(list(values_set))\n",
    "output_dict = {key: None for key in sorted_list}\n",
    "\n",
    "\n",
    "output_file = \"alignment_values_schema.json\"\n",
    "with open(output_file, \"w\") as json_file:\n",
    "    json.dump(output_dict, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
