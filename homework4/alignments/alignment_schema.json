{
  "agent configuration": [
    "single agent (cot)",
    "3 agents",
    "4 agents w/ llamaguard"
  ],
  "attack method": [
    "combination-1",
    "prefix injection",
    "refusal suppression",
    "combination-2",
    "aim"
  ],
  "attribute": [
    "emotion",
    "pitch",
    "energy",
    "speed"
  ],
  "dataset": [
    "toolbench",
    "ml-1m",
    "games",
    "lastfm",
    "dan",
    "hotpotqa",
    "factool chern et al. (2023)",
    "halueval li et al. (2023a)",
    "spider",
    "bird",
    "gsm8k",
    "textrospeech",
    "test dataset",
    "gsm8k",
    "hotpot-qa",
    "alfworld"
  ],
  "emotion label": [
    "love",
    "joy",
    "anger",
    "fear",
    "sadness",
    "neutral"
  ],
  "evaluation level": [
    "claim-level",
    "response-level"
  ],
  "gender": [
    "male",
    "female"
  ],
  "memory capacity": [
    "0",
    "1",
    "10",
    "25",
    "50"
  ],
  "memory tag configuration": [
    "default",
    "w/o cat",
    "w/o que",
    "w/o cat & que"
  ],
  "method": [
    "manual prompts",
    "enumeration",
    "role-playing+",
    "history records+",
    "reasoning guidance+",
    "output format+",
    "rpp+",
    "pop",
    "bprmf",
    "sasrec",
    "bm25",
    "unisrec",
    "vq-rec",
    "io",
    "cot",
    "bag",
    "tp",
    "tot",
    "cot [61]",
    "cot-sc [55]",
    "react [65]",
    "react \u2192 cot-sc",
    "react",
    "react-tuning",
    "cot-tuning",
    "ltc",
    "self-check (0)",
    "self-check (3)",
    "factool",
    "our method",
    "pair",
    "tap",
    "pap",
    "gptfuzzer",
    "redagent (ours)",
    "role-playing",
    "history records",
    "reasoning guidance",
    "output format",
    "rpp",
    "halueval",
    "ours",
    "always skeptic",
    "always trust",
    "true\u2192trust",
    "true\u2192skeptic",
    "cot@3",
    "bfs",
    "dfsdt",
    "radagent",
    "icl",
    "rand. select",
    "elo select"
  ],
  "metric index": [
    "1",
    "2",
    "3"
  ],
  "model": [
    "palm-2",
    "gpt-3.5",
    "gpt-4",
    "codellama-13b",
    "gpt-3.5-turbo",
    "codellama-13b-ft",
    "codellama-13b (e)",
    "gpt-3.5-turbo (e)",
    "codellama-13b-ft (e)",
    "vicuna-13b",
    "llama-2-70b",
    "mixtral-8x7b",
    "speech-gpt3.5",
    "perceptiveagent",
    "perceptiveagent -w/o captions",
    "palm-540b",
    "gpt3-175b",
    "palm-62b",
    "palm-8b",
    "llama-7b",
    "gpt-3.5-turbo-1106",
    "vicuna-7b-v1.5",
    "llama-2-7b-chat-hf",
    "gpt-4-1106-preview",
    "gemini-pro",
    "claude-3.5-sonnet",
    "codellama-13b",
    "gpt-3.5-turbo",
    "codellama-13b-ft",
    "llama-2-13b",
    "llama-2-7b",
    "mistral-7b-v0.2",
    "mixtral-8x7b-v0.1",
    "vicuna-13b-v1.5",
    "vicuna-33b",
    "vicuna-7b-v1.5",
    "ensemble-19",
    "zeroshot (gpt-4-turbo)",
    "zeroshot (gpt-4o)",
    "zse (gpt-4o)",
    "zsec (gpt-4o)",
    "codellama-7b",
    "codellama-7b-ft",
    "gpt-4-turbo",
    "gpt-3.5-turbo",
    "claude-2",
    "gpt-4",
    "exalt baseline",
    "zsec-gpt4turbo",
    "zsec-gpt4o",
    "mbcawf",
    "miawf-3",
    "miawf-5",
    "ensemble-9",
    "ensemble-8",
    "ensemble-17",
    "flan-t5-large",
    "vicuna-7b",
    "llama-2-13b",
    "gpt-3.5-turbo",
    "claude-2",
    "gpt-4"
  ],
  "planning method": [
    "re-ranking",
    "iterative correction",
    "tree search",
    "advanced planning"
  ],
  "prompt": [
    "prompt-1",
    "prompt-2"
  ],
  "query_budget": [
    "40",
    "same"
  ],
  "samples": [
    "80"
  ],
  "setting": [
    "zero",
    "few",
    "fine-tuning",
    "rltf"
  ],
  "shot type": [
    "0-shot",
    "1-shot",
    "5-shot"
  ],
  "task": [
    "solution ranking on complex tasks",
    "ablation study on rpp+",
    "attack success rate evaluation",
    "shortest-path reasoning task",
    "performance evaluation",
    "evaluating em scores on hotpotqa",
    "impact of memory tags on redagent performance",
    "jailbreak general-use llms",
    "enhancing recommendation ability",
    "qa",
    "summarization",
    "dialogue",
    "discrimination accuracy",
    "discrimination accuracy with executability check",
    "discrimination accuracy with execution result",
    "discrimination accuracy improvement",
    "analyzing common failure reasons in decision-making",
    "creative writing task",
    "openagi",
    "generalization performance evaluation",
    "text-to-sql parsing",
    "defense against harmful requests",
    "emotion detection",
    "impact of capacity on redagent performance",
    "discrimination abilities",
    "zero-shot task-solving performance",
    "evaluating token usage in input prompts",
    "defense using multi-agent systems",
    "speech captioning performance"
  ],
  "metrics": [
    "anq",
    "asr",
    "asr (%)",
    "acc",
    "acc.",
    "accuracy",
    "bert score",
    "bertscore",
    "clip score",
    "coherent score",
    "decision failure",
    "em score",
    "f1",
    "f1-score",
    "fpr",
    "fr",
    "gain",
    "h@1",
    "hallucinated tool fix ratio",
    "hallucinated tool ratio",
    "mrr",
    "n@1",
    "n@5",
    "n@10",
    "olr",
    "or",
    "outcome",
    "overall",
    "p",
    "pass rate (%)",
    "precision",
    "pref. rank",
    "r",
    "recall",
    "support",
    "token count",
    "tool call error fix ratio",
    "tool call error ratio",
    "unavailable tool",
    "user study",
    "vit score"
  ],
  "outcome":[]
}