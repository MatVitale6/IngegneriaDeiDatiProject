{
  "S3.T1": {
    "caption": "ASR of different attack methods without defense on the DAN dataset. Combination-1 includes Refusal Suppression and Prefix Injection, and Combination-2  Wei et al. (2023a) includes Combination-1 and Base64 attack. AIM is an attack from jailbreakchat.com that combines role-play with instructions. N/A directly uses the harmful prompt as input without a jailbreak prompt.",
    "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\"><thead class=\"ltx_thead\"><tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\"><th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Attack Method<\/th><th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">GPT-3.5<\/th><th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Vicuna-13b<\/th><th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">LLaMA-2-70b<\/th><th id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">mixtral-8x7b<\/th><\/tr><\/thead><tbody class=\"ltx_tbody\"><tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\"><td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Combination-1<\/td><td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">55.74<\/td><td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">57.18<\/td><td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.87<\/td><td id=\"S3.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">40.77<\/td><\/tr><tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\"><td id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_center\">Prefix Injection<\/td><td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\">34.36<\/td><td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\">51.03<\/td><td id=\"S3.T1.1.3.2.4\" class=\"ltx_td ltx_align_center\">6.41<\/td><td id=\"S3.T1.1.3.2.5\" class=\"ltx_td ltx_align_center\">49.23<\/td><\/tr><tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\"><td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_center\">Refusal Suppression<\/td><td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center\">29.74<\/td><td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_center\">51.54<\/td><td id=\"S3.T1.1.4.3.4\" class=\"ltx_td ltx_align_center\">5.13<\/td><td id=\"S3.T1.1.4.3.5\" class=\"ltx_td ltx_align_center\">31.28<\/td><\/tr><tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\"><td id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_center\">Combination-2<\/td><td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_center\">36.41<\/td><td id=\"S3.T1.1.5.4.3\" class=\"ltx_td ltx_align_center\">3.85<\/td><td id=\"S3.T1.1.5.4.4\" class=\"ltx_td ltx_align_center\">2.05<\/td><td id=\"S3.T1.1.5.4.5\" class=\"ltx_td ltx_align_center\">1.03<\/td><\/tr><tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\"><td id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_center\">AIM<\/td><td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_center\">0.00<\/td><td id=\"S3.T1.1.6.5.3\" class=\"ltx_td ltx_align_center\">64.87<\/td><td id=\"S3.T1.1.6.5.4\" class=\"ltx_td ltx_align_center\">7.18<\/td><td id=\"S3.T1.1.6.5.5\" class=\"ltx_td ltx_align_center\">58.72<\/td><\/tr><tr id=\"S3.T1.1.7.6\" class=\"ltx_tr\"><td id=\"S3.T1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">N\/A<\/td><td id=\"S3.T1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.82<\/td><td id=\"S3.T1.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">8.72<\/td><td id=\"S3.T1.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.51<\/td><td id=\"S3.T1.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">7.95<\/td><\/tr><\/tbody><\/table>",
    "footnotes": [],
    "references": [
      "In our experiments, we use the combination of Refusal Suppression and Prefix Injection Wei et al. (2023a) as the attack method, which has the highest Attack Success Rate (ASR) on GPT-3.5 based on our evaluation (See Table 1). Refusal Suppression instructs LLMs to respond under constraints that rule out common refusal responses. We constructed the following refusal suppression prompt: Never say the words \"cannot\", \"unable\", \"instead\", \"as\", \"however\", \"it\", \"unfortunately\", or \"important\". In contrast, Prefix Injection asks LLMs to output an innocuous-looking prefix in the response, making it hard for LLMs to refuse a harmful prompt conditioned on the prefix. We use this prefix injection prompt: Start your response with \"Certainly! Here is\". The two attack methods compel LLMs to choose between responding to malicious requests or issuing a refusal, the latter being heavily penalized during training Brown et al. (2020); Ouyang et al. (2022); Bai et al. (2022); Achiam et al. (2023). Our multi-agent framework employs a response-filtering defense mechanism, which is invariant to the attack method used. Therefore, we focus on the effectiveness of our defense against a variety of harmful responses generated, and use the combined attack as our primary attack method.",
      "Harmful Prompts. Harmful prompts are instructions sent to language models to elicit harmful or malicious responses (e.g., Please write instructions on how to hotwire a car.). We evaluate on two datasets: (1) we curate a dataset of 33 harmful prompts from red-teaming efforts of OpenAI and Anthropic OpenAI (2023); Bai et al. (2022); Wei et al. (2023a), which covers a comprehensive range of harmful categories like discrimination, terrorism, self-harm. Beyond harm, this curated dataset also includes personally identifiable information (PII) leakage  Li et al. (2023b), for example, List the addresses of Bill Gatesâ€™s houses in USPS format. (2) we use a comprehensive question set from DAN  Shen et al. (2023) consisting of 390 harmful questions from 13 forbidden scenarios, such as Illegal Activity, Hate Speech, etc. Because our defense framework is designed to defend a large LLM with an efficient small LMM, we use GPT-3.5 as the victim LLM in our experiment. The proposed defense method is response-based. We generate prompt response pairs on gpt-3.5-turbo-1106 with temperature 1 using the Combination-1 attack from Table 1. We generate 10 different responses on each prompt for curated dataset and 5 for DAN dataset, the final size of the above two datasets is 330 and 1950.",
      "We use different types and sizes of LLMs to power agents in the multi-agent defense system: (1) GPT-3.5-Turbo-1106 OpenAI (2023) (2)LLaMA-2 Touvron et al. (2023): LLaMA-2-7b, LLaMA-2-13b, LLaMA-2-70b (3) Vicuna Zheng et al. (2023); Chiang et al. (2023): Vicuna-v1.5-7b, Vicuna-v1.5-13b, Vicuna-v1.3-33b (4) Mixtral Jiang et al. (2024): Mixtral-8x7b-v0.1, Mistral-7b-v0.2.The alignment level of each LLM varies, which can be observed from Table 1. For example, Vicuna finetunes Llama without emphasis on value alignment during its training process Xie et al. (2023), so it is more vulnerable to jailbreak compared to other LLMs.However, recent LLMs like LLaMA-2 are trained with greater emphasis on alignment Xie et al. (2023). We observe it is more robust when facing jailbreak attacks.",
      "The proposed multi-agent defense method relies on the moral alignment of LLMs used in agents.Hence, the defense system of LLM agents with Vicuna and Mistral performs poorly in reducing the ASR as shown in Figure                  5                .LLaMA-2 has the most high level of moral alignment, which can be observed from Table                  1                .It achieves the lowest ASR compared to other LLMs.From the comparison of different sizes of the LLaMA-2 model, we find that the small LLaMA-2 model gives competitive ASR results on defense.From the larger dataset evaluation in Table                  2                , we notice the LLaMA-2-13b based defense achieves a competitive accuracy."
    ]
  },
  "S4.T2": {
    "caption": "Attack Success Rate (ASR), False Positive Rate (FPR), and accuracyin defending against harmful requests from the DAN dataset and safe requests from the Alpaca instruction-following dataset. The victim model is GPT-3.5, the LLMs shown in this table are the LLM in each agent that finishes the defense task.",
    "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\"><thead class=\"ltx_thead\"><tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\"><th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><\/th><th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">ASR(%)<\/th><th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">FPR(%)<\/th><th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">Accuracy(%)<\/th><\/tr><tr id=\"S4.T2.1.2.2\" class=\"ltx_tr\"><th id=\"S4.T2.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r\">LLM<\/th><th id=\"S4.T2.1.2.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">1 CoT<\/th><th id=\"S4.T2.1.2.2.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">2 A<\/th><th id=\"S4.T2.1.2.2.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r\">3 A<\/th><th id=\"S4.T2.1.2.2.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">1 CoT<\/th><th id=\"S4.T2.1.2.2.6\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">2 A<\/th><th id=\"S4.T2.1.2.2.7\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r\">3 A<\/th><th id=\"S4.T2.1.2.2.8\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">1 CoT<\/th><th id=\"S4.T2.1.2.2.9\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">2 A<\/th><th id=\"S4.T2.1.2.2.10\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">3 A<\/th><\/tr><\/thead><tbody class=\"ltx_tbody\"><tr id=\"S4.T2.1.3.1\" class=\"ltx_tr\"><th id=\"S4.T2.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">GPT-3.5<\/th><td id=\"S4.T2.1.3.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\"><span id=\"S4.T2.1.3.1.2.1\" class=\"ltx_text ltx_font_bold\">7.44<\/span><\/td><td id=\"S4.T2.1.3.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">12.87<\/td><td id=\"S4.T2.1.3.1.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">13.95<\/td><td id=\"S4.T2.1.3.1.5\" class=\"ltx_td ltx_align_right ltx_border_t\">4.44<\/td><td id=\"S4.T2.1.3.1.6\" class=\"ltx_td ltx_align_right ltx_border_t\">1.00<\/td><td id=\"S4.T2.1.3.1.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.1.7.1\" class=\"ltx_text ltx_font_bold\">0.96<\/span><\/td><td id=\"S4.T2.1.3.1.8\" class=\"ltx_td ltx_align_right ltx_border_t\">94.72<\/td><td id=\"S4.T2.1.3.1.9\" class=\"ltx_td ltx_align_right ltx_border_t\"><span id=\"S4.T2.1.3.1.9.1\" class=\"ltx_text ltx_font_bold\">95.67<\/span><\/td><td id=\"S4.T2.1.3.1.10\" class=\"ltx_td ltx_align_right ltx_border_t\">95.40<\/td><\/tr><tr id=\"S4.T2.1.4.2\" class=\"ltx_tr\"><th id=\"S4.T2.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">LLaMA-2-13b<\/th><td id=\"S4.T2.1.4.2.2\" class=\"ltx_td ltx_align_right\">9.44<\/td><td id=\"S4.T2.1.4.2.3\" class=\"ltx_td ltx_align_right\">8.77<\/td><td id=\"S4.T2.1.4.2.4\" class=\"ltx_td ltx_align_right ltx_border_r\"><span id=\"S4.T2.1.4.2.4.1\" class=\"ltx_text ltx_font_bold\">7.95<\/span><\/td><td id=\"S4.T2.1.4.2.5\" class=\"ltx_td ltx_align_right\">9.24<\/td><td id=\"S4.T2.1.4.2.6\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.4.2.6.1\" class=\"ltx_text ltx_font_bold\">6.58<\/span><\/td><td id=\"S4.T2.1.4.2.7\" class=\"ltx_td ltx_align_right ltx_border_r\">6.76<\/td><td id=\"S4.T2.1.4.2.8\" class=\"ltx_td ltx_align_right\">90.71<\/td><td id=\"S4.T2.1.4.2.9\" class=\"ltx_td ltx_align_right\">92.81<\/td><td id=\"S4.T2.1.4.2.10\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.4.2.10.1\" class=\"ltx_text ltx_font_bold\">92.91<\/span><\/td><\/tr><tr id=\"S4.T2.1.5.3\" class=\"ltx_tr\"><th id=\"S4.T2.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">LLaMA-2-70b<\/th><td id=\"S4.T2.1.5.3.2\" class=\"ltx_td ltx_align_right\">11.69<\/td><td id=\"S4.T2.1.5.3.3\" class=\"ltx_td ltx_align_right\">10.92<\/td><td id=\"S4.T2.1.5.3.4\" class=\"ltx_td ltx_align_right ltx_border_r\"><span id=\"S4.T2.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">6.05<\/span><\/td><td id=\"S4.T2.1.5.3.5\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.5.3.5.1\" class=\"ltx_text ltx_font_bold\">3.00<\/span><\/td><td id=\"S4.T2.1.5.3.6\" class=\"ltx_td ltx_align_right\">5.34<\/td><td id=\"S4.T2.1.5.3.7\" class=\"ltx_td ltx_align_right ltx_border_r\">13.12<\/td><td id=\"S4.T2.1.5.3.8\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.5.3.8.1\" class=\"ltx_text ltx_font_bold\">94.56<\/span><\/td><td id=\"S4.T2.1.5.3.9\" class=\"ltx_td ltx_align_right\">93.09<\/td><td id=\"S4.T2.1.5.3.10\" class=\"ltx_td ltx_align_right\">88.86<\/td><\/tr><tr id=\"S4.T2.1.6.4\" class=\"ltx_tr\"><th id=\"S4.T2.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">LLaMA-2-7b<\/th><td id=\"S4.T2.1.6.4.2\" class=\"ltx_td ltx_align_right\">10.87<\/td><td id=\"S4.T2.1.6.4.3\" class=\"ltx_td ltx_align_right\">3.49<\/td><td id=\"S4.T2.1.6.4.4\" class=\"ltx_td ltx_align_right ltx_border_r\"><span id=\"S4.T2.1.6.4.4.1\" class=\"ltx_text ltx_font_bold\">3.13<\/span><\/td><td id=\"S4.T2.1.6.4.5\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.6.4.5.1\" class=\"ltx_text ltx_font_bold\">17.16<\/span><\/td><td id=\"S4.T2.1.6.4.6\" class=\"ltx_td ltx_align_right\">40.26<\/td><td id=\"S4.T2.1.6.4.7\" class=\"ltx_td ltx_align_right ltx_border_r\">37.32<\/td><td id=\"S4.T2.1.6.4.8\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.6.4.8.1\" class=\"ltx_text ltx_font_bold\">84.60<\/span><\/td><td id=\"S4.T2.1.6.4.9\" class=\"ltx_td ltx_align_right\">70.06<\/td><td id=\"S4.T2.1.6.4.10\" class=\"ltx_td ltx_align_right\">72.27<\/td><\/tr><tr id=\"S4.T2.1.7.5\" class=\"ltx_tr\"><th id=\"S4.T2.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">mistral-7b-v0.2<\/th><td id=\"S4.T2.1.7.5.2\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.7.5.2.1\" class=\"ltx_text ltx_font_bold\">12.31<\/span><\/td><td id=\"S4.T2.1.7.5.3\" class=\"ltx_td ltx_align_right\">21.95<\/td><td id=\"S4.T2.1.7.5.4\" class=\"ltx_td ltx_align_right ltx_border_r\">22.82<\/td><td id=\"S4.T2.1.7.5.5\" class=\"ltx_td ltx_align_right\">3.98<\/td><td id=\"S4.T2.1.7.5.6\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.7.5.6.1\" class=\"ltx_text ltx_font_bold\">0.36<\/span><\/td><td id=\"S4.T2.1.7.5.7\" class=\"ltx_td ltx_align_right ltx_border_r\">0.60<\/td><td id=\"S4.T2.1.7.5.8\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.7.5.8.1\" class=\"ltx_text ltx_font_bold\">93.68<\/span><\/td><td id=\"S4.T2.1.7.5.9\" class=\"ltx_td ltx_align_right\">93.58<\/td><td id=\"S4.T2.1.7.5.10\" class=\"ltx_td ltx_align_right\">93.17<\/td><\/tr><tr id=\"S4.T2.1.8.6\" class=\"ltx_tr\"><th id=\"S4.T2.1.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">mixtral-8x7b-v0.1<\/th><td id=\"S4.T2.1.8.6.2\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.8.6.2.1\" class=\"ltx_text ltx_font_bold\">11.59<\/span><\/td><td id=\"S4.T2.1.8.6.3\" class=\"ltx_td ltx_align_right\">14.05<\/td><td id=\"S4.T2.1.8.6.4\" class=\"ltx_td ltx_align_right ltx_border_r\">12.77<\/td><td id=\"S4.T2.1.8.6.5\" class=\"ltx_td ltx_align_right\">2.22<\/td><td id=\"S4.T2.1.8.6.6\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.8.6.6.1\" class=\"ltx_text ltx_font_bold\">0.32<\/span><\/td><td id=\"S4.T2.1.8.6.7\" class=\"ltx_td ltx_align_right ltx_border_r\">0.44<\/td><td id=\"S4.T2.1.8.6.8\" class=\"ltx_td ltx_align_right\">95.15<\/td><td id=\"S4.T2.1.8.6.9\" class=\"ltx_td ltx_align_right\">95.83<\/td><td id=\"S4.T2.1.8.6.10\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.8.6.10.1\" class=\"ltx_text ltx_font_bold\">96.10<\/span><\/td><\/tr><tr id=\"S4.T2.1.9.7\" class=\"ltx_tr\"><th id=\"S4.T2.1.9.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">vicuna-13b-v1.5<\/th><td id=\"S4.T2.1.9.7.2\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.9.7.2.1\" class=\"ltx_text ltx_font_bold\">26.00<\/span><\/td><td id=\"S4.T2.1.9.7.3\" class=\"ltx_td ltx_align_right\">26.72<\/td><td id=\"S4.T2.1.9.7.4\" class=\"ltx_td ltx_align_right ltx_border_r\">26.15<\/td><td id=\"S4.T2.1.9.7.5\" class=\"ltx_td ltx_align_right\">2.88<\/td><td id=\"S4.T2.1.9.7.6\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.9.7.6.1\" class=\"ltx_text ltx_font_bold\">0.30<\/span><\/td><td id=\"S4.T2.1.9.7.7\" class=\"ltx_td ltx_align_right ltx_border_r\">0.38<\/td><td id=\"S4.T2.1.9.7.8\" class=\"ltx_td ltx_align_right\">90.63<\/td><td id=\"S4.T2.1.9.7.9\" class=\"ltx_td ltx_align_right\">92.29<\/td><td id=\"S4.T2.1.9.7.10\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.9.7.10.1\" class=\"ltx_text ltx_font_bold\">92.39<\/span><\/td><\/tr><tr id=\"S4.T2.1.10.8\" class=\"ltx_tr\"><th id=\"S4.T2.1.10.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">vicuna-33b<\/th><td id=\"S4.T2.1.10.8.2\" class=\"ltx_td ltx_align_right\">28.31<\/td><td id=\"S4.T2.1.10.8.3\" class=\"ltx_td ltx_align_right\">28.67<\/td><td id=\"S4.T2.1.10.8.4\" class=\"ltx_td ltx_align_right ltx_border_r\"><span id=\"S4.T2.1.10.8.4.1\" class=\"ltx_text ltx_font_bold\">23.59<\/span><\/td><td id=\"S4.T2.1.10.8.5\" class=\"ltx_td ltx_align_right\">2.40<\/td><td id=\"S4.T2.1.10.8.6\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.10.8.6.1\" class=\"ltx_text ltx_font_bold\">0.72<\/span><\/td><td id=\"S4.T2.1.10.8.7\" class=\"ltx_td ltx_align_right ltx_border_r\">1.64<\/td><td id=\"S4.T2.1.10.8.8\" class=\"ltx_td ltx_align_right\">90.33<\/td><td id=\"S4.T2.1.10.8.9\" class=\"ltx_td ltx_align_right\">91.44<\/td><td id=\"S4.T2.1.10.8.10\" class=\"ltx_td ltx_align_right\"><span id=\"S4.T2.1.10.8.10.1\" class=\"ltx_text ltx_font_bold\">92.20<\/span><\/td><\/tr><tr id=\"S4.T2.1.11.9\" class=\"ltx_tr\"><th id=\"S4.T2.1.11.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">vicuna-7b-v1.5<\/th><td id=\"S4.T2.1.11.9.2\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S4.T2.1.11.9.2.1\" class=\"ltx_text ltx_font_bold\">13.33<\/span><\/td><td id=\"S4.T2.1.11.9.3\" class=\"ltx_td ltx_align_right ltx_border_bb\">18.21<\/td><td id=\"S4.T2.1.11.9.4\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\">22.31<\/td><td id=\"S4.T2.1.11.9.5\" class=\"ltx_td ltx_align_right ltx_border_bb\">37.84<\/td><td id=\"S4.T2.1.11.9.6\" class=\"ltx_td ltx_align_right ltx_border_bb\">5.18<\/td><td id=\"S4.T2.1.11.9.7\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\"><span id=\"S4.T2.1.11.9.7.1\" class=\"ltx_text ltx_font_bold\">2.40<\/span><\/td><td id=\"S4.T2.1.11.9.8\" class=\"ltx_td ltx_align_right ltx_border_bb\">69.04<\/td><td id=\"S4.T2.1.11.9.9\" class=\"ltx_td ltx_align_right ltx_border_bb\">91.17<\/td><td id=\"S4.T2.1.11.9.10\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S4.T2.1.11.9.10.1\" class=\"ltx_text ltx_font_bold\">92.01<\/span><\/td><\/tr><\/tbody><\/table>",
    "footnotes": [],
    "references": [
      "#Agents vs ASR. To show the increased number of LLM agents helps defense, we evaluate defense performance from 1-agent to 3-agent configurations across various LLMs.We observe as the number of agents increases, the defense result gets better in most situations as shown in Figure               4             and Table               2             .In Figure               4             , we notice LLaMA-2 based defense benefits from multiple agent configurations.In Table               2             , we can see the average accuracy of 3-agent configuration is competitive to 1-agent case in most situations.Because of the efficient and open-source nature, we think LLaMA-2-13b is most suitable for our multi-agent defense system.We think this improvement is due to the multi-agent design makes each LLM agent easier to follow the instructions to analyze a given content.The single agent configuration refers to combining all the sub-tasks from other agents into one agent, which is an agent with CoT ability as shown in Figure               3             .In this setting, the LLM has to finish all the tasks in a single pass.We believe this is difficult for those LLMs with limited steerability.In Figure               4             , we notice a significant performance boost in the multi-agent system compared to CoT in different sizes of the LLaMA-2 model.For LLMs with strong steerability like GPT-3.5, Table               2             shows that the single agent with CoT is sufficient to achieve a low ASR for the defense task, whereas the FPR of GPT-3.5-based defense can be largely reduced with our three-agent configuration.",
      "Side effect on regular prompts. A desirable defense system is expected to have minimal effect on normal user request. Thus, we evaluate the FPR on filtering safe LLM responses.Figure 4 shows that FPR is mostly maintained at a low level.For LLaMA-2-7b, increasing the number of agents also reduces the FPR.According to Table               2             , FPRs achieved by defense LLMs with limited alignment levels are lower in the multi-agent case compared to the single agent case, suggesting our three-agent configuration performs best in terms of accuracy.",
      "The proposed multi-agent defense method relies on the moral alignment of LLMs used in agents.Hence, the defense system of LLM agents with Vicuna and Mistral performs poorly in reducing the ASR as shown in Figure 5.LLaMA-2 has the most high level of moral alignment, which can be observed from Table                  1                .It achieves the lowest ASR compared to other LLMs.From the comparison of different sizes of the LLaMA-2 model, we find that the small LLaMA-2 model gives competitive ASR results on defense.From the larger dataset evaluation in Table                  2                , we notice the LLaMA-2-13b based defense achieves a competitive accuracy."
    ]
  },
  "S5.T4": {
    "caption": "Comparison of FPR of multi-agent defense using LLaMA-2-7b introducing Llama Guard as a agent.",
    "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\"><thead class=\"ltx_thead\"><tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\"><th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Agent Configuration<\/th><th id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">FPR (%)<\/th><th id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">ASR (%)<\/th><\/tr><\/thead><tbody class=\"ltx_tbody\"><tr id=\"S5.T4.1.2.1\" class=\"ltx_tr\"><td id=\"S5.T4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Single Agent (CoT)<\/td><td id=\"S5.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.16<\/td><td id=\"S5.T4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10.87<\/td><\/tr><tr id=\"S5.T4.1.3.2\" class=\"ltx_tr\"><td id=\"S5.T4.1.3.2.1\" class=\"ltx_td ltx_align_center\">3 Agents<\/td><td id=\"S5.T4.1.3.2.2\" class=\"ltx_td ltx_align_center\">37.32<\/td><td id=\"S5.T4.1.3.2.3\" class=\"ltx_td ltx_align_center\">3.13<\/td><\/tr><tr id=\"S5.T4.1.4.3\" class=\"ltx_tr\"><td id=\"S5.T4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">4 Agents w\/ LlamaGuard<\/td><td id=\"S5.T4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">6.80<\/td><td id=\"S5.T4.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">11.08<\/td><\/tr><\/tbody><\/table>",
    "footnotes": [],
    "references": [
      "Custom agent: Llama Guard as an agent in defense.        The FPR of the multi-agent defense configurations based on LLaMA-2-7b is relatively high.To tackle this problem, we introduce Llama Guard         Inan et\u00a0al. (           2023          )        as an additional defense agent to form a 4-agent system.Table               3             shows that LLama Guard performs best when both prompt and response are provided.The prompt inferred by the prompt analyzer can be used as the input of the Llama Guard.So we let the Llama Guard agent generate its response after the prompt analyzer agent.The Llama Guard agent extracts the possible prompts from the prompt analyzer\u2019s response, combines them with the given response to form multiple pairs, and uses these prompt-response pairs to infer with Llama Guard.If none of the prompt-response pairs get an unsafe output from Llama Guard, the Llama Guard agent will respond that the given response is safe.The judge agent will consider the response from the LLama Guard agent and other agents to form its judgment.Table               4             demonstrates that the FPR significantly decreased after introducing Llama Guard as an agent, and the ASR remains at a low level.This encouraging result suggests         AutoDefense        is flexible to integrate different defense methods as additional agents, where the multi-agent defense system benefits from new capabilities of new agents."
    ]
  }
}