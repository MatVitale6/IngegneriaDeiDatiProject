<article class="ltx_document ltx_authors_1line ltx_leqno">
 <h1 class="ltx_title ltx_title_document">
  Optimizing Autonomous Driving for Safety: A Human-Centric Approach with LLM-Enhanced RLHF
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yuan Sun
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">
      WINLAB, Rutgers University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id2.2.id2">
      Piscataway, NJ,
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id3.3.id3">
      USA
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:%20ys820@soe.rutgers.edu%20">
      ys820@soe.rutgers.edu
     </a>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Salami Pargoo, Navid
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">
      WINLAB, Rutgers University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id5.2.id2">
      Piscataway, NJ,
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id6.3.id3">
      USA
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:%20navid.salamipargoo@rutgers.edu%20">
      navid.salamipargoo@rutgers.edu
     </a>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Peter J. Jin
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">
      Rutgers University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id8.2.id2">
      Piscataway, NJ,
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id9.3.id3">
      USA
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:%20peter.j.jin@rutgers.edu%20">
      peter.j.jin@rutgers.edu
     </a>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   and
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Jorge Ortiz
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">
      WINLAB, Rutgers University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id11.2.id2">
      Piscataway, NJ,
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id12.3.id3">
      USA
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:%20jorge.ortiz@rutgers.edu%20">
      jorge.ortiz@rutgers.edu
     </a>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract.
  </h6>
  <p class="ltx_p" id="id13.id1">
   Reinforcement Learning from Human Feedback (RLHF) is popular in large language models (LLMs), whereas traditional Reinforcement Learning (RL) often falls short. Current autonomous driving methods typically utilize either human feedback in machine learning, including RL, or LLMs. Most feedback guides the car agent‚Äôs learning process (e.g., controlling the car). RLHF is usually applied in the fine-tuning step, requiring direct human ‚Äùpreferences,‚Äù which are not commonly used in optimizing autonomous driving models. In this research, we innovatively combine RLHF and LLMs to enhance autonomous driving safety. Training a model with human guidance from scratch is inefficient. Our framework starts with a pre-trained autonomous car agent model and implements multiple human-controlled agents, such as cars and pedestrians, to simulate real-life road environments. The autonomous car model is not directly controlled by humans. We integrate both physical and physiological feedback to fine-tune the model, optimizing this process using LLMs. This multi-agent interactive environment ensures safe, realistic interactions before real-world application. Finally, we will validate our model using data gathered from real-life testbeds located in New Jersey and New York City.
  </p>
 </div>
 <div class="ltx_keywords">
 </div>
 <span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1">
  <sup class="ltx_note_mark">
   ‚Ä†
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     ‚Ä†
    </sup>
    <span class="ltx_note_type">
     copyright:
    </span>
    acmlicensed
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2">
  <sup class="ltx_note_mark">
   ‚Ä†
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     ‚Ä†
    </sup>
    <span class="ltx_note_type">
     journalyear:
    </span>
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3">
  <sup class="ltx_note_mark">
   ‚Ä†
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     ‚Ä†
    </sup>
    <span class="ltx_note_type">
     doi:
    </span>
    XXXXXXX.XXXXXXX
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4">
  <sup class="ltx_note_mark">
   ‚Ä†
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     ‚Ä†
    </sup>
    <span class="ltx_note_type">
     conference:
    </span>
    Make sure to enter the correct
conference title from your rights confirmation emai; June 03‚Äì05,
; Woodstock, NY
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5">
  <sup class="ltx_note_mark">
   ‚Ä†
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     ‚Ä†
    </sup>
    <span class="ltx_note_type">
     isbn:
    </span>
   </span>
  </span>
 </span>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1.
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Reinforcement Learning (RL) and Large Language Models (LLMs) play a crucial role in the development of autonomous driving systems. RL, a branch of machine learning, focuses on enabling agents to make optimal decisions over time by learning from their mistakes and experiences. Numerous studies have demonstrated the application of RL in autonomous driving. For instance,
    <cite class="ltx_cite ltx_citemacro_citep">
     (galias2019simulation,
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     )
    </cite>
    proposed using RL to map sensor observations to control outputs in simulated environments. Similarly,
    <cite class="ltx_cite ltx_citemacro_citep">
     (lillicrap2015continuous,
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     )
    </cite>
    explored deep RL for continuous control tasks, which are applicable to autonomous driving scenarios. Additionally,
    <cite class="ltx_cite ltx_citemacro_citep">
     (wang2023efficient,
     <a class="ltx_ref" href="#bib.bib15" title="">
      15
     </a>
     )
    </cite>
    introduced ASAP-RL, an efficient RL algorithm that utilizes motion skills and expert priors to enhance learning efficiency and driving performance in dense traffic. Moreover,
    <cite class="ltx_cite ltx_citemacro_citep">
     (hoel2018automated,
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     )
    </cite>
    presented a method for making decisions such as lane changing, accelerating, and braking on highways, employing Deep Q Networks (DQN) to train their model and predict optimal actions. Recent research has increasingly incorporated Large Language Models (LLMs) into autonomous driving systems, leveraging their capabilities for decision-making, reasoning, and interaction. For instance,
    <cite class="ltx_cite ltx_citemacro_citep">
     (cui2023drivellm,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib5" title="">
      5
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib10" title="">
      10
     </a>
     )
    </cite>
    integrated LLMs to enhance commonsense reasoning and high-level decision-making. In another study,
    <cite class="ltx_cite ltx_citemacro_citep">
     (duan2024prompting,
     <a class="ltx_ref" href="#bib.bib4" title="">
      4
     </a>
     )
    </cite>
    utilized LLMs to help autonomous driving models mimic human behavior, thereby improving end-to-end driving performance.
    <cite class="ltx_cite ltx_citemacro_citep">
     (wang2022adept,
     <a class="ltx_ref" href="#bib.bib16" title="">
      16
     </a>
     )
    </cite>
    employed GPT to extract crucial information from NHTSA accident reports using a QA approach, enabling the generation of diverse scene codes for simulation and testing. Additionally,
    <cite class="ltx_cite ltx_citemacro_citep">
     (tan2023language,
     <a class="ltx_ref" href="#bib.bib14" title="">
      14
     </a>
     )
    </cite>
    demonstrated the use of LLMs as powerful interpreters that translate user text queries into structured specifications of map lanes and vehicle locations for traffic simulation scenarios.
RLHF is a fundamental component in the training of Large Language Models (LLMs) and is regarded as an essential element of the modern LLM training pipeline
    <cite class="ltx_cite ltx_citemacro_citep">
     (kirk2023understanding,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib18" title="">
      18
     </a>
     )
    </cite>
    . RLHF is particularly well-suited for LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (sun2023reinforcement,
     <a class="ltx_ref" href="#bib.bib13" title="">
      13
     </a>
     )
    </cite>
    , as it involves RL agents learning from human preference feedback. This type of feedback is considered more intuitive for human users, better aligned with human values, and easier to obtain in various applications
    <cite class="ltx_cite ltx_citemacro_citep">
     (kirk2023understanding,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    However, most of the work applies RLHF to optimize LLMs because the scenarios in which humans use LLMs are more suitable for tracking human preferences. This alignment with human values ensures that the models perform more intuitively in real-world applications. In contrast, for autonomous driving scenarios, it is impractical for humans to provide preference feedback on a frame-by-frame basis. Consequently, RLHF is seldom used in autonomous driving contexts.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    In this research, we creatively apply RLHF to autonomous driving by modeling human preferences through various sensor feedback from our environment. We incorporate both physical and physiological feedback into the simulation to optimize the RL training loop for autonomous driving. Additionally, the LLM agent facilitates interaction within our multi-agent system. We posit that training autonomous car agents alongside human-driven cars in the simulation can significantly enhance safety and allow the agents to learn human preferences concurrently. This approach aligns the autonomous car models more closely with real-world scenarios, ultimately making the application of autonomous driving models safer in real-life contexts.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2.
   </span>
   Methodology
  </h2>
  <figure class="ltx_figure" id="S2.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="118" id="S2.F1.g1" src="/html/2406.04481/assets/x1.png" width="368"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1.
    </span>
    Overview of our human-centric multi-agent LLM-enhanced RLHF system framework. During the fine-tuning of an autonomous car model, human agents and proliferated LLM agents mimicking multiple human behaviors are incorporated into the environment to align with real-world human preferences.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    Our system (figure
    <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‚Ä£ 3. hardware setup ‚Ä£ Optimizing Autonomous Driving for Safety: A Human-Centric Approach with LLM-Enhanced RLHF">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    ) is designed as a multi-agent framework, centering on human interaction while incorporating LLM agents and autonomous car agents. The system includes human drivers, human pedestrians, and an LLM agent that mimics their behavior to generate training interactions for the car. Humans control the car using physical controllers such as steering wheels and pedals. Additionally, they wear various wearable sensors, including VR headsets, wristbands to collect and monitor physiological signals in real-time, and smart glasses to track focus. A camera is also set up in the environment to record human reactions. This collected multimodal data is sent to the simulation. Before integration, the LLM assists the car agent in understanding this data and aids the human agent in adapting to the simulation environment. The autonomous vehicle model learns from human feedback within the RL loop, with the LLM helping to interpret human data into ‚Äùpreferences‚Äù to optimize the model in the RL loop.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1.
    </span>
    RLHF
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     In traditional reinforcement learning, the objective of the agent is to develop a policy, a function that dictates its actions. This policy is optimized to maximize rewards provided by a distinct reward function based on the agent‚Äôs performance in a given task
     <cite class="ltx_cite ltx_citemacro_citep">
      (russell2016artificial,
      <a class="ltx_ref" href="#bib.bib11" title="">
       11
      </a>
      )
     </cite>
     . However, defining a reward function that accurately reflects human preferences is challenging. To address this, RLHF aims to train a ‚Äùreward model‚Äù directly from human feedback
     <cite class="ltx_cite ltx_citemacro_citep">
      (ziegler2019fine,
      <a class="ltx_ref" href="#bib.bib19" title="">
       19
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     However, in our scenario, it is typically difficult to obtain ‚Äùpreference‚Äù feedback directly on a frame-by-frame basis. For instance, when training an autonomous car model using RL, the car might simply reward itself with a positive score for avoiding collisions. However, the car might execute a rapid lane change that frightens the user. This type of feedback‚Äîreflecting user comfort and safety preferences‚Äîis crucial but challenging to capture. Additionally, scenarios such as aggressive braking, abrupt acceleration, or failing to yield to pedestrians can all contribute to negative user experiences, which are important ‚Äùpreferences‚Äù in the autonomous driving RL loop.At the same time, human driving behavior provides valuable feedback to the system, as it reflects real-world driving preferences and responses to various driving conditions.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p3">
    <p class="ltx_p" id="S2.SS1.p3.1">
     In our autonomous driving RLHF framework, the objective function
     <cite class="ltx_cite ltx_citemacro_citep">
      (stiennon2020learning,
      <a class="ltx_ref" href="#bib.bib12" title="">
       12
      </a>
      )
     </cite>
     is defined as follows:
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p4">
    <table class="ltx_equation ltx_eqn_table" id="S2.E1">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_left">
         (1)
        </span>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="\text{objective}(\phi)=\mathbb{E}_{(x,y)\sim D_{\pi^{RL}_{\phi}}}\left[r_{\theta}(x,y)-\beta\log\left(\frac{\pi^{RL}_{\phi}(y|x)}{\pi^{SFT}(y|x)}\right)\right]" class="ltx_Math" display="block" id="S2.E1.m1.9">
         <semantics id="S2.E1.m1.9a">
          <mrow id="S2.E1.m1.9.9" xref="S2.E1.m1.9.9.cmml">
           <mrow id="S2.E1.m1.9.9.3" xref="S2.E1.m1.9.9.3.cmml">
            <mtext id="S2.E1.m1.9.9.3.2" xref="S2.E1.m1.9.9.3.2a.cmml">
             objective
            </mtext>
            <mo id="S2.E1.m1.9.9.3.1" lspace="0em" rspace="0em" xref="S2.E1.m1.9.9.3.1.cmml">
             ‚Äã
            </mo>
            <mrow id="S2.E1.m1.9.9.3.3.2" xref="S2.E1.m1.9.9.3.cmml">
             <mo id="S2.E1.m1.9.9.3.3.2.1" stretchy="false" xref="S2.E1.m1.9.9.3.cmml">
              (
             </mo>
             <mi id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml">
              œï
             </mi>
             <mo id="S2.E1.m1.9.9.3.3.2.2" stretchy="false" xref="S2.E1.m1.9.9.3.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="S2.E1.m1.9.9.2" xref="S2.E1.m1.9.9.2.cmml">
            =
           </mo>
           <mrow id="S2.E1.m1.9.9.1" xref="S2.E1.m1.9.9.1.cmml">
            <msub id="S2.E1.m1.9.9.1.3" xref="S2.E1.m1.9.9.1.3.cmml">
             <mi id="S2.E1.m1.9.9.1.3.2" xref="S2.E1.m1.9.9.1.3.2.cmml">
              ùîº
             </mi>
             <mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml">
              <mrow id="S2.E1.m1.2.2.2.4.2" xref="S2.E1.m1.2.2.2.4.1.cmml">
               <mo id="S2.E1.m1.2.2.2.4.2.1" stretchy="false" xref="S2.E1.m1.2.2.2.4.1.cmml">
                (
               </mo>
               <mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">
                x
               </mi>
               <mo id="S2.E1.m1.2.2.2.4.2.2" xref="S2.E1.m1.2.2.2.4.1.cmml">
                ,
               </mo>
               <mi id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml">
                y
               </mi>
               <mo id="S2.E1.m1.2.2.2.4.2.3" stretchy="false" xref="S2.E1.m1.2.2.2.4.1.cmml">
                )
               </mo>
              </mrow>
              <mo id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.3.cmml">
               ‚àº
              </mo>
              <msub id="S2.E1.m1.2.2.2.5" xref="S2.E1.m1.2.2.2.5.cmml">
               <mi id="S2.E1.m1.2.2.2.5.2" xref="S2.E1.m1.2.2.2.5.2.cmml">
                D
               </mi>
               <msubsup id="S2.E1.m1.2.2.2.5.3" xref="S2.E1.m1.2.2.2.5.3.cmml">
                <mi id="S2.E1.m1.2.2.2.5.3.2.2" xref="S2.E1.m1.2.2.2.5.3.2.2.cmml">
                 œÄ
                </mi>
                <mi id="S2.E1.m1.2.2.2.5.3.3" xref="S2.E1.m1.2.2.2.5.3.3.cmml">
                 œï
                </mi>
                <mrow id="S2.E1.m1.2.2.2.5.3.2.3" xref="S2.E1.m1.2.2.2.5.3.2.3.cmml">
                 <mi id="S2.E1.m1.2.2.2.5.3.2.3.2" xref="S2.E1.m1.2.2.2.5.3.2.3.2.cmml">
                  R
                 </mi>
                 <mo id="S2.E1.m1.2.2.2.5.3.2.3.1" lspace="0em" rspace="0em" xref="S2.E1.m1.2.2.2.5.3.2.3.1.cmml">
                  ‚Äã
                 </mo>
                 <mi id="S2.E1.m1.2.2.2.5.3.2.3.3" xref="S2.E1.m1.2.2.2.5.3.2.3.3.cmml">
                  L
                 </mi>
                </mrow>
               </msubsup>
              </msub>
             </mrow>
            </msub>
            <mo id="S2.E1.m1.9.9.1.2" lspace="0em" rspace="0em" xref="S2.E1.m1.9.9.1.2.cmml">
             ‚Äã
            </mo>
            <mrow id="S2.E1.m1.9.9.1.1.1" xref="S2.E1.m1.9.9.1.1.2.cmml">
             <mo id="S2.E1.m1.9.9.1.1.1.2" xref="S2.E1.m1.9.9.1.1.2.1.cmml">
              [
             </mo>
             <mrow id="S2.E1.m1.9.9.1.1.1.1" xref="S2.E1.m1.9.9.1.1.1.1.cmml">
              <mrow id="S2.E1.m1.9.9.1.1.1.1.2" xref="S2.E1.m1.9.9.1.1.1.1.2.cmml">
               <msub id="S2.E1.m1.9.9.1.1.1.1.2.2" xref="S2.E1.m1.9.9.1.1.1.1.2.2.cmml">
                <mi id="S2.E1.m1.9.9.1.1.1.1.2.2.2" xref="S2.E1.m1.9.9.1.1.1.1.2.2.2.cmml">
                 r
                </mi>
                <mi id="S2.E1.m1.9.9.1.1.1.1.2.2.3" xref="S2.E1.m1.9.9.1.1.1.1.2.2.3.cmml">
                 Œ∏
                </mi>
               </msub>
               <mo id="S2.E1.m1.9.9.1.1.1.1.2.1" lspace="0em" rspace="0em" xref="S2.E1.m1.9.9.1.1.1.1.2.1.cmml">
                ‚Äã
               </mo>
               <mrow id="S2.E1.m1.9.9.1.1.1.1.2.3.2" xref="S2.E1.m1.9.9.1.1.1.1.2.3.1.cmml">
                <mo id="S2.E1.m1.9.9.1.1.1.1.2.3.2.1" stretchy="false" xref="S2.E1.m1.9.9.1.1.1.1.2.3.1.cmml">
                 (
                </mo>
                <mi id="S2.E1.m1.6.6" xref="S2.E1.m1.6.6.cmml">
                 x
                </mi>
                <mo id="S2.E1.m1.9.9.1.1.1.1.2.3.2.2" xref="S2.E1.m1.9.9.1.1.1.1.2.3.1.cmml">
                 ,
                </mo>
                <mi id="S2.E1.m1.7.7" xref="S2.E1.m1.7.7.cmml">
                 y
                </mi>
                <mo id="S2.E1.m1.9.9.1.1.1.1.2.3.2.3" stretchy="false" xref="S2.E1.m1.9.9.1.1.1.1.2.3.1.cmml">
                 )
                </mo>
               </mrow>
              </mrow>
              <mo id="S2.E1.m1.9.9.1.1.1.1.1" xref="S2.E1.m1.9.9.1.1.1.1.1.cmml">
               ‚àí
              </mo>
              <mrow id="S2.E1.m1.9.9.1.1.1.1.3" xref="S2.E1.m1.9.9.1.1.1.1.3.cmml">
               <mi id="S2.E1.m1.9.9.1.1.1.1.3.2" xref="S2.E1.m1.9.9.1.1.1.1.3.2.cmml">
                Œ≤
               </mi>
               <mo id="S2.E1.m1.9.9.1.1.1.1.3.1" lspace="0.167em" rspace="0em" xref="S2.E1.m1.9.9.1.1.1.1.3.1.cmml">
                ‚Äã
               </mo>
               <mrow id="S2.E1.m1.9.9.1.1.1.1.3.3.2" xref="S2.E1.m1.9.9.1.1.1.1.3.3.1.cmml">
                <mi id="S2.E1.m1.8.8" xref="S2.E1.m1.8.8.cmml">
                 log
                </mi>
                <mo id="S2.E1.m1.9.9.1.1.1.1.3.3.2a" xref="S2.E1.m1.9.9.1.1.1.1.3.3.1.cmml">
                 ‚Å°
                </mo>
                <mrow id="S2.E1.m1.9.9.1.1.1.1.3.3.2.1" xref="S2.E1.m1.9.9.1.1.1.1.3.3.1.cmml">
                 <mo id="S2.E1.m1.9.9.1.1.1.1.3.3.2.1.1" xref="S2.E1.m1.9.9.1.1.1.1.3.3.1.cmml">
                  (
                 </mo>
                 <mfrac id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">
                  <mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.cmml">
                   <msubsup id="S2.E1.m1.3.3.1.3" xref="S2.E1.m1.3.3.1.3.cmml">
                    <mi id="S2.E1.m1.3.3.1.3.2.2" xref="S2.E1.m1.3.3.1.3.2.2.cmml">
                     œÄ
                    </mi>
                    <mi id="S2.E1.m1.3.3.1.3.3" xref="S2.E1.m1.3.3.1.3.3.cmml">
                     œï
                    </mi>
                    <mrow id="S2.E1.m1.3.3.1.3.2.3" xref="S2.E1.m1.3.3.1.3.2.3.cmml">
                     <mi id="S2.E1.m1.3.3.1.3.2.3.2" xref="S2.E1.m1.3.3.1.3.2.3.2.cmml">
                      R
                     </mi>
                     <mo id="S2.E1.m1.3.3.1.3.2.3.1" lspace="0em" rspace="0em" xref="S2.E1.m1.3.3.1.3.2.3.1.cmml">
                      ‚Äã
                     </mo>
                     <mi id="S2.E1.m1.3.3.1.3.2.3.3" xref="S2.E1.m1.3.3.1.3.2.3.3.cmml">
                      L
                     </mi>
                    </mrow>
                   </msubsup>
                   <mo id="S2.E1.m1.3.3.1.2" lspace="0em" rspace="0em" xref="S2.E1.m1.3.3.1.2.cmml">
                    ‚Äã
                   </mo>
                   <mrow id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml">
                    <mo id="S2.E1.m1.3.3.1.1.1.2" stretchy="false" xref="S2.E1.m1.3.3.1.1.1.1.cmml">
                     (
                    </mo>
                    <mrow id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml">
                     <mi id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">
                      y
                     </mi>
                     <mo fence="false" id="S2.E1.m1.3.3.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml">
                      |
                     </mo>
                     <mi id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.3.cmml">
                      x
                     </mi>
                    </mrow>
                    <mo id="S2.E1.m1.3.3.1.1.1.3" stretchy="false" xref="S2.E1.m1.3.3.1.1.1.1.cmml">
                     )
                    </mo>
                   </mrow>
                  </mrow>
                  <mrow id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml">
                   <msup id="S2.E1.m1.4.4.2.3" xref="S2.E1.m1.4.4.2.3.cmml">
                    <mi id="S2.E1.m1.4.4.2.3.2" xref="S2.E1.m1.4.4.2.3.2.cmml">
                     œÄ
                    </mi>
                    <mrow id="S2.E1.m1.4.4.2.3.3" xref="S2.E1.m1.4.4.2.3.3.cmml">
                     <mi id="S2.E1.m1.4.4.2.3.3.2" xref="S2.E1.m1.4.4.2.3.3.2.cmml">
                      S
                     </mi>
                     <mo id="S2.E1.m1.4.4.2.3.3.1" lspace="0em" rspace="0em" xref="S2.E1.m1.4.4.2.3.3.1.cmml">
                      ‚Äã
                     </mo>
                     <mi id="S2.E1.m1.4.4.2.3.3.3" xref="S2.E1.m1.4.4.2.3.3.3.cmml">
                      F
                     </mi>
                     <mo id="S2.E1.m1.4.4.2.3.3.1a" lspace="0em" rspace="0em" xref="S2.E1.m1.4.4.2.3.3.1.cmml">
                      ‚Äã
                     </mo>
                     <mi id="S2.E1.m1.4.4.2.3.3.4" xref="S2.E1.m1.4.4.2.3.3.4.cmml">
                      T
                     </mi>
                    </mrow>
                   </msup>
                   <mo id="S2.E1.m1.4.4.2.2" lspace="0em" rspace="0em" xref="S2.E1.m1.4.4.2.2.cmml">
                    ‚Äã
                   </mo>
                   <mrow id="S2.E1.m1.4.4.2.1.1" xref="S2.E1.m1.4.4.2.1.1.1.cmml">
                    <mo id="S2.E1.m1.4.4.2.1.1.2" stretchy="false" xref="S2.E1.m1.4.4.2.1.1.1.cmml">
                     (
                    </mo>
                    <mrow id="S2.E1.m1.4.4.2.1.1.1" xref="S2.E1.m1.4.4.2.1.1.1.cmml">
                     <mi id="S2.E1.m1.4.4.2.1.1.1.2" xref="S2.E1.m1.4.4.2.1.1.1.2.cmml">
                      y
                     </mi>
                     <mo fence="false" id="S2.E1.m1.4.4.2.1.1.1.1" xref="S2.E1.m1.4.4.2.1.1.1.1.cmml">
                      |
                     </mo>
                     <mi id="S2.E1.m1.4.4.2.1.1.1.3" xref="S2.E1.m1.4.4.2.1.1.1.3.cmml">
                      x
                     </mi>
                    </mrow>
                    <mo id="S2.E1.m1.4.4.2.1.1.3" stretchy="false" xref="S2.E1.m1.4.4.2.1.1.1.cmml">
                     )
                    </mo>
                   </mrow>
                  </mrow>
                 </mfrac>
                 <mo id="S2.E1.m1.9.9.1.1.1.1.3.3.2.1.2" xref="S2.E1.m1.9.9.1.1.1.1.3.3.1.cmml">
                  )
                 </mo>
                </mrow>
               </mrow>
              </mrow>
             </mrow>
             <mo id="S2.E1.m1.9.9.1.1.1.3" xref="S2.E1.m1.9.9.1.1.2.1.cmml">
              ]
             </mo>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S2.E1.m1.9b">
           <apply id="S2.E1.m1.9.9.cmml" xref="S2.E1.m1.9.9">
            <eq id="S2.E1.m1.9.9.2.cmml" xref="S2.E1.m1.9.9.2">
            </eq>
            <apply id="S2.E1.m1.9.9.3.cmml" xref="S2.E1.m1.9.9.3">
             <times id="S2.E1.m1.9.9.3.1.cmml" xref="S2.E1.m1.9.9.3.1">
             </times>
             <ci id="S2.E1.m1.9.9.3.2a.cmml" xref="S2.E1.m1.9.9.3.2">
              <mtext id="S2.E1.m1.9.9.3.2.cmml" xref="S2.E1.m1.9.9.3.2">
               objective
              </mtext>
             </ci>
             <ci id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5">
              italic-œï
             </ci>
            </apply>
            <apply id="S2.E1.m1.9.9.1.cmml" xref="S2.E1.m1.9.9.1">
             <times id="S2.E1.m1.9.9.1.2.cmml" xref="S2.E1.m1.9.9.1.2">
             </times>
             <apply id="S2.E1.m1.9.9.1.3.cmml" xref="S2.E1.m1.9.9.1.3">
              <csymbol cd="ambiguous" id="S2.E1.m1.9.9.1.3.1.cmml" xref="S2.E1.m1.9.9.1.3">
               subscript
              </csymbol>
              <ci id="S2.E1.m1.9.9.1.3.2.cmml" xref="S2.E1.m1.9.9.1.3.2">
               ùîº
              </ci>
              <apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2">
               <csymbol cd="latexml" id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.3">
                similar-to
               </csymbol>
               <interval closure="open" id="S2.E1.m1.2.2.2.4.1.cmml" xref="S2.E1.m1.2.2.2.4.2">
                <ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">
                 ùë•
                </ci>
                <ci id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2">
                 ùë¶
                </ci>
               </interval>
               <apply id="S2.E1.m1.2.2.2.5.cmml" xref="S2.E1.m1.2.2.2.5">
                <csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.5.1.cmml" xref="S2.E1.m1.2.2.2.5">
                 subscript
                </csymbol>
                <ci id="S2.E1.m1.2.2.2.5.2.cmml" xref="S2.E1.m1.2.2.2.5.2">
                 ùê∑
                </ci>
                <apply id="S2.E1.m1.2.2.2.5.3.cmml" xref="S2.E1.m1.2.2.2.5.3">
                 <csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.5.3.1.cmml" xref="S2.E1.m1.2.2.2.5.3">
                  subscript
                 </csymbol>
                 <apply id="S2.E1.m1.2.2.2.5.3.2.cmml" xref="S2.E1.m1.2.2.2.5.3">
                  <csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.5.3.2.1.cmml" xref="S2.E1.m1.2.2.2.5.3">
                   superscript
                  </csymbol>
                  <ci id="S2.E1.m1.2.2.2.5.3.2.2.cmml" xref="S2.E1.m1.2.2.2.5.3.2.2">
                   ùúã
                  </ci>
                  <apply id="S2.E1.m1.2.2.2.5.3.2.3.cmml" xref="S2.E1.m1.2.2.2.5.3.2.3">
                   <times id="S2.E1.m1.2.2.2.5.3.2.3.1.cmml" xref="S2.E1.m1.2.2.2.5.3.2.3.1">
                   </times>
                   <ci id="S2.E1.m1.2.2.2.5.3.2.3.2.cmml" xref="S2.E1.m1.2.2.2.5.3.2.3.2">
                    ùëÖ
                   </ci>
                   <ci id="S2.E1.m1.2.2.2.5.3.2.3.3.cmml" xref="S2.E1.m1.2.2.2.5.3.2.3.3">
                    ùêø
                   </ci>
                  </apply>
                 </apply>
                 <ci id="S2.E1.m1.2.2.2.5.3.3.cmml" xref="S2.E1.m1.2.2.2.5.3.3">
                  italic-œï
                 </ci>
                </apply>
               </apply>
              </apply>
             </apply>
             <apply id="S2.E1.m1.9.9.1.1.2.cmml" xref="S2.E1.m1.9.9.1.1.1">
              <csymbol cd="latexml" id="S2.E1.m1.9.9.1.1.2.1.cmml" xref="S2.E1.m1.9.9.1.1.1.2">
               delimited-[]
              </csymbol>
              <apply id="S2.E1.m1.9.9.1.1.1.1.cmml" xref="S2.E1.m1.9.9.1.1.1.1">
               <minus id="S2.E1.m1.9.9.1.1.1.1.1.cmml" xref="S2.E1.m1.9.9.1.1.1.1.1">
               </minus>
               <apply id="S2.E1.m1.9.9.1.1.1.1.2.cmml" xref="S2.E1.m1.9.9.1.1.1.1.2">
                <times id="S2.E1.m1.9.9.1.1.1.1.2.1.cmml" xref="S2.E1.m1.9.9.1.1.1.1.2.1">
                </times>
                <apply id="S2.E1.m1.9.9.1.1.1.1.2.2.cmml" xref="S2.E1.m1.9.9.1.1.1.1.2.2">
                 <csymbol cd="ambiguous" id="S2.E1.m1.9.9.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.9.9.1.1.1.1.2.2">
                  subscript
                 </csymbol>
                 <ci id="S2.E1.m1.9.9.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.9.9.1.1.1.1.2.2.2">
                  ùëü
                 </ci>
                 <ci id="S2.E1.m1.9.9.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.9.9.1.1.1.1.2.2.3">
                  ùúÉ
                 </ci>
                </apply>
                <interval closure="open" id="S2.E1.m1.9.9.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.9.9.1.1.1.1.2.3.2">
                 <ci id="S2.E1.m1.6.6.cmml" xref="S2.E1.m1.6.6">
                  ùë•
                 </ci>
                 <ci id="S2.E1.m1.7.7.cmml" xref="S2.E1.m1.7.7">
                  ùë¶
                 </ci>
                </interval>
               </apply>
               <apply id="S2.E1.m1.9.9.1.1.1.1.3.cmml" xref="S2.E1.m1.9.9.1.1.1.1.3">
                <times id="S2.E1.m1.9.9.1.1.1.1.3.1.cmml" xref="S2.E1.m1.9.9.1.1.1.1.3.1">
                </times>
                <ci id="S2.E1.m1.9.9.1.1.1.1.3.2.cmml" xref="S2.E1.m1.9.9.1.1.1.1.3.2">
                 ùõΩ
                </ci>
                <apply id="S2.E1.m1.9.9.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.9.9.1.1.1.1.3.3.2">
                 <log id="S2.E1.m1.8.8.cmml" xref="S2.E1.m1.8.8">
                 </log>
                 <apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">
                  <divide id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4">
                  </divide>
                  <apply id="S2.E1.m1.3.3.1.cmml" xref="S2.E1.m1.3.3.1">
                   <times id="S2.E1.m1.3.3.1.2.cmml" xref="S2.E1.m1.3.3.1.2">
                   </times>
                   <apply id="S2.E1.m1.3.3.1.3.cmml" xref="S2.E1.m1.3.3.1.3">
                    <csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.3.1.cmml" xref="S2.E1.m1.3.3.1.3">
                     subscript
                    </csymbol>
                    <apply id="S2.E1.m1.3.3.1.3.2.cmml" xref="S2.E1.m1.3.3.1.3">
                     <csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.3.2.1.cmml" xref="S2.E1.m1.3.3.1.3">
                      superscript
                     </csymbol>
                     <ci id="S2.E1.m1.3.3.1.3.2.2.cmml" xref="S2.E1.m1.3.3.1.3.2.2">
                      ùúã
                     </ci>
                     <apply id="S2.E1.m1.3.3.1.3.2.3.cmml" xref="S2.E1.m1.3.3.1.3.2.3">
                      <times id="S2.E1.m1.3.3.1.3.2.3.1.cmml" xref="S2.E1.m1.3.3.1.3.2.3.1">
                      </times>
                      <ci id="S2.E1.m1.3.3.1.3.2.3.2.cmml" xref="S2.E1.m1.3.3.1.3.2.3.2">
                       ùëÖ
                      </ci>
                      <ci id="S2.E1.m1.3.3.1.3.2.3.3.cmml" xref="S2.E1.m1.3.3.1.3.2.3.3">
                       ùêø
                      </ci>
                     </apply>
                    </apply>
                    <ci id="S2.E1.m1.3.3.1.3.3.cmml" xref="S2.E1.m1.3.3.1.3.3">
                     italic-œï
                    </ci>
                   </apply>
                   <apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1">
                    <csymbol cd="latexml" id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1">
                     conditional
                    </csymbol>
                    <ci id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">
                     ùë¶
                    </ci>
                    <ci id="S2.E1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3">
                     ùë•
                    </ci>
                   </apply>
                  </apply>
                  <apply id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2">
                   <times id="S2.E1.m1.4.4.2.2.cmml" xref="S2.E1.m1.4.4.2.2">
                   </times>
                   <apply id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.3">
                    <csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.3.1.cmml" xref="S2.E1.m1.4.4.2.3">
                     superscript
                    </csymbol>
                    <ci id="S2.E1.m1.4.4.2.3.2.cmml" xref="S2.E1.m1.4.4.2.3.2">
                     ùúã
                    </ci>
                    <apply id="S2.E1.m1.4.4.2.3.3.cmml" xref="S2.E1.m1.4.4.2.3.3">
                     <times id="S2.E1.m1.4.4.2.3.3.1.cmml" xref="S2.E1.m1.4.4.2.3.3.1">
                     </times>
                     <ci id="S2.E1.m1.4.4.2.3.3.2.cmml" xref="S2.E1.m1.4.4.2.3.3.2">
                      ùëÜ
                     </ci>
                     <ci id="S2.E1.m1.4.4.2.3.3.3.cmml" xref="S2.E1.m1.4.4.2.3.3.3">
                      ùêπ
                     </ci>
                     <ci id="S2.E1.m1.4.4.2.3.3.4.cmml" xref="S2.E1.m1.4.4.2.3.3.4">
                      ùëá
                     </ci>
                    </apply>
                   </apply>
                   <apply id="S2.E1.m1.4.4.2.1.1.1.cmml" xref="S2.E1.m1.4.4.2.1.1">
                    <csymbol cd="latexml" id="S2.E1.m1.4.4.2.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.1.1.1.1">
                     conditional
                    </csymbol>
                    <ci id="S2.E1.m1.4.4.2.1.1.1.2.cmml" xref="S2.E1.m1.4.4.2.1.1.1.2">
                     ùë¶
                    </ci>
                    <ci id="S2.E1.m1.4.4.2.1.1.1.3.cmml" xref="S2.E1.m1.4.4.2.1.1.1.3">
                     ùë•
                    </ci>
                   </apply>
                  </apply>
                 </apply>
                </apply>
               </apply>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S2.E1.m1.9c">
           \text{objective}(\phi)=\mathbb{E}_{(x,y)\sim D_{\pi^{RL}_{\phi}}}\left[r_{\theta}(x,y)-\beta\log\left(\frac{\pi^{RL}_{\phi}(y|x)}{\pi^{SFT}(y|x)}\right)\right]
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="S2.SS1.p5">
    <p class="ltx_p" id="S2.SS1.p5.6">
     where ,in our work,
     <math alttext="x" class="ltx_Math" display="inline" id="S2.SS1.p5.1.m1.1">
      <semantics id="S2.SS1.p5.1.m1.1a">
       <mi id="S2.SS1.p5.1.m1.1.1" xref="S2.SS1.p5.1.m1.1.1.cmml">
        x
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p5.1.m1.1b">
        <ci id="S2.SS1.p5.1.m1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1">
         ùë•
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p5.1.m1.1c">
        x
       </annotation>
      </semantics>
     </math>
     represents the input data from various sensors, including physical sensors, physiological sensors, and simulation data such as LiDAR and camera inputs. The output
     <math alttext="y" class="ltx_Math" display="inline" id="S2.SS1.p5.2.m2.1">
      <semantics id="S2.SS1.p5.2.m2.1a">
       <mi id="S2.SS1.p5.2.m2.1.1" xref="S2.SS1.p5.2.m2.1.1.cmml">
        y
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p5.2.m2.1b">
        <ci id="S2.SS1.p5.2.m2.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1">
         ùë¶
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p5.2.m2.1c">
        y
       </annotation>
      </semantics>
     </math>
     denotes the actions taken by the autonomous vehicle. The reward function
     <math alttext="r_{\theta}(x,y)" class="ltx_Math" display="inline" id="S2.SS1.p5.3.m3.2">
      <semantics id="S2.SS1.p5.3.m3.2a">
       <mrow id="S2.SS1.p5.3.m3.2.3" xref="S2.SS1.p5.3.m3.2.3.cmml">
        <msub id="S2.SS1.p5.3.m3.2.3.2" xref="S2.SS1.p5.3.m3.2.3.2.cmml">
         <mi id="S2.SS1.p5.3.m3.2.3.2.2" xref="S2.SS1.p5.3.m3.2.3.2.2.cmml">
          r
         </mi>
         <mi id="S2.SS1.p5.3.m3.2.3.2.3" xref="S2.SS1.p5.3.m3.2.3.2.3.cmml">
          Œ∏
         </mi>
        </msub>
        <mo id="S2.SS1.p5.3.m3.2.3.1" lspace="0em" rspace="0em" xref="S2.SS1.p5.3.m3.2.3.1.cmml">
         ‚Äã
        </mo>
        <mrow id="S2.SS1.p5.3.m3.2.3.3.2" xref="S2.SS1.p5.3.m3.2.3.3.1.cmml">
         <mo id="S2.SS1.p5.3.m3.2.3.3.2.1" stretchy="false" xref="S2.SS1.p5.3.m3.2.3.3.1.cmml">
          (
         </mo>
         <mi id="S2.SS1.p5.3.m3.1.1" xref="S2.SS1.p5.3.m3.1.1.cmml">
          x
         </mi>
         <mo id="S2.SS1.p5.3.m3.2.3.3.2.2" xref="S2.SS1.p5.3.m3.2.3.3.1.cmml">
          ,
         </mo>
         <mi id="S2.SS1.p5.3.m3.2.2" xref="S2.SS1.p5.3.m3.2.2.cmml">
          y
         </mi>
         <mo id="S2.SS1.p5.3.m3.2.3.3.2.3" stretchy="false" xref="S2.SS1.p5.3.m3.2.3.3.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p5.3.m3.2b">
        <apply id="S2.SS1.p5.3.m3.2.3.cmml" xref="S2.SS1.p5.3.m3.2.3">
         <times id="S2.SS1.p5.3.m3.2.3.1.cmml" xref="S2.SS1.p5.3.m3.2.3.1">
         </times>
         <apply id="S2.SS1.p5.3.m3.2.3.2.cmml" xref="S2.SS1.p5.3.m3.2.3.2">
          <csymbol cd="ambiguous" id="S2.SS1.p5.3.m3.2.3.2.1.cmml" xref="S2.SS1.p5.3.m3.2.3.2">
           subscript
          </csymbol>
          <ci id="S2.SS1.p5.3.m3.2.3.2.2.cmml" xref="S2.SS1.p5.3.m3.2.3.2.2">
           ùëü
          </ci>
          <ci id="S2.SS1.p5.3.m3.2.3.2.3.cmml" xref="S2.SS1.p5.3.m3.2.3.2.3">
           ùúÉ
          </ci>
         </apply>
         <interval closure="open" id="S2.SS1.p5.3.m3.2.3.3.1.cmml" xref="S2.SS1.p5.3.m3.2.3.3.2">
          <ci id="S2.SS1.p5.3.m3.1.1.cmml" xref="S2.SS1.p5.3.m3.1.1">
           ùë•
          </ci>
          <ci id="S2.SS1.p5.3.m3.2.2.cmml" xref="S2.SS1.p5.3.m3.2.2">
           ùë¶
          </ci>
         </interval>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p5.3.m3.2c">
        r_{\theta}(x,y)
       </annotation>
      </semantics>
     </math>
     evaluates the quality of the action
     <math alttext="y" class="ltx_Math" display="inline" id="S2.SS1.p5.4.m4.1">
      <semantics id="S2.SS1.p5.4.m4.1a">
       <mi id="S2.SS1.p5.4.m4.1.1" xref="S2.SS1.p5.4.m4.1.1.cmml">
        y
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p5.4.m4.1b">
        <ci id="S2.SS1.p5.4.m4.1.1.cmml" xref="S2.SS1.p5.4.m4.1.1">
         ùë¶
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p5.4.m4.1c">
        y
       </annotation>
      </semantics>
     </math>
     given the sensor inputs
     <math alttext="x" class="ltx_Math" display="inline" id="S2.SS1.p5.5.m5.1">
      <semantics id="S2.SS1.p5.5.m5.1a">
       <mi id="S2.SS1.p5.5.m5.1.1" xref="S2.SS1.p5.5.m5.1.1.cmml">
        x
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p5.5.m5.1b">
        <ci id="S2.SS1.p5.5.m5.1.1.cmml" xref="S2.SS1.p5.5.m5.1.1">
         ùë•
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p5.5.m5.1c">
        x
       </annotation>
      </semantics>
     </math>
     , guided by human feedback. The term
     <math alttext="\beta\log\left(\frac{\pi^{RL}_{\phi}(y|x)}{\pi^{SFT}(y|x)}\right)" class="ltx_Math" display="inline" id="S2.SS1.p5.6.m6.3">
      <semantics id="S2.SS1.p5.6.m6.3a">
       <mrow id="S2.SS1.p5.6.m6.3.4" xref="S2.SS1.p5.6.m6.3.4.cmml">
        <mi id="S2.SS1.p5.6.m6.3.4.2" xref="S2.SS1.p5.6.m6.3.4.2.cmml">
         Œ≤
        </mi>
        <mo id="S2.SS1.p5.6.m6.3.4.1" lspace="0.167em" rspace="0em" xref="S2.SS1.p5.6.m6.3.4.1.cmml">
         ‚Äã
        </mo>
        <mrow id="S2.SS1.p5.6.m6.3.4.3.2" xref="S2.SS1.p5.6.m6.3.4.3.1.cmml">
         <mi id="S2.SS1.p5.6.m6.3.3" xref="S2.SS1.p5.6.m6.3.3.cmml">
          log
         </mi>
         <mo id="S2.SS1.p5.6.m6.3.4.3.2a" xref="S2.SS1.p5.6.m6.3.4.3.1.cmml">
          ‚Å°
         </mo>
         <mrow id="S2.SS1.p5.6.m6.3.4.3.2.1" xref="S2.SS1.p5.6.m6.3.4.3.1.cmml">
          <mo id="S2.SS1.p5.6.m6.3.4.3.2.1.1" xref="S2.SS1.p5.6.m6.3.4.3.1.cmml">
           (
          </mo>
          <mfrac id="S2.SS1.p5.6.m6.2.2" xref="S2.SS1.p5.6.m6.2.2.cmml">
           <mrow id="S2.SS1.p5.6.m6.1.1.1" xref="S2.SS1.p5.6.m6.1.1.1.cmml">
            <msubsup id="S2.SS1.p5.6.m6.1.1.1.3" xref="S2.SS1.p5.6.m6.1.1.1.3.cmml">
             <mi id="S2.SS1.p5.6.m6.1.1.1.3.2.2" xref="S2.SS1.p5.6.m6.1.1.1.3.2.2.cmml">
              œÄ
             </mi>
             <mi id="S2.SS1.p5.6.m6.1.1.1.3.3" xref="S2.SS1.p5.6.m6.1.1.1.3.3.cmml">
              œï
             </mi>
             <mrow id="S2.SS1.p5.6.m6.1.1.1.3.2.3" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3.cmml">
              <mi id="S2.SS1.p5.6.m6.1.1.1.3.2.3.2" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3.2.cmml">
               R
              </mi>
              <mo id="S2.SS1.p5.6.m6.1.1.1.3.2.3.1" lspace="0em" rspace="0em" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3.1.cmml">
               ‚Äã
              </mo>
              <mi id="S2.SS1.p5.6.m6.1.1.1.3.2.3.3" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3.3.cmml">
               L
              </mi>
             </mrow>
            </msubsup>
            <mo id="S2.SS1.p5.6.m6.1.1.1.2" lspace="0em" rspace="0em" xref="S2.SS1.p5.6.m6.1.1.1.2.cmml">
             ‚Äã
            </mo>
            <mrow id="S2.SS1.p5.6.m6.1.1.1.1.1" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.cmml">
             <mo id="S2.SS1.p5.6.m6.1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.cmml">
              (
             </mo>
             <mrow id="S2.SS1.p5.6.m6.1.1.1.1.1.1" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.cmml">
              <mi id="S2.SS1.p5.6.m6.1.1.1.1.1.1.2" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.2.cmml">
               y
              </mi>
              <mo fence="false" id="S2.SS1.p5.6.m6.1.1.1.1.1.1.1" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.1.cmml">
               |
              </mo>
              <mi id="S2.SS1.p5.6.m6.1.1.1.1.1.1.3" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.3.cmml">
               x
              </mi>
             </mrow>
             <mo id="S2.SS1.p5.6.m6.1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mrow id="S2.SS1.p5.6.m6.2.2.2" xref="S2.SS1.p5.6.m6.2.2.2.cmml">
            <msup id="S2.SS1.p5.6.m6.2.2.2.3" xref="S2.SS1.p5.6.m6.2.2.2.3.cmml">
             <mi id="S2.SS1.p5.6.m6.2.2.2.3.2" xref="S2.SS1.p5.6.m6.2.2.2.3.2.cmml">
              œÄ
             </mi>
             <mrow id="S2.SS1.p5.6.m6.2.2.2.3.3" xref="S2.SS1.p5.6.m6.2.2.2.3.3.cmml">
              <mi id="S2.SS1.p5.6.m6.2.2.2.3.3.2" xref="S2.SS1.p5.6.m6.2.2.2.3.3.2.cmml">
               S
              </mi>
              <mo id="S2.SS1.p5.6.m6.2.2.2.3.3.1" lspace="0em" rspace="0em" xref="S2.SS1.p5.6.m6.2.2.2.3.3.1.cmml">
               ‚Äã
              </mo>
              <mi id="S2.SS1.p5.6.m6.2.2.2.3.3.3" xref="S2.SS1.p5.6.m6.2.2.2.3.3.3.cmml">
               F
              </mi>
              <mo id="S2.SS1.p5.6.m6.2.2.2.3.3.1a" lspace="0em" rspace="0em" xref="S2.SS1.p5.6.m6.2.2.2.3.3.1.cmml">
               ‚Äã
              </mo>
              <mi id="S2.SS1.p5.6.m6.2.2.2.3.3.4" xref="S2.SS1.p5.6.m6.2.2.2.3.3.4.cmml">
               T
              </mi>
             </mrow>
            </msup>
            <mo id="S2.SS1.p5.6.m6.2.2.2.2" lspace="0em" rspace="0em" xref="S2.SS1.p5.6.m6.2.2.2.2.cmml">
             ‚Äã
            </mo>
            <mrow id="S2.SS1.p5.6.m6.2.2.2.1.1" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.cmml">
             <mo id="S2.SS1.p5.6.m6.2.2.2.1.1.2" stretchy="false" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.cmml">
              (
             </mo>
             <mrow id="S2.SS1.p5.6.m6.2.2.2.1.1.1" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.cmml">
              <mi id="S2.SS1.p5.6.m6.2.2.2.1.1.1.2" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.2.cmml">
               y
              </mi>
              <mo fence="false" id="S2.SS1.p5.6.m6.2.2.2.1.1.1.1" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.1.cmml">
               |
              </mo>
              <mi id="S2.SS1.p5.6.m6.2.2.2.1.1.1.3" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.3.cmml">
               x
              </mi>
             </mrow>
             <mo id="S2.SS1.p5.6.m6.2.2.2.1.1.3" stretchy="false" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
          </mfrac>
          <mo id="S2.SS1.p5.6.m6.3.4.3.2.1.2" xref="S2.SS1.p5.6.m6.3.4.3.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p5.6.m6.3b">
        <apply id="S2.SS1.p5.6.m6.3.4.cmml" xref="S2.SS1.p5.6.m6.3.4">
         <times id="S2.SS1.p5.6.m6.3.4.1.cmml" xref="S2.SS1.p5.6.m6.3.4.1">
         </times>
         <ci id="S2.SS1.p5.6.m6.3.4.2.cmml" xref="S2.SS1.p5.6.m6.3.4.2">
          ùõΩ
         </ci>
         <apply id="S2.SS1.p5.6.m6.3.4.3.1.cmml" xref="S2.SS1.p5.6.m6.3.4.3.2">
          <log id="S2.SS1.p5.6.m6.3.3.cmml" xref="S2.SS1.p5.6.m6.3.3">
          </log>
          <apply id="S2.SS1.p5.6.m6.2.2.cmml" xref="S2.SS1.p5.6.m6.2.2">
           <divide id="S2.SS1.p5.6.m6.2.2.3.cmml" xref="S2.SS1.p5.6.m6.2.2">
           </divide>
           <apply id="S2.SS1.p5.6.m6.1.1.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1">
            <times id="S2.SS1.p5.6.m6.1.1.1.2.cmml" xref="S2.SS1.p5.6.m6.1.1.1.2">
            </times>
            <apply id="S2.SS1.p5.6.m6.1.1.1.3.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3">
             <csymbol cd="ambiguous" id="S2.SS1.p5.6.m6.1.1.1.3.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3">
              subscript
             </csymbol>
             <apply id="S2.SS1.p5.6.m6.1.1.1.3.2.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3">
              <csymbol cd="ambiguous" id="S2.SS1.p5.6.m6.1.1.1.3.2.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3">
               superscript
              </csymbol>
              <ci id="S2.SS1.p5.6.m6.1.1.1.3.2.2.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3.2.2">
               ùúã
              </ci>
              <apply id="S2.SS1.p5.6.m6.1.1.1.3.2.3.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3">
               <times id="S2.SS1.p5.6.m6.1.1.1.3.2.3.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3.1">
               </times>
               <ci id="S2.SS1.p5.6.m6.1.1.1.3.2.3.2.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3.2">
                ùëÖ
               </ci>
               <ci id="S2.SS1.p5.6.m6.1.1.1.3.2.3.3.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3.2.3.3">
                ùêø
               </ci>
              </apply>
             </apply>
             <ci id="S2.SS1.p5.6.m6.1.1.1.3.3.cmml" xref="S2.SS1.p5.6.m6.1.1.1.3.3">
              italic-œï
             </ci>
            </apply>
            <apply id="S2.SS1.p5.6.m6.1.1.1.1.1.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1">
             <csymbol cd="latexml" id="S2.SS1.p5.6.m6.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.1">
              conditional
             </csymbol>
             <ci id="S2.SS1.p5.6.m6.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.2">
              ùë¶
             </ci>
             <ci id="S2.SS1.p5.6.m6.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1.1.3">
              ùë•
             </ci>
            </apply>
           </apply>
           <apply id="S2.SS1.p5.6.m6.2.2.2.cmml" xref="S2.SS1.p5.6.m6.2.2.2">
            <times id="S2.SS1.p5.6.m6.2.2.2.2.cmml" xref="S2.SS1.p5.6.m6.2.2.2.2">
            </times>
            <apply id="S2.SS1.p5.6.m6.2.2.2.3.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3">
             <csymbol cd="ambiguous" id="S2.SS1.p5.6.m6.2.2.2.3.1.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3">
              superscript
             </csymbol>
             <ci id="S2.SS1.p5.6.m6.2.2.2.3.2.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3.2">
              ùúã
             </ci>
             <apply id="S2.SS1.p5.6.m6.2.2.2.3.3.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3.3">
              <times id="S2.SS1.p5.6.m6.2.2.2.3.3.1.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3.3.1">
              </times>
              <ci id="S2.SS1.p5.6.m6.2.2.2.3.3.2.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3.3.2">
               ùëÜ
              </ci>
              <ci id="S2.SS1.p5.6.m6.2.2.2.3.3.3.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3.3.3">
               ùêπ
              </ci>
              <ci id="S2.SS1.p5.6.m6.2.2.2.3.3.4.cmml" xref="S2.SS1.p5.6.m6.2.2.2.3.3.4">
               ùëá
              </ci>
             </apply>
            </apply>
            <apply id="S2.SS1.p5.6.m6.2.2.2.1.1.1.cmml" xref="S2.SS1.p5.6.m6.2.2.2.1.1">
             <csymbol cd="latexml" id="S2.SS1.p5.6.m6.2.2.2.1.1.1.1.cmml" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.1">
              conditional
             </csymbol>
             <ci id="S2.SS1.p5.6.m6.2.2.2.1.1.1.2.cmml" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.2">
              ùë¶
             </ci>
             <ci id="S2.SS1.p5.6.m6.2.2.2.1.1.1.3.cmml" xref="S2.SS1.p5.6.m6.2.2.2.1.1.1.3">
              ùë•
             </ci>
            </apply>
           </apply>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p5.6.m6.3c">
        \beta\log\left(\frac{\pi^{RL}_{\phi}(y|x)}{\pi^{SFT}(y|x)}\right)
       </annotation>
      </semantics>
     </math>
     introduces a KL divergence penalty to ensure the new policy remains close to the initial supervised model, balancing learning from new data while retaining useful information from the initial model.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2.
    </span>
    LLM Integration in Autonomous Driving
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     The primary functions of the LLM in our work include acting as an agent in the simulation, facilitating interaction between humans and the simulation system, and optimizing the RL training loop.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.1.
     </span>
     LLM Agent in the Simulation
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS1.p1">
     <p class="ltx_p" id="S2.SS2.SSS1.p1.1">
      In this section, we emphasize our multi-agent system with two key use cases. First, the LLM agent can mimic human behavior to interact with the car agent when a human is not available. Second, when a human is in the loop, the LLM agent can act as another agent, such as a car or pedestrian, to increase the system‚Äôs complexity. For instance, human feedback differs when there is one car versus multiple cars on the road. The feedback in such a complex scenario is more representative of real-life situations.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.2.
     </span>
     Enhanced Human-Simulation Interaction Based on LLM
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS2.p1">
     <p class="ltx_p" id="S2.SS2.SSS2.p1.1">
      When the simulation interacts with the human agent, the LLM can enhance the interaction. Firstly, when sending data collected from humans to the system, the LLM can help interpret the data. For example, if a driver is skilled, the LLM might adjust the simulation weather to foggy conditions. Conversely, if the driver is less skilled, the LLM can help the user adapt to the environment before the car agent begins its training.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.3.
     </span>
     LLM-Enhanced RLHF
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS3.p1">
     <p class="ltx_p" id="S2.SS2.SSS3.p1.1">
      In the RLHF loop, ‚Äùpreferences‚Äù are not as straightforward as yes or no answers. The LLM can translate physical and physiological data into preference formats, which are then incorporated into the objective function. For example, if a driver‚Äôs heart rate increases significantly during a particular maneuver, the LLM can interpret this physiological response as a negative preference for that action. Similarly, if sensor data indicates smooth and confident handling of the vehicle, this can be translated into a positive preference. By integrating these nuanced preferences into the RL training loop, the autonomous driving model can be better aligned with human comfort and safety standards.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3.
   </span>
   hardware setup
  </h2>
  <figure class="ltx_figure" id="S3.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S3.F2.g1" src="/html/2406.04481/assets/fig/hardware2.jpg" width="598"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2.
    </span>
    Simulation room with VR headset, steering controls, and monitors for real-time multimodal data collection and autonomous driving optimization.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    The sensors utilized in our multi-agent LLM-enhanced RLHF system are categorized into two primary modalities: vehicle and physiological. The vehicle sensors, primarily sourced from the CARLA simulator and Logitech hardware, include acceleration, rotation (gyroscope), speed, brake, steering, throttle, and reverse, all sampled at approximately 60 Hz. These sensors capture the dynamic state and control inputs of the autonomous vehicle. The physiological sensors, provided by Empatica, measure various physiological signals such as blood volume pulse (64 Hz), heart rate (1 Hz), interbeat interval (varying), electrodermal activity (4 Hz), wrist acceleration (32 Hz), and body temperature (4 Hz). Additionally, the gaze modality employs an Adhawk sensor to track coordinates on the screen at a sampling rate of 125 Hz, capturing the human agent‚Äôs visual focus and attention. These sensors monitor the human agent‚Äôs physical and emotional responses during the simulation. Except for the monitor, we also have a VR headset to create an immersive environment. Additionally, a Raspberry Pi camera in the simulation room observes the human reaction to the simulation. This multi-modal data integration is crucial for fine-tuning the autonomous driving model, providing comprehensive feedback to align the model‚Äôs performance with human preferences and ensuring realistic and safe interactions in the simulation environment.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4.
   </span>
   Initial Implementation
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    Our initial implementation demonstrates the integration of the LLM with the car simulation system using the GPT-4 interface. The LLM agent can imitate human driving behavior, especially when interacting with a car agent in front. It also assists the car agent in managing situations such as avoiding collisions. Additionally, the LLM agent helps human users by instructing them on how to effectively navigate and use the simulation system.
   </p>
  </div>
  <figure class="ltx_figure" id="S4.F3">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="S4.F3.g1" src="/html/2406.04481/assets/x2.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 3.
    </span>
    Example of GPT-4o imitating a human agent in the CARLA simulation. The LLM agent is attempting to overtake the car in front in a human-like manner.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S4.F4">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="218" id="S4.F4.g1" src="/html/2406.04481/assets/x3.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 4.
    </span>
    Example of the LLM agent guiding the autonomous car agent to reverse away from a collision with a building.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S4.F5">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="240" id="S4.F5.g1" src="/html/2406.04481/assets/x4.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 5.
    </span>
    Example of the LLM agent assisting the human agent in using the simulation.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S4.p2">
   <p class="ltx_p" id="S4.p2.1">
    Furthermore, we plan to implement our experiments in our real-life city test bed, located in Harlem
    <cite class="ltx_cite ltx_citemacro_citep">
     (cosmos-lab,
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     )
    </cite>
    , NYC, and New Brunswick
    <cite class="ltx_cite ltx_citemacro_citep">
     (cait-datacity,
     <a class="ltx_ref" href="#bib.bib3" title="">
      3
     </a>
     )
    </cite>
    , NJ. The real-life data collected from these locations will be used to test the robustness of our algorithm. Additionally, we can import real-life data into the simulation as a cross-validation method. The figure
    <a class="ltx_ref" href="#S4.F6" title="Figure 6 ‚Ä£ 4. Initial Implementation ‚Ä£ Optimizing Autonomous Driving for Safety: A Human-Centric Approach with LLM-Enhanced RLHF">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    below shows an example of importing real-life road data from New Brunswick into the CARLA system.
   </p>
  </div>
  <figure class="ltx_figure" id="S4.F6">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="188" id="S4.F6.g1" src="/html/2406.04481/assets/x5.png" width="230"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 6.
    </span>
    Example of importing real-life road data from New Brunswick testbed into the CARLA simulation.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5.
   </span>
   Conclusion and Future Work
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In this work, we introduce a novel framework that integrates RLHF and LLMs to optimize autonomous driving models. We define human preferences within the RLHF framework and build a simulation-to-reality system based on this concept. Our method simulates a multi-agent environment for training the car agent, allowing it to learn human behaviors through multimodal sensory data. The LLM agent can proliferate multiple human agents by mimicking human behavior and facilitating interactions between the car agent and other agents on the road within the simulation. When optimizing the model, the LLM agent also interprets human data to enhance the model via RLHF. Our system incorporates both physical and simulation sensors. The initial implementation demonstrates various scenarios where LLMs are applied to the framework. This preliminary work establishes the foundational infrastructure for our experiments and discusses the theoretical feasibility of the framework.
   </p>
  </div>
  <div class="ltx_para" id="S5.p2">
   <p class="ltx_p" id="S5.p2.1">
    However, there is still much work to be done in the next stage of our plan. Firstly, the GPT-4 interface has rate limits; we may need to explore different interfaces for this study. The machine learning model for autonomous driving should be evaluated across different types of multimodal models to prove the robustness of our method. We will apply more real-life data to our research to improve the robustness of our method. We will recruit subjects with diverse backgrounds and varying driving skills for human evaluation. Individuals with good driving skills and those with less experience present different challenges in our study. We plan to provide a comprehensive evaluation of how different levels of background influence the RLHF autonomous driving framework.
   </p>
  </div>
  <div class="ltx_para" id="S5.p3">
   <p class="ltx_p" id="S5.p3.1">
    Finally, we hope that through our study, we can eventually propose a safe driving model that can help autonomous vehicles navigate real-life roads and contribute to the overall road safety of society.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6.
   </span>
   Acknowledgments
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    This work was supported by the National Science Foundation (NSF) as part of the Center for Smart Streetscapes, under NSF Cooperative Agreement EEC-2133516. DataCity Smart Mobility Testing Ground is jointly funded by Middlesex County Resolution 21-821-R, New Jersey Department of Transportation and Federal Highway Administration Research Project 21-60168.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (1)
    </span>
    <span class="ltx_bibblock">
     ‚ÄúCOSMOS Lab‚Äù Accessed: 2024-05-26
    </span>
    <span class="ltx_bibblock">
     URL:
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cosmos-lab.org/" target="_blank" title="">
      https://cosmos-lab.org/
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (2)
    </span>
    <span class="ltx_bibblock">
     Yaodong Cui et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúDriveLLM: Charting the path toward full autonomous driving with large language models‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      IEEE Transactions on Intelligent Vehicles
     </em>
    </span>
    <span class="ltx_bibblock">
     IEEE, 2023
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (3)
    </span>
    <span class="ltx_bibblock">
     ‚ÄúDataCity Smart Mobility Testing Ground‚Äù Accessed: 2024-05-26
    </span>
    <span class="ltx_bibblock">
     URL:
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cait.rutgers.edu/datacity/" target="_blank" title="">
      https://cait.rutgers.edu/datacity/
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (4)
    </span>
    <span class="ltx_bibblock">
     Yiqun Duan, Qiang Zhang and Renjing Xu
    </span>
    <span class="ltx_bibblock">
     ‚ÄúPrompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving Imitation Learning with LLMs‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2404.04869
     </em>
     , 2024
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (5)
    </span>
    <span class="ltx_bibblock">
     Daocheng Fu et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúLimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      arXiv preprint arXiv:2402.01246
     </em>
     , 2024
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (6)
    </span>
    <span class="ltx_bibblock">
     Christopher Galias et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúSimulation-based reinforcement learning for autonomous driving‚Äù, 2019
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (7)
    </span>
    <span class="ltx_bibblock">
     Carl-Johan Hoel, Krister Wolff and Leo Laine
    </span>
    <span class="ltx_bibblock">
     ‚ÄúAutomated speed and lane change decision making using deep reinforcement learning‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      2018 21st International Conference on Intelligent Transportation Systems (ITSC)
     </em>
     , 2018, pp. 2148‚Äì2155
    </span>
    <span class="ltx_bibblock">
     IEEE
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (8)
    </span>
    <span class="ltx_bibblock">
     Robert Kirk et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúUnderstanding the effects of rlhf on llm generalisation and diversity‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      arXiv preprint arXiv:2310.06452
     </em>
     , 2023
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (9)
    </span>
    <span class="ltx_bibblock">
     Timothy P Lillicrap et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúContinuous control with deep reinforcement learning‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:1509.02971
     </em>
     , 2015
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (10)
    </span>
    <span class="ltx_bibblock">
     Jimuyang Zhang Zanming Huang Arijit Ray and Eshed Ohn-Bar
    </span>
    <span class="ltx_bibblock">
     ‚ÄúFeedback-Guided Autonomous Driving‚Äù
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (11)
    </span>
    <span class="ltx_bibblock">
     Stuart J Russell and Peter Norvig
    </span>
    <span class="ltx_bibblock">
     ‚ÄúArtificial intelligence: a modern approach‚Äù
    </span>
    <span class="ltx_bibblock">
     Pearson, 2016
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (12)
    </span>
    <span class="ltx_bibblock">
     Nisan Stiennon et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúLearning to summarize with human feedback‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      Advances in Neural Information Processing Systems
     </em>
     <span class="ltx_text ltx_font_bold" id="bib.bib12.2.2">
      33
     </span>
     , 2020, pp. 3008‚Äì3021
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (13)
    </span>
    <span class="ltx_bibblock">
     Hao Sun
    </span>
    <span class="ltx_bibblock">
     ‚ÄúReinforcement learning in the era of llms: What is essential? what is needed? an rl perspective on rlhf, prompting, and beyond‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      arXiv preprint arXiv:2310.06147
     </em>
     , 2023
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (14)
    </span>
    <span class="ltx_bibblock">
     Shuhan Tan et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúLanguage conditioned traffic generation‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      arXiv preprint arXiv:2307.07947
     </em>
     , 2023
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (15)
    </span>
    <span class="ltx_bibblock">
     Letian Wang et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúEfficient reinforcement learning for autonomous driving with parameterized skills and priors‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      arXiv preprint arXiv:2305.04412
     </em>
     , 2023
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (16)
    </span>
    <span class="ltx_bibblock">
     Sen Wang et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúADEPT: A testing platform for simulated autonomous driving‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering
     </em>
     , 2022, pp. 1‚Äì4
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (17)
    </span>
    <span class="ltx_bibblock">
     Chen Zheng et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúBalancing Enhancement, Harmlessness, and General Capabilities: Enhancing Conversational LLMs with Direct RLHF‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:2403.02513
     </em>
     , 2024
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (18)
    </span>
    <span class="ltx_bibblock">
     Banghua Zhu, Michael Jordan and Jiantao Jiao
    </span>
    <span class="ltx_bibblock">
     ‚ÄúPrincipled reinforcement learning with human feedback from pairwise or k-wise comparisons‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      International Conference on Machine Learning
     </em>
     , 2023, pp. 43037‚Äì43067
    </span>
    <span class="ltx_bibblock">
     PMLR
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (19)
    </span>
    <span class="ltx_bibblock">
     Daniel M Ziegler et al.
    </span>
    <span class="ltx_bibblock">
     ‚ÄúFine-tuning language models from human preferences‚Äù
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      arXiv preprint arXiv:1909.08593
     </em>
     , 2019
    </span>
   </li>
  </ul>
 </section>
</article>
