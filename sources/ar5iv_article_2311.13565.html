<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Inderjeet Nair*
    <sup class="ltx_sup" id="id10.7.id1">
     1
    </sup>
    , Shwetha Somasundaram*
    <sup class="ltx_sup" id="id11.8.id2">
     2
    </sup>
    , Apoorv Saxena
    <sup class="ltx_sup" id="id12.9.id3">
     2
    </sup>
    , Koustava Goswami
    <sup class="ltx_sup" id="id13.10.id4">
     2
    </sup>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id14.11.id5">
     1
    </sup>
    University of Michigan, Ann Arbor, MI
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id15.12.id6">
     2
    </sup>
    Adobe Research, India
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id16.13.id7">
     inair@umich.edu
     <br class="ltx_break"/>
     {shsomasu,apoorvs,koustavag}@adobe.com
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id9.3">
   We address the task of evidence retrieval for long document question answering, which involves locating relevant paragraphs within a document to answer a question.
We aim to assess the applicability of large language models (LLMs) in the task of zero-shot long document evidence retrieval, owing to their unprecedented performance across various NLP tasks.
However, currently the LLMs can consume limited context lengths as input, thus providing document chunks as inputs might overlook the global context while missing out on capturing the inter-segment dependencies.
Moreover, directly feeding the large input sets can incur significant computational costs, particularly when processing the entire document (and potentially incurring monetary expenses with enterprise APIs like OpenAIâ€™s GPT variants).
To address these challenges, we propose a suite of techniques that exploit the discourse structure commonly found in documents. By utilizing this structure, we create a condensed representation of the document, enabling a more comprehensive understanding and analysis of relationships between different parts. We retain
   <math alttext="99.6\%" class="ltx_Math" display="inline" id="id7.1.m1.1">
    <semantics id="id7.1.m1.1a">
     <mrow id="id7.1.m1.1.1" xref="id7.1.m1.1.1.cmml">
      <mn id="id7.1.m1.1.1.2" xref="id7.1.m1.1.1.2.cmml">
       99.6
      </mn>
      <mo id="id7.1.m1.1.1.1" xref="id7.1.m1.1.1.1.cmml">
       %
      </mo>
     </mrow>
     <annotation-xml encoding="MathML-Content" id="id7.1.m1.1b">
      <apply id="id7.1.m1.1.1.cmml" xref="id7.1.m1.1.1">
       <csymbol cd="latexml" id="id7.1.m1.1.1.1.cmml" xref="id7.1.m1.1.1.1">
        percent
       </csymbol>
       <cn id="id7.1.m1.1.1.2.cmml" type="float" xref="id7.1.m1.1.1.2">
        99.6
       </cn>
      </apply>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="id7.1.m1.1c">
      99.6\%
     </annotation>
    </semantics>
   </math>
   of the best zero-shot approachâ€™s performance, while processing only
   <math alttext="26\%" class="ltx_Math" display="inline" id="id8.2.m2.1">
    <semantics id="id8.2.m2.1a">
     <mrow id="id8.2.m2.1.1" xref="id8.2.m2.1.1.cmml">
      <mn id="id8.2.m2.1.1.2" xref="id8.2.m2.1.1.2.cmml">
       26
      </mn>
      <mo id="id8.2.m2.1.1.1" xref="id8.2.m2.1.1.1.cmml">
       %
      </mo>
     </mrow>
     <annotation-xml encoding="MathML-Content" id="id8.2.m2.1b">
      <apply id="id8.2.m2.1.1.cmml" xref="id8.2.m2.1.1">
       <csymbol cd="latexml" id="id8.2.m2.1.1.1.cmml" xref="id8.2.m2.1.1.1">
        percent
       </csymbol>
       <cn id="id8.2.m2.1.1.2.cmml" type="integer" xref="id8.2.m2.1.1.2">
        26
       </cn>
      </apply>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="id8.2.m2.1c">
      26\%
     </annotation>
    </semantics>
   </math>
   of the total tokens used by the best approach in the information seeking evidence retrieval setup. We also show how our approach can be combined with
   <span class="ltx_text ltx_font_italic" id="id9.3.1">
    self-ask
   </span>
   reasoning agent to achieve best zero-shot performance in complex multi-hop question answering, just
   <math alttext="\approx 4\%" class="ltx_Math" display="inline" id="id9.3.m3.1">
    <semantics id="id9.3.m3.1a">
     <mrow id="id9.3.m3.1.1" xref="id9.3.m3.1.1.cmml">
      <mi id="id9.3.m3.1.1.2" xref="id9.3.m3.1.1.2.cmml">
      </mi>
      <mo id="id9.3.m3.1.1.1" xref="id9.3.m3.1.1.1.cmml">
       â‰ˆ
      </mo>
      <mrow id="id9.3.m3.1.1.3" xref="id9.3.m3.1.1.3.cmml">
       <mn id="id9.3.m3.1.1.3.2" xref="id9.3.m3.1.1.3.2.cmml">
        4
       </mn>
       <mo id="id9.3.m3.1.1.3.1" xref="id9.3.m3.1.1.3.1.cmml">
        %
       </mo>
      </mrow>
     </mrow>
     <annotation-xml encoding="MathML-Content" id="id9.3.m3.1b">
      <apply id="id9.3.m3.1.1.cmml" xref="id9.3.m3.1.1">
       <approx id="id9.3.m3.1.1.1.cmml" xref="id9.3.m3.1.1.1">
       </approx>
       <csymbol cd="latexml" id="id9.3.m3.1.1.2.cmml" xref="id9.3.m3.1.1.2">
        absent
       </csymbol>
       <apply id="id9.3.m3.1.1.3.cmml" xref="id9.3.m3.1.1.3">
        <csymbol cd="latexml" id="id9.3.m3.1.1.3.1.cmml" xref="id9.3.m3.1.1.3.1">
         percent
        </csymbol>
        <cn id="id9.3.m3.1.1.3.2.cmml" type="integer" xref="id9.3.m3.1.1.3.2">
         4
        </cn>
       </apply>
      </apply>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="id9.3.m3.1c">
      \approx 4\%
     </annotation>
    </semantics>
   </math>
   short of zero-shot performance using gold evidence.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <span class="ltx_note ltx_role_footnote" id="footnote1">
   <sup class="ltx_note_mark">
    â€ 
   </sup>
   <span class="ltx_note_outer">
    <span class="ltx_note_content">
     <sup class="ltx_note_mark">
      â€ 
     </sup>
     * Equal contribution
    </span>
   </span>
  </span>
  <span class="ltx_note ltx_role_footnote" id="footnote1a">
   <sup class="ltx_note_mark">
    â€ 
   </sup>
   <span class="ltx_note_outer">
    <span class="ltx_note_content">
     <sup class="ltx_note_mark">
      â€ 
     </sup>
     <sup class="ltx_sup" id="footnote1a.1">
      1
     </sup>
     Work done at Adobe Research, India
    </span>
   </span>
  </span>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Long Document Question Answering (LDQA) is a complex task that involves locating relevant evidence from lengthy documents to provide accurate answers to specific questions
    <cite class="ltx_cite ltx_citemacro_cite">
     Dasigi etÂ al. (
     <a class="ltx_ref" href="#bib.bib14" title="">
      2021
     </a>
     )
    </cite>
    . LDQA is challenging for the following reasons - a) Long documents often exceed the maximum token limit of existing transformer-based Pretrained Language Models (PLMs)
    <cite class="ltx_cite ltx_citemacro_cite">
     Devlin etÂ al. (
     <a class="ltx_ref" href="#bib.bib15" title="">
      2019
     </a>
     ); Liu etÂ al. (
     <a class="ltx_ref" href="#bib.bib31" title="">
      2019
     </a>
     ); Lewis etÂ al. (
     <a class="ltx_ref" href="#bib.bib30" title="">
      2020
     </a>
     ); Raffel etÂ al. (
     <a class="ltx_ref" href="#bib.bib46" title="">
      2020
     </a>
     )
    </cite>
    , posing a challenge in directly processing their content to extract pertinent information
    <cite class="ltx_cite ltx_citemacro_cite">
     Dong etÂ al. (
     <a class="ltx_ref" href="#bib.bib16" title="">
      2023
     </a>
     )
    </cite>
    . b) The information required to answer a question is often dispersed across different sections or paragraphs within the document which may require sophisticated reasoning process to identify and extract the relevant information
    <cite class="ltx_cite ltx_citemacro_cite">
     Nie etÂ al. (
     <a class="ltx_ref" href="#bib.bib38" title="">
      2022
     </a>
     )
    </cite>
    . c) Processing the entire document to find answers can be computationally expensive and inefficient
    <cite class="ltx_cite ltx_citemacro_cite">
     Dong etÂ al. (
     <a class="ltx_ref" href="#bib.bib16" title="">
      2023
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    One popular approach for LDQA is the retrieve-then-read method
    <cite class="ltx_cite ltx_citemacro_cite">
     Zheng etÂ al. (
     <a class="ltx_ref" href="#bib.bib63" title="">
      2020
     </a>
     ); Gong etÂ al. (
     <a class="ltx_ref" href="#bib.bib20" title="">
      2020
     </a>
     ); Nie etÂ al. (
     <a class="ltx_ref" href="#bib.bib38" title="">
      2022
     </a>
     ); Ainslie etÂ al. (
     <a class="ltx_ref" href="#bib.bib2" title="">
      2020
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     )
    </cite>
    ,
where relevant paragraphs are retrieved from the document to provide the answer.
A major drawback of existing works is reliance on supervised fine-tuning for the evidence selection phase, exhibiting poor generalization on out-of-distribution data
    <cite class="ltx_cite ltx_citemacro_cite">
     Thakur etÂ al. (
     <a class="ltx_ref" href="#bib.bib52" title="">
      2021
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    Given the remarkable few-shot/zero-shot performance and enhanced generalization capabilities demonstrated by Large Language Models (LLMs) across various Natural Language Generation and Understanding tasks
    <cite class="ltx_cite ltx_citemacro_cite">
     Brown etÂ al. (
     <a class="ltx_ref" href="#bib.bib6" title="">
      2020
     </a>
     ); Chen etÂ al. (
     <a class="ltx_ref" href="#bib.bib9" title="">
      2021
     </a>
     ); Rae etÂ al. (
     <a class="ltx_ref" href="#bib.bib45" title="">
      2022
     </a>
     ); Hoffmann etÂ al. (
     <a class="ltx_ref" href="#bib.bib26" title="">
      2022
     </a>
     ); Chowdhery etÂ al. (
     <a class="ltx_ref" href="#bib.bib11" title="">
      2022
     </a>
     )
    </cite>
    , we investigate the potential of leveraging these LLMs for zero-shot evidence retrieval. Notably, LLMs that have been instruction fine-tuned
    <cite class="ltx_cite ltx_citemacro_cite">
     Wei etÂ al. (
     <a class="ltx_ref" href="#bib.bib56" title="">
      2022a
     </a>
     ); Chung etÂ al. (
     <a class="ltx_ref" href="#bib.bib12" title="">
      2022
     </a>
     )
    </cite>
    or trained using Reinforcement Learning with Human Feedback
    <cite class="ltx_cite ltx_citemacro_cite">
     Bai etÂ al. (
     <a class="ltx_ref" href="#bib.bib3" title="">
      2022
     </a>
     ); Ouyang etÂ al. (
     <a class="ltx_ref" href="#bib.bib41" title="">
      2022
     </a>
     )
    </cite>
    exhibit exceptional generalization performance even on unseen tasks
    <cite class="ltx_cite ltx_citemacro_cite">
     Ouyang etÂ al. (
     <a class="ltx_ref" href="#bib.bib41" title="">
      2022
     </a>
     ); Min etÂ al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2022
     </a>
     ); OpenAI (
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023
     </a>
     )
    </cite>
    . Thus, we explore the feasibility of utilizing LLMs for zero-shot evidence retrieval.
However, LLMs, which are based on transformer architecture
    <cite class="ltx_cite ltx_citemacro_cite">
     Vaswani etÂ al. (
     <a class="ltx_ref" href="#bib.bib53" title="">
      2017
     </a>
     )
    </cite>
    , are limited by their context length and suffer from expensive inference times that increase quadratically with the number of tokens in the input. Additionally, utilizing enterprise LLM solutions such as OpenAIâ€™s
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.1">
     gpt-3.5-turbo
    </span>
    ,
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.2">
     text-davinci-003
    </span>
    ,
    <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.3">
     gpt-4
    </span>
    , etc.
    <span class="ltx_note ltx_role_footnote" id="footnote1b">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/pricing" target="_blank" title="">
        https://openai.com/pricing
       </a>
      </span>
     </span>
    </span>
    to process an entire long document without optimizations would incur significant monetary costs. This highlights the need for an LLM-based evidence retrieval solution that can achieve faster and more cost-effective inference by selectively processing relevant portions of the document, without compromising downstream performance.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    To overcome these challenges, we harness the inherent discourse structure commonly present in long documents. This structure encompasses the organization of topics, semantic segments, and information flow, enabling effective information search and knowledge acquisition for question answering.
    <cite class="ltx_cite ltx_citemacro_cite">
     Guthrie etÂ al. (
     <a class="ltx_ref" href="#bib.bib22" title="">
      1991
     </a>
     ); Meyer etÂ al. (
     <a class="ltx_ref" href="#bib.bib32" title="">
      1980
     </a>
     ); Taylor and Beach (
     <a class="ltx_ref" href="#bib.bib51" title="">
      1984
     </a>
     ); Cao and Wang (
     <a class="ltx_ref" href="#bib.bib7" title="">
      2022
     </a>
     ); Dong etÂ al. (
     <a class="ltx_ref" href="#bib.bib16" title="">
      2023
     </a>
     ); Nair etÂ al. (
     <a class="ltx_ref" href="#bib.bib34" title="">
      2023
     </a>
     )
    </cite>
    . Utilizing this valuable structure, we construct a condensed representation of the document by replacing the content within each section with a corresponding summary. This condensed representation is then fed to the LLM, enabling efficient processing of tokens while allowing the model to comprehensively analyze the entire input context for identifying relevant sections. Thereafter, the content within each relevant section is further processed by the LLM for fine-grained evidence retrieval. We call our proposed approach
    <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S1.p4.1.m1.1">
     <semantics id="S1.p4.1.m1.1a">
      <msup id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">
       <mi id="S1.p4.1.m1.1.1.2" xref="S1.p4.1.m1.1.1.2.cmml">
        ğƒ
       </mi>
       <mn id="S1.p4.1.m1.1.1.3" xref="S1.p4.1.m1.1.1.3.cmml">
        3
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b">
       <apply id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">
        <csymbol cd="ambiguous" id="S1.p4.1.m1.1.1.1.cmml" xref="S1.p4.1.m1.1.1">
         superscript
        </csymbol>
        <ci id="S1.p4.1.m1.1.1.2.cmml" xref="S1.p4.1.m1.1.1.2">
         ğƒ
        </ci>
        <cn id="S1.p4.1.m1.1.1.3.cmml" type="integer" xref="S1.p4.1.m1.1.1.3">
         3
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">
       \mathbf{D}^{3}
      </annotation>
     </semantics>
    </math>
    (
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">
     D
    </span>
    rilling
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">
     D
    </span>
    own into the
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">
     D
    </span>
    iscourse) due to the nature of the solution described above.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    Our approach undergoes evaluation in two distinct settings: Information Seeking and Multi-hop Reasoning in Question Answering. In the information seeking experiments, our approach retains the best zero-shot state-of-the-art (SoTA) results, while only utilizing 26% of the tokens employed by the SoTA approach. Additionally, we examine the robustness of our model across various document lengths and analyze the number of tokens required and latency for different zero-shot approaches. Moreover, we explore the integration of our approach with other zero-shot techniques within an agent framework designed to break down intricate queries into a sequence of simpler follow-up queries.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    LLMs in Retrieve-Then-Read Approaches
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     The retrieve-then-read
     <cite class="ltx_cite ltx_citemacro_cite">
      GreenÂ Jr etÂ al. (
      <a class="ltx_ref" href="#bib.bib21" title="">
       1961
      </a>
      ); Chen etÂ al. (
      <a class="ltx_ref" href="#bib.bib8" title="">
       2017
      </a>
      ); Wang etÂ al. (
      <a class="ltx_ref" href="#bib.bib55" title="">
       2018
      </a>
      ); Das etÂ al. (
      <a class="ltx_ref" href="#bib.bib13" title="">
       2019
      </a>
      ); Guu etÂ al. (
      <a class="ltx_ref" href="#bib.bib25" title="">
       2020
      </a>
      )
     </cite>
     approach is a widely adopted technique in open-domain
     <cite class="ltx_cite ltx_citemacro_cite">
      Voorhees etÂ al. (
      <a class="ltx_ref" href="#bib.bib54" title="">
       1999
      </a>
      ); Dunn etÂ al. (
      <a class="ltx_ref" href="#bib.bib17" title="">
       2017
      </a>
      ); Joshi etÂ al. (
      <a class="ltx_ref" href="#bib.bib27" title="">
       2017
      </a>
      ); Zhu etÂ al. (
      <a class="ltx_ref" href="#bib.bib64" title="">
       2021
      </a>
      )
     </cite>
     , multi-document question answering
     <cite class="ltx_cite ltx_citemacro_cite">
      Yang etÂ al. (
      <a class="ltx_ref" href="#bib.bib60" title="">
       2018
      </a>
      ); Perez etÂ al. (
      <a class="ltx_ref" href="#bib.bib43" title="">
       2020
      </a>
      ); Ferguson etÂ al. (
      <a class="ltx_ref" href="#bib.bib19" title="">
       2020
      </a>
      )
     </cite>
     and long-document question answering
     <cite class="ltx_cite ltx_citemacro_cite">
      Pereira etÂ al. (
      <a class="ltx_ref" href="#bib.bib42" title="">
       2023
      </a>
      )
     </cite>
     .
In this approach, LLMs are utilized specifically for the reader component, which generates responses based on the relevant fragments retrieved by the retriever
     <cite class="ltx_cite ltx_citemacro_cite">
      Pereira etÂ al. (
      <a class="ltx_ref" href="#bib.bib42" title="">
       2023
      </a>
      )
     </cite>
     . Although LLMs have been utilized as decision-making agents in browser interactions for document retrieval
     <cite class="ltx_cite ltx_citemacro_cite">
      Nakano etÂ al. (
      <a class="ltx_ref" href="#bib.bib35" title="">
       2022
      </a>
      )
     </cite>
     , their direct application for fine-grained evidence retrieval has not been extensively explored to the best of our knowledge. On that front, our paper is the first to evaluate the applicability of LLMs for evidence retrieval.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Chaining LLMs Runs for Question Answering
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Chaining in LLMs refers to the task of breaking complex overarching task into a sequence of fine-grained targetted sub-tasks where the information generated by a particular run of the sequence is passed to the subsequent runs
     <cite class="ltx_cite ltx_citemacro_cite">
      Wu etÂ al. (
      <a class="ltx_ref" href="#bib.bib58" title="">
       2022a
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib59" title="">
       b
      </a>
      )
     </cite>
     . This allows for realizing powerful machine learning applications without requiring any changes to the model architecture
     <cite class="ltx_cite ltx_citemacro_cite">
      Tan etÂ al. (
      <a class="ltx_ref" href="#bib.bib49" title="">
       2021
      </a>
      ); Betz etÂ al. (
      <a class="ltx_ref" href="#bib.bib4" title="">
       2021
      </a>
      ); Reynolds and McDonell (
      <a class="ltx_ref" href="#bib.bib48" title="">
       2021
      </a>
      )
     </cite>
     .
     <cite class="ltx_cite ltx_citemacro_citeauthor">
      <a class="ltx_ref" href="#bib.bib29" title="">
       LangChain
      </a>
     </cite>
     has implemented procedures using chaining for evidence retrieval and question answering in long documents. They employ three chaining variants (
     <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p1.1.1">
      map-reduce
     </span>
     ,
     <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p1.1.2">
      map-rerank
     </span>
     , and
     <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p1.1.3">
      refine
     </span>
     )
     <span class="ltx_note ltx_role_footnote" id="footnote2">
      <sup class="ltx_note_mark">
       2
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         2
        </sup>
        <span class="ltx_tag ltx_tag_note">
         2
        </span>
        <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://python.langchain.com/docs/modules/chains/document/" target="_blank" title="">
         https://python.langchain.com/docs/modules/chains/document/
        </a>
       </span>
      </span>
     </span>
     , which processes document chunks individually and aggregate the information from each chunk to derive the final answer. This implementation, however, processes the entire document input resulting in significant compute and monetary cost.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Evidence Retrieval for LDQA
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Prior evidence retrieval approaches typically employ following two mechanims which are trained by supervised fine-tuning - local processing to handle individual document chunks with occasional information flow between them
     <cite class="ltx_cite ltx_citemacro_cite">
      Gong etÂ al. (
      <a class="ltx_ref" href="#bib.bib20" title="">
       2020
      </a>
      )
     </cite>
     and global processing to aggregate the information from each chunk to identify relevant paragraphs
     <cite class="ltx_cite ltx_citemacro_cite">
      Zheng etÂ al. (
      <a class="ltx_ref" href="#bib.bib63" title="">
       2020
      </a>
      ); Ainslie etÂ al. (
      <a class="ltx_ref" href="#bib.bib2" title="">
       2020
      </a>
      ); Nie etÂ al. (
      <a class="ltx_ref" href="#bib.bib38" title="">
       2022
      </a>
      ); Ainslie etÂ al. (
      <a class="ltx_ref" href="#bib.bib1" title="">
       2023
      </a>
      )
     </cite>
     . Inspired by this strategy, our method represent each section using its corresponding summary in a local processing step and, in the global processing mechanism, we utilize a suitable verbalizer to concatenate the summaries from each section.
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F1">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="156" id="S2.F1.g1" src="/html/2311.13565/assets/x1.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 1:
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.F1.2.1">
      An illustration of the end-end pipeline of
      <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S2.F1.2.1.m1.1">
       <semantics id="S2.F1.2.1.m1.1b">
        <msup id="S2.F1.2.1.m1.1.1" xref="S2.F1.2.1.m1.1.1.cmml">
         <mi id="S2.F1.2.1.m1.1.1.2" xref="S2.F1.2.1.m1.1.1.2.cmml">
          ğƒ
         </mi>
         <mn id="S2.F1.2.1.m1.1.1.3" xref="S2.F1.2.1.m1.1.1.3.cmml">
          3
         </mn>
        </msup>
        <annotation-xml encoding="MathML-Content" id="S2.F1.2.1.m1.1c">
         <apply id="S2.F1.2.1.m1.1.1.cmml" xref="S2.F1.2.1.m1.1.1">
          <csymbol cd="ambiguous" id="S2.F1.2.1.m1.1.1.1.cmml" xref="S2.F1.2.1.m1.1.1">
           superscript
          </csymbol>
          <ci id="S2.F1.2.1.m1.1.1.2.cmml" xref="S2.F1.2.1.m1.1.1.2">
           ğƒ
          </ci>
          <cn id="S2.F1.2.1.m1.1.1.3.cmml" type="integer" xref="S2.F1.2.1.m1.1.1.3">
           3
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.F1.2.1.m1.1d">
         \mathbf{D}^{3}
        </annotation>
       </semantics>
      </math>
     </span>
     . Given a question and a long document with discourse structure that indicates sections, subsections etc., we first identify sections that are relevant for answering the question. Following this step we select relevant paragraphs from the paragraphs in the relevant sections. In the final step, we pass these relevant paragraphs to an LLM for question answering.
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S3.1.m1.1">
    <semantics id="S3.1.m1.1b">
     <msup id="S3.1.m1.1.1" xref="S3.1.m1.1.1.cmml">
      <mi id="S3.1.m1.1.1.2" xref="S3.1.m1.1.1.2.cmml">
       ğƒ
      </mi>
      <mn id="S3.1.m1.1.1.3" xref="S3.1.m1.1.1.3.cmml">
       3
      </mn>
     </msup>
     <annotation-xml encoding="MathML-Content" id="S3.1.m1.1c">
      <apply id="S3.1.m1.1.1.cmml" xref="S3.1.m1.1.1">
       <csymbol cd="ambiguous" id="S3.1.m1.1.1.1.cmml" xref="S3.1.m1.1.1">
        superscript
       </csymbol>
       <ci id="S3.1.m1.1.1.2.cmml" xref="S3.1.m1.1.1.2">
        ğƒ
       </ci>
       <cn id="S3.1.m1.1.1.3.cmml" type="integer" xref="S3.1.m1.1.1.3">
        3
       </cn>
      </apply>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="S3.1.m1.1d">
      \mathbf{D}^{3}
     </annotation>
    </semantics>
   </math>
   :
   <span class="ltx_text ltx_font_bold" id="S3.2.1">
    D
   </span>
   rilling
   <span class="ltx_text ltx_font_bold" id="S3.3.2">
    D
   </span>
   own into the
   <span class="ltx_text ltx_font_bold" id="S3.4.3">
    D
   </span>
   iscourse
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Problem Formulation
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.14">
     In LDQA, a question
     <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1">
      <semantics id="S3.SS1.p1.1.m1.1a">
       <mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">
        ğª
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b">
        <ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">
         ğª
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">
        \mathbf{q}
       </annotation>
      </semantics>
     </math>
     is asked for a document
     <math alttext="\mathbf{D}=[p_{1},p_{2},\dots,p_{n}]" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.4">
      <semantics id="S3.SS1.p1.2.m2.4a">
       <mrow id="S3.SS1.p1.2.m2.4.4" xref="S3.SS1.p1.2.m2.4.4.cmml">
        <mi id="S3.SS1.p1.2.m2.4.4.5" xref="S3.SS1.p1.2.m2.4.4.5.cmml">
         ğƒ
        </mi>
        <mo id="S3.SS1.p1.2.m2.4.4.4" xref="S3.SS1.p1.2.m2.4.4.4.cmml">
         =
        </mo>
        <mrow id="S3.SS1.p1.2.m2.4.4.3.3" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">
         <mo id="S3.SS1.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">
          [
         </mo>
         <msub id="S3.SS1.p1.2.m2.2.2.1.1.1" xref="S3.SS1.p1.2.m2.2.2.1.1.1.cmml">
          <mi id="S3.SS1.p1.2.m2.2.2.1.1.1.2" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.cmml">
           p
          </mi>
          <mn id="S3.SS1.p1.2.m2.2.2.1.1.1.3" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S3.SS1.p1.2.m2.4.4.3.3.5" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S3.SS1.p1.2.m2.3.3.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.cmml">
          <mi id="S3.SS1.p1.2.m2.3.3.2.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.cmml">
           p
          </mi>
          <mn id="S3.SS1.p1.2.m2.3.3.2.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml">
           2
          </mn>
         </msub>
         <mo id="S3.SS1.p1.2.m2.4.4.3.3.6" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S3.SS1.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS1.p1.2.m2.1.1.cmml">
          â€¦
         </mi>
         <mo id="S3.SS1.p1.2.m2.4.4.3.3.7" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S3.SS1.p1.2.m2.4.4.3.3.3" xref="S3.SS1.p1.2.m2.4.4.3.3.3.cmml">
          <mi id="S3.SS1.p1.2.m2.4.4.3.3.3.2" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2.cmml">
           p
          </mi>
          <mi id="S3.SS1.p1.2.m2.4.4.3.3.3.3" xref="S3.SS1.p1.2.m2.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S3.SS1.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S3.SS1.p1.2.m2.4.4.3.4.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.4b">
        <apply id="S3.SS1.p1.2.m2.4.4.cmml" xref="S3.SS1.p1.2.m2.4.4">
         <eq id="S3.SS1.p1.2.m2.4.4.4.cmml" xref="S3.SS1.p1.2.m2.4.4.4">
         </eq>
         <ci id="S3.SS1.p1.2.m2.4.4.5.cmml" xref="S3.SS1.p1.2.m2.4.4.5">
          ğƒ
         </ci>
         <list id="S3.SS1.p1.2.m2.4.4.3.4.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3">
          <apply id="S3.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS1.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2">
            ğ‘
           </ci>
           <cn id="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3">
            1
           </cn>
          </apply>
          <apply id="S3.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S3.SS1.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2">
            ğ‘
           </ci>
           <cn id="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3">
            2
           </cn>
          </apply>
          <ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">
           â€¦
          </ci>
          <apply id="S3.SS1.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S3.SS1.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.2">
            ğ‘
           </ci>
           <ci id="S3.SS1.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3.3">
            ğ‘›
           </ci>
          </apply>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.4c">
        \mathbf{D}=[p_{1},p_{2},\dots,p_{n}]
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="p_{i}(1\leq i\leq n)" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1">
      <semantics id="S3.SS1.p1.3.m3.1a">
       <mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">
        <msub id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">
         <mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">
          p
         </mi>
         <mi id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml">
          i
         </mi>
        </msub>
        <mo id="S3.SS1.p1.3.m3.1.1.2" lspace="0em" rspace="0em" xref="S3.SS1.p1.3.m3.1.1.2.cmml">
         â€‹
        </mo>
        <mrow id="S3.SS1.p1.3.m3.1.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.1.1.cmml">
         <mo id="S3.SS1.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.3.m3.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="S3.SS1.p1.3.m3.1.1.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.1.1.cmml">
          <mn id="S3.SS1.p1.3.m3.1.1.1.1.1.2" xref="S3.SS1.p1.3.m3.1.1.1.1.1.2.cmml">
           1
          </mn>
          <mo id="S3.SS1.p1.3.m3.1.1.1.1.1.3" xref="S3.SS1.p1.3.m3.1.1.1.1.1.3.cmml">
           â‰¤
          </mo>
          <mi id="S3.SS1.p1.3.m3.1.1.1.1.1.4" xref="S3.SS1.p1.3.m3.1.1.1.1.1.4.cmml">
           i
          </mi>
          <mo id="S3.SS1.p1.3.m3.1.1.1.1.1.5" xref="S3.SS1.p1.3.m3.1.1.1.1.1.5.cmml">
           â‰¤
          </mo>
          <mi id="S3.SS1.p1.3.m3.1.1.1.1.1.6" xref="S3.SS1.p1.3.m3.1.1.1.1.1.6.cmml">
           n
          </mi>
         </mrow>
         <mo id="S3.SS1.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.3.m3.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b">
        <apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">
         <times id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">
         </times>
         <apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3">
           subscript
          </csymbol>
          <ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">
           ğ‘
          </ci>
          <ci id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3">
           ğ‘–
          </ci>
         </apply>
         <apply id="S3.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1">
          <and id="S3.SS1.p1.3.m3.1.1.1.1.1a.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1">
          </and>
          <apply id="S3.SS1.p1.3.m3.1.1.1.1.1b.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1">
           <leq id="S3.SS1.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.1.3">
           </leq>
           <cn id="S3.SS1.p1.3.m3.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS1.p1.3.m3.1.1.1.1.1.2">
            1
           </cn>
           <ci id="S3.SS1.p1.3.m3.1.1.1.1.1.4.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.1.4">
            ğ‘–
           </ci>
          </apply>
          <apply id="S3.SS1.p1.3.m3.1.1.1.1.1c.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1">
           <leq id="S3.SS1.p1.3.m3.1.1.1.1.1.5.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.1.5">
           </leq>
           <share href="#S3.SS1.p1.3.m3.1.1.1.1.1.4.cmml" id="S3.SS1.p1.3.m3.1.1.1.1.1d.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1">
           </share>
           <ci id="S3.SS1.p1.3.m3.1.1.1.1.1.6.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.1.6">
            ğ‘›
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">
        p_{i}(1\leq i\leq n)
       </annotation>
      </semantics>
     </math>
     is the
     <math alttext="i^{th}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1">
      <semantics id="S3.SS1.p1.4.m4.1a">
       <msup id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">
        <mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">
         i
        </mi>
        <mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">
         <mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS1.p1.4.m4.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">
          â€‹
         </mo>
         <mi id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">
          h
         </mi>
        </mrow>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b">
        <apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">
          superscript
         </csymbol>
         <ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">
          ğ‘–
         </ci>
         <apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">
          <times id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1">
          </times>
          <ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">
           ğ‘¡
          </ci>
          <ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">
           â„
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">
        i^{th}
       </annotation>
      </semantics>
     </math>
     paragraph in the natural reading order of
     <math alttext="\mathbf{D}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1">
      <semantics id="S3.SS1.p1.5.m5.1a">
       <mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">
        ğƒ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b">
        <ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">
         ğƒ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">
        \mathbf{D}
       </annotation>
      </semantics>
     </math>
     . The task of LDQA is to retrieve a set of relevant paragraphs
     <math alttext="\mathbf{E}_{\mathbf{q}}\subseteq\mathbf{D}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1">
      <semantics id="S3.SS1.p1.6.m6.1a">
       <mrow id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">
        <msub id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">
         <mi id="S3.SS1.p1.6.m6.1.1.2.2" xref="S3.SS1.p1.6.m6.1.1.2.2.cmml">
          ğ„
         </mi>
         <mi id="S3.SS1.p1.6.m6.1.1.2.3" xref="S3.SS1.p1.6.m6.1.1.2.3.cmml">
          ğª
         </mi>
        </msub>
        <mo id="S3.SS1.p1.6.m6.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.cmml">
         âŠ†
        </mo>
        <mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">
         ğƒ
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b">
        <apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">
         <subset id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1">
         </subset>
         <apply id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS1.p1.6.m6.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2.2">
           ğ„
          </ci>
          <ci id="S3.SS1.p1.6.m6.1.1.2.3.cmml" xref="S3.SS1.p1.6.m6.1.1.2.3">
           ğª
          </ci>
         </apply>
         <ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">
          ğƒ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">
        \mathbf{E}_{\mathbf{q}}\subseteq\mathbf{D}
       </annotation>
      </semantics>
     </math>
     and generate a free-form answer
     <math alttext="\mathbf{a}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1">
      <semantics id="S3.SS1.p1.7.m7.1a">
       <mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">
        ğš
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b">
        <ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">
         ğš
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">
        \mathbf{a}
       </annotation>
      </semantics>
     </math>
     based on
     <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1">
      <semantics id="S3.SS1.p1.8.m8.1a">
       <mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">
        ğª
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b">
        <ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">
         ğª
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">
        \mathbf{q}
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="\mathbf{D}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1">
      <semantics id="S3.SS1.p1.9.m9.1a">
       <mi id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">
        ğƒ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b">
        <ci id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">
         ğƒ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">
        \mathbf{D}
       </annotation>
      </semantics>
     </math>
     <cite class="ltx_cite ltx_citemacro_cite">
      Dasigi etÂ al. (
      <a class="ltx_ref" href="#bib.bib14" title="">
       2021
      </a>
      ); Nie etÂ al. (
      <a class="ltx_ref" href="#bib.bib38" title="">
       2022
      </a>
      )
     </cite>
     . Due to the length of the documents, often exceeding
     <math alttext="5" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1">
      <semantics id="S3.SS1.p1.10.m10.1a">
       <mn id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">
        5
       </mn>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b">
        <cn id="S3.SS1.p1.10.m10.1.1.cmml" type="integer" xref="S3.SS1.p1.10.m10.1.1">
         5
        </cn>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">
        5
       </annotation>
      </semantics>
     </math>
     K tokens, we employ the retrieve-then-read strategy. This approach involves first determining
     <math alttext="\mathbf{E}_{\mathbf{q}}" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m11.1">
      <semantics id="S3.SS1.p1.11.m11.1a">
       <msub id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml">
        <mi id="S3.SS1.p1.11.m11.1.1.2" xref="S3.SS1.p1.11.m11.1.1.2.cmml">
         ğ„
        </mi>
        <mi id="S3.SS1.p1.11.m11.1.1.3" xref="S3.SS1.p1.11.m11.1.1.3.cmml">
         ğª
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b">
        <apply id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.2">
          ğ„
         </ci>
         <ci id="S3.SS1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3">
          ğª
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">
        \mathbf{E}_{\mathbf{q}}
       </annotation>
      </semantics>
     </math>
     and subsequently generating
     <math alttext="\mathbf{a}" class="ltx_Math" display="inline" id="S3.SS1.p1.12.m12.1">
      <semantics id="S3.SS1.p1.12.m12.1a">
       <mi id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml">
        ğš
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b">
        <ci id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1">
         ğš
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">
        \mathbf{a}
       </annotation>
      </semantics>
     </math>
     using only
     <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S3.SS1.p1.13.m13.1">
      <semantics id="S3.SS1.p1.13.m13.1a">
       <mi id="S3.SS1.p1.13.m13.1.1" xref="S3.SS1.p1.13.m13.1.1.cmml">
        ğª
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m13.1b">
        <ci id="S3.SS1.p1.13.m13.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1">
         ğª
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.13.m13.1c">
        \mathbf{q}
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="\mathbf{E}_{\mathbf{q}}" class="ltx_Math" display="inline" id="S3.SS1.p1.14.m14.1">
      <semantics id="S3.SS1.p1.14.m14.1a">
       <msub id="S3.SS1.p1.14.m14.1.1" xref="S3.SS1.p1.14.m14.1.1.cmml">
        <mi id="S3.SS1.p1.14.m14.1.1.2" xref="S3.SS1.p1.14.m14.1.1.2.cmml">
         ğ„
        </mi>
        <mi id="S3.SS1.p1.14.m14.1.1.3" xref="S3.SS1.p1.14.m14.1.1.3.cmml">
         ğª
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m14.1b">
        <apply id="S3.SS1.p1.14.m14.1.1.cmml" xref="S3.SS1.p1.14.m14.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.14.m14.1.1.1.cmml" xref="S3.SS1.p1.14.m14.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.14.m14.1.1.2.cmml" xref="S3.SS1.p1.14.m14.1.1.2">
          ğ„
         </ci>
         <ci id="S3.SS1.p1.14.m14.1.1.3.cmml" xref="S3.SS1.p1.14.m14.1.1.3">
          ğª
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.14.m14.1c">
        \mathbf{E}_{\mathbf{q}}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Motivation
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     The cognitive strategy employed by humans to search for relevant information from a document entails a systematic approach of first categorizing the information within the document to determine relevant coarse segments and then conducting a deeper analysis of the relevant categories to extract fine-grained segments
     <cite class="ltx_cite ltx_citemacro_cite">
      Guthrie and Kirsch (
      <a class="ltx_ref" href="#bib.bib23" title="">
       1987
      </a>
      ); Guthrie etÂ al. (
      <a class="ltx_ref" href="#bib.bib22" title="">
       1991
      </a>
      ); Guthrie and Mosenthal (
      <a class="ltx_ref" href="#bib.bib24" title="">
       1987
      </a>
      )
     </cite>
     . Long documents often possess a well-structured discourse that categorizes information coherently based on topical similarity
     <cite class="ltx_cite ltx_citemacro_cite">
      Cao and Wang (
      <a class="ltx_ref" href="#bib.bib7" title="">
       2022
      </a>
      ); Nair etÂ al. (
      <a class="ltx_ref" href="#bib.bib34" title="">
       2023
      </a>
      ); Dong etÂ al. (
      <a class="ltx_ref" href="#bib.bib16" title="">
       2023
      </a>
      )
     </cite>
     . This inherent discourse structure serves as a valuable framework, enabling effective categorization of information and facilitating a clear and logical flow of ideas within the document.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     Drawing from these insights, we posit that encapsulating the essence of a section through its name and content summary would yield valuable cues in determining its relevance for answering specific questions. Thereafter, we emulate the above-described cognitive process by fine-grained analysis of relevant sections to extract evidence paragraphs. This methodology offers three key advantages:
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">
      (1)
     </span>
     By condensing each section with its name and summary, we can effectively reduce the documentâ€™s token count, enabling LLMs to analyze the entire context and make accurate inferences.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.2">
      (2)
     </span>
     By efficiently filtering out irrelevant sections in the initial stage, our method reduces the number of tokens processed.
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.3">
      (3)
     </span>
     Our method is applicable for any instruction-following LLMs
     <cite class="ltx_cite ltx_citemacro_cite">
      Ouyang etÂ al. (
      <a class="ltx_ref" href="#bib.bib41" title="">
       2022
      </a>
      ); Min etÂ al. (
      <a class="ltx_ref" href="#bib.bib33" title="">
       2022
      </a>
      ); OpenAI (
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     , enabling zero-shot application without the need for architectural modifications.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Methodology
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.9">
     Instead of representing a document
     <math alttext="\mathbf{D}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1">
      <semantics id="S3.SS3.p1.1.m1.1a">
       <mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">
        ğƒ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b">
        <ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">
         ğƒ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">
        \mathbf{D}
       </annotation>
      </semantics>
     </math>
     as a ordered set of constituent paragraphs, we represent
     <math alttext="\mathbf{D}=[S_{1},S_{2},\dots,S_{k}]" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.4">
      <semantics id="S3.SS3.p1.2.m2.4a">
       <mrow id="S3.SS3.p1.2.m2.4.4" xref="S3.SS3.p1.2.m2.4.4.cmml">
        <mi id="S3.SS3.p1.2.m2.4.4.5" xref="S3.SS3.p1.2.m2.4.4.5.cmml">
         ğƒ
        </mi>
        <mo id="S3.SS3.p1.2.m2.4.4.4" xref="S3.SS3.p1.2.m2.4.4.4.cmml">
         =
        </mo>
        <mrow id="S3.SS3.p1.2.m2.4.4.3.3" xref="S3.SS3.p1.2.m2.4.4.3.4.cmml">
         <mo id="S3.SS3.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S3.SS3.p1.2.m2.4.4.3.4.cmml">
          [
         </mo>
         <msub id="S3.SS3.p1.2.m2.2.2.1.1.1" xref="S3.SS3.p1.2.m2.2.2.1.1.1.cmml">
          <mi id="S3.SS3.p1.2.m2.2.2.1.1.1.2" xref="S3.SS3.p1.2.m2.2.2.1.1.1.2.cmml">
           S
          </mi>
          <mn id="S3.SS3.p1.2.m2.2.2.1.1.1.3" xref="S3.SS3.p1.2.m2.2.2.1.1.1.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S3.SS3.p1.2.m2.4.4.3.3.5" xref="S3.SS3.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S3.SS3.p1.2.m2.3.3.2.2.2" xref="S3.SS3.p1.2.m2.3.3.2.2.2.cmml">
          <mi id="S3.SS3.p1.2.m2.3.3.2.2.2.2" xref="S3.SS3.p1.2.m2.3.3.2.2.2.2.cmml">
           S
          </mi>
          <mn id="S3.SS3.p1.2.m2.3.3.2.2.2.3" xref="S3.SS3.p1.2.m2.3.3.2.2.2.3.cmml">
           2
          </mn>
         </msub>
         <mo id="S3.SS3.p1.2.m2.4.4.3.3.6" xref="S3.SS3.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S3.SS3.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS3.p1.2.m2.1.1.cmml">
          â€¦
         </mi>
         <mo id="S3.SS3.p1.2.m2.4.4.3.3.7" xref="S3.SS3.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S3.SS3.p1.2.m2.4.4.3.3.3" xref="S3.SS3.p1.2.m2.4.4.3.3.3.cmml">
          <mi id="S3.SS3.p1.2.m2.4.4.3.3.3.2" xref="S3.SS3.p1.2.m2.4.4.3.3.3.2.cmml">
           S
          </mi>
          <mi id="S3.SS3.p1.2.m2.4.4.3.3.3.3" xref="S3.SS3.p1.2.m2.4.4.3.3.3.3.cmml">
           k
          </mi>
         </msub>
         <mo id="S3.SS3.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S3.SS3.p1.2.m2.4.4.3.4.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.4b">
        <apply id="S3.SS3.p1.2.m2.4.4.cmml" xref="S3.SS3.p1.2.m2.4.4">
         <eq id="S3.SS3.p1.2.m2.4.4.4.cmml" xref="S3.SS3.p1.2.m2.4.4.4">
         </eq>
         <ci id="S3.SS3.p1.2.m2.4.4.5.cmml" xref="S3.SS3.p1.2.m2.4.4.5">
          ğƒ
         </ci>
         <list id="S3.SS3.p1.2.m2.4.4.3.4.cmml" xref="S3.SS3.p1.2.m2.4.4.3.3">
          <apply id="S3.SS3.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS3.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.2.2.1.1.1.2">
            ğ‘†
           </ci>
           <cn id="S3.SS3.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS3.p1.2.m2.2.2.1.1.1.3">
            1
           </cn>
          </apply>
          <apply id="S3.SS3.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS3.p1.2.m2.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS3.p1.2.m2.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S3.SS3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.3.3.2.2.2.2">
            ğ‘†
           </ci>
           <cn id="S3.SS3.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS3.p1.2.m2.3.3.2.2.2.3">
            2
           </cn>
          </apply>
          <ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">
           â€¦
          </ci>
          <apply id="S3.SS3.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS3.p1.2.m2.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS3.p1.2.m2.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S3.SS3.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS3.p1.2.m2.4.4.3.3.3.2">
            ğ‘†
           </ci>
           <ci id="S3.SS3.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS3.p1.2.m2.4.4.3.3.3.3">
            ğ‘˜
           </ci>
          </apply>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.4c">
        \mathbf{D}=[S_{1},S_{2},\dots,S_{k}]
       </annotation>
      </semantics>
     </math>
     <span class="ltx_note ltx_role_footnote" id="footnote3">
      <sup class="ltx_note_mark">
       3
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         3
        </sup>
        <span class="ltx_tag ltx_tag_note">
         3
        </span>
        In practice, documents often have a hierarchical discourse structure, consisting of multiple levels of sections
        <cite class="ltx_cite ltx_citemacro_cite">
         Nair etÂ al. (
         <a class="ltx_ref" href="#bib.bib34" title="">
          2023
         </a>
         )
        </cite>
        . To handle this, we can flatten the structure using a pre-order traversal approach. When verbalizing a specific section, we concatenate the names of all sections along the path from the root node to that particular node in the discourse structure. This flattening process allows us to represent the document as a list of sections while considering the hierarchical relationships among sections.
       </span>
      </span>
     </span>
     , where
     <math alttext="S_{i}(1\leq i\leq k)" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1">
      <semantics id="S3.SS3.p1.3.m3.1a">
       <mrow id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">
        <msub id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">
         <mi id="S3.SS3.p1.3.m3.1.1.3.2" xref="S3.SS3.p1.3.m3.1.1.3.2.cmml">
          S
         </mi>
         <mi id="S3.SS3.p1.3.m3.1.1.3.3" xref="S3.SS3.p1.3.m3.1.1.3.3.cmml">
          i
         </mi>
        </msub>
        <mo id="S3.SS3.p1.3.m3.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.p1.3.m3.1.1.2.cmml">
         â€‹
        </mo>
        <mrow id="S3.SS3.p1.3.m3.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.1.cmml">
         <mo id="S3.SS3.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.3.m3.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="S3.SS3.p1.3.m3.1.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.1.cmml">
          <mn id="S3.SS3.p1.3.m3.1.1.1.1.1.2" xref="S3.SS3.p1.3.m3.1.1.1.1.1.2.cmml">
           1
          </mn>
          <mo id="S3.SS3.p1.3.m3.1.1.1.1.1.3" xref="S3.SS3.p1.3.m3.1.1.1.1.1.3.cmml">
           â‰¤
          </mo>
          <mi id="S3.SS3.p1.3.m3.1.1.1.1.1.4" xref="S3.SS3.p1.3.m3.1.1.1.1.1.4.cmml">
           i
          </mi>
          <mo id="S3.SS3.p1.3.m3.1.1.1.1.1.5" xref="S3.SS3.p1.3.m3.1.1.1.1.1.5.cmml">
           â‰¤
          </mo>
          <mi id="S3.SS3.p1.3.m3.1.1.1.1.1.6" xref="S3.SS3.p1.3.m3.1.1.1.1.1.6.cmml">
           k
          </mi>
         </mrow>
         <mo id="S3.SS3.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.3.m3.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b">
        <apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">
         <times id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">
         </times>
         <apply id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.3.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3">
           subscript
          </csymbol>
          <ci id="S3.SS3.p1.3.m3.1.1.3.2.cmml" xref="S3.SS3.p1.3.m3.1.1.3.2">
           ğ‘†
          </ci>
          <ci id="S3.SS3.p1.3.m3.1.1.3.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3">
           ğ‘–
          </ci>
         </apply>
         <apply id="S3.SS3.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1">
          <and id="S3.SS3.p1.3.m3.1.1.1.1.1a.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1">
          </and>
          <apply id="S3.SS3.p1.3.m3.1.1.1.1.1b.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1">
           <leq id="S3.SS3.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.3">
           </leq>
           <cn id="S3.SS3.p1.3.m3.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS3.p1.3.m3.1.1.1.1.1.2">
            1
           </cn>
           <ci id="S3.SS3.p1.3.m3.1.1.1.1.1.4.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.4">
            ğ‘–
           </ci>
          </apply>
          <apply id="S3.SS3.p1.3.m3.1.1.1.1.1c.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1">
           <leq id="S3.SS3.p1.3.m3.1.1.1.1.1.5.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.5">
           </leq>
           <share href="#S3.SS3.p1.3.m3.1.1.1.1.1.4.cmml" id="S3.SS3.p1.3.m3.1.1.1.1.1d.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1">
           </share>
           <ci id="S3.SS3.p1.3.m3.1.1.1.1.1.6.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.6">
            ğ‘˜
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">
        S_{i}(1\leq i\leq k)
       </annotation>
      </semantics>
     </math>
     denotes
     <math alttext="i^{th}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1">
      <semantics id="S3.SS3.p1.4.m4.1a">
       <msup id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">
        <mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">
         i
        </mi>
        <mrow id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">
         <mi id="S3.SS3.p1.4.m4.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S3.SS3.p1.4.m4.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS3.p1.4.m4.1.1.3.1.cmml">
          â€‹
         </mo>
         <mi id="S3.SS3.p1.4.m4.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.3.3.cmml">
          h
         </mi>
        </mrow>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b">
        <apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">
          superscript
         </csymbol>
         <ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">
          ğ‘–
         </ci>
         <apply id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">
          <times id="S3.SS3.p1.4.m4.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.3.1">
          </times>
          <ci id="S3.SS3.p1.4.m4.1.1.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.3.2">
           ğ‘¡
          </ci>
          <ci id="S3.SS3.p1.4.m4.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3">
           â„
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">
        i^{th}
       </annotation>
      </semantics>
     </math>
     section, such that,
     <math alttext="\texttt{name}(S_{i})" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m5.1">
      <semantics id="S3.SS3.p1.5.m5.1a">
       <mrow id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">
        <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.5.m5.1.1.3" xref="S3.SS3.p1.5.m5.1.1.3a.cmml">
         name
        </mtext>
        <mo id="S3.SS3.p1.5.m5.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.p1.5.m5.1.1.2.cmml">
         â€‹
        </mo>
        <mrow id="S3.SS3.p1.5.m5.1.1.1.1" xref="S3.SS3.p1.5.m5.1.1.1.1.1.cmml">
         <mo id="S3.SS3.p1.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.5.m5.1.1.1.1.1.cmml">
          (
         </mo>
         <msub id="S3.SS3.p1.5.m5.1.1.1.1.1" xref="S3.SS3.p1.5.m5.1.1.1.1.1.cmml">
          <mi id="S3.SS3.p1.5.m5.1.1.1.1.1.2" xref="S3.SS3.p1.5.m5.1.1.1.1.1.2.cmml">
           S
          </mi>
          <mi id="S3.SS3.p1.5.m5.1.1.1.1.1.3" xref="S3.SS3.p1.5.m5.1.1.1.1.1.3.cmml">
           i
          </mi>
         </msub>
         <mo id="S3.SS3.p1.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.5.m5.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b">
        <apply id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">
         <times id="S3.SS3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.2">
         </times>
         <ci id="S3.SS3.p1.5.m5.1.1.3a.cmml" xref="S3.SS3.p1.5.m5.1.1.3">
          <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3">
           name
          </mtext>
         </ci>
         <apply id="S3.SS3.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.p1.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.2">
           ğ‘†
          </ci>
          <ci id="S3.SS3.p1.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.3">
           ğ‘–
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">
        \texttt{name}(S_{i})
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="\texttt{paragraphs}(S_{i})" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m6.1">
      <semantics id="S3.SS3.p1.6.m6.1a">
       <mrow id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">
        <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.6.m6.1.1.3" xref="S3.SS3.p1.6.m6.1.1.3a.cmml">
         paragraphs
        </mtext>
        <mo id="S3.SS3.p1.6.m6.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.p1.6.m6.1.1.2.cmml">
         â€‹
        </mo>
        <mrow id="S3.SS3.p1.6.m6.1.1.1.1" xref="S3.SS3.p1.6.m6.1.1.1.1.1.cmml">
         <mo id="S3.SS3.p1.6.m6.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.6.m6.1.1.1.1.1.cmml">
          (
         </mo>
         <msub id="S3.SS3.p1.6.m6.1.1.1.1.1" xref="S3.SS3.p1.6.m6.1.1.1.1.1.cmml">
          <mi id="S3.SS3.p1.6.m6.1.1.1.1.1.2" xref="S3.SS3.p1.6.m6.1.1.1.1.1.2.cmml">
           S
          </mi>
          <mi id="S3.SS3.p1.6.m6.1.1.1.1.1.3" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.cmml">
           i
          </mi>
         </msub>
         <mo id="S3.SS3.p1.6.m6.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.6.m6.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b">
        <apply id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">
         <times id="S3.SS3.p1.6.m6.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.2">
         </times>
         <ci id="S3.SS3.p1.6.m6.1.1.3a.cmml" xref="S3.SS3.p1.6.m6.1.1.3">
          <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.6.m6.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.3">
           paragraphs
          </mtext>
         </ci>
         <apply id="S3.SS3.p1.6.m6.1.1.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.p1.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.2">
           ğ‘†
          </ci>
          <ci id="S3.SS3.p1.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3">
           ğ‘–
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">
        \texttt{paragraphs}(S_{i})
       </annotation>
      </semantics>
     </math>
     denotes its name / heading and the list of constituent paragraphs respectively (
     <math alttext="\texttt{paragraphs}(S_{i})=[p_{i,j}]_{j=1}^{|S_{i}|}" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m7.5">
      <semantics id="S3.SS3.p1.7.m7.5a">
       <mrow id="S3.SS3.p1.7.m7.5.5" xref="S3.SS3.p1.7.m7.5.5.cmml">
        <mrow id="S3.SS3.p1.7.m7.4.4.1" xref="S3.SS3.p1.7.m7.4.4.1.cmml">
         <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.7.m7.4.4.1.3" xref="S3.SS3.p1.7.m7.4.4.1.3a.cmml">
          paragraphs
         </mtext>
         <mo id="S3.SS3.p1.7.m7.4.4.1.2" lspace="0em" rspace="0em" xref="S3.SS3.p1.7.m7.4.4.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.p1.7.m7.4.4.1.1.1" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.cmml">
          <mo id="S3.SS3.p1.7.m7.4.4.1.1.1.2" stretchy="false" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.cmml">
           (
          </mo>
          <msub id="S3.SS3.p1.7.m7.4.4.1.1.1.1" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.cmml">
           <mi id="S3.SS3.p1.7.m7.4.4.1.1.1.1.2" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.2.cmml">
            S
           </mi>
           <mi id="S3.SS3.p1.7.m7.4.4.1.1.1.1.3" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.3.cmml">
            i
           </mi>
          </msub>
          <mo id="S3.SS3.p1.7.m7.4.4.1.1.1.3" stretchy="false" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <mo id="S3.SS3.p1.7.m7.5.5.3" xref="S3.SS3.p1.7.m7.5.5.3.cmml">
         =
        </mo>
        <msubsup id="S3.SS3.p1.7.m7.5.5.2" xref="S3.SS3.p1.7.m7.5.5.2.cmml">
         <mrow id="S3.SS3.p1.7.m7.5.5.2.1.1.1" xref="S3.SS3.p1.7.m7.5.5.2.1.1.2.cmml">
          <mo id="S3.SS3.p1.7.m7.5.5.2.1.1.1.2" stretchy="false" xref="S3.SS3.p1.7.m7.5.5.2.1.1.2.1.cmml">
           [
          </mo>
          <msub id="S3.SS3.p1.7.m7.5.5.2.1.1.1.1" xref="S3.SS3.p1.7.m7.5.5.2.1.1.1.1.cmml">
           <mi id="S3.SS3.p1.7.m7.5.5.2.1.1.1.1.2" xref="S3.SS3.p1.7.m7.5.5.2.1.1.1.1.2.cmml">
            p
           </mi>
           <mrow id="S3.SS3.p1.7.m7.2.2.2.4" xref="S3.SS3.p1.7.m7.2.2.2.3.cmml">
            <mi id="S3.SS3.p1.7.m7.1.1.1.1" xref="S3.SS3.p1.7.m7.1.1.1.1.cmml">
             i
            </mi>
            <mo id="S3.SS3.p1.7.m7.2.2.2.4.1" xref="S3.SS3.p1.7.m7.2.2.2.3.cmml">
             ,
            </mo>
            <mi id="S3.SS3.p1.7.m7.2.2.2.2" xref="S3.SS3.p1.7.m7.2.2.2.2.cmml">
             j
            </mi>
           </mrow>
          </msub>
          <mo id="S3.SS3.p1.7.m7.5.5.2.1.1.1.3" stretchy="false" xref="S3.SS3.p1.7.m7.5.5.2.1.1.2.1.cmml">
           ]
          </mo>
         </mrow>
         <mrow id="S3.SS3.p1.7.m7.5.5.2.1.3" xref="S3.SS3.p1.7.m7.5.5.2.1.3.cmml">
          <mi id="S3.SS3.p1.7.m7.5.5.2.1.3.2" xref="S3.SS3.p1.7.m7.5.5.2.1.3.2.cmml">
           j
          </mi>
          <mo id="S3.SS3.p1.7.m7.5.5.2.1.3.1" xref="S3.SS3.p1.7.m7.5.5.2.1.3.1.cmml">
           =
          </mo>
          <mn id="S3.SS3.p1.7.m7.5.5.2.1.3.3" xref="S3.SS3.p1.7.m7.5.5.2.1.3.3.cmml">
           1
          </mn>
         </mrow>
         <mrow id="S3.SS3.p1.7.m7.3.3.1.1" xref="S3.SS3.p1.7.m7.3.3.1.2.cmml">
          <mo id="S3.SS3.p1.7.m7.3.3.1.1.2" stretchy="false" xref="S3.SS3.p1.7.m7.3.3.1.2.1.cmml">
           |
          </mo>
          <msub id="S3.SS3.p1.7.m7.3.3.1.1.1" xref="S3.SS3.p1.7.m7.3.3.1.1.1.cmml">
           <mi id="S3.SS3.p1.7.m7.3.3.1.1.1.2" xref="S3.SS3.p1.7.m7.3.3.1.1.1.2.cmml">
            S
           </mi>
           <mi id="S3.SS3.p1.7.m7.3.3.1.1.1.3" xref="S3.SS3.p1.7.m7.3.3.1.1.1.3.cmml">
            i
           </mi>
          </msub>
          <mo id="S3.SS3.p1.7.m7.3.3.1.1.3" stretchy="false" xref="S3.SS3.p1.7.m7.3.3.1.2.1.cmml">
           |
          </mo>
         </mrow>
        </msubsup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.5b">
        <apply id="S3.SS3.p1.7.m7.5.5.cmml" xref="S3.SS3.p1.7.m7.5.5">
         <eq id="S3.SS3.p1.7.m7.5.5.3.cmml" xref="S3.SS3.p1.7.m7.5.5.3">
         </eq>
         <apply id="S3.SS3.p1.7.m7.4.4.1.cmml" xref="S3.SS3.p1.7.m7.4.4.1">
          <times id="S3.SS3.p1.7.m7.4.4.1.2.cmml" xref="S3.SS3.p1.7.m7.4.4.1.2">
          </times>
          <ci id="S3.SS3.p1.7.m7.4.4.1.3a.cmml" xref="S3.SS3.p1.7.m7.4.4.1.3">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.p1.7.m7.4.4.1.3.cmml" xref="S3.SS3.p1.7.m7.4.4.1.3">
            paragraphs
           </mtext>
          </ci>
          <apply id="S3.SS3.p1.7.m7.4.4.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.4.4.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.4.4.1.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.4.4.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS3.p1.7.m7.4.4.1.1.1.1.2.cmml" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.2">
            ğ‘†
           </ci>
           <ci id="S3.SS3.p1.7.m7.4.4.1.1.1.1.3.cmml" xref="S3.SS3.p1.7.m7.4.4.1.1.1.1.3">
            ğ‘–
           </ci>
          </apply>
         </apply>
         <apply id="S3.SS3.p1.7.m7.5.5.2.cmml" xref="S3.SS3.p1.7.m7.5.5.2">
          <csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.5.5.2.2.cmml" xref="S3.SS3.p1.7.m7.5.5.2">
           superscript
          </csymbol>
          <apply id="S3.SS3.p1.7.m7.5.5.2.1.cmml" xref="S3.SS3.p1.7.m7.5.5.2">
           <csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.5.5.2.1.2.cmml" xref="S3.SS3.p1.7.m7.5.5.2">
            subscript
           </csymbol>
           <apply id="S3.SS3.p1.7.m7.5.5.2.1.1.2.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.1.1">
            <csymbol cd="latexml" id="S3.SS3.p1.7.m7.5.5.2.1.1.2.1.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.1.1.2">
             delimited-[]
            </csymbol>
            <apply id="S3.SS3.p1.7.m7.5.5.2.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.1.1.1">
             <csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.5.5.2.1.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.1.1.1">
              subscript
             </csymbol>
             <ci id="S3.SS3.p1.7.m7.5.5.2.1.1.1.1.2.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.1.1.1.2">
              ğ‘
             </ci>
             <list id="S3.SS3.p1.7.m7.2.2.2.3.cmml" xref="S3.SS3.p1.7.m7.2.2.2.4">
              <ci id="S3.SS3.p1.7.m7.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1.1.1">
               ğ‘–
              </ci>
              <ci id="S3.SS3.p1.7.m7.2.2.2.2.cmml" xref="S3.SS3.p1.7.m7.2.2.2.2">
               ğ‘—
              </ci>
             </list>
            </apply>
           </apply>
           <apply id="S3.SS3.p1.7.m7.5.5.2.1.3.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.3">
            <eq id="S3.SS3.p1.7.m7.5.5.2.1.3.1.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.3.1">
            </eq>
            <ci id="S3.SS3.p1.7.m7.5.5.2.1.3.2.cmml" xref="S3.SS3.p1.7.m7.5.5.2.1.3.2">
             ğ‘—
            </ci>
            <cn id="S3.SS3.p1.7.m7.5.5.2.1.3.3.cmml" type="integer" xref="S3.SS3.p1.7.m7.5.5.2.1.3.3">
             1
            </cn>
           </apply>
          </apply>
          <apply id="S3.SS3.p1.7.m7.3.3.1.2.cmml" xref="S3.SS3.p1.7.m7.3.3.1.1">
           <abs id="S3.SS3.p1.7.m7.3.3.1.2.1.cmml" xref="S3.SS3.p1.7.m7.3.3.1.1.2">
           </abs>
           <apply id="S3.SS3.p1.7.m7.3.3.1.1.1.cmml" xref="S3.SS3.p1.7.m7.3.3.1.1.1">
            <csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.3.3.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.3.3.1.1.1">
             subscript
            </csymbol>
            <ci id="S3.SS3.p1.7.m7.3.3.1.1.1.2.cmml" xref="S3.SS3.p1.7.m7.3.3.1.1.1.2">
             ğ‘†
            </ci>
            <ci id="S3.SS3.p1.7.m7.3.3.1.1.1.3.cmml" xref="S3.SS3.p1.7.m7.3.3.1.1.1.3">
             ğ‘–
            </ci>
           </apply>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.5c">
        \texttt{paragraphs}(S_{i})=[p_{i,j}]_{j=1}^{|S_{i}|}
       </annotation>
      </semantics>
     </math>
     where
     <math alttext="|S_{i}|" class="ltx_Math" display="inline" id="S3.SS3.p1.8.m8.1">
      <semantics id="S3.SS3.p1.8.m8.1a">
       <mrow id="S3.SS3.p1.8.m8.1.1.1" xref="S3.SS3.p1.8.m8.1.1.2.cmml">
        <mo id="S3.SS3.p1.8.m8.1.1.1.2" stretchy="false" xref="S3.SS3.p1.8.m8.1.1.2.1.cmml">
         |
        </mo>
        <msub id="S3.SS3.p1.8.m8.1.1.1.1" xref="S3.SS3.p1.8.m8.1.1.1.1.cmml">
         <mi id="S3.SS3.p1.8.m8.1.1.1.1.2" xref="S3.SS3.p1.8.m8.1.1.1.1.2.cmml">
          S
         </mi>
         <mi id="S3.SS3.p1.8.m8.1.1.1.1.3" xref="S3.SS3.p1.8.m8.1.1.1.1.3.cmml">
          i
         </mi>
        </msub>
        <mo id="S3.SS3.p1.8.m8.1.1.1.3" stretchy="false" xref="S3.SS3.p1.8.m8.1.1.2.1.cmml">
         |
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b">
        <apply id="S3.SS3.p1.8.m8.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.1">
         <abs id="S3.SS3.p1.8.m8.1.1.2.1.cmml" xref="S3.SS3.p1.8.m8.1.1.1.2">
         </abs>
         <apply id="S3.SS3.p1.8.m8.1.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.p1.8.m8.1.1.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.p1.8.m8.1.1.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.1.1.2">
           ğ‘†
          </ci>
          <ci id="S3.SS3.p1.8.m8.1.1.1.1.3.cmml" xref="S3.SS3.p1.8.m8.1.1.1.1.3">
           ğ‘–
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">
        |S_{i}|
       </annotation>
      </semantics>
     </math>
     denotes number of constituent paragraphs). Note that,
     <math alttext="\sum_{i=1}^{k}|S_{i}|=n" class="ltx_Math" display="inline" id="S3.SS3.p1.9.m9.1">
      <semantics id="S3.SS3.p1.9.m9.1a">
       <mrow id="S3.SS3.p1.9.m9.1.1" xref="S3.SS3.p1.9.m9.1.1.cmml">
        <mrow id="S3.SS3.p1.9.m9.1.1.1" xref="S3.SS3.p1.9.m9.1.1.1.cmml">
         <msubsup id="S3.SS3.p1.9.m9.1.1.1.2" xref="S3.SS3.p1.9.m9.1.1.1.2.cmml">
          <mo id="S3.SS3.p1.9.m9.1.1.1.2.2.2" xref="S3.SS3.p1.9.m9.1.1.1.2.2.2.cmml">
           âˆ‘
          </mo>
          <mrow id="S3.SS3.p1.9.m9.1.1.1.2.2.3" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3.cmml">
           <mi id="S3.SS3.p1.9.m9.1.1.1.2.2.3.2" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3.2.cmml">
            i
           </mi>
           <mo id="S3.SS3.p1.9.m9.1.1.1.2.2.3.1" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3.1.cmml">
            =
           </mo>
           <mn id="S3.SS3.p1.9.m9.1.1.1.2.2.3.3" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3.3.cmml">
            1
           </mn>
          </mrow>
          <mi id="S3.SS3.p1.9.m9.1.1.1.2.3" xref="S3.SS3.p1.9.m9.1.1.1.2.3.cmml">
           k
          </mi>
         </msubsup>
         <mrow id="S3.SS3.p1.9.m9.1.1.1.1.1" xref="S3.SS3.p1.9.m9.1.1.1.1.2.cmml">
          <mo id="S3.SS3.p1.9.m9.1.1.1.1.1.2" lspace="0em" stretchy="false" xref="S3.SS3.p1.9.m9.1.1.1.1.2.1.cmml">
           |
          </mo>
          <msub id="S3.SS3.p1.9.m9.1.1.1.1.1.1" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.cmml">
           <mi id="S3.SS3.p1.9.m9.1.1.1.1.1.1.2" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.2.cmml">
            S
           </mi>
           <mi id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.cmml">
            i
           </mi>
          </msub>
          <mo id="S3.SS3.p1.9.m9.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.9.m9.1.1.1.1.2.1.cmml">
           |
          </mo>
         </mrow>
        </mrow>
        <mo id="S3.SS3.p1.9.m9.1.1.2" xref="S3.SS3.p1.9.m9.1.1.2.cmml">
         =
        </mo>
        <mi id="S3.SS3.p1.9.m9.1.1.3" xref="S3.SS3.p1.9.m9.1.1.3.cmml">
         n
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m9.1b">
        <apply id="S3.SS3.p1.9.m9.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1">
         <eq id="S3.SS3.p1.9.m9.1.1.2.cmml" xref="S3.SS3.p1.9.m9.1.1.2">
         </eq>
         <apply id="S3.SS3.p1.9.m9.1.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1">
          <apply id="S3.SS3.p1.9.m9.1.1.1.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2">
           <csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.1.1.1.2.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2">
            superscript
           </csymbol>
           <apply id="S3.SS3.p1.9.m9.1.1.1.2.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2">
            <csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.1.1.1.2.2.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2">
             subscript
            </csymbol>
            <sum id="S3.SS3.p1.9.m9.1.1.1.2.2.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2.2.2">
            </sum>
            <apply id="S3.SS3.p1.9.m9.1.1.1.2.2.3.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3">
             <eq id="S3.SS3.p1.9.m9.1.1.1.2.2.3.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3.1">
             </eq>
             <ci id="S3.SS3.p1.9.m9.1.1.1.2.2.3.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3.2">
              ğ‘–
             </ci>
             <cn id="S3.SS3.p1.9.m9.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.SS3.p1.9.m9.1.1.1.2.2.3.3">
              1
             </cn>
            </apply>
           </apply>
           <ci id="S3.SS3.p1.9.m9.1.1.1.2.3.cmml" xref="S3.SS3.p1.9.m9.1.1.1.2.3">
            ğ‘˜
           </ci>
          </apply>
          <apply id="S3.SS3.p1.9.m9.1.1.1.1.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1">
           <abs id="S3.SS3.p1.9.m9.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.2">
           </abs>
           <apply id="S3.SS3.p1.9.m9.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="S3.SS3.p1.9.m9.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.2">
             ğ‘†
            </ci>
            <ci id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3">
             ğ‘–
            </ci>
           </apply>
          </apply>
         </apply>
         <ci id="S3.SS3.p1.9.m9.1.1.3.cmml" xref="S3.SS3.p1.9.m9.1.1.3">
          ğ‘›
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p1.9.m9.1c">
        \sum_{i=1}^{k}|S_{i}|=n
       </annotation>
      </semantics>
     </math>
     . Inspired by the cognitive process of knowledge acquisition / information search for question answering, our approach first finds the relevant sections that may answer the question and then, analyses the paragraphs from the relevant sections for fine-grained evidence paragraph retrieval. (Figure
     <a class="ltx_ref" href="#S2.F1" title="Figure 1 â€£ 2.3 Evidence Retrieval for LDQA â€£ 2 Related Work â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     )
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.3.1
     </span>
     Finding Relevant Sections
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS1.p1">
     <p class="ltx_p" id="S3.SS3.SSS1.p1.3">
      The crux of this step is to represent the content in each section
      <math alttext="S_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.1.m1.1">
       <semantics id="S3.SS3.SSS1.p1.1.m1.1a">
        <msub id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">
         <mi id="S3.SS3.SSS1.p1.1.m1.1.1.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml">
          S
         </mi>
         <mi id="S3.SS3.SSS1.p1.1.m1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml">
          i
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b">
         <apply id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.2">
           ğ‘†
          </ci>
          <ci id="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3">
           ğ‘–
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">
         S_{i}
        </annotation>
       </semantics>
      </math>
      by the summary of
      <math alttext="\texttt{paragraphs}(S_{i})" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.2.m2.1">
       <semantics id="S3.SS3.SSS1.p1.2.m2.1a">
        <mrow id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml">
         <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.2.m2.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.3a.cmml">
          paragraphs
         </mtext>
         <mo id="S3.SS3.SSS1.p1.2.m2.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.SSS1.p1.2.m2.1.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.cmml">
          <mo id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.cmml">
           (
          </mo>
          <msub id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.cmml">
           <mi id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.2.cmml">
            S
           </mi>
           <mi id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.3.cmml">
            i
           </mi>
          </msub>
          <mo id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b">
         <apply id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1">
          <times id="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.2">
          </times>
          <ci id="S3.SS3.SSS1.p1.2.m2.1.1.3a.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3">
            paragraphs
           </mtext>
          </ci>
          <apply id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.2">
            ğ‘†
           </ci>
           <ci id="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.1.1.3">
            ğ‘–
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">
         \texttt{paragraphs}(S_{i})
        </annotation>
       </semantics>
      </math>
      . Summarization
      <cite class="ltx_cite ltx_citemacro_cite">
       El-Kassas etÂ al. (
       <a class="ltx_ref" href="#bib.bib18" title="">
        2021
       </a>
       )
      </cite>
      refers to the task of generating a concise summary for a given input that captures its main idea within a limited number of tokens, effectively conveying its topical essence. We denote the summarization operation by
      <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.3.m3.1">
       <semantics id="S3.SS3.SSS1.p1.3.m3.1a">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml">
         ğ’®
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.1b">
         <ci id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">
          ğ’®
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.1c">
         \mathcal{S}
        </annotation>
       </semantics>
      </math>
      , for which we have used
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS1.p1.3.1">
       bart-large
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       Lewis etÂ al. (
       <a class="ltx_ref" href="#bib.bib30" title="">
        2020
       </a>
       )
      </cite>
      fine-tuned over CNN/Daily-Mail Corpus
      <cite class="ltx_cite ltx_citemacro_cite">
       Nallapati etÂ al. (
       <a class="ltx_ref" href="#bib.bib36" title="">
        2016
       </a>
       )
      </cite>
      . Thereafter, we represent the entire document as follows:
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS1.p1.4.1">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS1.p1.4.1.1">
       * Section:
      </span>
      <math alttext="\texttt{name}(S_{1})" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.4.1.m1.1">
       <semantics id="S3.SS3.SSS1.p1.4.1.m1.1a">
        <mrow id="S3.SS3.SSS1.p1.4.1.m1.1.1" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.cmml">
         <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.4.1.m1.1.1.3" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.3a.cmml">
          name
         </mtext>
         <mo id="S3.SS3.SSS1.p1.4.1.m1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.cmml">
          <mo id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.cmml">
           (
          </mo>
          <msub id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.cmml">
           <mi id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.2.cmml">
            S
           </mi>
           <mn id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.3.cmml">
            1
           </mn>
          </msub>
          <mo id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.4.1.m1.1b">
         <apply id="S3.SS3.SSS1.p1.4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.4.1.m1.1.1">
          <times id="S3.SS3.SSS1.p1.4.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.2">
          </times>
          <ci id="S3.SS3.SSS1.p1.4.1.m1.1.1.3a.cmml" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.3">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.4.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.3">
            name
           </mtext>
          </ci>
          <apply id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.2">
            ğ‘†
           </ci>
           <cn id="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p1.4.1.m1.1.1.1.1.1.3">
            1
           </cn>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.4.1.m1.1c">
         \texttt{name}(S_{1})
        </annotation>
       </semantics>
      </math>
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS1.p1.5.2">
      <math alttext="\mathcal{S}(\texttt{paragraphs}(S_{1}))" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.5.2.m1.1">
       <semantics id="S3.SS3.SSS1.p1.5.2.m1.1a">
        <mrow id="S3.SS3.SSS1.p1.5.2.m1.1.1" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.5.2.m1.1.1.3" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.3.cmml">
          ğ’®
         </mi>
         <mo id="S3.SS3.SSS1.p1.5.2.m1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.cmml">
          <mo id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.cmml">
           (
          </mo>
          <mrow id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.cmml">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.3a.cmml">
            paragraphs
           </mtext>
           <mo id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.2.cmml">
            â€‹
           </mo>
           <mrow id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.cmml">
            <mo id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.cmml">
             (
            </mo>
            <msub id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.cmml">
             <mi id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.2.cmml">
              S
             </mi>
             <mn id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.3.cmml">
              1
             </mn>
            </msub>
            <mo id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <mo id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.5.2.m1.1b">
         <apply id="S3.SS3.SSS1.p1.5.2.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1">
          <times id="S3.SS3.SSS1.p1.5.2.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.2">
          </times>
          <ci id="S3.SS3.SSS1.p1.5.2.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.3">
           ğ’®
          </ci>
          <apply id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1">
           <times id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.2">
           </times>
           <ci id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.3a.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.3">
            <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.3">
             paragraphs
            </mtext>
           </ci>
           <apply id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.2">
             ğ‘†
            </ci>
            <cn id="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p1.5.2.m1.1.1.1.1.1.1.1.1.3">
             1
            </cn>
           </apply>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.5.2.m1.1c">
         \mathcal{S}(\texttt{paragraphs}(S_{1}))
        </annotation>
       </semantics>
      </math>
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS1.p1.6.3">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS1.p1.6.3.1">
       * Section:
      </span>
      <math alttext="\texttt{name}(S_{2})" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.6.3.m1.1">
       <semantics id="S3.SS3.SSS1.p1.6.3.m1.1a">
        <mrow id="S3.SS3.SSS1.p1.6.3.m1.1.1" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.cmml">
         <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.6.3.m1.1.1.3" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.3a.cmml">
          name
         </mtext>
         <mo id="S3.SS3.SSS1.p1.6.3.m1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.cmml">
          <mo id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.cmml">
           (
          </mo>
          <msub id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.cmml">
           <mi id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.2.cmml">
            S
           </mi>
           <mn id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.3.cmml">
            2
           </mn>
          </msub>
          <mo id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.6.3.m1.1b">
         <apply id="S3.SS3.SSS1.p1.6.3.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.6.3.m1.1.1">
          <times id="S3.SS3.SSS1.p1.6.3.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.2">
          </times>
          <ci id="S3.SS3.SSS1.p1.6.3.m1.1.1.3a.cmml" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.3">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.6.3.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.3">
            name
           </mtext>
          </ci>
          <apply id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.2">
            ğ‘†
           </ci>
           <cn id="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p1.6.3.m1.1.1.1.1.1.3">
            2
           </cn>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.6.3.m1.1c">
         \texttt{name}(S_{2})
        </annotation>
       </semantics>
      </math>
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS1.p1.7.4">
      <math alttext="\mathcal{S}(\texttt{paragraphs}(S_{2}))" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.7.4.m1.1">
       <semantics id="S3.SS3.SSS1.p1.7.4.m1.1a">
        <mrow id="S3.SS3.SSS1.p1.7.4.m1.1.1" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.7.4.m1.1.1.3" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.3.cmml">
          ğ’®
         </mi>
         <mo id="S3.SS3.SSS1.p1.7.4.m1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.cmml">
          <mo id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.cmml">
           (
          </mo>
          <mrow id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.cmml">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.3a.cmml">
            paragraphs
           </mtext>
           <mo id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.2.cmml">
            â€‹
           </mo>
           <mrow id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.cmml">
            <mo id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.cmml">
             (
            </mo>
            <msub id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.cmml">
             <mi id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.2.cmml">
              S
             </mi>
             <mn id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.3.cmml">
              2
             </mn>
            </msub>
            <mo id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <mo id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.7.4.m1.1b">
         <apply id="S3.SS3.SSS1.p1.7.4.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1">
          <times id="S3.SS3.SSS1.p1.7.4.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.2">
          </times>
          <ci id="S3.SS3.SSS1.p1.7.4.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.3">
           ğ’®
          </ci>
          <apply id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1">
           <times id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.2">
           </times>
           <ci id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.3a.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.3">
            <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.3">
             paragraphs
            </mtext>
           </ci>
           <apply id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.2">
             ğ‘†
            </ci>
            <cn id="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p1.7.4.m1.1.1.1.1.1.1.1.1.3">
             2
            </cn>
           </apply>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.7.4.m1.1c">
         \mathcal{S}(\texttt{paragraphs}(S_{2}))
        </annotation>
       </semantics>
      </math>
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS1.p1.8.5">
      <math alttext="\cdots" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.8.5.m1.1">
       <semantics id="S3.SS3.SSS1.p1.8.5.m1.1a">
        <mi id="S3.SS3.SSS1.p1.8.5.m1.1.1" mathvariant="normal" xref="S3.SS3.SSS1.p1.8.5.m1.1.1.cmml">
         â‹¯
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.8.5.m1.1b">
         <ci id="S3.SS3.SSS1.p1.8.5.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.8.5.m1.1.1">
          â‹¯
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.8.5.m1.1c">
         \cdots
        </annotation>
       </semantics>
      </math>
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS1.p1.9.6">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS1.p1.9.6.1">
       * Section:
      </span>
      <math alttext="\texttt{name}(S_{k})" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.9.6.m1.1">
       <semantics id="S3.SS3.SSS1.p1.9.6.m1.1a">
        <mrow id="S3.SS3.SSS1.p1.9.6.m1.1.1" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.cmml">
         <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.9.6.m1.1.1.3" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.3a.cmml">
          name
         </mtext>
         <mo id="S3.SS3.SSS1.p1.9.6.m1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.cmml">
          <mo id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.cmml">
           (
          </mo>
          <msub id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.cmml">
           <mi id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.2.cmml">
            S
           </mi>
           <mi id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.3.cmml">
            k
           </mi>
          </msub>
          <mo id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.9.6.m1.1b">
         <apply id="S3.SS3.SSS1.p1.9.6.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1">
          <times id="S3.SS3.SSS1.p1.9.6.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.2">
          </times>
          <ci id="S3.SS3.SSS1.p1.9.6.m1.1.1.3a.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.3">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.9.6.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.3">
            name
           </mtext>
          </ci>
          <apply id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.2">
            ğ‘†
           </ci>
           <ci id="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.9.6.m1.1.1.1.1.1.3">
            ğ‘˜
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.9.6.m1.1c">
         \texttt{name}(S_{k})
        </annotation>
       </semantics>
      </math>
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS1.p1.10.7">
      <math alttext="\mathcal{S}(\texttt{paragraphs}(S_{k}))" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.10.7.m1.1">
       <semantics id="S3.SS3.SSS1.p1.10.7.m1.1a">
        <mrow id="S3.SS3.SSS1.p1.10.7.m1.1.1" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.10.7.m1.1.1.3" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.3.cmml">
          ğ’®
         </mi>
         <mo id="S3.SS3.SSS1.p1.10.7.m1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.2.cmml">
          â€‹
         </mo>
         <mrow id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.cmml">
          <mo id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.cmml">
           (
          </mo>
          <mrow id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.cmml">
           <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.3a.cmml">
            paragraphs
           </mtext>
           <mo id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.2.cmml">
            â€‹
           </mo>
           <mrow id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.cmml">
            <mo id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.cmml">
             (
            </mo>
            <msub id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.cmml">
             <mi id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.2.cmml">
              S
             </mi>
             <mi id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.3.cmml">
              k
             </mi>
            </msub>
            <mo id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <mo id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.10.7.m1.1b">
         <apply id="S3.SS3.SSS1.p1.10.7.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1">
          <times id="S3.SS3.SSS1.p1.10.7.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.2">
          </times>
          <ci id="S3.SS3.SSS1.p1.10.7.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.3">
           ğ’®
          </ci>
          <apply id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1">
           <times id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.2">
           </times>
           <ci id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.3a.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.3">
            <mtext class="ltx_mathvariant_monospace" id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.3">
             paragraphs
            </mtext>
           </ci>
           <apply id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.2">
             ğ‘†
            </ci>
            <ci id="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.10.7.m1.1.1.1.1.1.1.1.1.3">
             ğ‘˜
            </ci>
           </apply>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.10.7.m1.1c">
         \mathcal{S}(\texttt{paragraphs}(S_{k}))
        </annotation>
       </semantics>
      </math>
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS1.p2">
     <p class="ltx_p" id="S3.SS3.SSS1.p2.2">
      An instruction is passed to an LLM involving the above representation to identify all the sections that are relevant to
      <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.1.m1.1">
       <semantics id="S3.SS3.SSS1.p2.1.m1.1a">
        <mi id="S3.SS3.SSS1.p2.1.m1.1.1" xref="S3.SS3.SSS1.p2.1.m1.1.1.cmml">
         ğª
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.1.m1.1b">
         <ci id="S3.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1">
          ğª
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.1.m1.1c">
         \mathbf{q}
        </annotation>
       </semantics>
      </math>
      . Due to this condensed representation, the LLM can process the entire document context enabling comprehensive analysis of long range dependencies for accurate inference. Let the set of sections identified as relevant be denoted by
      <math alttext="{\mathbf{R}_{\mathbf{q}}}\subseteq\mathbf{D}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.2.m2.1">
       <semantics id="S3.SS3.SSS1.p2.2.m2.1a">
        <mrow id="S3.SS3.SSS1.p2.2.m2.1.1" xref="S3.SS3.SSS1.p2.2.m2.1.1.cmml">
         <msub id="S3.SS3.SSS1.p2.2.m2.1.1.2" xref="S3.SS3.SSS1.p2.2.m2.1.1.2.cmml">
          <mi id="S3.SS3.SSS1.p2.2.m2.1.1.2.2" xref="S3.SS3.SSS1.p2.2.m2.1.1.2.2.cmml">
           ğ‘
          </mi>
          <mi id="S3.SS3.SSS1.p2.2.m2.1.1.2.3" xref="S3.SS3.SSS1.p2.2.m2.1.1.2.3.cmml">
           ğª
          </mi>
         </msub>
         <mo id="S3.SS3.SSS1.p2.2.m2.1.1.1" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.cmml">
          âŠ†
         </mo>
         <mi id="S3.SS3.SSS1.p2.2.m2.1.1.3" xref="S3.SS3.SSS1.p2.2.m2.1.1.3.cmml">
          ğƒ
         </mi>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.2.m2.1b">
         <apply id="S3.SS3.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1">
          <subset id="S3.SS3.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.1">
          </subset>
          <apply id="S3.SS3.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.2">
           <csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.2.m2.1.1.2.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.2">
            subscript
           </csymbol>
           <ci id="S3.SS3.SSS1.p2.2.m2.1.1.2.2.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.2.2">
            ğ‘
           </ci>
           <ci id="S3.SS3.SSS1.p2.2.m2.1.1.2.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.2.3">
            ğª
           </ci>
          </apply>
          <ci id="S3.SS3.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.3">
           ğƒ
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.2.m2.1c">
         {\mathbf{R}_{\mathbf{q}}}\subseteq\mathbf{D}
        </annotation>
       </semantics>
      </math>
      .
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.3.2
     </span>
     Fine-Grained Evidence Retrieval
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS2.p1">
     <p class="ltx_p" id="S3.SS3.SSS2.p1.3">
      The objective of this step is to infer the set of relevant paragraphs from
      <math alttext="{\mathbf{R}_{\mathbf{q}}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.1.m1.1">
       <semantics id="S3.SS3.SSS2.p1.1.m1.1a">
        <msub id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml">
         <mi id="S3.SS3.SSS2.p1.1.m1.1.1.2" xref="S3.SS3.SSS2.p1.1.m1.1.1.2.cmml">
          ğ‘
         </mi>
         <mi id="S3.SS3.SSS2.p1.1.m1.1.1.3" xref="S3.SS3.SSS2.p1.1.m1.1.1.3.cmml">
          ğª
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b">
         <apply id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1.2">
           ğ‘
          </ci>
          <ci id="S3.SS3.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1.3">
           ğª
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">
         {\mathbf{R}_{\mathbf{q}}}
        </annotation>
       </semantics>
      </math>
      . Here, we explain multiple zero-shot strategies to achieve this step. We, first, obtain a set of all paragraphs
      <math alttext="{\mathbf{P}_{\mathbf{q}}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.2.m2.1">
       <semantics id="S3.SS3.SSS2.p1.2.m2.1a">
        <msub id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml">
         <mi id="S3.SS3.SSS2.p1.2.m2.1.1.2" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml">
          ğ
         </mi>
         <mi id="S3.SS3.SSS2.p1.2.m2.1.1.3" xref="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml">
          ğª
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b">
         <apply id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.2">
           ğ
          </ci>
          <ci id="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.3">
           ğª
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">
         {\mathbf{P}_{\mathbf{q}}}
        </annotation>
       </semantics>
      </math>
      associated with
      <math alttext="{\mathbf{R}_{\mathbf{q}}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.3.m3.1">
       <semantics id="S3.SS3.SSS2.p1.3.m3.1a">
        <msub id="S3.SS3.SSS2.p1.3.m3.1.1" xref="S3.SS3.SSS2.p1.3.m3.1.1.cmml">
         <mi id="S3.SS3.SSS2.p1.3.m3.1.1.2" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml">
          ğ‘
         </mi>
         <mi id="S3.SS3.SSS2.p1.3.m3.1.1.3" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml">
          ğª
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.3.m3.1b">
         <apply id="S3.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.2">
           ğ‘
          </ci>
          <ci id="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3">
           ğª
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.3.m3.1c">
         {\mathbf{R}_{\mathbf{q}}}
        </annotation>
       </semantics>
      </math>
      .
     </p>
     <table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
      <tbody>
       <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
        <td class="ltx_eqn_cell ltx_eqn_center_padleft">
        </td>
        <td class="ltx_eqn_cell ltx_align_center">
         <math alttext="\mathbf{P}_{\mathbf{q}}=\bigcup_{S\in\mathbf{R}_{\mathbf{q}}}\texttt{paragraphs}(S)" class="ltx_Math" display="block" id="S3.Ex1.m1.1">
          <semantics id="S3.Ex1.m1.1a">
           <mrow id="S3.Ex1.m1.1.2" xref="S3.Ex1.m1.1.2.cmml">
            <msub id="S3.Ex1.m1.1.2.2" xref="S3.Ex1.m1.1.2.2.cmml">
             <mi id="S3.Ex1.m1.1.2.2.2" xref="S3.Ex1.m1.1.2.2.2.cmml">
              ğ
             </mi>
             <mi id="S3.Ex1.m1.1.2.2.3" xref="S3.Ex1.m1.1.2.2.3.cmml">
              ğª
             </mi>
            </msub>
            <mo id="S3.Ex1.m1.1.2.1" rspace="0.111em" xref="S3.Ex1.m1.1.2.1.cmml">
             =
            </mo>
            <mrow id="S3.Ex1.m1.1.2.3" xref="S3.Ex1.m1.1.2.3.cmml">
             <munder id="S3.Ex1.m1.1.2.3.1" xref="S3.Ex1.m1.1.2.3.1.cmml">
              <mo id="S3.Ex1.m1.1.2.3.1.2" movablelimits="false" xref="S3.Ex1.m1.1.2.3.1.2.cmml">
               â‹ƒ
              </mo>
              <mrow id="S3.Ex1.m1.1.2.3.1.3" xref="S3.Ex1.m1.1.2.3.1.3.cmml">
               <mi id="S3.Ex1.m1.1.2.3.1.3.2" xref="S3.Ex1.m1.1.2.3.1.3.2.cmml">
                S
               </mi>
               <mo id="S3.Ex1.m1.1.2.3.1.3.1" xref="S3.Ex1.m1.1.2.3.1.3.1.cmml">
                âˆˆ
               </mo>
               <msub id="S3.Ex1.m1.1.2.3.1.3.3" xref="S3.Ex1.m1.1.2.3.1.3.3.cmml">
                <mi id="S3.Ex1.m1.1.2.3.1.3.3.2" xref="S3.Ex1.m1.1.2.3.1.3.3.2.cmml">
                 ğ‘
                </mi>
                <mi id="S3.Ex1.m1.1.2.3.1.3.3.3" xref="S3.Ex1.m1.1.2.3.1.3.3.3.cmml">
                 ğª
                </mi>
               </msub>
              </mrow>
             </munder>
             <mrow id="S3.Ex1.m1.1.2.3.2" xref="S3.Ex1.m1.1.2.3.2.cmml">
              <mtext class="ltx_mathvariant_monospace" id="S3.Ex1.m1.1.2.3.2.2" xref="S3.Ex1.m1.1.2.3.2.2a.cmml">
               paragraphs
              </mtext>
              <mo id="S3.Ex1.m1.1.2.3.2.1" lspace="0em" rspace="0em" xref="S3.Ex1.m1.1.2.3.2.1.cmml">
               â€‹
              </mo>
              <mrow id="S3.Ex1.m1.1.2.3.2.3.2" xref="S3.Ex1.m1.1.2.3.2.cmml">
               <mo id="S3.Ex1.m1.1.2.3.2.3.2.1" stretchy="false" xref="S3.Ex1.m1.1.2.3.2.cmml">
                (
               </mo>
               <mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">
                S
               </mi>
               <mo id="S3.Ex1.m1.1.2.3.2.3.2.2" stretchy="false" xref="S3.Ex1.m1.1.2.3.2.cmml">
                )
               </mo>
              </mrow>
             </mrow>
            </mrow>
           </mrow>
           <annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b">
            <apply id="S3.Ex1.m1.1.2.cmml" xref="S3.Ex1.m1.1.2">
             <eq id="S3.Ex1.m1.1.2.1.cmml" xref="S3.Ex1.m1.1.2.1">
             </eq>
             <apply id="S3.Ex1.m1.1.2.2.cmml" xref="S3.Ex1.m1.1.2.2">
              <csymbol cd="ambiguous" id="S3.Ex1.m1.1.2.2.1.cmml" xref="S3.Ex1.m1.1.2.2">
               subscript
              </csymbol>
              <ci id="S3.Ex1.m1.1.2.2.2.cmml" xref="S3.Ex1.m1.1.2.2.2">
               ğ
              </ci>
              <ci id="S3.Ex1.m1.1.2.2.3.cmml" xref="S3.Ex1.m1.1.2.2.3">
               ğª
              </ci>
             </apply>
             <apply id="S3.Ex1.m1.1.2.3.cmml" xref="S3.Ex1.m1.1.2.3">
              <apply id="S3.Ex1.m1.1.2.3.1.cmml" xref="S3.Ex1.m1.1.2.3.1">
               <csymbol cd="ambiguous" id="S3.Ex1.m1.1.2.3.1.1.cmml" xref="S3.Ex1.m1.1.2.3.1">
                subscript
               </csymbol>
               <union id="S3.Ex1.m1.1.2.3.1.2.cmml" xref="S3.Ex1.m1.1.2.3.1.2">
               </union>
               <apply id="S3.Ex1.m1.1.2.3.1.3.cmml" xref="S3.Ex1.m1.1.2.3.1.3">
                <in id="S3.Ex1.m1.1.2.3.1.3.1.cmml" xref="S3.Ex1.m1.1.2.3.1.3.1">
                </in>
                <ci id="S3.Ex1.m1.1.2.3.1.3.2.cmml" xref="S3.Ex1.m1.1.2.3.1.3.2">
                 ğ‘†
                </ci>
                <apply id="S3.Ex1.m1.1.2.3.1.3.3.cmml" xref="S3.Ex1.m1.1.2.3.1.3.3">
                 <csymbol cd="ambiguous" id="S3.Ex1.m1.1.2.3.1.3.3.1.cmml" xref="S3.Ex1.m1.1.2.3.1.3.3">
                  subscript
                 </csymbol>
                 <ci id="S3.Ex1.m1.1.2.3.1.3.3.2.cmml" xref="S3.Ex1.m1.1.2.3.1.3.3.2">
                  ğ‘
                 </ci>
                 <ci id="S3.Ex1.m1.1.2.3.1.3.3.3.cmml" xref="S3.Ex1.m1.1.2.3.1.3.3.3">
                  ğª
                 </ci>
                </apply>
               </apply>
              </apply>
              <apply id="S3.Ex1.m1.1.2.3.2.cmml" xref="S3.Ex1.m1.1.2.3.2">
               <times id="S3.Ex1.m1.1.2.3.2.1.cmml" xref="S3.Ex1.m1.1.2.3.2.1">
               </times>
               <ci id="S3.Ex1.m1.1.2.3.2.2a.cmml" xref="S3.Ex1.m1.1.2.3.2.2">
                <mtext class="ltx_mathvariant_monospace" id="S3.Ex1.m1.1.2.3.2.2.cmml" xref="S3.Ex1.m1.1.2.3.2.2">
                 paragraphs
                </mtext>
               </ci>
               <ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">
                ğ‘†
               </ci>
              </apply>
             </apply>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">
            \mathbf{P}_{\mathbf{q}}=\bigcup_{S\in\mathbf{R}_{\mathbf{q}}}\texttt{paragraphs}(S)
           </annotation>
          </semantics>
         </math>
        </td>
        <td class="ltx_eqn_cell ltx_eqn_center_padright">
        </td>
       </tr>
      </tbody>
     </table>
     <p class="ltx_p" id="S3.SS3.SSS2.p1.4">
      Thereafter, one of the following strategy can be employed for fine-grained retrieval:
     </p>
     <ol class="ltx_enumerate" id="S3.I1">
      <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        1.
       </span>
       <div class="ltx_para" id="S3.I1.i1.p1">
        <p class="ltx_p" id="S3.I1.i1.p1.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.I1.i1.p1.1.1">
          MonoT5
         </span>
         : This employs MonoT5
         <cite class="ltx_cite ltx_citemacro_cite">
          Nogueira etÂ al. (
          <a class="ltx_ref" href="#bib.bib39" title="">
           2020
          </a>
          )
         </cite>
         , which a sequence-to-sequence model trained over the task of Document Re-ranking
         <cite class="ltx_cite ltx_citemacro_cite">
          Nguyen etÂ al. (
          <a class="ltx_ref" href="#bib.bib37" title="">
           2016
          </a>
          )
         </cite>
         , to select the most relevant paragraphs from
         <math alttext="\mathbf{P}_{\mathbf{q}}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1">
          <semantics id="S3.I1.i1.p1.1.m1.1a">
           <msub id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">
            <mi id="S3.I1.i1.p1.1.m1.1.1.2" xref="S3.I1.i1.p1.1.m1.1.1.2.cmml">
             ğ
            </mi>
            <mi id="S3.I1.i1.p1.1.m1.1.1.3" xref="S3.I1.i1.p1.1.m1.1.1.3.cmml">
             ğª
            </mi>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b">
            <apply id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S3.I1.i1.p1.1.m1.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2">
              ğ
             </ci>
             <ci id="S3.I1.i1.p1.1.m1.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3">
              ğª
             </ci>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">
            \mathbf{P}_{\mathbf{q}}
           </annotation>
          </semantics>
         </math>
         .
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        2.
       </span>
       <div class="ltx_para" id="S3.I1.i2.p1">
        <p class="ltx_p" id="S3.I1.i2.p1.3">
         <span class="ltx_text ltx_font_smallcaps" id="S3.I1.i2.p1.3.1">
          Base
         </span>
         : Each paragraph from
         <math alttext="\mathbf{P}_{\mathbf{q}}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1">
          <semantics id="S3.I1.i2.p1.1.m1.1a">
           <msub id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml">
            <mi id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml">
             ğ
            </mi>
            <mi id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml">
             ğª
            </mi>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b">
            <apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">
              ğ
             </ci>
             <ci id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">
              ğª
             </ci>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">
            \mathbf{P}_{\mathbf{q}}
           </annotation>
          </semantics>
         </math>
         is marked with an identifier and then, these identifier annotated paragraphs are concatenated with a newline separator. Thereafter, we prompt the LLM in a zero-shot manner to generate all paragraph identifiers whose corresponding paragraph is relevant to
         <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1">
          <semantics id="S3.I1.i2.p1.2.m2.1a">
           <mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">
            ğª
           </mi>
           <annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b">
            <ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">
             ğª
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">
            \mathbf{q}
           </annotation>
          </semantics>
         </math>
         . If the number of paragraphs in
         <math alttext="\mathbf{P}_{\mathbf{q}}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.1">
          <semantics id="S3.I1.i2.p1.3.m3.1a">
           <msub id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml">
            <mi id="S3.I1.i2.p1.3.m3.1.1.2" xref="S3.I1.i2.p1.3.m3.1.1.2.cmml">
             ğ
            </mi>
            <mi id="S3.I1.i2.p1.3.m3.1.1.3" xref="S3.I1.i2.p1.3.m3.1.1.3.cmml">
             ğª
            </mi>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b">
            <apply id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">
             <csymbol cd="ambiguous" id="S3.I1.i2.p1.3.m3.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">
              subscript
             </csymbol>
             <ci id="S3.I1.i2.p1.3.m3.1.1.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.2">
              ğ
             </ci>
             <ci id="S3.I1.i2.p1.3.m3.1.1.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3">
              ğª
             </ci>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">
            \mathbf{P}_{\mathbf{q}}
           </annotation>
          </semantics>
         </math>
         exceeds the maximum context length of LLM, we make multiple LLM calls. In each call, we fit the maximum number of paragraphs that can fit into the context length, ensuring that paragraphs are not â€˜choppedâ€™.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        3.
       </span>
       <div class="ltx_para" id="S3.I1.i3.p1">
        <p class="ltx_p" id="S3.I1.i3.p1.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.I1.i3.p1.1.1">
          HierBase
         </span>
         : In our approach, we adopt a two-step process to capture the essence of each paragraph. Firstly, we represent paragraphs using their corresponding summaries obtained through
         <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1">
          <semantics id="S3.I1.i3.p1.1.m1.1a">
           <mi class="ltx_font_mathcaligraphic" id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml">
            ğ’®
           </mi>
           <annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b">
            <ci id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1">
             ğ’®
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">
            \mathcal{S}
           </annotation>
          </semantics>
         </math>
         . Following that, we employ the
         <span class="ltx_text ltx_font_smallcaps" id="S3.I1.i3.p1.1.2">
          Base
         </span>
         strategy to identify potentially relevant candidates. In the next stage, we apply the
         <span class="ltx_text ltx_font_smallcaps" id="S3.I1.i3.p1.1.3">
          Base
         </span>
         technique once again, this time considering the original content of the paragraphs, to pinpoint the most relevant ones.
        </p>
       </div>
      </li>
     </ol>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS2.p2">
     <p class="ltx_p" id="S3.SS3.SSS2.p2.1">
      In our experimental evaluation, we also explore the effectiveness of chaining these strategies in succession. One such method, called
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.SSS2.p2.1.1">
       Base + MonoT5
      </span>
      , combines the
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.SSS2.p2.1.2">
       Base
      </span>
      strategy with
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.SSS2.p2.1.3">
       MonoT5
      </span>
      . This approach initially identifies a relevant set of paragraphs using the
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.SSS2.p2.1.4">
       Base
      </span>
      strategy and subsequently employs
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.SSS2.p2.1.5">
       MonoT5
      </span>
      to refine the selection further, retaining only the most relevant ones from the initially identified set.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS2.p3">
     <p class="ltx_p" id="S3.SS3.SSS2.p3.2">
      For most of the experiments presented in the upcoming sections, we use
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.2.1">
       bart-large
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       Lewis etÂ al. (
       <a class="ltx_ref" href="#bib.bib30" title="">
        2020
       </a>
       )
      </cite>
      trained over the CNN/Daily-Mail Corpus
      <cite class="ltx_cite ltx_citemacro_cite">
       Nallapati etÂ al. (
       <a class="ltx_ref" href="#bib.bib36" title="">
        2016
       </a>
       )
      </cite>
      for
      <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.1.m1.1">
       <semantics id="S3.SS3.SSS2.p3.1.m1.1a">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p3.1.m1.1.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.cmml">
         ğ’®
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.1.m1.1b">
         <ci id="S3.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1">
          ğ’®
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.1.m1.1c">
         \mathcal{S}
        </annotation>
       </semantics>
      </math>
      . For retrieval and question answering, we utilize the highly capable
      <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S3.SS3.SSS2.p3.2.2">
       gpt-3.5-turbo
      </span>
      model, known for its remarkable performance across a wide range of NLP tasks, all while being more cost-effective
      <cite class="ltx_cite ltx_citemacro_cite">
       Ye etÂ al. (
       <a class="ltx_ref" href="#bib.bib62" title="">
        2023
       </a>
       )
      </cite>
      when compared against
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.2.3">
       text-davinci-003
      </span>
      . To identify the most relevant sectionsÂ§
      <a class="ltx_ref" href="#S3.SS3.SSS1" title="3.3.1 Finding Relevant Sections â€£ 3.3 Methodology â€£ 3 ğƒÂ³: Drilling Down into the Discourse â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
       <span class="ltx_text ltx_ref_tag">
        3.3.1
       </span>
      </a>
      , we prompt the LLM with the following instruction:
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS2.p3.5">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.5.1">
       Document section structure:
       <br class="ltx_break"/>
      </span>
      {
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.5.2">
       Condensed representation described in Â§
       <a class="ltx_ref" href="#S3.SS3.SSS1" title="3.3.1 Finding Relevant Sections â€£ 3.3 Methodology â€£ 3 ğƒÂ³: Drilling Down into the Discourse â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
        <span class="ltx_text ltx_ref_tag">
         3.3.1
        </span>
       </a>
      </span>
      }
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS2.p3.3.1">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.3.1.1">
       Question:
       <br class="ltx_break"/>
      </span>
      {
      <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.3.1.m1.1">
       <semantics id="S3.SS3.SSS2.p3.3.1.m1.1a">
        <mi id="S3.SS3.SSS2.p3.3.1.m1.1.1" xref="S3.SS3.SSS2.p3.3.1.m1.1.1.cmml">
         ğª
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.3.1.m1.1b">
         <ci id="S3.SS3.SSS2.p3.3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p3.3.1.m1.1.1">
          ğª
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.3.1.m1.1c">
         \mathbf{q}
        </annotation>
       </semantics>
      </math>
      }
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS2.p3.6">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.6.1">
       List all section names that may be relevant for answering the question. Respond with comma-separated section name list. Provide an empty response if none of the sections are relevant.
      </span>
     </p>
     <p class="ltx_p" id="S3.SS3.SSS2.p3.7">
      For the
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.SSS2.p3.7.1">
       Base
      </span>
      strategy described in Â§
      <a class="ltx_ref" href="#S3.SS3.SSS2" title="3.3.2 Fine-Grained Evidence Retrieval â€£ 3.3 Methodology â€£ 3 ğƒÂ³: Drilling Down into the Discourse â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
       <span class="ltx_text ltx_ref_tag">
        3.3.2
       </span>
      </a>
      , we employ the following prompt:
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS2.p3.8">
      {
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.8.1">
       Paragraphs annotated with identifier (Â§
       <a class="ltx_ref" href="#S3.SS3.SSS2" title="3.3.2 Fine-Grained Evidence Retrieval â€£ 3.3 Methodology â€£ 3 ğƒÂ³: Drilling Down into the Discourse â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
        <span class="ltx_text ltx_ref_tag">
         3.3.2
        </span>
       </a>
       )
      </span>
      }
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS2.p3.4.1">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.4.1.1">
       Question:
       <br class="ltx_break"/>
      </span>
      {
      <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.4.1.m1.1">
       <semantics id="S3.SS3.SSS2.p3.4.1.m1.1a">
        <mi id="S3.SS3.SSS2.p3.4.1.m1.1.1" xref="S3.SS3.SSS2.p3.4.1.m1.1.1.cmml">
         ğª
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.4.1.m1.1b">
         <ci id="S3.SS3.SSS2.p3.4.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p3.4.1.m1.1.1">
          ğª
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.4.1.m1.1c">
         \mathbf{q}
        </annotation>
       </semantics>
      </math>
      }
     </p>
     <p class="ltx_p ltx_align_center" id="S3.SS3.SSS2.p3.9">
      <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS2.p3.9.1">
       Find paragraph ids that contains relevant information for answering the question. Respond with comma-separated id list. Provide an empty response if none of the paragraphs are relevant.
      </span>
     </p>
    </div>
    <figure class="ltx_table" id="S3.T1">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.2">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S3.T1.2.3.1">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.3.1.1" rowspan="2">
         <span class="ltx_text" id="S3.T1.2.3.1.1.1">
          Approach
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S3.T1.2.3.1.2">
         Answering Performance
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.3.1.3">
         Evidence
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.3.1.4">
         Tokens
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.3.1.5">
         API
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.1.1">
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.2">
         Extractive
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.3">
         Abstractive
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.4">
         Yes/No
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.5">
         Unanswerable
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.6">
         Overall
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.1">
         <math alttext="F_{1}" class="ltx_Math" display="inline" id="S3.T1.1.1.1.m1.1">
          <semantics id="S3.T1.1.1.1.m1.1a">
           <msub id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">
            <mi id="S3.T1.1.1.1.m1.1.1.2" xref="S3.T1.1.1.1.m1.1.1.2.cmml">
             F
            </mi>
            <mn id="S3.T1.1.1.1.m1.1.1.3" xref="S3.T1.1.1.1.m1.1.1.3.cmml">
             1
            </mn>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b">
            <apply id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S3.T1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S3.T1.1.1.1.m1.1.1.2.cmml" xref="S3.T1.1.1.1.m1.1.1.2">
              ğ¹
             </ci>
             <cn id="S3.T1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1.3">
              1
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">
            F_{1}
           </annotation>
          </semantics>
         </math>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.7">
         Processed
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.1.1.8">
         Calls
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.4.2">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.4.2.1.1">
          Human
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          Dasigi etÂ al. (
          <a class="ltx_ref" href="#bib.bib14" title="">
           2021
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.2">
         58.92
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.3">
         39.71
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.4">
         78.98
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.5">
         69.44
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.6">
         60.92
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.7">
         71.62
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.8">
         -
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.2.9">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.5.3">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.5.3.1.1">
          CGSN
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          Nie etÂ al. (
          <a class="ltx_ref" href="#bib.bib38" title="">
           2022
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.2">
         34.75
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.3">
         14.39
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.4">
         68.14
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.5">
         71.84
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.6">
         39.44
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.7">
         53.98
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.8">
         -
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.5.3.9">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.6.4">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.6.4.1.1">
          LED
         </span>
         *
         <cite class="ltx_cite ltx_citemacro_cite">
          Nie etÂ al. (
          <a class="ltx_ref" href="#bib.bib38" title="">
           2022
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.2">
         52.41
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.3">
         23.44
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.4">
         76.96
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.5">
         77.91
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.6">
         52.87
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.7">
         -
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.8">
         -
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.6.4.9">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.7.5">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.1">
         <span class="ltx_text ltx_font_typewriter" id="S3.T1.2.7.5.1.1">
          gpt-3.5-turbo
         </span>
         *
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.2">
         54.86
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.3">
         27.74
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.4">
         81.50
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.5">
         95.76
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.6">
         57.99
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.7">
         -
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.8">
         -
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.7.5.9">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.8.6">
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S3.T1.2.8.6.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.8.6.1.1">
          Zero-Shot / Unsupervised Methods
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.9.7">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.9.7.1.1">
          MonoT5
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          Nogueira etÂ al. (
          <a class="ltx_ref" href="#bib.bib39" title="">
           2020
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.2">
         42.84
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.3">
         25.84
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.4">
         82.23
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.5">
         69.09
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.6">
         47.21
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.7">
         34.23
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.8">
         -
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.9.7.9">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.10.8">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.10.8.1.1">
          DPR
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          Karpukhin etÂ al. (
          <a class="ltx_ref" href="#bib.bib28" title="">
           2020
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.2">
         31.58
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.3">
         18.57
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.4">
         78.46
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.5">
         84.33
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.6">
         42.11
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.7">
         19.32
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.8">
         -
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.10.8.9">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.11.9">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.1">
         <span class="ltx_text ltx_font_typewriter" id="S3.T1.2.11.9.1.1">
          cross-encoder-ms-marco-MiniLM-L-12-v2
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.2">
         38.69
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.3">
         23.25
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.4">
         78.04
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.5">
         71.42
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.6">
         43.48
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.7">
         30.76
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.8">
         -
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.11.9.9">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.12.10">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.12.10.1.1">
          Paragraph
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.2">
         45.20
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.3">
         26.02
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.4">
         76.13
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.5">
         72.56
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.6">
         47.92
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.7">
         32.02
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.8">
         8519.37
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.12.10.9">
         47.24
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.13.11">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.13.11.1.1">
          Chunk
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.2">
         45.96
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.3">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.13.11.3.1">
          29.61
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.4">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.13.11.4.1">
          84.30
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.5">
         65.57
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.6">
         49.00
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.7">
         35.59
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.8">
         5411.44
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.13.11.9">
         2.44
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.14.12">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.14.12.1.1">
          Map-Reduce
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.2">
         21.37
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.3">
         19.65
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.4">
         76.47
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.5">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.14.12.5.1">
          90.28
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.6">
         39.26
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.7">
         12.84
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.8">
         12730.13
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.14.12.9">
         48.24
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.15.13">
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.15.13.1.1">
          Map-Reduce Optimized
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.2">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.15.13.2.1">
          47.45
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.3">
         26.05
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.4">
         82.79
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.5">
         71.32
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.6">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.15.13.6.1">
          50.13
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.7">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.15.13.7.1">
          50.11
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.8">
         7491.97
        </td>
        <td class="ltx_td ltx_align_center" id="S3.T1.2.15.13.9">
         3.69
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T1.2.2">
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.1">
         <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S3.T1.2.2.1.m1.1">
          <semantics id="S3.T1.2.2.1.m1.1a">
           <msup id="S3.T1.2.2.1.m1.1.1" xref="S3.T1.2.2.1.m1.1.1.cmml">
            <mi id="S3.T1.2.2.1.m1.1.1.2" xref="S3.T1.2.2.1.m1.1.1.2.cmml">
             ğƒ
            </mi>
            <mn id="S3.T1.2.2.1.m1.1.1.3" xref="S3.T1.2.2.1.m1.1.1.3.cmml">
             3
            </mn>
           </msup>
           <annotation-xml encoding="MathML-Content" id="S3.T1.2.2.1.m1.1b">
            <apply id="S3.T1.2.2.1.m1.1.1.cmml" xref="S3.T1.2.2.1.m1.1.1">
             <csymbol cd="ambiguous" id="S3.T1.2.2.1.m1.1.1.1.cmml" xref="S3.T1.2.2.1.m1.1.1">
              superscript
             </csymbol>
             <ci id="S3.T1.2.2.1.m1.1.1.2.cmml" xref="S3.T1.2.2.1.m1.1.1.2">
              ğƒ
             </ci>
             <cn id="S3.T1.2.2.1.m1.1.1.3.cmml" type="integer" xref="S3.T1.2.2.1.m1.1.1.3">
              3
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.T1.2.2.1.m1.1c">
            \mathbf{D}^{3}
           </annotation>
          </semantics>
         </math>
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.2.1.1">
          -Base
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.2">
         42.90
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.3">
         23.65
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.4">
         74.35
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.5">
         79.61
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.6">
         47.45
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.7">
         49.92
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.8">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.2.8.1">
          1980.94
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.2.9">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.2.9.1">
          1.99
         </span>
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 1:
      </span>
      <span class="ltx_text ltx_font_bold" id="S3.T1.6.1">
       Comparison of various zero-shot approaches against SoTA methods for QASPER dataset.
      </span>
      The simplest algorithm from
      <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S3.T1.4.m1.1">
       <semantics id="S3.T1.4.m1.1b">
        <msup id="S3.T1.4.m1.1.1" xref="S3.T1.4.m1.1.1.cmml">
         <mi id="S3.T1.4.m1.1.1.2" xref="S3.T1.4.m1.1.1.2.cmml">
          ğƒ
         </mi>
         <mn id="S3.T1.4.m1.1.1.3" xref="S3.T1.4.m1.1.1.3.cmml">
          3
         </mn>
        </msup>
        <annotation-xml encoding="MathML-Content" id="S3.T1.4.m1.1c">
         <apply id="S3.T1.4.m1.1.1.cmml" xref="S3.T1.4.m1.1.1">
          <csymbol cd="ambiguous" id="S3.T1.4.m1.1.1.1.cmml" xref="S3.T1.4.m1.1.1">
           superscript
          </csymbol>
          <ci id="S3.T1.4.m1.1.1.2.cmml" xref="S3.T1.4.m1.1.1.2">
           ğƒ
          </ci>
          <cn id="S3.T1.4.m1.1.1.3.cmml" type="integer" xref="S3.T1.4.m1.1.1.3">
           3
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.T1.4.m1.1d">
         \mathbf{D}^{3}
        </annotation>
       </semantics>
      </math>
      family yields competitive value across several metrics while being zero-shot and requiring least number of tokens. *: Inference obtained using gold evidence.
     </figcaption>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Baselines:
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.8">
    We consider the following zero-shot approaches for performance comparison:
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S4.p1.8.1">
     (1)
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.2">
     MonoT5
    </span>
    : In this approach,
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.3">
     MonoT5
    </span>
    is directly applied to re-rank the paragraphs of
    <math alttext="\mathbf{D}=[p_{1},p_{2},\dots,p_{n}]" class="ltx_Math" display="inline" id="S4.p1.1.m1.4">
     <semantics id="S4.p1.1.m1.4a">
      <mrow id="S4.p1.1.m1.4.4" xref="S4.p1.1.m1.4.4.cmml">
       <mi id="S4.p1.1.m1.4.4.5" xref="S4.p1.1.m1.4.4.5.cmml">
        ğƒ
       </mi>
       <mo id="S4.p1.1.m1.4.4.4" xref="S4.p1.1.m1.4.4.4.cmml">
        =
       </mo>
       <mrow id="S4.p1.1.m1.4.4.3.3" xref="S4.p1.1.m1.4.4.3.4.cmml">
        <mo id="S4.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S4.p1.1.m1.4.4.3.4.cmml">
         [
        </mo>
        <msub id="S4.p1.1.m1.2.2.1.1.1" xref="S4.p1.1.m1.2.2.1.1.1.cmml">
         <mi id="S4.p1.1.m1.2.2.1.1.1.2" xref="S4.p1.1.m1.2.2.1.1.1.2.cmml">
          p
         </mi>
         <mn id="S4.p1.1.m1.2.2.1.1.1.3" xref="S4.p1.1.m1.2.2.1.1.1.3.cmml">
          1
         </mn>
        </msub>
        <mo id="S4.p1.1.m1.4.4.3.3.5" xref="S4.p1.1.m1.4.4.3.4.cmml">
         ,
        </mo>
        <msub id="S4.p1.1.m1.3.3.2.2.2" xref="S4.p1.1.m1.3.3.2.2.2.cmml">
         <mi id="S4.p1.1.m1.3.3.2.2.2.2" xref="S4.p1.1.m1.3.3.2.2.2.2.cmml">
          p
         </mi>
         <mn id="S4.p1.1.m1.3.3.2.2.2.3" xref="S4.p1.1.m1.3.3.2.2.2.3.cmml">
          2
         </mn>
        </msub>
        <mo id="S4.p1.1.m1.4.4.3.3.6" xref="S4.p1.1.m1.4.4.3.4.cmml">
         ,
        </mo>
        <mi id="S4.p1.1.m1.1.1" mathvariant="normal" xref="S4.p1.1.m1.1.1.cmml">
         â€¦
        </mi>
        <mo id="S4.p1.1.m1.4.4.3.3.7" xref="S4.p1.1.m1.4.4.3.4.cmml">
         ,
        </mo>
        <msub id="S4.p1.1.m1.4.4.3.3.3" xref="S4.p1.1.m1.4.4.3.3.3.cmml">
         <mi id="S4.p1.1.m1.4.4.3.3.3.2" xref="S4.p1.1.m1.4.4.3.3.3.2.cmml">
          p
         </mi>
         <mi id="S4.p1.1.m1.4.4.3.3.3.3" xref="S4.p1.1.m1.4.4.3.3.3.3.cmml">
          n
         </mi>
        </msub>
        <mo id="S4.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S4.p1.1.m1.4.4.3.4.cmml">
         ]
        </mo>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.4b">
       <apply id="S4.p1.1.m1.4.4.cmml" xref="S4.p1.1.m1.4.4">
        <eq id="S4.p1.1.m1.4.4.4.cmml" xref="S4.p1.1.m1.4.4.4">
        </eq>
        <ci id="S4.p1.1.m1.4.4.5.cmml" xref="S4.p1.1.m1.4.4.5">
         ğƒ
        </ci>
        <list id="S4.p1.1.m1.4.4.3.4.cmml" xref="S4.p1.1.m1.4.4.3.3">
         <apply id="S4.p1.1.m1.2.2.1.1.1.cmml" xref="S4.p1.1.m1.2.2.1.1.1">
          <csymbol cd="ambiguous" id="S4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S4.p1.1.m1.2.2.1.1.1">
           subscript
          </csymbol>
          <ci id="S4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S4.p1.1.m1.2.2.1.1.1.2">
           ğ‘
          </ci>
          <cn id="S4.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S4.p1.1.m1.2.2.1.1.1.3">
           1
          </cn>
         </apply>
         <apply id="S4.p1.1.m1.3.3.2.2.2.cmml" xref="S4.p1.1.m1.3.3.2.2.2">
          <csymbol cd="ambiguous" id="S4.p1.1.m1.3.3.2.2.2.1.cmml" xref="S4.p1.1.m1.3.3.2.2.2">
           subscript
          </csymbol>
          <ci id="S4.p1.1.m1.3.3.2.2.2.2.cmml" xref="S4.p1.1.m1.3.3.2.2.2.2">
           ğ‘
          </ci>
          <cn id="S4.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S4.p1.1.m1.3.3.2.2.2.3">
           2
          </cn>
         </apply>
         <ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">
          â€¦
         </ci>
         <apply id="S4.p1.1.m1.4.4.3.3.3.cmml" xref="S4.p1.1.m1.4.4.3.3.3">
          <csymbol cd="ambiguous" id="S4.p1.1.m1.4.4.3.3.3.1.cmml" xref="S4.p1.1.m1.4.4.3.3.3">
           subscript
          </csymbol>
          <ci id="S4.p1.1.m1.4.4.3.3.3.2.cmml" xref="S4.p1.1.m1.4.4.3.3.3.2">
           ğ‘
          </ci>
          <ci id="S4.p1.1.m1.4.4.3.3.3.3.cmml" xref="S4.p1.1.m1.4.4.3.3.3.3">
           ğ‘›
          </ci>
         </apply>
        </list>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.1.m1.4c">
       \mathbf{D}=[p_{1},p_{2},\dots,p_{n}]
      </annotation>
     </semantics>
    </math>
    based on
    <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S4.p1.2.m2.1">
     <semantics id="S4.p1.2.m2.1a">
      <mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">
       ğª
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b">
       <ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">
        ğª
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">
       \mathbf{q}
      </annotation>
     </semantics>
    </math>
    .
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S4.p1.8.4">
     (2)
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.5">
     DPR
    </span>
    : Dense Passage Retrieval (DPR)
    <cite class="ltx_cite ltx_citemacro_cite">
     Karpukhin etÂ al. (
     <a class="ltx_ref" href="#bib.bib28" title="">
      2020
     </a>
     )
    </cite>
    is a retrieval approach that leverages dense representations. This method utilizes a bi-encoder architecture to generate embeddings for both the documents and the query independently which are used for finding the most relevant documents.
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S4.p1.8.6">
     (3)
    </span>
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.8.7">
     cross-encoder-ms-marco-MiniLM-L-12-v2
    </span>
    : This model is a cross-encoder reranker which employs Siamese learning and BERT-like architecture. This model is offered in the
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.8.8">
     sentence-transformers
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     Reimers and Gurevych (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2019
     </a>
     )
    </cite>
    library. While the library provides many different model checkpoints, we chose
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.8.9">
     cross-encoder-ms-marco-MiniLM-L-12-v2
    </span>
    as it yielded highest
    <math alttext="F_{1}" class="ltx_Math" display="inline" id="S4.p1.3.m3.1">
     <semantics id="S4.p1.3.m3.1a">
      <msub id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">
       <mi id="S4.p1.3.m3.1.1.2" xref="S4.p1.3.m3.1.1.2.cmml">
        F
       </mi>
       <mn id="S4.p1.3.m3.1.1.3" xref="S4.p1.3.m3.1.1.3.cmml">
        1
       </mn>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b">
       <apply id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">
        <csymbol cd="ambiguous" id="S4.p1.3.m3.1.1.1.cmml" xref="S4.p1.3.m3.1.1">
         subscript
        </csymbol>
        <ci id="S4.p1.3.m3.1.1.2.cmml" xref="S4.p1.3.m3.1.1.2">
         ğ¹
        </ci>
        <cn id="S4.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.p1.3.m3.1.1.3">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">
       F_{1}
      </annotation>
     </semantics>
    </math>
    score for evidence retrieval.
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S4.p1.8.10">
     (4)
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.11">
     Paragraph
    </span>
    : Every paragraph in
    <math alttext="\mathbf{D}" class="ltx_Math" display="inline" id="S4.p1.4.m4.1">
     <semantics id="S4.p1.4.m4.1a">
      <mi id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">
       ğƒ
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b">
       <ci id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">
        ğƒ
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">
       \mathbf{D}
      </annotation>
     </semantics>
    </math>
    is processed by the LLM independently to assess its relevance to
    <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S4.p1.5.m5.1">
     <semantics id="S4.p1.5.m5.1a">
      <mi id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">
       ğª
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b">
       <ci id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">
        ğª
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">
       \mathbf{q}
      </annotation>
     </semantics>
    </math>
    through a boolean prompt.
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S4.p1.8.12">
     (5)
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.13">
     Chunk
    </span>
    : The document is partitioned into consecutive fragments, aiming to accommodate as many paragraphs as possible within a predefined token limit called as chunk size (
    <math alttext="3500" class="ltx_Math" display="inline" id="S4.p1.6.m6.1">
     <semantics id="S4.p1.6.m6.1a">
      <mn id="S4.p1.6.m6.1.1" xref="S4.p1.6.m6.1.1.cmml">
       3500
      </mn>
      <annotation-xml encoding="MathML-Content" id="S4.p1.6.m6.1b">
       <cn id="S4.p1.6.m6.1.1.cmml" type="integer" xref="S4.p1.6.m6.1.1">
        3500
       </cn>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.6.m6.1c">
       3500
      </annotation>
     </semantics>
    </math>
    ). Subsequently,
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.14">
     Base
    </span>
    is applied for each fragment.
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S4.p1.8.15">
     (6)
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.16">
     Map-Reduce
    </span>
    : This approach, widely adopted in the literature, involves evaluating the relevance of each paragraph to
    <math alttext="\mathbf{q}" class="ltx_Math" display="inline" id="S4.p1.7.m7.1">
     <semantics id="S4.p1.7.m7.1a">
      <mi id="S4.p1.7.m7.1.1" xref="S4.p1.7.m7.1.1.cmml">
       ğª
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.p1.7.m7.1b">
       <ci id="S4.p1.7.m7.1.1.cmml" xref="S4.p1.7.m7.1.1">
        ğª
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.7.m7.1c">
       \mathbf{q}
      </annotation>
     </semantics>
    </math>
    and subsequently processing the relevant paragraphs together in a single call to the LLM. However, we observed that using
    <cite class="ltx_cite ltx_citemacro_citeauthor">
     <a class="ltx_ref" href="#bib.bib29" title="">
      LangChain
     </a>
    </cite>
    â€™s implementation directly led to subpar performance in terms of evidence retrieval
    <math alttext="F_{1}" class="ltx_Math" display="inline" id="S4.p1.8.m8.1">
     <semantics id="S4.p1.8.m8.1a">
      <msub id="S4.p1.8.m8.1.1" xref="S4.p1.8.m8.1.1.cmml">
       <mi id="S4.p1.8.m8.1.1.2" xref="S4.p1.8.m8.1.1.2.cmml">
        F
       </mi>
       <mn id="S4.p1.8.m8.1.1.3" xref="S4.p1.8.m8.1.1.3.cmml">
        1
       </mn>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S4.p1.8.m8.1b">
       <apply id="S4.p1.8.m8.1.1.cmml" xref="S4.p1.8.m8.1.1">
        <csymbol cd="ambiguous" id="S4.p1.8.m8.1.1.1.cmml" xref="S4.p1.8.m8.1.1">
         subscript
        </csymbol>
        <ci id="S4.p1.8.m8.1.1.2.cmml" xref="S4.p1.8.m8.1.1.2">
         ğ¹
        </ci>
        <cn id="S4.p1.8.m8.1.1.3.cmml" type="integer" xref="S4.p1.8.m8.1.1.3">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.8.m8.1c">
       F_{1}
      </annotation>
     </semantics>
    </math>
    -score and inference cost. This can be attributed to the incompatibility of the prompt with the target domain, resulting in significant performance degradation due to
    <span class="ltx_text ltx_font_typewriter" id="S4.p1.8.17">
     gpt-3.5-turbo
    </span>
    â€™s high sensitivity to the prompt
    <cite class="ltx_cite ltx_citemacro_cite">
     Ye etÂ al. (
     <a class="ltx_ref" href="#bib.bib62" title="">
      2023
     </a>
     )
    </cite>
    .
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S4.p1.8.18">
     (7)
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.19">
     Map-Reduce Optimized
    </span>
    : For better alignment with our target task, we made crucial modifications to the original implementation. Building upon the observation that
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.20">
     Chunk
    </span>
    outperforms
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.21">
     Paragraph
    </span>
    in terms of performance, we decided to process document chunks instead of individual paragraphs using the
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.22">
     Base
    </span>
    technique. Following the initial stage, where relevant paragraphs are identified, we concatenate them and subject them to the same strategy (
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.8.23">
     Base
    </span>
    ) for further processing.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Experiments and Results
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.2">
    We mainly assess the applicability of our method in two scenarios:
    <span class="ltx_text ltx_font_bold" id="S5.p1.2.1">
     (1)
    </span>
    Â§
    <a class="ltx_ref" href="#S5.SS1" title="5.1 Performance for Information-Seeking Setting â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
     <span class="ltx_text ltx_ref_tag">
      5.1
     </span>
    </a>
    : Information-seeking setting
    <cite class="ltx_cite ltx_citemacro_cite">
     Dasigi etÂ al. (
     <a class="ltx_ref" href="#bib.bib14" title="">
      2021
     </a>
     )
    </cite>
    and
    <span class="ltx_text ltx_font_bold" id="S5.p1.2.2">
     (2)
    </span>
    Â§
    <a class="ltx_ref" href="#S5.SS1" title="5.1 Performance for Information-Seeking Setting â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
     <span class="ltx_text ltx_ref_tag">
      5.1
     </span>
    </a>
    : Multi-hop Reasoning in Question Answering
    <cite class="ltx_cite ltx_citemacro_cite">
     Yang etÂ al. (
     <a class="ltx_ref" href="#bib.bib60" title="">
      2018
     </a>
     )
    </cite>
    . Thereafter, we conduct an extensive analysis of our approachâ€™s performance across various configurations, as discussed in Â§
    <a class="ltx_ref" href="#S5.SS3.SSS1" title="5.3.1 Performance of different configurations of ğƒÂ³ â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
     <span class="ltx_text ltx_ref_tag">
      5.3.1
     </span>
    </a>
    , and examine its effectiveness in different document length categories, as outlined in Â§
    <a class="ltx_ref" href="#S5.SS3.SSS2" title="5.3.2 Performance across Different Document Length categories â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
     <span class="ltx_text ltx_ref_tag">
      5.3.2
     </span>
    </a>
    . Thereafter, we justify the need for the inclusion of global context modeling in Â§
    <a class="ltx_ref" href="#S5.SS3.SSS3" title="5.3.3 Need for Global Context Modeling â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
     <span class="ltx_text ltx_ref_tag">
      5.3.3
     </span>
    </a>
    , and highlight the significance of incorporating discourse information in Â§
    <a class="ltx_ref" href="#S5.SS3.SSS4" title="5.3.4 Role of Discourse Headings and Sub-headings â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
     <span class="ltx_text ltx_ref_tag">
      5.3.4
     </span>
    </a>
    . Finally, Â§
    <a class="ltx_ref" href="#S5.SS3.SSS5" title="5.3.5 Evidence Retrieval Performance over Question Categories â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
     <span class="ltx_text ltx_ref_tag">
      5.3.5
     </span>
    </a>
    we compare our methods performance with the best performing zero-shot approach for different categories and identify scope for improvement. In our analyses, we will also include insights into the inference cost and latency associated with utilizing large language models (LLMs) for the
    <span class="ltx_text ltx_font_bold" id="S5.p1.2.3">
     evidence retrieval stage
    </span>
    . This will encompass the monetary cost and the processing efficiency measured in terms of the number of tokens processed and the number of LLM inferences. It is important to note that these measurements pertain exclusively to LLMs and do not encompass smaller fine-tuned models. Unless otherwise specified, we would be using
    <span class="ltx_text ltx_font_smallcaps" id="S5.p1.2.4">
     Base
    </span>
    approach for fine-grained retrieval and the overall approach would be called
    <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.p1.1.m1.1">
     <semantics id="S5.p1.1.m1.1a">
      <msup id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">
       <mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">
        ğƒ
       </mi>
       <mn id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">
        3
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b">
       <apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">
        <csymbol cd="ambiguous" id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1">
         superscript
        </csymbol>
        <ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">
         ğƒ
        </ci>
        <cn id="S5.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.p1.1.m1.1.1.3">
         3
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">
       \mathbf{D}^{3}
      </annotation>
     </semantics>
    </math>
    -
    <span class="ltx_text ltx_font_smallcaps" id="S5.p1.2.5">
     Base
    </span>
    . Due to the monetary cost associated with
    <span class="ltx_text ltx_font_typewriter" id="S5.p1.2.6">
     gpt
    </span>
    -based LLMs, we experiment with
    <math alttext="150" class="ltx_Math" display="inline" id="S5.p1.2.m2.1">
     <semantics id="S5.p1.2.m2.1a">
      <mn id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">
       150
      </mn>
      <annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b">
       <cn id="S5.p1.2.m2.1.1.cmml" type="integer" xref="S5.p1.2.m2.1.1">
        150
       </cn>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">
       150
      </annotation>
     </semantics>
    </math>
    randomly sampled documents for all the experiments.
   </p>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Performance for Information-Seeking Setting
   </h3>
   <figure class="ltx_figure" id="S5.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="98" id="S5.F2.g1" src="/html/2311.13565/assets/x2.png" width="207"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2:
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.F2.2.1">
      Qualitative comparison of
      <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.F2.2.1.m1.1">
       <semantics id="S5.F2.2.1.m1.1b">
        <msup id="S5.F2.2.1.m1.1.1" xref="S5.F2.2.1.m1.1.1.cmml">
         <mi id="S5.F2.2.1.m1.1.1.2" xref="S5.F2.2.1.m1.1.1.2.cmml">
          ğƒ
         </mi>
         <mn id="S5.F2.2.1.m1.1.1.3" xref="S5.F2.2.1.m1.1.1.3.cmml">
          3
         </mn>
        </msup>
        <annotation-xml encoding="MathML-Content" id="S5.F2.2.1.m1.1c">
         <apply id="S5.F2.2.1.m1.1.1.cmml" xref="S5.F2.2.1.m1.1.1">
          <csymbol cd="ambiguous" id="S5.F2.2.1.m1.1.1.1.cmml" xref="S5.F2.2.1.m1.1.1">
           superscript
          </csymbol>
          <ci id="S5.F2.2.1.m1.1.1.2.cmml" xref="S5.F2.2.1.m1.1.1.2">
           ğƒ
          </ci>
          <cn id="S5.F2.2.1.m1.1.1.3.cmml" type="integer" xref="S5.F2.2.1.m1.1.1.3">
           3
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.F2.2.1.m1.1d">
         \mathbf{D}^{3}
        </annotation>
       </semantics>
      </math>
      -
      <span class="ltx_text ltx_font_smallcaps" id="S5.F2.2.1.1">
       Base
      </span>
      with publicly available Zero-shot Approaches such as
      <span class="ltx_text ltx_font_smallcaps" id="S5.F2.2.1.2">
       MonoT5
      </span>
      and Langchainâ€™s
      <span class="ltx_text ltx_font_smallcaps" id="S5.F2.2.1.3">
       Map-Reduce
      </span>
     </span>
     : "Tokens used" refers to the total number of tokens processed by the evidence retrieval and question answering stage to generate the final answer. Similarly "Total OpenAI Calls" also computes the number of API calls over both the tasks.
    </figcaption>
   </figure>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     We assess the performance of the models on the QASPER dataset
     <cite class="ltx_cite ltx_citemacro_cite">
      Dasigi etÂ al. (
      <a class="ltx_ref" href="#bib.bib14" title="">
       2021
      </a>
      )
     </cite>
     , which comprises information-seeking questions designed for lengthy research papers. The dataset includes a set of ground truth evidence paragraphs and answers. The questions are categorized as extractive, abstractive, yes/no, and unanswerable, and our proposed method must accurately discern the questionâ€™s intent to generate a relevant response.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p2">
    <p class="ltx_p" id="S5.SS1.p2.2">
     Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 â€£ 3.3.2 Fine-Grained Evidence Retrieval â€£ 3.3 Methodology â€£ 3 ğƒÂ³: Drilling Down into the Discourse â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     presents the results of various approaches, including a fine-tuned state-of-the-art (SoTA) model
     <cite class="ltx_cite ltx_citemacro_cite">
      Nie etÂ al. (
      <a class="ltx_ref" href="#bib.bib38" title="">
       2022
      </a>
      )
     </cite>
     , fine-tuned LED model evaluated on gold evidence, and zero-shot
     <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.2.1">
      gpt-3.5-turbo
     </span>
     model evaluated on gold evidence. Among them, our simplest approach,
     <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1">
      <semantics id="S5.SS1.p2.1.m1.1a">
       <msup id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">
        <mi id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">
         ğƒ
        </mi>
        <mn id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">
         3
        </mn>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b">
        <apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">
          ğƒ
         </ci>
         <cn id="S5.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p2.1.m1.1.1.3">
          3
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">
        \mathbf{D}^{3}
       </annotation>
      </semantics>
     </math>
     -
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p2.2.2">
      Base
     </span>
     , achieves competitive performance in terms of Evidence
     <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.1">
      <semantics id="S5.SS1.p2.2.m2.1a">
       <msub id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">
        <mi id="S5.SS1.p2.2.m2.1.1.2" xref="S5.SS1.p2.2.m2.1.1.2.cmml">
         F
        </mi>
        <mn id="S5.SS1.p2.2.m2.1.1.3" xref="S5.SS1.p2.2.m2.1.1.3.cmml">
         1
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b">
        <apply id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S5.SS1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1.2">
          ğ¹
         </ci>
         <cn id="S5.SS1.p2.2.m2.1.1.3.cmml" type="integer" xref="S5.SS1.p2.2.m2.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">
        F_{1}
       </annotation>
      </semantics>
     </math>
     score. Notably, it retains 99.6% of the performance of the best zero-shot approach,
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p2.2.3">
      Map-Reduce Optimized
     </span>
     , while processing only 26% of the tokens required by the latter.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p3">
    <p class="ltx_p" id="S5.SS1.p3.1">
     The original implementation of
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.1">
      Map-Reduce
     </span>
     suffers from two main limitations. Firstly, it processes each paragraph independently, overlooking the effectiveness of chunk-level processing over paragraph-level processing. Secondly, it employs suboptimal few-shot prompting to retrieve relevant sources, resulting in increased processing costs and poor performance when the few-shot prompting is not well-aligned with the domain. Due to these significant processing costs and the underperformance of
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.2">
      Paragraph
     </span>
     and
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.3">
      Map-Reduce
     </span>
     , we exclude their evaluations from subsequent analyses. Similarly, among the non-LLM baselines, we exclude the evaluations of
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.4">
      DPR
     </span>
     and
     <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p3.1.5">
      cross-encoder-ms-marco-MiniLM-L-12-v2
     </span>
     due to their poor performance.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS1.p4">
    <p class="ltx_p" id="S5.SS1.p4.1">
     While it is possible to enhance the performance of our approach,
     <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.SS1.p4.1.m1.1">
      <semantics id="S5.SS1.p4.1.m1.1a">
       <msup id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml">
        <mi id="S5.SS1.p4.1.m1.1.1.2" xref="S5.SS1.p4.1.m1.1.1.2.cmml">
         ğƒ
        </mi>
        <mn id="S5.SS1.p4.1.m1.1.1.3" xref="S5.SS1.p4.1.m1.1.1.3.cmml">
         3
        </mn>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b">
        <apply id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">
         <csymbol cd="ambiguous" id="S5.SS1.p4.1.m1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S5.SS1.p4.1.m1.1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.1.2">
          ğƒ
         </ci>
         <cn id="S5.SS1.p4.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p4.1.m1.1.1.3">
          3
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">
        \mathbf{D}^{3}
       </annotation>
      </semantics>
     </math>
     , with alternative configurations (as shown in Section
     <a class="ltx_ref" href="#S5.SS3.SSS1" title="5.3.1 Performance of different configurations of ğƒÂ³ â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
      <span class="ltx_text ltx_ref_tag">
       5.3.1
      </span>
     </a>
     ), it remains an excellent choice for rapid testing in different domains. Its cost-effectiveness and minimal latency in terms of API calls make it highly suitable for such purposes.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Performance for Questions Requiring Multi-Hop Reasoning
   </h3>
   <figure class="ltx_table" id="S5.T2">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T2.4">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T2.4.5.1">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.1" rowspan="2">
        <span class="ltx_text" id="S5.T2.4.5.1.1.1">
         Approach
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.2">
        Evidence
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.3">
        Answer
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.4">
        Tokens
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.5">
        API
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.2.2">
       <td class="ltx_td ltx_align_center" id="S5.T2.1.1.1">
        <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1">
         <semantics id="S5.T2.1.1.1.m1.1a">
          <msub id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml">
           <mi id="S5.T2.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.m1.1.1.2.cmml">
            F
           </mi>
           <mn id="S5.T2.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.m1.1.1.3.cmml">
            1
           </mn>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b">
           <apply id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S5.T2.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">
             subscript
            </csymbol>
            <ci id="S5.T2.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.m1.1.1.2">
             ğ¹
            </ci>
            <cn id="S5.T2.1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T2.1.1.1.m1.1.1.3">
             1
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">
           F_{1}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.2.2.2">
        <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.T2.2.2.2.m1.1">
         <semantics id="S5.T2.2.2.2.m1.1a">
          <msub id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml">
           <mi id="S5.T2.2.2.2.m1.1.1.2" xref="S5.T2.2.2.2.m1.1.1.2.cmml">
            F
           </mi>
           <mn id="S5.T2.2.2.2.m1.1.1.3" xref="S5.T2.2.2.2.m1.1.1.3.cmml">
            1
           </mn>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b">
           <apply id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">
            <csymbol cd="ambiguous" id="S5.T2.2.2.2.m1.1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">
             subscript
            </csymbol>
            <ci id="S5.T2.2.2.2.m1.1.1.2.cmml" xref="S5.T2.2.2.2.m1.1.1.2">
             ğ¹
            </ci>
            <cn id="S5.T2.2.2.2.m1.1.1.3.cmml" type="integer" xref="S5.T2.2.2.2.m1.1.1.3">
             1
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">
           F_{1}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.2.2.3">
        Processed
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.2.2.4">
        Calls
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.6.2">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.6.2.1">
        CGSN
        <cite class="ltx_cite ltx_citemacro_cite">
         Nie etÂ al. (
         <a class="ltx_ref" href="#bib.bib38" title="">
          2022
         </a>
         )
        </cite>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.6.2.2">
        92.02
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.6.2.3">
        57.80
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.6.2.4">
        -
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.6.2.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.7.3">
       <td class="ltx_td ltx_align_center" id="S5.T2.4.7.3.1">
        LED*
        <cite class="ltx_cite ltx_citemacro_cite">
         Nie etÂ al. (
         <a class="ltx_ref" href="#bib.bib38" title="">
          2022
         </a>
         )
        </cite>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.7.3.2">
        -
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.7.3.3">
        58.94
       </td>
       <td class="ltx_td" id="S5.T2.4.7.3.4">
       </td>
       <td class="ltx_td" id="S5.T2.4.7.3.5">
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.8.4">
       <td class="ltx_td ltx_align_center" id="S5.T2.4.8.4.1">
        <span class="ltx_text ltx_font_typewriter" id="S5.T2.4.8.4.1.1">
         gpt-3.5-turbo
        </span>
        *
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.8.4.2">
        -
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.8.4.3">
        47.01
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.8.4.4">
        -
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.8.4.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.9.5">
       <td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S5.T2.4.9.5.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.9.5.1.1">
         Zero-Shot Approaches
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.10.6">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.10.6.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.10.6.1.1">
         MonoT5
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.10.6.2">
        <span class="ltx_text ltx_font_bold" id="S5.T2.4.10.6.2.1">
         62.33
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.10.6.3">
        37.91
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.10.6.4">
        -
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.10.6.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.11.7">
       <td class="ltx_td ltx_align_center" id="S5.T2.4.11.7.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.11.7.1.1">
         Chunk
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.11.7.2">
        40.79
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.11.7.3">
        36.81
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.11.7.4">
        6702.78
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.11.7.5">
        2.45
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.12.8">
       <td class="ltx_td ltx_align_center" id="S5.T2.4.12.8.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.12.8.1.1">
         Map-Reduce Optimized
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.12.8.2">
        39.52
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.12.8.3">
        <span class="ltx_text ltx_font_bold" id="S5.T2.4.12.8.3.1">
         37.93
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.12.8.4">
        8329.81
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.12.8.5">
        3.58
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.3.3">
       <td class="ltx_td ltx_align_center" id="S5.T2.3.3.1">
        <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T2.3.3.1.m1.1">
         <semantics id="S5.T2.3.3.1.m1.1a">
          <msup id="S5.T2.3.3.1.m1.1.1" xref="S5.T2.3.3.1.m1.1.1.cmml">
           <mi id="S5.T2.3.3.1.m1.1.1.2" xref="S5.T2.3.3.1.m1.1.1.2.cmml">
            ğƒ
           </mi>
           <mn id="S5.T2.3.3.1.m1.1.1.3" xref="S5.T2.3.3.1.m1.1.1.3.cmml">
            3
           </mn>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S5.T2.3.3.1.m1.1b">
           <apply id="S5.T2.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.1.m1.1.1">
            <csymbol cd="ambiguous" id="S5.T2.3.3.1.m1.1.1.1.cmml" xref="S5.T2.3.3.1.m1.1.1">
             superscript
            </csymbol>
            <ci id="S5.T2.3.3.1.m1.1.1.2.cmml" xref="S5.T2.3.3.1.m1.1.1.2">
             ğƒ
            </ci>
            <cn id="S5.T2.3.3.1.m1.1.1.3.cmml" type="integer" xref="S5.T2.3.3.1.m1.1.1.3">
             3
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.3.3.1.m1.1c">
           \mathbf{D}^{3}
          </annotation>
         </semantics>
        </math>
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.3.3.1.1">
         -Base
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.3.3.2">
        31.05
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.3.3.3">
        23.55
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.3.3.4">
        <span class="ltx_text ltx_font_bold" id="S5.T2.3.3.4.1">
         3141.29
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.3.3.5">
        <span class="ltx_text ltx_font_bold" id="S5.T2.3.3.5.1">
         2.10
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.13.9">
       <td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S5.T2.4.13.9.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.13.9.1.1">
         Zero-Shot Approaches Augmented with Self-Ask
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.14.10">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.14.10.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.14.10.1.1">
         MonoT5
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.14.10.2">
        <span class="ltx_text ltx_font_bold" id="S5.T2.4.14.10.2.1">
         33.56
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.14.10.3">
        40.36
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.14.10.4">
        <span class="ltx_text ltx_font_bold" id="S5.T2.4.14.10.4.1">
         719.54
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.14.10.5">
        <span class="ltx_text ltx_font_bold" id="S5.T2.4.14.10.5.1">
         1.62
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.15.11">
       <td class="ltx_td ltx_align_center" id="S5.T2.4.15.11.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.15.11.1.1">
         Chunk
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.15.11.2">
        20.66
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.15.11.3">
        39.59
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.15.11.4">
        9822.49
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.15.11.5">
        5.0
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.16.12">
       <td class="ltx_td ltx_align_center" id="S5.T2.4.16.12.1">
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.16.12.1.1">
         Map-Reduce Optimized
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.16.12.2">
        30.19
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.16.12.3">
        38.32
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.16.12.4">
        12253.42
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T2.4.16.12.5">
        6.83
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T2.4.4">
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.1">
        <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T2.4.4.1.m1.1">
         <semantics id="S5.T2.4.4.1.m1.1a">
          <msup id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml">
           <mi id="S5.T2.4.4.1.m1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.2.cmml">
            ğƒ
           </mi>
           <mn id="S5.T2.4.4.1.m1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.3.cmml">
            3
           </mn>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b">
           <apply id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1">
            <csymbol cd="ambiguous" id="S5.T2.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1">
             superscript
            </csymbol>
            <ci id="S5.T2.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.2">
             ğƒ
            </ci>
            <cn id="S5.T2.4.4.1.m1.1.1.3.cmml" type="integer" xref="S5.T2.4.4.1.m1.1.1.3">
             3
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">
           \mathbf{D}^{3}
          </annotation>
         </semantics>
        </math>
        <span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.4.1.1">
         -Base
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.2">
        26.87
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.3">
        <span class="ltx_text ltx_font_bold" id="S5.T2.4.4.3.1">
         43.45
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4">
        5376.29
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.5">
        5.17
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     <span class="ltx_text ltx_font_bold" id="S5.T2.10.1">
      Comparison of various zero-shot approaches for HOTPOTQA-Doc Dataset.
     </span>
     While directly applying
     <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T2.6.m1.1">
      <semantics id="S5.T2.6.m1.1b">
       <msup id="S5.T2.6.m1.1.1" xref="S5.T2.6.m1.1.1.cmml">
        <mi id="S5.T2.6.m1.1.1.2" xref="S5.T2.6.m1.1.1.2.cmml">
         ğƒ
        </mi>
        <mn id="S5.T2.6.m1.1.1.3" xref="S5.T2.6.m1.1.1.3.cmml">
         3
        </mn>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S5.T2.6.m1.1c">
        <apply id="S5.T2.6.m1.1.1.cmml" xref="S5.T2.6.m1.1.1">
         <csymbol cd="ambiguous" id="S5.T2.6.m1.1.1.1.cmml" xref="S5.T2.6.m1.1.1">
          superscript
         </csymbol>
         <ci id="S5.T2.6.m1.1.1.2.cmml" xref="S5.T2.6.m1.1.1.2">
          ğƒ
         </ci>
         <cn id="S5.T2.6.m1.1.1.3.cmml" type="integer" xref="S5.T2.6.m1.1.1.3">
          3
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.T2.6.m1.1d">
        \mathbf{D}^{3}
       </annotation>
      </semantics>
     </math>
     -
     <span class="ltx_text ltx_font_smallcaps" id="S5.T2.11.2">
      Base
     </span>
     leads to poor performance, combining this with
     <span class="ltx_text ltx_font_italic" id="S5.T2.12.3">
      self-ask
     </span>
     prompting methodology yields best performance while processing least number of tokens when compared against other zero-shot LLM-based methods. *: Inference obtained using gold evidence.
    </figcaption>
   </figure>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     Here, we use HOTPOTQA-Doc dataset
     <cite class="ltx_cite ltx_citemacro_cite">
      Yang etÂ al. (
      <a class="ltx_ref" href="#bib.bib60" title="">
       2018
      </a>
      ); Nie etÂ al. (
      <a class="ltx_ref" href="#bib.bib38" title="">
       2022
      </a>
      )
     </cite>
     , where the objective is to answer a complex query involving multi-hop reasoning given two long documents. We have investigated the performance of different zero-shot approaches using two schemes:
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">
      (a) Direct Processing:
     </span>
     Queries are directly fed to the Zero-Shot retrievers to get the relevant evidences.
     <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">
      (b)
      <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.2.1">
       self-ask
      </span>
      based Processing:
     </span>
     By leveraging the power of elicitive prompting
     <cite class="ltx_cite ltx_citemacro_cite">
      Yao etÂ al. (
      <a class="ltx_ref" href="#bib.bib61" title="">
       2022
      </a>
      ); Press etÂ al. (
      <a class="ltx_ref" href="#bib.bib44" title="">
       2022
      </a>
      ); Wei etÂ al. (
      <a class="ltx_ref" href="#bib.bib57" title="">
       2022b
      </a>
      )
     </cite>
     , we employ the technique of
     <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.3">
      self-ask
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Press etÂ al. (
      <a class="ltx_ref" href="#bib.bib44" title="">
       2022
      </a>
      )
     </cite>
     . This approach entails decomposing a complex query into a series of simpler questions, which collectively form the basis for the final answer. Through iterative questioning, the agent analyzes prior answers and previously posed questions to generate subsequent inquiries. Leveraging the zero-shot retrieval approach, the agent obtains relevant answers for each question.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS2.p2">
    <p class="ltx_p" id="S5.SS2.p2.1">
     The results for this experiment are tabulated at Table
     <a class="ltx_ref" href="#S5.T2" title="Table 2 â€£ 5.2 Performance for Questions Requiring Multi-Hop Reasoning â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     . We note the following observations:
    </p>
    <ul class="ltx_itemize" id="S5.I1">
     <li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       â€¢
      </span>
      <div class="ltx_para" id="S5.I1.i1.p1">
       <p class="ltx_p" id="S5.I1.i1.p1.2">
        <span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.2.2">
         Evidence
         <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.I1.i1.p1.1.1.m1.1">
          <semantics id="S5.I1.i1.p1.1.1.m1.1a">
           <msub id="S5.I1.i1.p1.1.1.m1.1.1" xref="S5.I1.i1.p1.1.1.m1.1.1.cmml">
            <mi id="S5.I1.i1.p1.1.1.m1.1.1.2" xref="S5.I1.i1.p1.1.1.m1.1.1.2.cmml">
             F
            </mi>
            <mn id="S5.I1.i1.p1.1.1.m1.1.1.3" xref="S5.I1.i1.p1.1.1.m1.1.1.3.cmml">
             1
            </mn>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.1.m1.1b">
            <apply id="S5.I1.i1.p1.1.1.m1.1.1.cmml" xref="S5.I1.i1.p1.1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.I1.i1.p1.1.1.m1.1.1.1.cmml" xref="S5.I1.i1.p1.1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S5.I1.i1.p1.1.1.m1.1.1.2.cmml" xref="S5.I1.i1.p1.1.1.m1.1.1.2">
              ğ¹
             </ci>
             <cn id="S5.I1.i1.p1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.I1.i1.p1.1.1.m1.1.1.3">
              1
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.1.m1.1c">
            F_{1}
           </annotation>
          </semantics>
         </math>
         poorly correlated with Answer
         <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.I1.i1.p1.2.2.m2.1">
          <semantics id="S5.I1.i1.p1.2.2.m2.1a">
           <msub id="S5.I1.i1.p1.2.2.m2.1.1" xref="S5.I1.i1.p1.2.2.m2.1.1.cmml">
            <mi id="S5.I1.i1.p1.2.2.m2.1.1.2" xref="S5.I1.i1.p1.2.2.m2.1.1.2.cmml">
             F
            </mi>
            <mn id="S5.I1.i1.p1.2.2.m2.1.1.3" xref="S5.I1.i1.p1.2.2.m2.1.1.3.cmml">
             1
            </mn>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.2.2.m2.1b">
            <apply id="S5.I1.i1.p1.2.2.m2.1.1.cmml" xref="S5.I1.i1.p1.2.2.m2.1.1">
             <csymbol cd="ambiguous" id="S5.I1.i1.p1.2.2.m2.1.1.1.cmml" xref="S5.I1.i1.p1.2.2.m2.1.1">
              subscript
             </csymbol>
             <ci id="S5.I1.i1.p1.2.2.m2.1.1.2.cmml" xref="S5.I1.i1.p1.2.2.m2.1.1.2">
              ğ¹
             </ci>
             <cn id="S5.I1.i1.p1.2.2.m2.1.1.3.cmml" type="integer" xref="S5.I1.i1.p1.2.2.m2.1.1.3">
              1
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.I1.i1.p1.2.2.m2.1c">
            F_{1}
           </annotation>
          </semantics>
         </math>
        </span>
        : Considering same question answering model were used (
        <span class="ltx_text ltx_font_typewriter" id="S5.I1.i1.p1.2.3">
         gpt-3.5-turbo
        </span>
        ) for each of the zero-shot approaches, we find that the answer performance of
        <span class="ltx_text ltx_font_smallcaps" id="S5.I1.i1.p1.2.4">
         Map-Reduce Optimized
        </span>
        aligns with that of
        <span class="ltx_text ltx_font_smallcaps" id="S5.I1.i1.p1.2.5">
         MonoT5
        </span>
        , albeit with noticeably lower evidence retrieval efficacy. Itâ€™s worth noting that during dataset construction, only the paragraphs utilized for generating answers were preserved, which does not imply the irrelevance of other paragraphs in addressing the question. This observation highlights the presence of this artifact.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       â€¢
      </span>
      <div class="ltx_para" id="S5.I1.i2.p1">
       <p class="ltx_p" id="S5.I1.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">
         Augmenting with
         <span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.1.1">
          self-ask
         </span>
         boosts performance
        </span>
        : This highlights the fact that zero-shot retrievers are better positioned to retrieve fragments for simpler queries and
        <span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.2">
         self-ask
        </span>
        effectively uses them to get better performance. In fact, our approach
        <math alttext="\mathbf{D}^{3}-\textsc{Base}" class="ltx_Math" display="inline" id="S5.I1.i2.p1.1.m1.1">
         <semantics id="S5.I1.i2.p1.1.m1.1a">
          <mrow id="S5.I1.i2.p1.1.m1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.cmml">
           <msup id="S5.I1.i2.p1.1.m1.1.1.2" xref="S5.I1.i2.p1.1.m1.1.1.2.cmml">
            <mi id="S5.I1.i2.p1.1.m1.1.1.2.2" xref="S5.I1.i2.p1.1.m1.1.1.2.2.cmml">
             ğƒ
            </mi>
            <mn id="S5.I1.i2.p1.1.m1.1.1.2.3" xref="S5.I1.i2.p1.1.m1.1.1.2.3.cmml">
             3
            </mn>
           </msup>
           <mo id="S5.I1.i2.p1.1.m1.1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.1.cmml">
            âˆ’
           </mo>
           <mtext class="ltx_font_smallcaps" id="S5.I1.i2.p1.1.m1.1.1.3" xref="S5.I1.i2.p1.1.m1.1.1.3a.cmml">
            Base
           </mtext>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.m1.1b">
           <apply id="S5.I1.i2.p1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1">
            <minus id="S5.I1.i2.p1.1.m1.1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1.1">
            </minus>
            <apply id="S5.I1.i2.p1.1.m1.1.1.2.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2">
             <csymbol cd="ambiguous" id="S5.I1.i2.p1.1.m1.1.1.2.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2">
              superscript
             </csymbol>
             <ci id="S5.I1.i2.p1.1.m1.1.1.2.2.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.2">
              ğƒ
             </ci>
             <cn id="S5.I1.i2.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.I1.i2.p1.1.m1.1.1.2.3">
              3
             </cn>
            </apply>
            <ci id="S5.I1.i2.p1.1.m1.1.1.3a.cmml" xref="S5.I1.i2.p1.1.m1.1.1.3">
             <mtext class="ltx_font_smallcaps" id="S5.I1.i2.p1.1.m1.1.1.3.cmml" xref="S5.I1.i2.p1.1.m1.1.1.3">
              Base
             </mtext>
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.m1.1c">
           \mathbf{D}^{3}-\textsc{Base}
          </annotation>
         </semantics>
        </math>
        is very close in performance to zero-shot question answering with gold evidence.
       </p>
      </div>
     </li>
    </ul>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Ablations &amp; Analyses
   </h3>
   <section class="ltx_subsubsection" id="S5.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.1
     </span>
     Performance of different configurations of
     <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.1.m1.1">
      <semantics id="S5.SS3.SSS1.1.m1.1b">
       <msup id="S5.SS3.SSS1.1.m1.1.1" xref="S5.SS3.SSS1.1.m1.1.1.cmml">
        <mi id="S5.SS3.SSS1.1.m1.1.1.2" xref="S5.SS3.SSS1.1.m1.1.1.2.cmml">
         ğƒ
        </mi>
        <mn id="S5.SS3.SSS1.1.m1.1.1.3" xref="S5.SS3.SSS1.1.m1.1.1.3.cmml">
         3
        </mn>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.1.m1.1c">
        <apply id="S5.SS3.SSS1.1.m1.1.1.cmml" xref="S5.SS3.SSS1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S5.SS3.SSS1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS1.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S5.SS3.SSS1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS1.1.m1.1.1.2">
          ğƒ
         </ci>
         <cn id="S5.SS3.SSS1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.SSS1.1.m1.1.1.3">
          3
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS3.SSS1.1.m1.1d">
        \mathbf{D}^{3}
       </annotation>
      </semantics>
     </math>
    </h4>
    <figure class="ltx_table" id="S5.T3">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.2">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S5.T3.2.3.1">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.3.1.1" rowspan="2">
         <span class="ltx_text" id="S5.T3.2.3.1.1.1">
          Approach
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S5.T3.2.3.1.2">
         Answering Performance
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.3.1.3">
         Evidence
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.3.1.4">
         Tokens
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.3.1.5">
         API
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.1.1">
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.2">
         Extractive
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.3">
         Abstractive
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.4">
         Yes/No
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.5">
         Unanswerable
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.6">
         Overall
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.1">
         <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.T3.1.1.1.m1.1">
          <semantics id="S5.T3.1.1.1.m1.1a">
           <msub id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml">
            <mi id="S5.T3.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.m1.1.1.2.cmml">
             F
            </mi>
            <mn id="S5.T3.1.1.1.m1.1.1.3" xref="S5.T3.1.1.1.m1.1.1.3.cmml">
             1
            </mn>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b">
            <apply id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T3.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S5.T3.1.1.1.m1.1.1.2.cmml" xref="S5.T3.1.1.1.m1.1.1.2">
              ğ¹
             </ci>
             <cn id="S5.T3.1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.1.1.1.m1.1.1.3">
              1
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">
            F_{1}
           </annotation>
          </semantics>
         </math>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.7">
         Processed
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.1.1.8">
         Calls
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.4.2">
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S5.T3.2.4.2.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.4.2.1.1">
          Our Primary Approach
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.2">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.1">
         <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T3.2.2.1.m1.1">
          <semantics id="S5.T3.2.2.1.m1.1a">
           <msup id="S5.T3.2.2.1.m1.1.1" xref="S5.T3.2.2.1.m1.1.1.cmml">
            <mi id="S5.T3.2.2.1.m1.1.1.2" xref="S5.T3.2.2.1.m1.1.1.2.cmml">
             ğƒ
            </mi>
            <mn id="S5.T3.2.2.1.m1.1.1.3" xref="S5.T3.2.2.1.m1.1.1.3.cmml">
             3
            </mn>
           </msup>
           <annotation-xml encoding="MathML-Content" id="S5.T3.2.2.1.m1.1b">
            <apply id="S5.T3.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T3.2.2.1.m1.1.1.1.cmml" xref="S5.T3.2.2.1.m1.1.1">
              superscript
             </csymbol>
             <ci id="S5.T3.2.2.1.m1.1.1.2.cmml" xref="S5.T3.2.2.1.m1.1.1.2">
              ğƒ
             </ci>
             <cn id="S5.T3.2.2.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.2.2.1.m1.1.1.3">
              3
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.2.2.1.m1.1c">
            \mathbf{D}^{3}
           </annotation>
          </semantics>
         </math>
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.2.1.1">
          -Base
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.2">
         42.90
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.3">
         23.65
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.4">
         74.35
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5">
         79.61
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.6">
         47.45
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.7">
         49.92
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.8">
         1980.94
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.9">
         1.99
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.5.3">
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S5.T3.2.5.3.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.5.3.1.1">
          Variations in Fine-grained Evidence Retrieval
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.6.4">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.6.4.1.1">
          monoT5
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.2">
         34.86
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.3">
         20.47
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.4">
         67.59
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.5">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.6.4.5.1">
          88.64
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.6">
         43.33
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.7">
         32.73
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.8">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.6.4.8.1">
          844.09
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.6.4.9">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.6.4.9.1">
          1.0
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.7.5">
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.7.5.1.1">
          monoT5+Base
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.2">
         39.61
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.3">
         22.31
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.4">
         74.32
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.5">
         87.35
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.6">
         47.19
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.7">
         44.39
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.8">
         1520.35
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.7.5.9">
         1.95
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.8.6">
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.8.6.1.1">
          Base+monoT5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.2">
         39.62
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.3">
         23.66
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.4">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.8.6.4.1">
          74.54
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.5">
         82.33
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.6">
         46.42
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.7">
         40.23
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.8">
         1980.94
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.8.6.9">
         1.99
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.9.7">
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.9.7.1.1">
          HierBase
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.2">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.9.7.2.1">
          45.48
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.3">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.9.7.3.1">
          24.14
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.4">
         71.55
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.5">
         86.18
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.6">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.9.7.6.1">
          49.48
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.7">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.9.7.7.1">
          50.09
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.8">
         2125.67
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.9.7.9">
         2.85
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.10.8">
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S5.T3.2.10.8.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.10.8.1.1">
          Replacing Fine-Tuned Summarization Model with Instruction Aligned LLM
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.11.9">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.1">
         <span class="ltx_text ltx_font_typewriter" id="S5.T3.2.11.9.1.1">
          gpt-3.5-turbo
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.2">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.11.9.2.1">
          43.89
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.3">
         27.31
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.4">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.11.9.4.1">
          79.81
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.5">
         75.55
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.6">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.11.9.6.1">
          49.28
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.7">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.11.9.7.1">
          51.19
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.8">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.11.9.8.1">
          2106.57
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.11.9.9">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.11.9.9.1">
          2.0
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.12.10">
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.1">
         <span class="ltx_text ltx_font_typewriter" id="S5.T3.2.12.10.1.1">
          text-davinci-003
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.2">
         43.04
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.3">
         27.04
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.4">
         79.28
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.5">
         76.32
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.6">
         48.61
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.7">
         50.37
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.8">
         2239.97
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.12.10.9">
         2.03
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.13.11">
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.1">
         <span class="ltx_text ltx_font_typewriter" id="S5.T3.2.13.11.1.1">
          vicuna-13b
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.2">
         43.03
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.3">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.13.11.3.1">
          27.70
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.4">
         75.16
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.5">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.13.11.5.1">
          79.55
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.6">
         49.09
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.7">
         50.09
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.8">
         2208.63
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.13.11.9">
         2.14
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.14.12">
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S5.T3.2.14.12.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.14.12.1.1">
          Varying LLMs for Retrieval
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.15.13">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.1">
         <span class="ltx_text ltx_font_typewriter" id="S5.T3.2.15.13.1.1">
          text-davinci-003
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.2">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.15.13.2.1">
          41.45
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.3">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.15.13.3.1">
          24.12
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.4">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.15.13.4.1">
          79.08
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.5">
         77.72
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.6">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.15.13.6.1">
          47.11
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.7">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.15.13.7.1">
          37.53
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.8">
         2673.26
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.15.13.9">
         2.0
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.16.14">
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.1">
         <span class="ltx_text ltx_font_typewriter" id="S5.T3.2.16.14.1.1">
          vicuna-13b
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.2">
         23.35
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.3">
         15.38
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.4">
         74.07
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.5">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.16.14.5.1">
          86.88
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.6">
         36.52
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.7">
         28.10
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.8">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.16.14.8.1">
          1810.48
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.2.16.14.9">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.16.14.9.1">
          1.85
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.17.15">
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S5.T3.2.17.15.1">
         <span class="ltx_text ltx_font_smallcaps" id="S5.T3.2.17.15.1.1">
          Varying LLMs for Question Answering
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.18.16">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.1">
         <span class="ltx_text ltx_font_typewriter" id="S5.T3.2.18.16.1.1">
          text-davinci-003
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.2">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.18.16.2.1">
          49.99
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.3">
         20.33
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.4">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.18.16.4.1">
          77.86
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.5">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.18.16.5.1">
          90.82
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.6">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.18.16.6.1">
          52.51
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.7">
         49.92
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.8">
         1980.94
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.18.16.9">
         1.99
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.2.19.17">
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.1">
         <span class="ltx_text ltx_font_typewriter" id="S5.T3.2.19.17.1.1">
          vicuna-13b
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.2">
         31.71
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.3">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.19.17.3.1">
          21.34
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.4">
         62.29
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.5">
         60.43
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.6">
         37.06
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.7">
         49.92
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.8">
         1980.94
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.19.17.9">
         1.99
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 3:
      </span>
      <span class="ltx_text ltx_font_bold" id="S5.T3.4.1">
       Performance for different
       <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T3.4.1.m1.1">
        <semantics id="S5.T3.4.1.m1.1b">
         <msup id="S5.T3.4.1.m1.1.1" xref="S5.T3.4.1.m1.1.1.cmml">
          <mi id="S5.T3.4.1.m1.1.1.2" xref="S5.T3.4.1.m1.1.1.2.cmml">
           ğƒ
          </mi>
          <mn id="S5.T3.4.1.m1.1.1.3" xref="S5.T3.4.1.m1.1.1.3.cmml">
           3
          </mn>
         </msup>
         <annotation-xml encoding="MathML-Content" id="S5.T3.4.1.m1.1c">
          <apply id="S5.T3.4.1.m1.1.1.cmml" xref="S5.T3.4.1.m1.1.1">
           <csymbol cd="ambiguous" id="S5.T3.4.1.m1.1.1.1.cmml" xref="S5.T3.4.1.m1.1.1">
            superscript
           </csymbol>
           <ci id="S5.T3.4.1.m1.1.1.2.cmml" xref="S5.T3.4.1.m1.1.1.2">
            ğƒ
           </ci>
           <cn id="S5.T3.4.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.4.1.m1.1.1.3">
            3
           </cn>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.T3.4.1.m1.1d">
          \mathbf{D}^{3}
         </annotation>
        </semantics>
       </math>
       configurations for QASPER dataset.
      </span>
     </figcaption>
    </figure>
    <div class="ltx_para" id="S5.SS3.SSS1.p1">
     <p class="ltx_p" id="S5.SS3.SSS1.p1.1">
      We investigated several configurations to determine possible directions to improve the performance. Following explorations were performed (Table
      <a class="ltx_ref" href="#S5.T3" title="Table 3 â€£ 5.3.1 Performance of different configurations of ğƒÂ³ â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      ):
     </p>
     <ul class="ltx_itemize" id="S5.I2">
      <li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        â€¢
       </span>
       <div class="ltx_para" id="S5.I2.i1.p1">
        <p class="ltx_p" id="S5.I2.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i1.p1.1.1">
          Variations in fine-grained retrieval
         </span>
         : Although employing
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i1.p1.1.2">
          MonoT5
         </span>
         can reduce inference costs, it also adversely affects evidence retrieval performance, as evidenced by the table. Conversely,
         <math alttext="\mathbf{D}^{3}-" class="ltx_Math" display="inline" id="S5.I2.i1.p1.1.m1.1">
          <semantics id="S5.I2.i1.p1.1.m1.1a">
           <mrow id="S5.I2.i1.p1.1.m1.1.1" xref="S5.I2.i1.p1.1.m1.1.1.cmml">
            <msup id="S5.I2.i1.p1.1.m1.1.1.2" xref="S5.I2.i1.p1.1.m1.1.1.2.cmml">
             <mi id="S5.I2.i1.p1.1.m1.1.1.2.2" xref="S5.I2.i1.p1.1.m1.1.1.2.2.cmml">
              ğƒ
             </mi>
             <mn id="S5.I2.i1.p1.1.m1.1.1.2.3" xref="S5.I2.i1.p1.1.m1.1.1.2.3.cmml">
              3
             </mn>
            </msup>
            <mo id="S5.I2.i1.p1.1.m1.1.1.3" xref="S5.I2.i1.p1.1.m1.1.1.3.cmml">
             âˆ’
            </mo>
           </mrow>
           <annotation-xml encoding="MathML-Content" id="S5.I2.i1.p1.1.m1.1b">
            <apply id="S5.I2.i1.p1.1.m1.1.1.cmml" xref="S5.I2.i1.p1.1.m1.1.1">
             <csymbol cd="latexml" id="S5.I2.i1.p1.1.m1.1.1.1.cmml" xref="S5.I2.i1.p1.1.m1.1.1">
              limit-from
             </csymbol>
             <apply id="S5.I2.i1.p1.1.m1.1.1.2.cmml" xref="S5.I2.i1.p1.1.m1.1.1.2">
              <csymbol cd="ambiguous" id="S5.I2.i1.p1.1.m1.1.1.2.1.cmml" xref="S5.I2.i1.p1.1.m1.1.1.2">
               superscript
              </csymbol>
              <ci id="S5.I2.i1.p1.1.m1.1.1.2.2.cmml" xref="S5.I2.i1.p1.1.m1.1.1.2.2">
               ğƒ
              </ci>
              <cn id="S5.I2.i1.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.I2.i1.p1.1.m1.1.1.2.3">
               3
              </cn>
             </apply>
             <minus id="S5.I2.i1.p1.1.m1.1.1.3.cmml" xref="S5.I2.i1.p1.1.m1.1.1.3">
             </minus>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.I2.i1.p1.1.m1.1c">
            \mathbf{D}^{3}-
           </annotation>
          </semantics>
         </math>
         <span class="ltx_text ltx_font_smallcaps" id="S5.I2.i1.p1.1.3">
          HierBase
         </span>
         demonstrates a enhancement in performance with only a marginal increase in inference cost.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        â€¢
       </span>
       <div class="ltx_para" id="S5.I2.i2.p1">
        <p class="ltx_p" id="S5.I2.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i2.p1.1.1">
          Using LLMs for summarization
         </span>
         : We replaced fine-tuned summarizer with enterprise LLMs such as
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i2.p1.1.2">
          gpt-3.5-turbo
          <span class="ltx_note ltx_role_footnote" id="footnote4">
           <sup class="ltx_note_mark">
            4
           </sup>
           <span class="ltx_note_outer">
            <span class="ltx_note_content">
             <sup class="ltx_note_mark">
              4
             </sup>
             <span class="ltx_tag ltx_tag_note">
              <span class="ltx_text ltx_font_serif" id="footnote4.1.1.1">
               4
              </span>
             </span>
             <a class="ltx_ref ltx_url" href="https://openai.com/blog/chatgpt" target="_blank" title="">
              https://openai.com/blog/chatgpt
             </a>
            </span>
           </span>
          </span>
         </span>
         and
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i2.p1.1.3">
          text-davinci-003
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          Ouyang etÂ al. (
          <a class="ltx_ref" href="#bib.bib41" title="">
           2022
          </a>
          )
         </cite>
         and an open-source LLM,
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i2.p1.1.4">
          vicuna-13b
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          Chiang etÂ al. (
          <a class="ltx_ref" href="#bib.bib10" title="">
           2023
          </a>
          )
         </cite>
         . While the performance increased along several metrics, there is additional processing cost to get the condensed representation of the document (very minimal when smaller
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i2.p1.1.5">
          bart-large
         </span>
         based summarizer was used).
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        â€¢
       </span>
       <div class="ltx_para" id="S5.I2.i3.p1">
        <p class="ltx_p" id="S5.I2.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i3.p1.1.1">
          Exploring alternative LLMs for retrieval
         </span>
         : In this analysis, we observe a decline in performance when utilizing other LLMs, highlighting the superiority of
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i3.p1.1.2">
          gpt-3.5-turbo
         </span>
         as the optimal choice for retrieval tasks.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        â€¢
       </span>
       <div class="ltx_para" id="S5.I2.i4.p1">
        <p class="ltx_p" id="S5.I2.i4.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i4.p1.1.1">
          Investigating alternative LLMs for question answering
         </span>
         : We observe a performance boost when employing
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i4.p1.1.2">
          text-davinci-003
         </span>
         . However, it is important to consider the higher monetary cost associated with using this API compared to
         <span class="ltx_text ltx_font_typewriter" id="S5.I2.i4.p1.1.3">
          gpt-3.5-turbo
         </span>
         .
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.2
     </span>
     Performance across Different Document Length categories
    </h4>
    <figure class="ltx_figure" id="S5.F3">
     <div class="ltx_flex_figure">
      <div class="ltx_flex_cell ltx_flex_size_3">
       <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf1">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="194" id="S5.F3.sf1.g1" src="/html/2311.13565/assets/final_evidence_f1.png" width="192"/>
        <figcaption class="ltx_caption">
         <span class="ltx_tag ltx_tag_figure">
          (a)
         </span>
         Evidence
         <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.F3.sf1.2.m1.1">
          <semantics id="S5.F3.sf1.2.m1.1b">
           <msub id="S5.F3.sf1.2.m1.1.1" xref="S5.F3.sf1.2.m1.1.1.cmml">
            <mi id="S5.F3.sf1.2.m1.1.1.2" xref="S5.F3.sf1.2.m1.1.1.2.cmml">
             F
            </mi>
            <mn id="S5.F3.sf1.2.m1.1.1.3" xref="S5.F3.sf1.2.m1.1.1.3.cmml">
             1
            </mn>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S5.F3.sf1.2.m1.1c">
            <apply id="S5.F3.sf1.2.m1.1.1.cmml" xref="S5.F3.sf1.2.m1.1.1">
             <csymbol cd="ambiguous" id="S5.F3.sf1.2.m1.1.1.1.cmml" xref="S5.F3.sf1.2.m1.1.1">
              subscript
             </csymbol>
             <ci id="S5.F3.sf1.2.m1.1.1.2.cmml" xref="S5.F3.sf1.2.m1.1.1.2">
              ğ¹
             </ci>
             <cn id="S5.F3.sf1.2.m1.1.1.3.cmml" type="integer" xref="S5.F3.sf1.2.m1.1.1.3">
              1
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.F3.sf1.2.m1.1d">
            F_{1}
           </annotation>
          </semantics>
         </math>
         across different document length categories
        </figcaption>
       </figure>
      </div>
      <div class="ltx_flex_cell ltx_flex_size_3">
       <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf2">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="201" id="S5.F3.sf2.g1" src="/html/2311.13565/assets/final_num_tokens.png" width="192"/>
        <figcaption class="ltx_caption">
         <span class="ltx_tag ltx_tag_figure">
          (b)
         </span>
         Tokens Processed for retrieval across different document length categories
        </figcaption>
       </figure>
      </div>
      <div class="ltx_flex_cell ltx_flex_size_3">
       <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf3">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="197" id="S5.F3.sf3.g1" src="/html/2311.13565/assets/final_num_calls.png" width="192"/>
        <figcaption class="ltx_caption">
         <span class="ltx_tag ltx_tag_figure">
          (c)
         </span>
         API calls for retrieval across different document length categories
        </figcaption>
       </figure>
      </div>
     </div>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 3:
      </span>
      <span class="ltx_text ltx_font_bold" id="S5.F3.2.1">
       Analysing the performance of different approaches across different length categories along three metrics for QASPER Dataset
      </span>
     </figcaption>
    </figure>
    <div class="ltx_para" id="S5.SS3.SSS2.p1">
     <p class="ltx_p" id="S5.SS3.SSS2.p1.1">
      We divided the test set into different categories based on their respective lengths. We notice the advantage of our method along three aspects:
     </p>
     <ul class="ltx_itemize" id="S5.I3">
      <li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        â€¢
       </span>
       <div class="ltx_para" id="S5.I3.i1.p1">
        <p class="ltx_p" id="S5.I3.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I3.i1.p1.1.1">
          Evidence
          <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.I3.i1.p1.1.1.m1.1">
           <semantics id="S5.I3.i1.p1.1.1.m1.1a">
            <msub id="S5.I3.i1.p1.1.1.m1.1.1" xref="S5.I3.i1.p1.1.1.m1.1.1.cmml">
             <mi id="S5.I3.i1.p1.1.1.m1.1.1.2" xref="S5.I3.i1.p1.1.1.m1.1.1.2.cmml">
              F
             </mi>
             <mn id="S5.I3.i1.p1.1.1.m1.1.1.3" xref="S5.I3.i1.p1.1.1.m1.1.1.3.cmml">
              1
             </mn>
            </msub>
            <annotation-xml encoding="MathML-Content" id="S5.I3.i1.p1.1.1.m1.1b">
             <apply id="S5.I3.i1.p1.1.1.m1.1.1.cmml" xref="S5.I3.i1.p1.1.1.m1.1.1">
              <csymbol cd="ambiguous" id="S5.I3.i1.p1.1.1.m1.1.1.1.cmml" xref="S5.I3.i1.p1.1.1.m1.1.1">
               subscript
              </csymbol>
              <ci id="S5.I3.i1.p1.1.1.m1.1.1.2.cmml" xref="S5.I3.i1.p1.1.1.m1.1.1.2">
               ğ¹
              </ci>
              <cn id="S5.I3.i1.p1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.I3.i1.p1.1.1.m1.1.1.3">
               1
              </cn>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.I3.i1.p1.1.1.m1.1c">
             F_{1}
            </annotation>
           </semantics>
          </math>
         </span>
         : Our approach consistently achieves competitive performance in evidence retrieval across various document length categories (Figure
         <a class="ltx_ref" href="#S5.F3" title="Figure 3 â€£ 5.3.2 Performance across Different Document Length categories â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
          <span class="ltx_text ltx_ref_tag">
           3
          </span>
         </a>
         (a)).
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        â€¢
       </span>
       <div class="ltx_para" id="S5.I3.i2.p1">
        <p class="ltx_p" id="S5.I3.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I3.i2.p1.1.1">
          Evidence Retrieval Cost
         </span>
         : Our approach significantly reduces the number of processed tokens compared to other methods in all document length categories (Figure
         <a class="ltx_ref" href="#S5.F3" title="Figure 3 â€£ 5.3.2 Performance across Different Document Length categories â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
          <span class="ltx_text ltx_ref_tag">
           3
          </span>
         </a>
         (b)). This cost-efficient characteristic makes it an excellent choice for minimizing both inference and monetary costs, regardless of the documentâ€™s length .
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I3.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        â€¢
       </span>
       <div class="ltx_para" id="S5.I3.i3.p1">
        <p class="ltx_p" id="S5.I3.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I3.i3.p1.1.1">
          Latency
         </span>
         : Irrespective of the documentâ€™s length, our approach maintains a minimal latency by making approximately
         <math alttext="2" class="ltx_Math" display="inline" id="S5.I3.i3.p1.1.m1.1">
          <semantics id="S5.I3.i3.p1.1.m1.1a">
           <mn id="S5.I3.i3.p1.1.m1.1.1" xref="S5.I3.i3.p1.1.m1.1.1.cmml">
            2
           </mn>
           <annotation-xml encoding="MathML-Content" id="S5.I3.i3.p1.1.m1.1b">
            <cn id="S5.I3.i3.p1.1.m1.1.1.cmml" type="integer" xref="S5.I3.i3.p1.1.m1.1.1">
             2
            </cn>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.I3.i3.p1.1.m1.1c">
            2
           </annotation>
          </semantics>
         </math>
         API calls to the LLM (Figure
         <a class="ltx_ref" href="#S5.F3" title="Figure 3 â€£ 5.3.2 Performance across Different Document Length categories â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
          <span class="ltx_text ltx_ref_tag">
           3
          </span>
         </a>
         (c)). This efficient performance further highlights its desirability and suitability for various applications.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.3
     </span>
     Need for Global Context Modeling
    </h4>
    <figure class="ltx_figure" id="S5.F4">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="202" id="S5.F4.g1" src="/html/2311.13565/assets/plots/Ablation_over_chunk_size.png" width="269"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 4:
      </span>
      <span class="ltx_text ltx_font_bold" id="S5.F4.2.1">
       Evidence Precision, Recall and
       <math alttext="\mathbf{F_{1}}" class="ltx_Math" display="inline" id="S5.F4.2.1.m1.1">
        <semantics id="S5.F4.2.1.m1.1b">
         <msub id="S5.F4.2.1.m1.1.1" xref="S5.F4.2.1.m1.1.1.cmml">
          <mi id="S5.F4.2.1.m1.1.1.2" xref="S5.F4.2.1.m1.1.1.2.cmml">
           ğ…
          </mi>
          <mn id="S5.F4.2.1.m1.1.1.3" xref="S5.F4.2.1.m1.1.1.3.cmml">
           ğŸ
          </mn>
         </msub>
         <annotation-xml encoding="MathML-Content" id="S5.F4.2.1.m1.1c">
          <apply id="S5.F4.2.1.m1.1.1.cmml" xref="S5.F4.2.1.m1.1.1">
           <csymbol cd="ambiguous" id="S5.F4.2.1.m1.1.1.1.cmml" xref="S5.F4.2.1.m1.1.1">
            subscript
           </csymbol>
           <ci id="S5.F4.2.1.m1.1.1.2.cmml" xref="S5.F4.2.1.m1.1.1.2">
            ğ…
           </ci>
           <cn id="S5.F4.2.1.m1.1.1.3.cmml" type="integer" xref="S5.F4.2.1.m1.1.1.3">
            1
           </cn>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.F4.2.1.m1.1d">
          \mathbf{F_{1}}
         </annotation>
        </semantics>
       </math>
       over different chunk lengths for QASPER Dataset
      </span>
     </figcaption>
    </figure>
    <div class="ltx_para" id="S5.SS3.SSS3.p1">
     <p class="ltx_p" id="S5.SS3.SSS3.p1.3">
      In this section, we investigate the effect of changing the chunk size of the baseline
      <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.SSS3.p1.3.1">
       Chunk
      </span>
      in terms of evidence precision, recall and
      <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p1.1.m1.1">
       <semantics id="S5.SS3.SSS3.p1.1.m1.1a">
        <msub id="S5.SS3.SSS3.p1.1.m1.1.1" xref="S5.SS3.SSS3.p1.1.m1.1.1.cmml">
         <mi id="S5.SS3.SSS3.p1.1.m1.1.1.2" xref="S5.SS3.SSS3.p1.1.m1.1.1.2.cmml">
          F
         </mi>
         <mn id="S5.SS3.SSS3.p1.1.m1.1.1.3" xref="S5.SS3.SSS3.p1.1.m1.1.1.3.cmml">
          1
         </mn>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p1.1.m1.1b">
         <apply id="S5.SS3.SSS3.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS3.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S5.SS3.SSS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS3.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S5.SS3.SSS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS3.p1.1.m1.1.1.2">
           ğ¹
          </ci>
          <cn id="S5.SS3.SSS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.SSS3.p1.1.m1.1.1.3">
           1
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS3.SSS3.p1.1.m1.1c">
         F_{1}
        </annotation>
       </semantics>
      </math>
      -score. As we see from Figure
      <a class="ltx_ref" href="#S5.F4" title="Figure 4 â€£ 5.3.3 Need for Global Context Modeling â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      , the precision and
      <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p1.2.m2.1">
       <semantics id="S5.SS3.SSS3.p1.2.m2.1a">
        <msub id="S5.SS3.SSS3.p1.2.m2.1.1" xref="S5.SS3.SSS3.p1.2.m2.1.1.cmml">
         <mi id="S5.SS3.SSS3.p1.2.m2.1.1.2" xref="S5.SS3.SSS3.p1.2.m2.1.1.2.cmml">
          F
         </mi>
         <mn id="S5.SS3.SSS3.p1.2.m2.1.1.3" xref="S5.SS3.SSS3.p1.2.m2.1.1.3.cmml">
          1
         </mn>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p1.2.m2.1b">
         <apply id="S5.SS3.SSS3.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS3.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S5.SS3.SSS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.SSS3.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S5.SS3.SSS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.SSS3.p1.2.m2.1.1.2">
           ğ¹
          </ci>
          <cn id="S5.SS3.SSS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS3.SSS3.p1.2.m2.1.1.3">
           1
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS3.SSS3.p1.2.m2.1c">
         F_{1}
        </annotation>
       </semantics>
      </math>
      -score increases at the cost of modest decrease in recall as the chunk-size increasing. This observation underscores the fact that larger chunk sizes enable the model to capture longer-range relationships and contextual information, resulting in improved performance. By processing the entire document in a single pass,
      <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.SS3.SSS3.p1.3.m3.1">
       <semantics id="S5.SS3.SSS3.p1.3.m3.1a">
        <msup id="S5.SS3.SSS3.p1.3.m3.1.1" xref="S5.SS3.SSS3.p1.3.m3.1.1.cmml">
         <mi id="S5.SS3.SSS3.p1.3.m3.1.1.2" xref="S5.SS3.SSS3.p1.3.m3.1.1.2.cmml">
          ğƒ
         </mi>
         <mn id="S5.SS3.SSS3.p1.3.m3.1.1.3" xref="S5.SS3.SSS3.p1.3.m3.1.1.3.cmml">
          3
         </mn>
        </msup>
        <annotation-xml encoding="MathML-Content" id="S5.SS3.SSS3.p1.3.m3.1b">
         <apply id="S5.SS3.SSS3.p1.3.m3.1.1.cmml" xref="S5.SS3.SSS3.p1.3.m3.1.1">
          <csymbol cd="ambiguous" id="S5.SS3.SSS3.p1.3.m3.1.1.1.cmml" xref="S5.SS3.SSS3.p1.3.m3.1.1">
           superscript
          </csymbol>
          <ci id="S5.SS3.SSS3.p1.3.m3.1.1.2.cmml" xref="S5.SS3.SSS3.p1.3.m3.1.1.2">
           ğƒ
          </ci>
          <cn id="S5.SS3.SSS3.p1.3.m3.1.1.3.cmml" type="integer" xref="S5.SS3.SSS3.p1.3.m3.1.1.3">
           3
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS3.SSS3.p1.3.m3.1c">
         \mathbf{D}^{3}
        </annotation>
       </semantics>
      </math>
      benefits from accessing the global context and long-range relationships, leading to enhanced performance.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.4
     </span>
     Role of Discourse Headings and Sub-headings
    </h4>
    <figure class="ltx_table" id="S5.T4">
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.3">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S5.T4.3.4.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T4.3.4.1.1" rowspan="2">
         <span class="ltx_text" id="S5.T4.3.4.1.1.1">
          Approach
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.3.4.1.2">
         Evidence
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.3.4.1.3">
         Tokens
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.3.4.1.4">
         API
        </th>
       </tr>
       <tr class="ltx_tr" id="S5.T4.1.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.1.1">
         <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.T4.1.1.1.m1.1">
          <semantics id="S5.T4.1.1.1.m1.1a">
           <msub id="S5.T4.1.1.1.m1.1.1" xref="S5.T4.1.1.1.m1.1.1.cmml">
            <mi id="S5.T4.1.1.1.m1.1.1.2" xref="S5.T4.1.1.1.m1.1.1.2.cmml">
             F
            </mi>
            <mn id="S5.T4.1.1.1.m1.1.1.3" xref="S5.T4.1.1.1.m1.1.1.3.cmml">
             1
            </mn>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.m1.1b">
            <apply id="S5.T4.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T4.1.1.1.m1.1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S5.T4.1.1.1.m1.1.1.2.cmml" xref="S5.T4.1.1.1.m1.1.1.2">
              ğ¹
             </ci>
             <cn id="S5.T4.1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T4.1.1.1.m1.1.1.3">
              1
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T4.1.1.1.m1.1c">
            F_{1}
           </annotation>
          </semantics>
         </math>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.1.2">
         Processed
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.1.3">
         Calls
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S5.T4.2.2">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S5.T4.2.2.1">
         <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T4.2.2.1.m1.1">
          <semantics id="S5.T4.2.2.1.m1.1a">
           <msup id="S5.T4.2.2.1.m1.1.1" xref="S5.T4.2.2.1.m1.1.1.cmml">
            <mi id="S5.T4.2.2.1.m1.1.1.2" xref="S5.T4.2.2.1.m1.1.1.2.cmml">
             ğƒ
            </mi>
            <mn id="S5.T4.2.2.1.m1.1.1.3" xref="S5.T4.2.2.1.m1.1.1.3.cmml">
             3
            </mn>
           </msup>
           <annotation-xml encoding="MathML-Content" id="S5.T4.2.2.1.m1.1b">
            <apply id="S5.T4.2.2.1.m1.1.1.cmml" xref="S5.T4.2.2.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T4.2.2.1.m1.1.1.1.cmml" xref="S5.T4.2.2.1.m1.1.1">
              superscript
             </csymbol>
             <ci id="S5.T4.2.2.1.m1.1.1.2.cmml" xref="S5.T4.2.2.1.m1.1.1.2">
              ğƒ
             </ci>
             <cn id="S5.T4.2.2.1.m1.1.1.3.cmml" type="integer" xref="S5.T4.2.2.1.m1.1.1.3">
              3
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T4.2.2.1.m1.1c">
            \mathbf{D}^{3}
           </annotation>
          </semantics>
         </math>
         <span class="ltx_text ltx_font_smallcaps" id="S5.T4.2.2.1.1">
          -Base
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.2">
         49.92
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.3">
         1980.94
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.4">
         1.99
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T4.3.3">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S5.T4.3.3.1">
         <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T4.3.3.1.m1.1">
          <semantics id="S5.T4.3.3.1.m1.1a">
           <msup id="S5.T4.3.3.1.m1.1.1" xref="S5.T4.3.3.1.m1.1.1.cmml">
            <mi id="S5.T4.3.3.1.m1.1.1.2" xref="S5.T4.3.3.1.m1.1.1.2.cmml">
             ğƒ
            </mi>
            <mn id="S5.T4.3.3.1.m1.1.1.3" xref="S5.T4.3.3.1.m1.1.1.3.cmml">
             3
            </mn>
           </msup>
           <annotation-xml encoding="MathML-Content" id="S5.T4.3.3.1.m1.1b">
            <apply id="S5.T4.3.3.1.m1.1.1.cmml" xref="S5.T4.3.3.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T4.3.3.1.m1.1.1.1.cmml" xref="S5.T4.3.3.1.m1.1.1">
              superscript
             </csymbol>
             <ci id="S5.T4.3.3.1.m1.1.1.2.cmml" xref="S5.T4.3.3.1.m1.1.1.2">
              ğƒ
             </ci>
             <cn id="S5.T4.3.3.1.m1.1.1.3.cmml" type="integer" xref="S5.T4.3.3.1.m1.1.1.3">
              3
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T4.3.3.1.m1.1c">
            \mathbf{D}^{3}
           </annotation>
          </semantics>
         </math>
         <span class="ltx_text ltx_font_smallcaps" id="S5.T4.3.3.1.1">
          -Base
         </span>
         Ã—
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.3.3.2">
         43.11
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.3.3.3">
         2183.55
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.3.3.4">
         1.88
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 4:
      </span>
      <span class="ltx_text ltx_font_bold" id="S5.T4.5.1">
       Performance of different methods with and without section information (denoted by Ã—) for QASPER dataset.
      </span>
     </figcaption>
    </figure>
    <div class="ltx_para" id="S5.SS3.SSS4.p1">
     <p class="ltx_p" id="S5.SS3.SSS4.p1.1">
      To assess the importance of section headings / sub-headings in the discourse structure for retrieval, we replaced them with randomly initialized Universally Unique Identifiers (UUIDs) and test evidence retrieval performance over the QASPER dataset (Table
      <a class="ltx_ref" href="#S5.T4" title="Table 4 â€£ 5.3.4 Role of Discourse Headings and Sub-headings â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      ). The significant decrease in the performance shows that section headings / sub-headings are crucial in conveying the topical essence of a section, which is needed for accurate retrieval.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.5
     </span>
     Evidence Retrieval Performance over Question Categories
    </h4>
    <div class="ltx_para" id="S5.SS3.SSS5.p1">
     <p class="ltx_p" id="S5.SS3.SSS5.p1.1">
      In this section, we compare
      <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.SS3.SSS5.p1.1.m1.1">
       <semantics id="S5.SS3.SSS5.p1.1.m1.1a">
        <msup id="S5.SS3.SSS5.p1.1.m1.1.1" xref="S5.SS3.SSS5.p1.1.m1.1.1.cmml">
         <mi id="S5.SS3.SSS5.p1.1.m1.1.1.2" xref="S5.SS3.SSS5.p1.1.m1.1.1.2.cmml">
          ğƒ
         </mi>
         <mn id="S5.SS3.SSS5.p1.1.m1.1.1.3" xref="S5.SS3.SSS5.p1.1.m1.1.1.3.cmml">
          3
         </mn>
        </msup>
        <annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p1.1.m1.1b">
         <apply id="S5.SS3.SSS5.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS5.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S5.SS3.SSS5.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS5.p1.1.m1.1.1">
           superscript
          </csymbol>
          <ci id="S5.SS3.SSS5.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS5.p1.1.m1.1.1.2">
           ğƒ
          </ci>
          <cn id="S5.SS3.SSS5.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.SSS5.p1.1.m1.1.1.3">
           3
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS3.SSS5.p1.1.m1.1c">
         \mathbf{D}^{3}
        </annotation>
       </semantics>
      </math>
      -
      <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.SSS5.p1.1.1">
       Base
      </span>
      with the best performing zero-shot baseline
      <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.SSS5.p1.1.2">
       map-reduce optimized (MRO)
      </span>
      over different question categories in QASPER to identify differences in model performance (Table
      <a class="ltx_ref" href="#S5.T5" title="Table 5 â€£ 5.3.5 Evidence Retrieval Performance over Question Categories â€£ 5.3 Ablations &amp; Analyses â€£ 5 Experiments and Results â€£ Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      ). While our approach is precise in identifying the evidence paragraphs, it occasionally falls short in identifying all pertinent evidence (i.e. lower recall). This indicates that representing a section with a summary leads to loss of information and the LLM may miscategorize its relevancy to a question due to this loss of information. Designing an effective strategy to prevent loss of vital information for a particular question may be a future research direction.
     </p>
    </div>
    <figure class="ltx_table" id="S5.T5">
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.4">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S5.T5.4.5.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.4.5.1.1">
         Question
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.4.5.1.2">
         Evidence
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.4.5.1.3">
         Evidence
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.4.5.1.4">
         Evidence
        </th>
       </tr>
       <tr class="ltx_tr" id="S5.T5.1.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.1.2">
         Category
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.1.3">
         Precision
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.1.4">
         Recall
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.1.1">
         <math alttext="F_{1}" class="ltx_Math" display="inline" id="S5.T5.1.1.1.m1.1">
          <semantics id="S5.T5.1.1.1.m1.1a">
           <msub id="S5.T5.1.1.1.m1.1.1" xref="S5.T5.1.1.1.m1.1.1.cmml">
            <mi id="S5.T5.1.1.1.m1.1.1.2" xref="S5.T5.1.1.1.m1.1.1.2.cmml">
             F
            </mi>
            <mn id="S5.T5.1.1.1.m1.1.1.3" xref="S5.T5.1.1.1.m1.1.1.3.cmml">
             1
            </mn>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.m1.1b">
            <apply id="S5.T5.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T5.1.1.1.m1.1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S5.T5.1.1.1.m1.1.1.2.cmml" xref="S5.T5.1.1.1.m1.1.1.2">
              ğ¹
             </ci>
             <cn id="S5.T5.1.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T5.1.1.1.m1.1.1.3">
              1
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T5.1.1.1.m1.1c">
            F_{1}
           </annotation>
          </semantics>
         </math>
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S5.T5.4.4">
        <td class="ltx_td" id="S5.T5.4.4.4">
        </td>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.2.2.1">
         (
         <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T5.2.2.1.m1.1">
          <semantics id="S5.T5.2.2.1.m1.1a">
           <msup id="S5.T5.2.2.1.m1.1.1" xref="S5.T5.2.2.1.m1.1.1.cmml">
            <mi id="S5.T5.2.2.1.m1.1.1.2" xref="S5.T5.2.2.1.m1.1.1.2.cmml">
             ğƒ
            </mi>
            <mn id="S5.T5.2.2.1.m1.1.1.3" xref="S5.T5.2.2.1.m1.1.1.3.cmml">
             3
            </mn>
           </msup>
           <annotation-xml encoding="MathML-Content" id="S5.T5.2.2.1.m1.1b">
            <apply id="S5.T5.2.2.1.m1.1.1.cmml" xref="S5.T5.2.2.1.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T5.2.2.1.m1.1.1.1.cmml" xref="S5.T5.2.2.1.m1.1.1">
              superscript
             </csymbol>
             <ci id="S5.T5.2.2.1.m1.1.1.2.cmml" xref="S5.T5.2.2.1.m1.1.1.2">
              ğƒ
             </ci>
             <cn id="S5.T5.2.2.1.m1.1.1.3.cmml" type="integer" xref="S5.T5.2.2.1.m1.1.1.3">
              3
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T5.2.2.1.m1.1c">
            \mathbf{D}^{3}
           </annotation>
          </semantics>
         </math>
         /
         <span class="ltx_text ltx_font_smallcaps" id="S5.T5.2.2.1.1">
          MRO
         </span>
         )
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.3.3.2">
         (
         <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T5.3.3.2.m1.1">
          <semantics id="S5.T5.3.3.2.m1.1a">
           <msup id="S5.T5.3.3.2.m1.1.1" xref="S5.T5.3.3.2.m1.1.1.cmml">
            <mi id="S5.T5.3.3.2.m1.1.1.2" xref="S5.T5.3.3.2.m1.1.1.2.cmml">
             ğƒ
            </mi>
            <mn id="S5.T5.3.3.2.m1.1.1.3" xref="S5.T5.3.3.2.m1.1.1.3.cmml">
             3
            </mn>
           </msup>
           <annotation-xml encoding="MathML-Content" id="S5.T5.3.3.2.m1.1b">
            <apply id="S5.T5.3.3.2.m1.1.1.cmml" xref="S5.T5.3.3.2.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T5.3.3.2.m1.1.1.1.cmml" xref="S5.T5.3.3.2.m1.1.1">
              superscript
             </csymbol>
             <ci id="S5.T5.3.3.2.m1.1.1.2.cmml" xref="S5.T5.3.3.2.m1.1.1.2">
              ğƒ
             </ci>
             <cn id="S5.T5.3.3.2.m1.1.1.3.cmml" type="integer" xref="S5.T5.3.3.2.m1.1.1.3">
              3
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T5.3.3.2.m1.1c">
            \mathbf{D}^{3}
           </annotation>
          </semantics>
         </math>
         /
         <span class="ltx_text ltx_font_smallcaps" id="S5.T5.3.3.2.1">
          MRO
         </span>
         )
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.4.4.3">
         (
         <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T5.4.4.3.m1.1">
          <semantics id="S5.T5.4.4.3.m1.1a">
           <msup id="S5.T5.4.4.3.m1.1.1" xref="S5.T5.4.4.3.m1.1.1.cmml">
            <mi id="S5.T5.4.4.3.m1.1.1.2" xref="S5.T5.4.4.3.m1.1.1.2.cmml">
             ğƒ
            </mi>
            <mn id="S5.T5.4.4.3.m1.1.1.3" xref="S5.T5.4.4.3.m1.1.1.3.cmml">
             3
            </mn>
           </msup>
           <annotation-xml encoding="MathML-Content" id="S5.T5.4.4.3.m1.1b">
            <apply id="S5.T5.4.4.3.m1.1.1.cmml" xref="S5.T5.4.4.3.m1.1.1">
             <csymbol cd="ambiguous" id="S5.T5.4.4.3.m1.1.1.1.cmml" xref="S5.T5.4.4.3.m1.1.1">
              superscript
             </csymbol>
             <ci id="S5.T5.4.4.3.m1.1.1.2.cmml" xref="S5.T5.4.4.3.m1.1.1.2">
              ğƒ
             </ci>
             <cn id="S5.T5.4.4.3.m1.1.1.3.cmml" type="integer" xref="S5.T5.4.4.3.m1.1.1.3">
              3
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T5.4.4.3.m1.1c">
            \mathbf{D}^{3}
           </annotation>
          </semantics>
         </math>
         /
         <span class="ltx_text ltx_font_smallcaps" id="S5.T5.4.4.3.1">
          MRO
         </span>
         )
        </th>
       </tr>
       <tr class="ltx_tr" id="S5.T5.4.6.1">
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.6.1.1">
         Extractive
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.6.1.2">
         52.63 / 52.19
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.6.1.3">
         71.9 / 81.49
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.6.1.4">
         56.39 / 57.46
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T5.4.7.2">
        <td class="ltx_td ltx_align_center" id="S5.T5.4.7.2.1">
         Abstractive
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.4.7.2.2">
         41.25 / 45.1
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.4.7.2.3">
         52.51 / 71.57
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.4.7.2.4">
         41.78 / 50.12
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T5.4.8.3">
        <td class="ltx_td ltx_align_center" id="S5.T5.4.8.3.1">
         Yes/No
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.4.8.3.2">
         43.6 / 38.79
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.4.8.3.3">
         59.6 / 55.31
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.4.8.3.4">
         45.53 / 40.18
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T5.4.9.4">
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.9.4.1">
         Unanswerable
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.9.4.2">
         42.94 / 25.74
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.9.4.3">
         44.4 / 25.46
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.9.4.4">
         43.43 / 25.10
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 5:
      </span>
      <span class="ltx_text ltx_font_bold" id="S5.T5.6.1">
       Comparison of evidence retrieval performance of
       <math alttext="\mathbf{D}^{3}" class="ltx_Math" display="inline" id="S5.T5.6.1.m1.1">
        <semantics id="S5.T5.6.1.m1.1b">
         <msup id="S5.T5.6.1.m1.1.1" xref="S5.T5.6.1.m1.1.1.cmml">
          <mi id="S5.T5.6.1.m1.1.1.2" xref="S5.T5.6.1.m1.1.1.2.cmml">
           ğƒ
          </mi>
          <mn id="S5.T5.6.1.m1.1.1.3" xref="S5.T5.6.1.m1.1.1.3.cmml">
           3
          </mn>
         </msup>
         <annotation-xml encoding="MathML-Content" id="S5.T5.6.1.m1.1c">
          <apply id="S5.T5.6.1.m1.1.1.cmml" xref="S5.T5.6.1.m1.1.1">
           <csymbol cd="ambiguous" id="S5.T5.6.1.m1.1.1.1.cmml" xref="S5.T5.6.1.m1.1.1">
            superscript
           </csymbol>
           <ci id="S5.T5.6.1.m1.1.1.2.cmml" xref="S5.T5.6.1.m1.1.1.2">
            ğƒ
           </ci>
           <cn id="S5.T5.6.1.m1.1.1.3.cmml" type="integer" xref="S5.T5.6.1.m1.1.1.3">
            3
           </cn>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.T5.6.1.m1.1d">
          \mathbf{D}^{3}
         </annotation>
        </semantics>
       </math>
       -
       <span class="ltx_text ltx_font_smallcaps" id="S5.T5.6.1.1">
        Base
       </span>
       with the best performing zero-shot baseline
       <span class="ltx_text ltx_font_smallcaps" id="S5.T5.6.1.2">
        map-reduce optimized (MRO)
       </span>
      </span>
     </figcaption>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    We demonstrated a zero-shot approach for evidence retrieval which leverages the discourse structure of the document for information categorization which not only yielded competitive performance for information seeking and question answering with multi-hop reasoning setting, but also processed lowest number of tokens resulting in significant compute and cost savings. This approach demonstrates several desirable characteristics such as robustness in evidence retrieval performance, lower latency, etc. all across different document length ranges.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Limitations
  </h2>
  <div class="ltx_para" id="S7.p1">
   <ul class="ltx_itemize" id="S7.I1">
    <li class="ltx_item" id="S7.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      â€¢
     </span>
     <div class="ltx_para" id="S7.I1.i1.p1">
      <p class="ltx_p" id="S7.I1.i1.p1.1">
       Although our approach demonstrated competitive performance in the information seeking setup, there is room for improvement, particularly when confronted with questions that require intricate multi-hop reasoning. Since we represent the document by summarizing each section, there is a potential loss of critical information that is essential for addressing complex queries necessitating multi-hop reasoning. Moving forward, we aim to explore methods that allow for accurate section selection while minimizing inference costs and mitigating information loss.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S7.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      â€¢
     </span>
     <div class="ltx_para" id="S7.I1.i2.p1">
      <p class="ltx_p" id="S7.I1.i2.p1.1">
       Our experimental analyses primarily focus on enterprise-level language models, which require enterprise compute credits. In the future, we plan to explore the capabilities of more advanced open-source models as they become available, which may offer enhanced performance and accessibility.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S7.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      â€¢
     </span>
     <div class="ltx_para" id="S7.I1.i3.p1">
      <p class="ltx_p" id="S7.I1.i3.p1.1">
       While our experiments have primarily centered around single-document use cases, we have yet to delve into the realm of retrieval involving multiple documents or collections. This area remains unexplored, and we anticipate investigating strategies and techniques to effectively handle such scenarios.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S7.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      â€¢
     </span>
     <div class="ltx_para" id="S7.I1.i4.p1">
      <p class="ltx_p" id="S7.I1.i4.p1.1">
       Although our evaluations provided insight into how various summarizers impacted the final downstream performance, the current study did not inherently assess the quality of summarization. In future work, we aim to assess the summarizationâ€™s faithfulness to the original content and its impact on end-to-end performance.
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ainslie etÂ al. (2023)
    </span>
    <span class="ltx_bibblock">
     Joshua Ainslie, Tao Lei, Michiel deÂ Jong, Santiago OntaÃ±Ã³n, Siddhartha
Brahma, Yury Zemlyanskiy, David Uthus, Mandy Guo, James Lee-Thorp, YiÂ Tay,
etÂ al. 2023.
    </span>
    <span class="ltx_bibblock">
     Colt5: Faster long-range transformers with conditional computation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint arXiv:2303.09752
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ainslie etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek, Zachary Fisher,
Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, and LiÂ Yang. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.19" target="_blank" title="">
      ETC:
Encoding long and structured inputs in transformers
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)
     </em>
     , pages 268â€“284, Online. Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bai etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph,
Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage,
Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna
Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown,
Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2204.05862" target="_blank" title="">
      Training a helpful and
harmless assistant with reinforcement learning from human feedback
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Betz etÂ al. (2021)
    </span>
    <span class="ltx_bibblock">
     Gregor Betz, Kyle Richardson, and Christian Voigt. 2021.
    </span>
    <span class="ltx_bibblock">
     Thinking aloud: Dynamic context generation improves zero-shot
reasoning performance of gpt-2.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2103.13033
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bevilacqua etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Michele Bevilacqua, Giuseppe Ottaviano, Patrick Lewis, Scott Yih, Sebastian
Riedel, and Fabio Petroni. 2022.
    </span>
    <span class="ltx_bibblock">
     Autoregressive search engines: Generating substrings as document
identifiers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      Advances in Neural Information Processing Systems
     </em>
     ,
35:31668â€“31683.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, JaredÂ D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
etÂ al. 2020.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      Advances in neural information processing systems
     </em>
     ,
33:1877â€“1901.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cao and Wang (2022)
    </span>
    <span class="ltx_bibblock">
     Shuyang Cao and LuÂ Wang. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.58" target="_blank" title="">
      HIBRIDS:
Attention with hierarchical biases for structure-aware long document
summarization
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pages 786â€“807,
Dublin, Ireland. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen etÂ al. (2017)
    </span>
    <span class="ltx_bibblock">
     Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P17-1171" target="_blank" title="">
      Reading Wikipedia to
answer open-domain questions
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pages 1870â€“1879,
Vancouver, Canada. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen etÂ al. (2021)
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde deÂ Oliveira
Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
Brockman, etÂ al. 2021.
    </span>
    <span class="ltx_bibblock">
     Evaluating large language models trained on code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2107.03374
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chiang etÂ al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wei-Lin Chiang, Zhuohan Li, ZiÂ Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
Zheng, Siyuan Zhuang, Yonghao Zhuang, JosephÂ E Gonzalez, etÂ al. 2023.
    </span>
    <span class="ltx_bibblock">
     Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt
quality.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      See https://vicuna. lmsys. org (accessed 14 April 2023)
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chowdhery etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
Adam Roberts, Paul Barham, HyungÂ Won Chung, Charles Sutton, Sebastian
Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
Abhishek Rao, Parker Barnes, YiÂ Tay, Noam Shazeer, Vinodkumar Prabhakaran,
Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
Dohan, Shivani Agrawal, Mark Omernick, AndrewÂ M. Dai,
ThanumalayanÂ Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2204.02311" target="_blank" title="">
      Palm: Scaling language
modeling with pathways
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chung etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     HyungÂ Won Chung, LeÂ Hou, Shayne Longpre, Barret Zoph, YiÂ Tay, William Fedus,
Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson,
ShixiangÂ Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha
Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter,
Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew
Dai, Hongkun Yu, Slav Petrov, EdÂ H. Chi, Jeff Dean, Jacob Devlin, Adam
Roberts, Denny Zhou, QuocÂ V. Le, and Jason Wei. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2210.11416" target="_blank" title="">
      Scaling
instruction-finetuned language models
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Das etÂ al. (2019)
    </span>
    <span class="ltx_bibblock">
     Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, and Andrew McCallum. 2019.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=HkfPSh05K7" target="_blank" title="">
      Multi-step
retriever-reader interaction for scalable open-domain question answering
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      International Conference on Learning Representations
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dasigi etÂ al. (2021)
    </span>
    <span class="ltx_bibblock">
     Pradeep Dasigi, Kyle Lo, IzÂ Beltagy, Arman Cohan, NoahÂ A. Smith, and Matt
Gardner. 2021.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.365" target="_blank" title="">
      A dataset of
information-seeking questions and answers anchored in research papers
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies
     </em>
     , pages 4599â€“4610, Online. Association for Computational
Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Devlin etÂ al. (2019)
    </span>
    <span class="ltx_bibblock">
     Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1423" target="_blank" title="">
      BERT: Pre-training of
deep bidirectional transformers for language understanding
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)
     </em>
     , pages 4171â€“4186,
Minneapolis, Minnesota. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong etÂ al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zican Dong, Tianyi Tang, Lunyi Li, and WayneÂ Xin Zhao. 2023.
    </span>
    <span class="ltx_bibblock">
     A survey on long text modeling with transformers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      arXiv preprint arXiv:2302.14502
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dunn etÂ al. (2017)
    </span>
    <span class="ltx_bibblock">
     Matthew Dunn, Levent Sagun, Mike Higgins, VÂ Ugur Guney, Volkan Cirik, and
Kyunghyun Cho. 2017.
    </span>
    <span class="ltx_bibblock">
     Searchqa: A new q&amp;a dataset augmented with context from a search
engine.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:1704.05179
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     El-Kassas etÂ al. (2021)
    </span>
    <span class="ltx_bibblock">
     WafaaÂ S El-Kassas, CherifÂ R Salama, AhmedÂ A Rafea, and HodaÂ K Mohamed. 2021.
    </span>
    <span class="ltx_bibblock">
     Automatic text summarization: A comprehensive survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      Expert systems with applications
     </em>
     , 165:113679.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ferguson etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     James Ferguson, Matt Gardner, Hannaneh Hajishirzi, Tushar Khot, and Pradeep
Dasigi. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.86" target="_blank" title="">
      IIRC: A
dataset of incomplete information reading comprehension questions
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)
     </em>
     , pages 1137â€“1147, Online. Association
for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gong etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Hongyu Gong, Yelong Shen, Dian Yu, Jianshu Chen, and Dong Yu. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.603" target="_blank" title="">
      Recurrent
chunking mechanisms for long-text machine reading comprehension
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics
     </em>
     , pages 6751â€“6761, Online. Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     GreenÂ Jr etÂ al. (1961)
    </span>
    <span class="ltx_bibblock">
     BertÂ F GreenÂ Jr, AliceÂ K Wolf, Carol Chomsky, and Kenneth Laughery. 1961.
    </span>
    <span class="ltx_bibblock">
     Baseball: an automatic question-answerer.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      Papers presented at the May 9-11, 1961, western joint
IRE-AIEE-ACM computer conference
     </em>
     , pages 219â€“224.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guthrie etÂ al. (1991)
    </span>
    <span class="ltx_bibblock">
     JohnÂ T Guthrie, Tracy Britten, and KÂ Georgene Barker. 1991.
    </span>
    <span class="ltx_bibblock">
     Roles of document structure, cognitive strategy, and awareness in
searching for information.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      Reading Research Quarterly
     </em>
     , pages 300â€“324.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guthrie and Kirsch (1987)
    </span>
    <span class="ltx_bibblock">
     JohnÂ T Guthrie and IrwinÂ S Kirsch. 1987.
    </span>
    <span class="ltx_bibblock">
     Distinctions between reading comprehension and locating information
in text.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      Journal of educational psychology
     </em>
     , 79(3):220.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guthrie and Mosenthal (1987)
    </span>
    <span class="ltx_bibblock">
     JohnÂ T Guthrie and Peter Mosenthal. 1987.
    </span>
    <span class="ltx_bibblock">
     Literacy as multidimensional: Locating information and reading
comprehension.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      Educational Psychologist
     </em>
     , 22(3-4):279â€“297.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guu etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020.
    </span>
    <span class="ltx_bibblock">
     Retrieval augmented language model pre-training.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      International conference on machine learning
     </em>
     , pages
3929â€“3938. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hoffmann etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor
Cai, Eliza Rutherford, Diego deÂ LasÂ Casas, LisaÂ Anne Hendricks, Johannes
Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George vanÂ den
Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich
Elsen, JackÂ W. Rae, Oriol Vinyals, and Laurent Sifre. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2203.15556" target="_blank" title="">
      Training compute-optimal
large language models
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Joshi etÂ al. (2017)
    </span>
    <span class="ltx_bibblock">
     Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. 2017.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P17-1147" target="_blank" title="">
      TriviaQA: A large
scale distantly supervised challenge dataset for reading comprehension
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pages 1601â€“1611,
Vancouver, Canada. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Karpukhin etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey
Edunov, Danqi Chen, and Wen-tau Yih. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.550" target="_blank" title="">
      Dense
passage retrieval for open-domain question answering
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)
     </em>
     , pages 6769â€“6781, Online. Association
for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (29)
    </span>
    <span class="ltx_bibblock">
     LangChain.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/hwchase17/langchain" target="_blank" title="">
      Langchain
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewis etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.703" target="_blank" title="">
      BART:
Denoising sequence-to-sequence pre-training for natural language generation,
translation, and comprehension
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics
     </em>
     , pages 7871â€“7880, Online. Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu etÂ al. (2019)
    </span>
    <span class="ltx_bibblock">
     Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.
    </span>
    <span class="ltx_bibblock">
     Roberta: A robustly optimized bert pretraining approach.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:1907.11692
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Meyer etÂ al. (1980)
    </span>
    <span class="ltx_bibblock">
     Bonnie J.Â F. Meyer, DavidÂ M. Brandt, and GeorgeÂ J. Bluth. 1980.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://www.jstor.org/stable/747349" target="_blank" title="">
      Use of top-level
structure in text: Key for reading comprehension of ninth-grade students
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      Reading Research Quarterly
     </em>
     , 16(1):72â€“103.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Min etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Sewon Min, Mike Lewis, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.201" target="_blank" title="">
      MetaICL:
Learning to learn in context
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      Proceedings of the 2022 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies
     </em>
     , pages 2791â€“2809, Seattle, United States. Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nair etÂ al. (2023)
    </span>
    <span class="ltx_bibblock">
     Inderjeet Nair, Aparna Garimella, BalajiÂ Vasan Srinivasan, Natwar Modani,
Niyati Chhaya, Srikrishna Karanam, and Sumit Shekhar. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.findings-eacl.65" target="_blank" title="">
      A neural
CRF-based hierarchical approach for linear text segmentation
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      Findings of the Association for Computational Linguistics:
EACL 2023
     </em>
     , pages 883â€“893, Dubrovnik, Croatia. Association for Computational
Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nakano etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina
Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders,
XuÂ Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew
Knight, Benjamin Chess, and John Schulman. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2112.09332" target="_blank" title="">
      Webgpt: Browser-assisted
question-answering with human feedback
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nallapati etÂ al. (2016)
    </span>
    <span class="ltx_bibblock">
     Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Ã‡aÄŸlar
GulÃ§ehre, and Bing Xiang. 2016.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/K16-1028" target="_blank" title="">
      Abstractive text
summarization using sequence-to-sequence RNNs and beyond
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      Proceedings of the 20th SIGNLL Conference on Computational
Natural Language Learning
     </em>
     , pages 280â€“290, Berlin, Germany. Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nguyen etÂ al. (2016)
    </span>
    <span class="ltx_bibblock">
     Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan
Majumder, and LiÂ Deng. 2016.
    </span>
    <span class="ltx_bibblock">
     Ms marco: A human generated machine reading comprehension dataset.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      choice
     </em>
     , 2640:660.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nie etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Yuxiang Nie, Heyan Huang, Wei Wei, and Xian-Ling Mao. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.emnlp-main.336" target="_blank" title="">
      Capturing
global structural information in long document question answering with
compressive graph selector network
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing
     </em>
     , pages 5036â€“5047, Abu Dhabi, United Arab
Emirates. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nogueira etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, and Jimmy Lin. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.findings-emnlp.63" target="_blank" title="">
      Document
ranking with a pretrained sequence-to-sequence model
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      Findings of the Association for Computational Linguistics:
EMNLP 2020
     </em>
     , pages 708â€“718, Online. Association for Computational
Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.08774" target="_blank" title="">
      Gpt-4 technical report
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ouyang etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Long Ouyang, Jeff Wu, XuÂ Jiang, Diogo Almeida, CarrollÂ L. Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2203.02155" target="_blank" title="">
      Training language models to
follow instructions with human feedback
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pereira etÂ al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jayr Pereira, Robson Fidalgo, Roberto Lotufo, and Rodrigo Nogueira. 2023.
    </span>
    <span class="ltx_bibblock">
     Visconde: Multi-document qa with gpt-3 and neural reranking.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      European Conference on Information Retrieval
     </em>
     , pages
534â€“543. Springer.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Perez etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Ethan Perez, Patrick Lewis, Wen-tau Yih, Kyunghyun Cho, and Douwe Kiela. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.713" target="_blank" title="">
      Unsupervised
question decomposition for question answering
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)
     </em>
     , pages 8864â€“8880, Online. Association
for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Press etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, NoahÂ A Smith, and Mike
Lewis. 2022.
    </span>
    <span class="ltx_bibblock">
     Measuring and narrowing the compositionality gap in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      arXiv preprint arXiv:2210.03350
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rae etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     JackÂ W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann,
Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young,
Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell,
George vanÂ den Driessche, LisaÂ Anne Hendricks, Maribeth Rauh, Po-Sen Huang,
Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan
Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu,
Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme
Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens,
XiangÂ Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya,
Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau,
Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas
Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien
deÂ MassonÂ dâ€™Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor
Babuschkin, Aidan Clark, Diego deÂ LasÂ Casas, Aurelia Guy, Chris Jones, James
Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel,
William Isaac, EdÂ Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol
Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray
Kavukcuoglu, and Geoffrey Irving. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2112.11446" target="_blank" title="">
      Scaling language models:
Methods, analysis &amp; insights from training gopher
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Raffel etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and PeterÂ J Liu. 2020.
    </span>
    <span class="ltx_bibblock">
     Exploring the limits of transfer learning with a unified text-to-text
transformer.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      Journal of Machine Learning Research
     </em>
     , 21:1â€“67.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Reimers and Gurevych (2019)
    </span>
    <span class="ltx_bibblock">
     Nils Reimers and Iryna Gurevych. 2019.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-1410" target="_blank" title="">
      Sentence-BERT:
Sentence embeddings using Siamese BERT-networks
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)
     </em>
     , pages 3982â€“3992, Hong Kong,
China. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Reynolds and McDonell (2021)
    </span>
    <span class="ltx_bibblock">
     Laria Reynolds and Kyle McDonell. 2021.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3411763.3451760" target="_blank" title="">
      Prompt programming
for large language models: Beyond the few-shot paradigm
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">
      Extended Abstracts of the 2021 CHI Conference on Human
Factors in Computing Systems
     </em>
     , CHI EA â€™21, New York, NY, USA. Association for
Computing Machinery.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tan etÂ al. (2021)
    </span>
    <span class="ltx_bibblock">
     Bowen Tan, Zichao Yang, Maruan Al-Shedivat, Eric Xing, and Zhiting Hu. 2021.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.341" target="_blank" title="">
      Progressive
generation of long text with pretrained language models
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">
      Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies
     </em>
     , pages 4313â€“4324, Online. Association for Computational
Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tay etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     YiÂ Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen
Qin, Kai Hui, Zhe Zhao, Jai Gupta, etÂ al. 2022.
    </span>
    <span class="ltx_bibblock">
     Transformer memory as a differentiable search index.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">
      Advances in Neural Information Processing Systems
     </em>
     ,
35:21831â€“21843.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Taylor and Beach (1984)
    </span>
    <span class="ltx_bibblock">
     BarbaraÂ M. Taylor and RichardÂ W. Beach. 1984.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://www.jstor.org/stable/747358" target="_blank" title="">
      The effects of text
structure instruction on middle-grade studentsâ€™ comprehension and production
of expository text
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      Reading Research Quarterly
     </em>
     , 19(2):134â€“146.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Thakur etÂ al. (2021)
    </span>
    <span class="ltx_bibblock">
     Nandan Thakur, Nils Reimers, Andreas RÃ¼cklÃ©, Abhishek Srivastava, and
Iryna Gurevych. 2021.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=wCu6T5xFjeJ" target="_blank" title="">
      BEIR: A
heterogeneous benchmark for zero-shot evaluation of information retrieval
models
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">
      Thirty-fifth Conference on Neural Information Processing
Systems Datasets and Benchmarks Track (Round 2)
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Vaswani etÂ al. (2017)
    </span>
    <span class="ltx_bibblock">
     Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017.
    </span>
    <span class="ltx_bibblock">
     Attention is all you need.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">
      Advances in neural information processing systems
     </em>
     , 30.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Voorhees etÂ al. (1999)
    </span>
    <span class="ltx_bibblock">
     EllenÂ M Voorhees etÂ al. 1999.
    </span>
    <span class="ltx_bibblock">
     The trec-8 question answering track report.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">
      Trec
     </em>
     , volumeÂ 99, pages 77â€“82.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang etÂ al. (2018)
    </span>
    <span class="ltx_bibblock">
     Shuohang Wang, MoÂ Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu
Chang, Gerry Tesauro, Bowen Zhou, and Jing Jiang. 2018.
    </span>
    <span class="ltx_bibblock">
     R 3: Reinforced ranker-reader for open-domain question answering.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">
      Proceedings of the AAAI Conference on Artificial
Intelligence
     </em>
     , volumeÂ 32.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei etÂ al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, AdamsÂ Wei Yu, Brian Lester,
Nan Du, AndrewÂ M. Dai, and QuocÂ V Le. 2022a.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=gEZrGCozdqR" target="_blank" title="">
      Finetuned
language models are zero-shot learners
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">
      International Conference on Learning Representations
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei etÂ al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia,
EdÂ H. Chi, QuocÂ V Le, and Denny Zhou. 2022b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=_VjQlMeSB_J" target="_blank" title="">
      Chain of thought
prompting elicits reasoning in large language models
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">
      Advances in Neural Information Processing Systems
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu etÂ al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,
Michael Terry, and CarrieÂ J Cai. 2022a.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3491101.3519729" target="_blank" title="">
      Promptchainer:
Chaining large language model prompts through visual programming
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">
      Extended Abstracts of the 2022 CHI Conference on Human
Factors in Computing Systems
     </em>
     , CHI EA â€™22, New York, NY, USA. Association for
Computing Machinery.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu etÂ al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Tongshuang Wu, Michael Terry, and CarrieÂ Jun Cai. 2022b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3491102.3517582" target="_blank" title="">
      Ai chains:
Transparent and controllable human-ai interaction by chaining large language
model prompts
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">
      Proceedings of the 2022 CHI Conference on Human Factors in
Computing Systems
     </em>
     , CHI â€™22, New York, NY, USA. Association for Computing
Machinery.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang etÂ al. (2018)
    </span>
    <span class="ltx_bibblock">
     Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan
Salakhutdinov, and ChristopherÂ D. Manning. 2018.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D18-1259" target="_blank" title="">
      HotpotQA: A dataset
for diverse, explainable multi-hop question answering
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">
      Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing
     </em>
     , pages 2369â€“2380, Brussels, Belgium.
Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao etÂ al. (2022)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao, Dian Yu, Izhak Shafran, KarthikÂ R Narasimhan, and
Yuan Cao. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=tvI4u1ylcqs" target="_blank" title="">
      React:
Synergizing reasoning and acting in language models
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">
      NeurIPS 2022 Foundation Models for Decision Making
Workshop
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ye etÂ al. (2023)
    </span>
    <span class="ltx_bibblock">
     Junjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai Shao, Shichun Liu, Yuhan Cui,
Zeyang Zhou, Chao Gong, Yang Shen, etÂ al. 2023.
    </span>
    <span class="ltx_bibblock">
     A comprehensive capability analysis of gpt-3 and gpt-3.5 series
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">
      arXiv preprint arXiv:2303.10420
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng etÂ al. (2020)
    </span>
    <span class="ltx_bibblock">
     BoÂ Zheng, Haoyang Wen, Yaobo Liang, Nan Duan, Wanxiang Che, Daxin Jiang, Ming
Zhou, and Ting Liu. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.599" target="_blank" title="">
      Document
modeling with graph attention networks for multi-grained machine reading
comprehension
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">
      Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics
     </em>
     , pages 6708â€“6718, Online. Association for
Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu etÂ al. (2021)
    </span>
    <span class="ltx_bibblock">
     Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, and
Tat-Seng Chua. 2021.
    </span>
    <span class="ltx_bibblock">
     Retrieving and reading: A comprehensive survey on open-domain
question answering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">
      arXiv preprint arXiv:2101.00774
     </em>
     .
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_para" id="p1">
  <p class="ltx_p" id="p1.1">
  </p>
 </div>
</article>
