<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  Stance Detection with Collaborative Role-Infused LLM-Based Agents
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Xiaochong Lan,
Chen Gao,
Depeng Jin,
Yong Li
    <br class="ltx_break"/>
    Department of Electronic Engineering, BNRist, Tsinghua University, China
    <br class="ltx_break"/>
    lanxc22@mails.tsinghua.edu.cn, {chgao96, jindp, liyong07}@tsinghua.edu.cn
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id1.id1">
   Stance detection automatically detects the stance in a text towards a target, vital for content analysis in web and social media research. Despite their promising capabilities, LLMs encounter challenges when directly applied to stance detection. First, stance detection demands multi-aspect knowledge, from deciphering event-related terminologies to understanding the expression styles in social media platforms. Second, stance detection requires advanced reasoning to infer authors‚Äô implicit viewpoints, as stance are often subtly embedded rather than overtly stated in the text. To address these challenges, we design a three-stage framework COLA (short for
   <span class="ltx_text ltx_font_bold" id="id1.id1.1">
    C
   </span>
   ollaborative r
   <span class="ltx_text ltx_font_bold" id="id1.id1.2">
    O
   </span>
   le-infused
   <span class="ltx_text ltx_font_bold" id="id1.id1.3">
    L
   </span>
   LM-based
   <span class="ltx_text ltx_font_bold" id="id1.id1.4">
    A
   </span>
   gents) in which LLMs are designated distinct roles, creating a collaborative system where each role contributes uniquely. Initially, in the multidimensional text analysis stage, we configure the LLMs to act as a linguistic expert, a domain specialist, and a social media veteran to get a multifaceted analysis of texts, thus overcoming the first challenge. Next, in the reasoning-enhanced debating stage, for each potential stance, we designate a specific LLM-based agent to advocate for it, guiding the LLM to detect logical connections between text features and stance, tackling the second challenge. Finally, in the stance conclusion stage, a final decision maker agent consolidates prior insights to determine the stance. Our approach avoids extra annotated data and model training and is highly usable. We achieve state-of-the-art performance across multiple datasets. Ablation studies validate the effectiveness of each design role in handling stance detection. Further experiments have demonstrated the explainability and the versatility of our approach. Our approach excels in usability, accuracy, effectiveness, explainability and versatility, highlighting its value.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Stance detection is commonly defined as automatically detecting the stance (as
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">
     Favor
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">
     Against
    </span>
    , or
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.3">
     Neutral
    </span>
    ) of the text producer towards a target
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib30" title="">
      mohammad2016semeval
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib31" title="">
      mohammad2017stance
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib6" title="">
      alturayeif2023systematic
     </a>
    </cite>
    . Stance detection plays a pivotal role in the analysis of large-scale text data on the web and social media platforms
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib23" title="">
      jang2018explaining
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib42" title="">
      upadhyaya2023multi
     </a>
    </cite>
    . Over the years, numerous methodologies have been proposed for stance detection
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib24" title="">
      kuccuk2020stance
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib3" title="">
      aldayel2021stance
     </a>
    </cite>
    . However, a persistent challenge lies in the need to train models specifically for the targets of interest. Even with advancements in cross-target stance detection
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib26" title="">
      liang2021target
     </a>
    </cite>
    and zero-shot stance detection
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib4" title="">
      allaway2020zero
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib25" title="">
      liang2022zero
     </a>
    </cite>
    , a suitable training on annotated corpora is often required. Acquiring large-scale labeled datasets is not trivial, which curtails the model‚Äôs usability.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Recently, large language models (LLMs) have demonstrated remarkable capabilities across various applications
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib10" title="">
      brown2020language
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib34" title="">
      park2023generative
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib2" title="">
      ahn2022can
     </a>
    </cite>
    . The inherent semantic understanding of these large models presents an exciting opportunity for stance detection. Most LLMs can be easily interacted with by users through zero-shot prompting. This significantly enhances the usability of models. Thus, with their strength and usability, large language models could reshape how we approach stance detection.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    Researchers have discerned the transformative potential LLMs bring to stance detection. Some works have proposed simple methods using LLMs for stance detection
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib51" title="">
      zhang2022would
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib52" title="">
      zhang2023investigating
     </a>
    </cite>
    . Yet, while these works report satisfactory results on specific subset of certain datasets, our rigorous replications indicate these methods often underperform compared to the state-of-the-art non-LLM baselines. This can be attributed to two inherent challenges with stance detection, which can be listed as follows and are further illustrated in Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    .
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      ‚Ä¢
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">
        First, stance detection demands multi-aspect knowledge.
       </span>
       Sentences may contain elements like domain-specific terms, cultural references, social media linguistic styles, and more. These are not immediately comprehensible to large language models and require specialized parsing to be truly understood.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      ‚Ä¢
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">
        Second, stance detection necessitates advanced reasoning.
       </span>
       Often, authors don‚Äôt state their stances directly but inadvertently reveal them in various ways, such as through their attitudes towards related topics or events. Stance detection requires reasoning from various textual features to arrive at the correct stance.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="232" id="S1.F1.g1" src="/html/2310.10467/assets/x1.png" width="277"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    Illustration of the challenges of stance detection.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    To address these challenges, we introduce our three-stage framework named COLA(short for
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">
     C
    </span>
    ollaborative r
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">
     O
    </span>
    le-infused
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">
     L
    </span>
    LM-based
    <span class="ltx_text ltx_font_bold" id="S1.p4.1.4">
     A
    </span>
    gents). We design a stance detection system consisting of role-infused LLM-based agents, with each role bearing distinct responsibilities and significance. To counter the first challenge, we initiate a multidimensional text analysis stage. In this stage, LLMs are designated with three roles, named as linguistic expert, domain specialist, and social media veteran, to analyze text from various perspectives. While the linguistic expert delve into syntax, diction, and tenses, the domain specialist elucidate characters, events, and other textual elements. What‚Äôs more, the social media veteran decode platform-specific terminologies and expression styles. Their combined insights help unearth stance indicators in the text. Addressing the second challenge, we propose a reasoning-enhanced debating stage. Here, we assign advocates for each potential stance category. Drawing evidence from the preceding phase, these advocates present arguments to bolster their respective stances, forcing the LLMs to discern the latent logic connecting textual features and actual stances. Lastly, a stance conclusion stage determines the text‚Äôs stance, drawing insights both from the text itself and the debates.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    Our approach does not necessitate annotated data nor additional model training, hence ensuring high
    <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">
     usability
    </span>
    . Extensive experiments validate our method‚Äôs superior performance over existing baselines, affirming its
    <span class="ltx_text ltx_font_bold" id="S1.p5.1.2">
     accuracy
     <span class="ltx_note ltx_role_footnote" id="footnote1">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         1
        </sup>
        <span class="ltx_tag ltx_tag_note">
         <span class="ltx_text ltx_font_medium" id="footnote1.1.1.1">
          1
         </span>
        </span>
        <span class="ltx_text ltx_font_medium" id="footnote1.4">
         In this article, unless explicitly stated otherwise, we use
        </span>
        <span class="ltx_text ltx_font_medium ltx_font_italic" id="footnote1.5">
         accuracy
        </span>
        <span class="ltx_text ltx_font_medium" id="footnote1.6">
         to express the overall strong performance of the model on classification tasks, rather than solely referring to the accuracy metric.
        </span>
       </span>
      </span>
     </span>
    </span>
    . A representative result is that our zero-shot framework achieves a 21.7% absolute improvement compared to the best in-target labeled data dependent baseline on the
    <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S1.p5.1.m1.1">
     <semantics id="S1.p5.1.m1.1a">
      <msub id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">
       <mi id="S1.p5.1.m1.1.1.2" xref="S1.p5.1.m1.1.1.2.cmml">
        F
       </mi>
       <mrow id="S1.p5.1.m1.1.1.3" xref="S1.p5.1.m1.1.1.3.cmml">
        <mi id="S1.p5.1.m1.1.1.3.2" xref="S1.p5.1.m1.1.1.3.2.cmml">
         a
        </mi>
        <mo id="S1.p5.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S1.p5.1.m1.1.1.3.1.cmml">
         ‚Äã
        </mo>
        <mi id="S1.p5.1.m1.1.1.3.3" xref="S1.p5.1.m1.1.1.3.3.cmml">
         v
        </mi>
        <mo id="S1.p5.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S1.p5.1.m1.1.1.3.1.cmml">
         ‚Äã
        </mo>
        <mi id="S1.p5.1.m1.1.1.3.4" xref="S1.p5.1.m1.1.1.3.4.cmml">
         g
        </mi>
       </mrow>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b">
       <apply id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">
        <csymbol cd="ambiguous" id="S1.p5.1.m1.1.1.1.cmml" xref="S1.p5.1.m1.1.1">
         subscript
        </csymbol>
        <ci id="S1.p5.1.m1.1.1.2.cmml" xref="S1.p5.1.m1.1.1.2">
         ùêπ
        </ci>
        <apply id="S1.p5.1.m1.1.1.3.cmml" xref="S1.p5.1.m1.1.1.3">
         <times id="S1.p5.1.m1.1.1.3.1.cmml" xref="S1.p5.1.m1.1.1.3.1">
         </times>
         <ci id="S1.p5.1.m1.1.1.3.2.cmml" xref="S1.p5.1.m1.1.1.3.2">
          ùëé
         </ci>
         <ci id="S1.p5.1.m1.1.1.3.3.cmml" xref="S1.p5.1.m1.1.1.3.3">
          ùë£
         </ci>
         <ci id="S1.p5.1.m1.1.1.3.4.cmml" xref="S1.p5.1.m1.1.1.3.4">
          ùëî
         </ci>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">
       F_{avg}
      </annotation>
     </semantics>
    </math>
    metric on the CC target of the SEM16 dataset. Ablation studies elucidate the
    <span class="ltx_text ltx_font_bold" id="S1.p5.1.3">
     effectiveness
    </span>
    of each module in handling stance detection. Case studies and quantitative experiments substantiate our approach‚Äôs
    <span class="ltx_text ltx_font_bold" id="S1.p5.1.4">
     explainability
    </span>
    . The powerful performance of our proposed framework in a series of text classification tasks underscores its
    <span class="ltx_text ltx_font_bold" id="S1.p5.1.5">
     versatility
    </span>
    . Our approach stands out for its usability, accuracy, effectiveness, explainability, and versatility, all of which highlight its value.
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    Our main contributions are summarized as follows:
   </p>
   <ul class="ltx_itemize" id="S1.I2">
    <li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      ‚Ä¢
     </span>
     <div class="ltx_para" id="S1.I2.i1.p1">
      <p class="ltx_p" id="S1.I2.i1.p1.1">
       We are among the first to delve into harnessing LLMs to bolster stance detection.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      ‚Ä¢
     </span>
     <div class="ltx_para" id="S1.I2.i2.p1">
      <p class="ltx_p" id="S1.I2.i2.p1.1">
       We introduce a approach based on collaborative role-infused LLM-empowered agents, which exhibits outstanding performance on stance detection and achieves high levels of usability and explainability.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I2.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      ‚Ä¢
     </span>
     <div class="ltx_para" id="S1.I2.i3.p1">
      <p class="ltx_p" id="S1.I2.i3.p1.1">
       Our proposed three-stage framework‚Äîanalyst, debater, and summarizer‚Äîoffers significant potential for a range of text classification tasks, providing a powerful tool for text analysis on web and social media.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p7">
   <p class="ltx_p" id="S1.p7.1">
    The subsequent sections are organized as follows. We first review related works. The wen describe our three-stage framework in detail. We then presents our experiments, providing robust empirical evidence that demonstrated the superiority of our method from multiple perspectives. Lastly, we conclude our work and highlight potential areas for future improvement.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    This section is structured as follows: First, we provide a detailed overview of advancements in stance detection. Next, we introduce recent progress in large language models. Lastly, we focus on reviewing a subset of works closely related to ours, specifically multi LLM-based agents systems.
   </p>
  </div>
  <div class="ltx_para" id="S2.p2">
   <p class="ltx_p" id="S2.p2.1">
    <span class="ltx_text ltx_font_bold" id="S2.p2.1.1">
     Stance detection.
    </span>
    Stance detection aims to discern the stance of the author towards a particular target from textual content. Typically, stances are categorized into favor, against, neutral. A plethora of algorithms for stance detection have been proposed by researchers, encompassing both feature-based methods
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib1" title="">
      addawood2017stance
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib9" title="">
      bar2017stance
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib29" title="">
      lozhnikov2020stance
     </a>
    </cite>
    and deep learning techniques
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib21" title="">
      hercig2017detecting
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib47" title="">
      wei2018target
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib28" title="">
      liu2021enhancing
     </a>
    </cite>
    . These methodologies have enabled in-depth analysis of content on the internet and social media platforms. For example, Jang et al.
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib23" title="">
      jang2018explaining
     </a>
    </cite>
    develop a method to find controversies on social media by generating stance-aware summaries of tweets. Grcar et al.
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib20" title="">
      grvcar2017stance
     </a>
    </cite>
    examine the Twitter stance before the Brexit referendum, revealing the pro-Brexit camp‚Äôs higher influence.
   </p>
  </div>
  <div class="ltx_para" id="S2.p3">
   <p class="ltx_p" id="S2.p3.1">
    Conventionally, stance detection necessitates training on datasets annotated for the specific target. Such datasets are not trivially obtainable, thereby constraining the usability of many methods. Recognizing this limitation, researchers have ventured into cross-target stance detection, aiming to train classifiers that can adapt to unfamiliar but related targets after being trained on a known target
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib49" title="">
      xu2018cross
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib46" title="">
      wei2019modeling
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib26" title="">
      liang2021target
     </a>
    </cite>
    . Recently, there has been an emergence of zero-shot stance detection approaches that automatically detects the stance on unseen tasks
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib4" title="">
      allaway2020zero
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib25" title="">
      liang2022zero
     </a>
    </cite>
    . However, all these methods require training on annotated datasets. Unlike these methods, our approach uses pre-trained LLM, removing the need for additional annotated data. Through prompt engineering, we refine these models without extra training, offering a solution with high usability.
   </p>
  </div>
  <div class="ltx_para" id="S2.p4">
   <p class="ltx_p" id="S2.p4.1">
    <span class="ltx_text ltx_font_bold" id="S2.p4.1.1">
     Large language models.
    </span>
    Large language models (LLMs) represent one of the most significant advancements of artificial intelligence in recent years. With the release of ChatGPT
    <span class="ltx_note ltx_role_footnote" id="footnote2">
     <sup class="ltx_note_mark">
      2
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        2
       </sup>
       <span class="ltx_tag ltx_tag_note">
        2
       </span>
       chat.openai.com
      </span>
     </span>
    </span>
    at the end of 2022, LLMs witnessed a meteoric rise in attention, predominantly driven by their outstanding performance. A myriad of LLMs, such as GPT-4
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib33" title="">
      openai2023gpt
     </a>
    </cite>
    , Llama 2
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib41" title="">
      touvron2023llama
     </a>
    </cite>
    , ChatGLM
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib50" title="">
      zeng2022glm
     </a>
    </cite>
    , and others, have been introduced at a rapid pace. In conventional NLP tasks, the zero-shot capabilities of these LLMs often rival or even surpass meticulously crafted, domain-specific models
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib45" title="">
      wei2021finetuned
     </a>
    </cite>
    . The emergence of robust capabilities, such as planning and reasoning within LLMs, has further enabled their adoption across diverse applications. Some endeavors integrate LLMs with existing tools
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib37" title="">
      qin2023toolllm
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib38" title="">
      schick2023toolformer
     </a>
    </cite>
    , others explore the potential of LLMs to create new tools
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib11" title="">
      cai2023large
     </a>
    </cite>
    , and there is a growing trend towards leveraging LLMs for dynamic decision-making, planning, and embodied intelligence
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib2" title="">
      ahn2022can
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib39" title="">
      shinn2023reflexion
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib48" title="">
      xiang2023language
     </a>
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S2.p5">
   <p class="ltx_p" id="S2.p5.1">
    Inherently, the vast knowledge and potent semantic understanding of LLMs offer immense potential in tackling stance detection tasks. Several research initiatives have indeed explored the application of LLMs in stance detection
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib51" title="">
      zhang2022would
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib54" title="">
      ziems2023can
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib52" title="">
      zhang2023investigating
     </a>
    </cite>
    . However, these existing methods often adopt a relatively straightforward approach, neglecting the intrinsic challenges specific to stance detection. As a result, our rigorous replication efforts have frequently found their performance to be subpar in comparison to training dependent baselines. In contrast, our method is specifically tailored to cater to the expert knowledge and intricate reasoning often required for stance detection, consequently achieving commendable results.
   </p>
  </div>
  <figure class="ltx_figure" id="S2.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="235" id="S2.F2.g1" src="/html/2310.10467/assets/x2.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    Architecture of our proposed COLA. In the multidimensional text analysis stage, the liguisic expert, the domain specialist and the social media veteran analyze the text from web or social media from various perspectives, providing a holistic understanding. In the reasoning-enhanced debating stage, for each possible stance, a debater defends it, seeking possible logical chains between text features and stance. Finally, in the stance conclusion stage, a final judge determines the stance based on the statements made by all debaters.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S2.p6">
   <p class="ltx_p" id="S2.p6.1">
    <span class="ltx_text ltx_font_bold" id="S2.p6.1.1">
     Multi LLM-based agents system.
    </span>
    Systems comprised of multiple LLM-based agents have demonstrated complex and powerful capabilities not inherent to individual LLM. Leveraging the human-like capacities of LLM, systems formed from multiple LLM-based agents have been applied in both online and offline societal simulations, showcasing credibility at the individual level and emergent social behaviors. For instance, Part et al.
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib34" title="">
      park2023generative
     </a>
    </cite>
    construct an AI town with 25 agents, witnessing phenomena such as mayoral elections and party organization. Gao et al.
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib19" title="">
      gao2023s
     </a>
    </cite>
    conduct simulations of online social networks with thousands of LLM-based agents, observing group emotional responses and opinion shifts that mirrored real-world trends. What‚Äôs more, some studies have employed collaborative efforts between LLMs with distinct roles to accomplish tasks. In METAGPT
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib22" title="">
      hong2023metagpt
     </a>
    </cite>
    , LLM-based agents with different roles collaboratively develop computer software, while DERA
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib32" title="">
      nair2023dera
     </a>
    </cite>
    uses discussions among various agents to refine medical summary dialogues and care plan generation. Additionally, several efforts have utilized debates between large language model agents to enhance model performance. For example, ChatEval
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib12" title="">
      chan2023chateval
     </a>
    </cite>
    improves text evaluation capabilities through multi-agent debates. Du et al.
    <cite class="ltx_cite ltx_citemacro_cite">
     <a class="ltx_ref" href="#bib.bib18" title="">
      du2023improving
     </a>
    </cite>
    amplify the factuality and reasoning capacities of large language models by facilitating debates among them.
   </p>
  </div>
  <div class="ltx_para" id="S2.p7">
   <p class="ltx_p" id="S2.p7.1">
    To the best of our knowledge, our work is the pioneering effort in employing muilti LLM-based agents system for the task of stance detection.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Methods
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    In this section, we desribe our proposed COLA in detail. The architecture of COLA is shown in Figure
    <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‚Ä£ 2 Related Work ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    .
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Task Description
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.6">
     In stance detection, the objective is to decide the stance of a given opinionated document with respect to a specified target. Let us define a dataset
     <math alttext="D=\{(x_{i}=(d_{i},t_{i}),y_{i})\}^{n}_{i=1}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1">
      <semantics id="S3.SS1.p1.1.m1.1a">
       <mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">
        <mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">
         D
        </mi>
        <mo id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">
         =
        </mo>
        <msubsup id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">
         <mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml">
          <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml">
           {
          </mo>
          <mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
           <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
            (
           </mo>
           <mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
            <msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.cmml">
             <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.2.cmml">
              x
             </mi>
             <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.3.cmml">
              i
             </mi>
            </msub>
            <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">
             =
            </mo>
            <mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">
             <mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">
              <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">
               (
              </mo>
              <msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">
               <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">
                d
               </mi>
               <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">
                i
               </mi>
              </msub>
              <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.4" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">
               ,
              </mo>
              <msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">
               <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">
                t
               </mi>
               <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">
                i
               </mi>
              </msub>
              <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">
               )
              </mo>
             </mrow>
             <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">
              ,
             </mo>
             <msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">
              <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">
               y
              </mi>
              <mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">
               i
              </mi>
             </msub>
            </mrow>
           </mrow>
           <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml">
            )
           </mo>
          </mrow>
          <mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml">
           }
          </mo>
         </mrow>
         <mrow id="S3.SS1.p1.1.m1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.3.cmml">
          <mi id="S3.SS1.p1.1.m1.1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.1.3.2.cmml">
           i
          </mi>
          <mo id="S3.SS1.p1.1.m1.1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.1.3.1.cmml">
           =
          </mo>
          <mn id="S3.SS1.p1.1.m1.1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.1.3.3.cmml">
           1
          </mn>
         </mrow>
         <mi id="S3.SS1.p1.1.m1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.3.cmml">
          n
         </mi>
        </msubsup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b">
        <apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">
         <eq id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">
         </eq>
         <ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">
          ùê∑
         </ci>
         <apply id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1">
           subscript
          </csymbol>
          <apply id="S3.SS1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1">
            superscript
           </csymbol>
           <set id="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1">
            <apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1">
             <eq id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3">
             </eq>
             <apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4">
              <csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4">
               subscript
              </csymbol>
              <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.2">
               ùë•
              </ci>
              <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.4.3">
               ùëñ
              </ci>
             </apply>
             <list id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2">
              <interval closure="open" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">
               <apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">
                <csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">
                 subscript
                </csymbol>
                <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">
                 ùëë
                </ci>
                <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">
                 ùëñ
                </ci>
               </apply>
               <apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">
                <csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">
                 subscript
                </csymbol>
                <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">
                 ùë°
                </ci>
                <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3">
                 ùëñ
                </ci>
               </apply>
              </interval>
              <apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2">
               <csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2">
                subscript
               </csymbol>
               <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2">
                ùë¶
               </ci>
               <ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3">
                ùëñ
               </ci>
              </apply>
             </list>
            </apply>
           </set>
           <ci id="S3.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.3">
            ùëõ
           </ci>
          </apply>
          <apply id="S3.SS1.p1.1.m1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.3">
           <eq id="S3.SS1.p1.1.m1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.3.1">
           </eq>
           <ci id="S3.SS1.p1.1.m1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.3.2">
            ùëñ
           </ci>
           <cn id="S3.SS1.p1.1.m1.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.1.3.3">
            1
           </cn>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">
        D=\{(x_{i}=(d_{i},t_{i}),y_{i})\}^{n}_{i=1}
       </annotation>
      </semantics>
     </math>
     consisting of
     <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1">
      <semantics id="S3.SS1.p1.2.m2.1a">
       <mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">
        n
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b">
        <ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">
         ùëõ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">
        n
       </annotation>
      </semantics>
     </math>
     instances. For each instance,
     <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1">
      <semantics id="S3.SS1.p1.3.m3.1a">
       <msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">
        <mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">
         x
        </mi>
        <mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b">
        <apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">
          ùë•
         </ci>
         <ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">
          ùëñ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">
        x_{i}
       </annotation>
      </semantics>
     </math>
     represents a tuple comprising a document
     <math alttext="d_{i}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1">
      <semantics id="S3.SS1.p1.4.m4.1a">
       <msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">
        <mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">
         d
        </mi>
        <mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b">
        <apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">
          ùëë
         </ci>
         <ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">
          ùëñ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">
        d_{i}
       </annotation>
      </semantics>
     </math>
     and a corresponding target
     <math alttext="t_{i}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1">
      <semantics id="S3.SS1.p1.5.m5.1a">
       <msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">
        <mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">
         t
        </mi>
        <mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b">
        <apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">
          ùë°
         </ci>
         <ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">
          ùëñ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">
        t_{i}
       </annotation>
      </semantics>
     </math>
     . The task is to detect the stance
     <math alttext="y_{i}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1">
      <semantics id="S3.SS1.p1.6.m6.1a">
       <msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">
        <mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">
         y
        </mi>
        <mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b">
        <apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">
          ùë¶
         </ci>
         <ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">
          ùëñ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">
        y_{i}
       </annotation>
      </semantics>
     </math>
     , which can be one of the following categories: favor, against, or neutral.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Multidimensional Text Analysis Stage
   </h3>
   <section class="ltx_subsubsection" id="S3.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.1
     </span>
     Challenge:
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS1.p1">
     <p class="ltx_p" id="S3.SS2.SSS1.p1.1">
      Stance detection necessitates a profound grasp of multi-aspect knowledge. Sentences on social media that convey the author‚Äôs stance may be influenced by various linguistic phenomena, such as grammatical structures, tenses, and moods. There is also often an abundance of domain-specific terminologies, including references to characters, political parties, and events, and their relationships with the target. Additionally, unique language features of social media, such as hashtags, come into play. Although large language models have assimilated vast knowledge from their training data, their direct application for stance detection often fails to adequately harness this knowledge, leading to suboptimal results, a fact corroborated by our subsequent experiments.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.2
     </span>
     Approach:
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS2.p1">
     <p class="ltx_p" id="S3.SS2.SSS2.p1.1">
      To address this challenge and leverage the rich knowledge encoded within large language models, we designed a multidimensional text analysis stage. During this stage, we introduced three distinct LLM-based agents to parse the text from different perspectives, ensuring a comprehensive understanding of potential elements influencing the author‚Äôs stance.These agents are the Linguistic Expert, Domain Specialist, and Social Media Veteran. We ask the LLM to behave in the way of the roles through prompting.
Specifically, the inputs and outputs of the role-infused agents in this stage are as follows.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p2">
     <p class="ltx_p" id="S3.SS2.SSS2.p2.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p2.1.1">
       Input:
      </span>
      A text with a stance.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p3">
     <p class="ltx_p" id="S3.SS2.SSS2.p3.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p3.1.1">
       Output:
      </span>
      The individual analyses of the text by the linguistic expert, the domain specialist, and the social media veteran.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p4">
     <p class="ltx_p" id="S3.SS2.SSS2.p4.1">
      The detailed configurations of agents are as follows.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p5">
     <p class="ltx_p" id="S3.SS2.SSS2.p5.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p5.1.1">
       Liguistic Expert.
      </span>
      This Agent is tasked with dissecting the text from a linguistic standpoint, exploring factors including but not limited to:
     </p>
     <ul class="ltx_itemize" id="S3.I1">
      <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I1.i1.p1">
        <p class="ltx_p" id="S3.I1.i1.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.1">
          Grammatical structure.
         </span>
         The arrangement and relationship of words in a sentence, which determines how different elements combine to produce specific meanings.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I1.i2.p1">
        <p class="ltx_p" id="S3.I1.i2.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.1">
          Tense and inflection.
         </span>
         Tense identifies when an action occurs, influencing the stance‚Äôs immediacy or distance. Inflection adjusts word forms, providing clues about the sentence‚Äôs grammatical and relational context.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I1.i3.p1">
        <p class="ltx_p" id="S3.I1.i3.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I1.i3.p1.1.1">
          Rhetorical devices.
         </span>
         These are techniques used to enhance the expressiveness of language. By emphasizing, contrasting, or evoking emotions, they shape the tone and attitude of a statement.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I1.i4.p1">
        <p class="ltx_p" id="S3.I1.i4.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I1.i4.p1.1.1">
          Lexical choices.
         </span>
         The selection of particular words or phrases in writing, which can reveal deeper nuances, biases, or viewpoints about a topic.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p6">
     <p class="ltx_p" id="S3.SS2.SSS2.p6.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p6.1.1">
       Domain Specialist.
      </span>
      This agent focuses on domain-relevant knowledge, exploring facets such as:
     </p>
     <ul class="ltx_itemize" id="S3.I2">
      <li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I2.i1.p1">
        <p class="ltx_p" id="S3.I2.i1.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I2.i1.p1.1.1">
          Characters.
         </span>
         Key individuals or entities in a text.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I2.i2.p1">
        <p class="ltx_p" id="S3.I2.i2.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I2.i2.p1.1.1">
          Events.
         </span>
         Significant occurrences within a text. How they‚Äôre portrayed can hint at the author‚Äôs stance on certain issues or topics.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I2.i3.p1">
        <p class="ltx_p" id="S3.I2.i3.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I2.i3.p1.1.1">
          Organizations.
         </span>
         Established groups mentioned. Their depiction can showcase the author‚Äôs feelings towards certain societal structures or institutions.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I2.i4.p1">
        <p class="ltx_p" id="S3.I2.i4.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I2.i4.p1.1.1">
          Parties.
         </span>
         Political groups with distinct ideologies. A text‚Äôs treatment of these can provide insights into the author‚Äôs political leanings or criticisms.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I2.i5" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I2.i5.p1">
        <p class="ltx_p" id="S3.I2.i5.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I2.i5.p1.1.1">
          Religions.
         </span>
         Specific faiths or spiritual beliefs. How they are referenced might shed light on the author‚Äôs personal beliefs or societal observations.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p7">
     <p class="ltx_p" id="S3.SS2.SSS2.p7.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p7.1.1">
       Social Media Veteran.
      </span>
      This agent delves into the nuances of social media expression, focusing on aspects like:
     </p>
     <ul class="ltx_itemize" id="S3.I3">
      <li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I3.i1.p1">
        <p class="ltx_p" id="S3.I3.i1.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I3.i1.p1.1.1">
          Hashtags.
         </span>
         Specific labels used on social media platforms, assisting in categorizing posts or emphasizing specific themes, making content easily discoverable.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I3.i2.p1">
        <p class="ltx_p" id="S3.I3.i2.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I3.i2.p1.1.1">
          Internet slang and colloquialisms.
         </span>
         These refer to informal terms and expressions often used in online communities. Their usage can introduce nuances, cultural contexts, or specific attitudes, making them significant indicators of the underlying stance in a statement.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        ‚Ä¢
       </span>
       <div class="ltx_para" id="S3.I3.i3.p1">
        <p class="ltx_p" id="S3.I3.i3.p1.1">
         <span class="ltx_text ltx_font_italic" id="S3.I3.i3.p1.1.1">
          Emotional tone.
         </span>
         This captures the sentiment inherent in a piece of writing, revealing the author‚Äôs feelings, whether positive, negative, or neutral, about a particular subject.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Reasoning-Enhanced Debating Stage
   </h3>
   <section class="ltx_subsubsection" id="S3.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.3.1
     </span>
     Challenge:
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS1.p1">
     <p class="ltx_p" id="S3.SS3.SSS1.p1.1">
      The task of stance detection requires sophisticated reasoning. Authors often do not explicitly state their positions in a text. Instead, their stance may be implied through their sentiment towards certain entities or by mechanisms like comparison and contrast. Identifying these implicit stances requires detailed reasoning. Although large-scale language models possess some reasoning capabilities, their performance can be suboptimal in intricate reasoning tasks without proper guidance, which can affect the quality of stance detection results.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.3.2
     </span>
     Approach:
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS2.p1">
     <p class="ltx_p" id="S3.SS3.SSS2.p1.1">
      Drawing inspiration from recent works that leverage discussions or debates among large models to enhance their performance
      <cite class="ltx_cite ltx_citemacro_cite">
       <a class="ltx_ref" href="#bib.bib18" title="">
        du2023improving
       </a>
       ;
       <a class="ltx_ref" href="#bib.bib12" title="">
        chan2023chateval
       </a>
       ;
       <a class="ltx_ref" href="#bib.bib27" title="">
        liang2023encouraging
       </a>
      </cite>
      , especially in reasoning tasks, we introduce a reasoning-enhanced debating stage. In this stage, for every potential stance, an agent is designated. This agent seeks evidence from expert analyses of the text and advocates for its designated stance. Specifically, the inputs and outputs of agents in this stage are as follows.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS2.p2">
     <p class="ltx_p" id="S3.SS3.SSS2.p2.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p2.1.1">
       Input:
      </span>
      A text with a stance. The analyses of the text by the linguistic expert, the domain specialist, and the social media veteran.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS2.p3">
     <p class="ltx_p" id="S3.SS3.SSS2.p3.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p3.1.1">
       Output:
      </span>
      The debate from each agent for the stance they support, including the evidence it chooses and its logical chain.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS2.p4">
     <p class="ltx_p" id="S3.SS3.SSS2.p4.1">
      In our framework, we only engage in a single round of debate, reserving multi-round debates for future exploration. Directing agents to search for evidence and defend their aligned stances compels the large language model to establish logical connections between discerned textual features (as well as their multifaceted interpretations) and the actual underlying stance of the text. By having multiple agents debate in favor of different stances, the system encourages the large model‚Äôs divergent thinking. This generates a plethora of potential text stance interpretations, ensuring that the probable correct interpretation has a higher likelihood of being produced by the system. These outputs subsequently feed into the stance conclusion stage, which renders a final, judicious judgment.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.4
    </span>
    Stance Conclusion Stage
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     To infer a conclusive stance from diverse agent debates, we introduce the stance conclusion stage. In this stage, a judger agent determines the final stance of a text based on both the text itself and the arguments presented by debater agents. The process is delineated as:
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p2">
    <p class="ltx_p" id="S3.SS4.p2.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.1">
      Input:
     </span>
     A text with an embedded stance. Arguments from each agent, including evidence and their logical reasoning.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p3">
    <p class="ltx_p" id="S3.SS4.p3.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.1">
      Output:
     </span>
     The identified stance of the text.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p4">
    <p class="ltx_p" id="S3.SS4.p4.1">
     The judger agent evaluates the text‚Äôs inherent qualities, the evidence provided by debaters, and their logical frameworks to reach an informed decision.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p5">
    <p class="ltx_p" id="S3.SS4.p5.1">
     After going through the three stages mentioned above, we have effectively extracted the underlying stance towards the given target from the text.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Experimental Setup
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    In this section, we describe the specific setup of our experiments.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Datasets
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     We conduct experiments on three distinct datasets:
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">
      SEM16
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib30" title="">
       mohammad2016semeval
      </a>
     </cite>
     . This dataset features six specific targets from diverse domains, namely
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.2">
      Donald Trump
     </span>
     (DT),
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.3">
      Hillary Clinton
     </span>
     (HC),
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.4">
      Feminist Movement
     </span>
     (FM),
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.5">
      Legalization of Abortion
     </span>
     (LA),
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.6">
      Atheism
     </span>
     (A), and
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.7">
      Climate Change is Real Concern
     </span>
     (CC). Each instance is classified into one of three stance categories:
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.8">
      Favor
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.9">
      Against
     </span>
     , or
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.10">
      None
     </span>
     .
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p3">
    <p class="ltx_p" id="S4.SS1.p3.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">
      WT-WT
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib15" title="">
       conforti2020will
      </a>
     </cite>
     . Specializing in discourse about mergers and acquisitions between companies, this dataset comprises four targets:
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.2">
      CVS_AET
     </span>
     (CA),
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.3">
      CI_ESRX
     </span>
     (CE),
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.4">
      ANTM_CI
     </span>
     (AC),
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.5">
      and AET_HUM
     </span>
     (AH). Stance labels include
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.6">
      Support
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.7">
      Refute
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.8">
      Comment
     </span>
     (Neutral), or
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.9">
      Unrelated
     </span>
     .
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p4">
    <p class="ltx_p" id="S4.SS1.p4.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">
      VAST
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib4" title="">
       allaway2020zero
      </a>
     </cite>
     . This dataset is characterized by its large number of varying targets. An instance in VAST includes a sentence, a target, and a stance, which may be
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.2">
      Pro
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.3">
      Con
     </span>
     , or
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.4">
      Neutral
     </span>
     .
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p5">
    <p class="ltx_p" id="S4.SS1.p5.1">
     The statistics of our utilized datasets are shown in Table
     <a class="ltx_ref" href="#S4.T1" title="Table 1 ‚Ä£ 4.1 Datasets ‚Ä£ 4 Experimental Setup ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . Due to the zero-shot nature of our method, we do not split the dataset into training, development, and testing sets, but instead conduct experiments on the entire dataset. For zero-shot stance detection approaches, we evaluate their performance across all three datasets. However, for in-target stance detection methods, we assess their performance on SEM16 and WT-WT, because the targets within the VAST dataset are mainly few-shot or zero-shot. The datasets contain no personally identifiable information, but may contain offensive content because the text has a clear stance on topics such as religion, politics, climate, etc. We strictly adhere to the requirements of the respective licenses when using all datasets mentioned in the paper.
    </p>
   </div>
   <figure class="ltx_table" id="S4.T1">
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S4.T1.1.1.1">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1">
        Dataset
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.1.2">
        Target
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.3">
        Pro
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.4">
        Con
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.5">
        Neutral
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.6">
        Unrelated
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.2.2">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.2.2.1" rowspan="6">
        <span class="ltx_text" id="S4.T1.1.2.2.1.1">
         SEM16
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.2.2.2">
        DT
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.2.3">
        148
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.2.4">
        299
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.2.5">
        260
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.2.6">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.3.3">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.3.3.1">
        HC
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.3.3.2">
        163
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.3.3.3">
        565
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.3.3.4">
        256
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.3.3.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.4.4">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.4.4.1">
        FM
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.4.4.2">
        268
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.4.4.3">
        511
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.4.4.4">
        170
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.4.4.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.5.5">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.5.5.1">
        LA
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.5.5.2">
        167
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.5.5.3">
        544
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.5.5.4">
        222
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.5.5.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.6.6">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.6.6.1">
        A
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.6.6.2">
        124
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.6.6.3">
        464
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.6.6.4">
        145
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.6.6.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.7.7">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.7.7.1">
        CC
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.7.7.2">
        335
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.7.7.3">
        26
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.7.7.4">
        203
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.7.7.5">
        -
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.8.8">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.8.8.1" rowspan="4">
        <span class="ltx_text" id="S4.T1.1.8.8.1.1">
         WT-WT
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.8.8.2">
        CA
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.8.8.3">
        2469
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.8.8.4">
        518
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.8.8.5">
        5520
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.8.8.6">
        3115
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.9.9">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.9.9.1">
        CE
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.9.9.2">
        773
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.9.9.3">
        253
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.9.9.4">
        947
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.9.9.5">
        554
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.10.10">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.10.10.1">
        AC
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.10.10.2">
        970
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.10.10.3">
        1969
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.10.10.4">
        3098
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.10.10.5">
        5007
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.11.11">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.11.11.1">
        AH
       </th>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.11.11.2">
        1038
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.11.11.3">
        1106
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.11.11.4">
        2804
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T1.1.11.11.5">
        2949
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T1.1.12.12">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.12.12.1">
        VAST
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.12.12.2">
        -
       </th>
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.12.12.3">
        6952
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.12.12.4">
        7297
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.12.12.5">
        4296
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.12.12.6">
        -
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 1:
     </span>
     Statistics of our utilized datasets.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Experimental Implementation
   </h3>
   <section class="ltx_subsubsection" id="S4.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.1
     </span>
     Implementation of COLA
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS1.p1">
     <p class="ltx_p" id="S4.SS2.SSS1.p1.1">
      In our study, we employ the GPT-3.5 Turbo model, provided by OpenAI, as our backbone. We opt for GPT-3.5 Turbo primarily due to its superior performance, cost-effectiveness, and the ease of interaction offered via the OpenAI API. These attributes not only facilitate efficient research but also ensure the usability of our methodology for future applications. By utilizing the system instruction feature available through the OpenAI API, we instruct the model to act as various agent roles, feeding text inputs via prompts and collecting textual outputs from the model. To maximize reproducibility, we set the temperature parameter to 0. The reported results are the average of 5 repeated runs to ensure statistical reliability.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.2
     </span>
     Evaluation Metric
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS2.p1">
     <p class="ltx_p" id="S4.SS2.SSS2.p1.1">
      For SEM16 dataset, following Allaway et al.
      <cite class="ltx_cite ltx_citemacro_cite">
       <a class="ltx_ref" href="#bib.bib5" title="">
        allaway2021adversarial
       </a>
      </cite>
      , we calculate
      <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p1.1.m1.1">
       <semantics id="S4.SS2.SSS2.p1.1.m1.1a">
        <msub id="S4.SS2.SSS2.p1.1.m1.1.1" xref="S4.SS2.SSS2.p1.1.m1.1.1.cmml">
         <mi id="S4.SS2.SSS2.p1.1.m1.1.1.2" xref="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml">
          F
         </mi>
         <mrow id="S4.SS2.SSS2.p1.1.m1.1.1.3" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml">
          <mi id="S4.SS2.SSS2.p1.1.m1.1.1.3.2" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.2.cmml">
           a
          </mi>
          <mo id="S4.SS2.SSS2.p1.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S4.SS2.SSS2.p1.1.m1.1.1.3.3" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.3.cmml">
           v
          </mi>
          <mo id="S4.SS2.SSS2.p1.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S4.SS2.SSS2.p1.1.m1.1.1.3.4" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.4.cmml">
           g
          </mi>
         </mrow>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.1.m1.1b">
         <apply id="S4.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.2">
           ùêπ
          </ci>
          <apply id="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3">
           <times id="S4.SS2.SSS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.1">
           </times>
           <ci id="S4.SS2.SSS2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.2">
            ùëé
           </ci>
           <ci id="S4.SS2.SSS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.3">
            ùë£
           </ci>
           <ci id="S4.SS2.SSS2.p1.1.m1.1.1.3.4.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.4">
            ùëî
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.1.m1.1c">
         F_{avg}
        </annotation>
       </semantics>
      </math>
      , which represents the average of F1 scores for
      <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.p1.1.1">
       Favor
      </span>
      and
      <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.p1.1.2">
       Against
      </span>
      . For the WT-WT dataset, we follow the guidelines set by Conforti et al.
      <cite class="ltx_cite ltx_citemacro_cite">
       <a class="ltx_ref" href="#bib.bib15" title="">
        conforti2020will
       </a>
      </cite>
      and calculate the Macro-F1 score for each target. For the VAST dataset, we adopt the method from Allaway et al.
      <cite class="ltx_cite ltx_citemacro_cite">
       <a class="ltx_ref" href="#bib.bib4" title="">
        allaway2020zero
       </a>
      </cite>
      and compute the F1 score for
      <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.p1.1.3">
       Pro
      </span>
      ,
      <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.p1.1.4">
       Con
      </span>
      and the Macro-F1 score to assess model performance.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Comparison Methods
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     We compare COLA with state-of-the-art (SOTA) methods in stance detection. We conduct comparisons with methods for two tasks: zero-shot stance detection and in-target stance detection.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p2">
    <p class="ltx_p" id="S4.SS3.p2.1">
     We compare our method with various zero-shot stance detection methods. This includes adversarial learning method: TOAD
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib5" title="">
       allaway2021adversarial
      </a>
     </cite>
     , contrastive learning methods: PT-HCL
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib25" title="">
       liang2022zero
      </a>
     </cite>
     , Bert-based techniques: TGA-Net
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib25" title="">
       liang2022zero
      </a>
     </cite>
     and Bert-GCN
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib28" title="">
       liu2021enhancing
      </a>
     </cite>
     . We also include two baselines based on large language models: GPT-3.5 Turbo and GPT-3.5 Turbo+Chain-of-thought(COT), both of which can be considered zero-shots, implemented in strict accordance with Zhang et al.
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib51" title="">
       zhang2022would
      </a>
     </cite>
     and Zhang et al.
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib52" title="">
       zhang2023investigating
      </a>
     </cite>
     , respectively.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p3">
    <p class="ltx_p" id="S4.SS3.p3.1">
     To further verify the performance of our model, we compare our model to in-target stance detection methods. Such methods undergo extensive training on datasets for a given target and are then evaluated on the test set of the same target. In contrast, our method remains strictly zero-shot, with
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p3.1.1">
      no fine-tuning
     </span>
     applied to our backbone model. We compare our approach with various in-target stance detection baselines, including RNN-based methods: BiCond
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib8" title="">
       augenstein2016stance
      </a>
     </cite>
     , and ATT-LSTM
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib44" title="">
       wang2016attention
      </a>
     </cite>
     ; Attention-based method: CrossNet
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib49" title="">
       xu2018cross
      </a>
     </cite>
     ; Bert-based method: BERT
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib17" title="">
       devlin2018bert
      </a>
     </cite>
     ; and Graph-based methods: ASGCN
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib53" title="">
       zhang2019aspect
      </a>
     </cite>
     and TPDG
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib26" title="">
       liang2021target
      </a>
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p4">
    <p class="ltx_p" id="S4.SS3.p4.1">
     For non-LLM approaches, we retrieve results from existing literature for a comprehensive comparison
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib15" title="">
       conforti2020will
      </a>
      ;
      <a class="ltx_ref" href="#bib.bib4" title="">
       allaway2020zero
      </a>
      ;
      <a class="ltx_ref" href="#bib.bib5" title="">
       allaway2021adversarial
      </a>
      ;
      <a class="ltx_ref" href="#bib.bib28" title="">
       liu2021enhancing
      </a>
      ;
      <a class="ltx_ref" href="#bib.bib26" title="">
       liang2021target
      </a>
      ;
      <a class="ltx_ref" href="#bib.bib25" title="">
       liang2022zero
      </a>
     </cite>
     .
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Experimental Results
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In this section, we aim to answer the following research questions (RQs) with the help of experimental results:
   </p>
  </div>
  <div class="ltx_para" id="S5.p2">
   <p class="ltx_p" id="S5.p2.1">
    RQ1: How is the performance of COLA compare with state-of-the-art stance detection models?
    <span class="ltx_text ltx_font_bold" id="S5.p2.1.1">
     (Accuracy)
    </span>
   </p>
  </div>
  <div class="ltx_para" id="S5.p3">
   <p class="ltx_p" id="S5.p3.1">
    RQ2: Is every component in our model effective and contributory to performance enhancement?
    <span class="ltx_text ltx_font_bold" id="S5.p3.1.1">
     (Effectiveness)
    </span>
   </p>
  </div>
  <div class="ltx_para" id="S5.p4">
   <p class="ltx_p" id="S5.p4.1">
    RQ3: Can our model explain the rationale and logic behind its stance determinations?
    <span class="ltx_text ltx_font_bold" id="S5.p4.1.1">
     (Explainability)
    </span>
   </p>
  </div>
  <div class="ltx_para" id="S5.p5">
   <p class="ltx_p" id="S5.p5.1">
    RQ4: Is our framework adaptable for other text classification tasks related to web and social media content analysis?
    <span class="ltx_text ltx_font_bold" id="S5.p5.1.1">
     (Versatility)
    </span>
   </p>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Overall Performance (RQ1)
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     In Table
     <a class="ltx_ref" href="#S5.T2" title="Table 2 ‚Ä£ 5.1 Overall Performance (RQ1) ‚Ä£ 5 Experimental Results ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , we present the zero-shot stance detection performance of COLA across three datasets in comparison to baseline methods. Furthermore, Table
     <a class="ltx_ref" href="#S5.T3" title="Table 3 ‚Ä£ 5.1 Overall Performance (RQ1) ‚Ä£ 5 Experimental Results ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     showcases the results of both our zero-shot COLA and the in-target labeled data dependent baselines on the SEM16 and WT-WT datasets for the in-target stance detection task. Overall results have demonstrated the strong performance of our approach. Specifically, the key findings are enumerated below.
    </p>
    <ul class="ltx_itemize" id="S5.I1">
     <li class="ltx_item" id="S5.I1.1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
      </span>
      <figure class="ltx_table" id="S5.T2">
       <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.10" style="width:398.7pt;height:129.6pt;vertical-align:-0.0pt;">
        <span class="ltx_transformed_inner" style="transform:translate(-49.8pt,16.2pt) scale(0.8,0.8) ;">
         <table class="ltx_tabular ltx_align_middle" id="S5.T2.10.10">
          <tbody class="ltx_tbody">
           <tr class="ltx_tr" id="S5.T2.10.10.11.1">
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.10.10.11.1.1" rowspan="2">
             <span class="ltx_text ltx_font_bold" id="S5.T2.10.10.11.1.1.1">
              Model
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6" id="S5.T2.10.10.11.1.2">
             <span class="ltx_text ltx_font_bold" id="S5.T2.10.10.11.1.2.1">
              SEM16(%)
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="S5.T2.10.10.11.1.3">
             <span class="ltx_text ltx_font_bold" id="S5.T2.10.10.11.1.3.1">
              WT-WT(%)
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S5.T2.10.10.11.1.4">
             <span class="ltx_text ltx_font_bold" id="S5.T2.10.10.11.1.4.1">
              VAST(%)
             </span>
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.12.2">
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.1">
             DT
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.2">
             HC
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.3">
             FM
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.4">
             LA
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.5">
             A
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.12.2.6">
             CC
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.7">
             CA
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.8">
             CE
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.9">
             AC
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.12.2.10">
             AH
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.11">
             Pro
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.12">
             Con
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.12.2.13">
             All
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.13.3">
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.10.10.13.3.1">
             TOAD
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.2">
             49.5
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.3">
             51.2
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.4">
             54.1
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.5">
             46.2
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.6">
             46.1
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.10.10.13.3.7">
             30.9
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.8">
             55.3
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.9">
             57.7
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.10">
             58.6
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.10.10.13.3.11">
             61.7
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.12">
             42.6
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.13">
             36.7
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.10.10.13.3.14">
             41.0
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.14.4">
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.14.4.1">
             TGA Net
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.2">
             40.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.3">
             49.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.4">
             46.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.5">
             45.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.6">
             52.7
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.14.4.7">
             36.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.8">
             65.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.9">
             63.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.10">
             69.9
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.14.4.11">
             68.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.12">
             55.4
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.13">
             58.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.14.4.14">
             66.6
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.15.5">
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.15.5.1">
             BERT-GCN
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.2">
             42.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.3">
             50.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.4">
             44.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.5">
             44.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.6">
             53.6
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.15.5.7">
             35.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.8">
             67.8
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.9">
             64.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.10">
             70.7
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.15.5.11">
             69.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.12">
             58.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.13">
             60.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.15.5.14">
             68.6
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.16.6">
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.16.6.1">
             PT-HCL
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.2">
             50.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.3">
             54.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.4">
             54.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.5">
             50.9
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.6">
             56.5
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.16.6.7">
             38.9
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.8">
             73.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.9">
             69.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.10">
             76.7
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.16.6.11">
             76.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.12">
             61.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.13">
             63.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.16.6.14">
             71.6
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.17.7">
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.17.7.1">
             GPT-3.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.2">
             69.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.3">
             74.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.4">
             59.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.5">
             52.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.6">
             8.1
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.17.7.7">
             24.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.8">
             65.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.9">
             61.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.10">
             64.3
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.17.7.11">
             66.4
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.12">
             66.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.13">
             67.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.17.7.14">
             65.0
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.18.8">
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.18.8.1">
             GPT-3.5+COT
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.2">
             69.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.3">
             75.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.4">
             60.8
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.5">
             55.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.6">
             10.3
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.18.8.7">
             25.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.8">
             66.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.9">
             63.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.10">
             65.5
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.10.10.18.8.11">
             66.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.12">
             68.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.13">
             66.4
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T2.10.10.18.8.14">
             66.4
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T2.10.10.10">
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T2.10.10.10.11">
             COLA(ours)
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.10.10.10.12">
             <span class="ltx_text ltx_font_bold" id="S5.T2.10.10.10.12.1">
              71.2
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.10.10.10.13">
             <span class="ltx_text ltx_font_bold" id="S5.T2.10.10.10.13.1">
              75.9
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.1.1.1.1">
             <math alttext="\textbf{69.1}^{*}" class="ltx_Math" display="inline" id="S5.T2.1.1.1.1.m1.1">
              <semantics id="S5.T2.1.1.1.1.m1.1a">
               <msup id="S5.T2.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.1.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.1.m1.1.1.2a.cmml">
                 69.1
                </mtext>
                <mo id="S5.T2.1.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.1.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b">
                <apply id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.1.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.1.1.1.1.m1.1.1.2a.cmml" xref="S5.T2.1.1.1.1.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.1.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.1.m1.1.1.2">
                   69.1
                  </mtext>
                 </ci>
                 <times id="S5.T2.1.1.1.1.m1.1.1.3.cmml" xref="S5.T2.1.1.1.1.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">
                \textbf{69.1}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.2.2.2.2">
             <math alttext="\textbf{71.0}^{*}" class="ltx_Math" display="inline" id="S5.T2.2.2.2.2.m1.1">
              <semantics id="S5.T2.2.2.2.2.m1.1a">
               <msup id="S5.T2.2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.2.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.2.2.2.2.m1.1.1.2" xref="S5.T2.2.2.2.2.m1.1.1.2a.cmml">
                 71.0
                </mtext>
                <mo id="S5.T2.2.2.2.2.m1.1.1.3" xref="S5.T2.2.2.2.2.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.m1.1b">
                <apply id="S5.T2.2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.2.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.2.2.2.2.m1.1.1.1.cmml" xref="S5.T2.2.2.2.2.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.2.2.2.2.m1.1.1.2a.cmml" xref="S5.T2.2.2.2.2.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.2.2.2.2.m1.1.1.2.cmml" xref="S5.T2.2.2.2.2.m1.1.1.2">
                   71.0
                  </mtext>
                 </ci>
                 <times id="S5.T2.2.2.2.2.m1.1.1.3.cmml" xref="S5.T2.2.2.2.2.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.m1.1c">
                \textbf{71.0}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.3.3.3.3">
             <math alttext="\textbf{62.3}^{*}" class="ltx_Math" display="inline" id="S5.T2.3.3.3.3.m1.1">
              <semantics id="S5.T2.3.3.3.3.m1.1a">
               <msup id="S5.T2.3.3.3.3.m1.1.1" xref="S5.T2.3.3.3.3.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.3.3.3.3.m1.1.1.2" xref="S5.T2.3.3.3.3.m1.1.1.2a.cmml">
                 62.3
                </mtext>
                <mo id="S5.T2.3.3.3.3.m1.1.1.3" xref="S5.T2.3.3.3.3.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.m1.1b">
                <apply id="S5.T2.3.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.3.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.3.3.3.3.m1.1.1.1.cmml" xref="S5.T2.3.3.3.3.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.3.3.3.3.m1.1.1.2a.cmml" xref="S5.T2.3.3.3.3.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.3.3.3.3.m1.1.1.2.cmml" xref="S5.T2.3.3.3.3.m1.1.1.2">
                   62.3
                  </mtext>
                 </ci>
                 <times id="S5.T2.3.3.3.3.m1.1.1.3.cmml" xref="S5.T2.3.3.3.3.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.m1.1c">
                \textbf{62.3}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T2.4.4.4.4">
             <math alttext="\textbf{64.0}^{*}" class="ltx_Math" display="inline" id="S5.T2.4.4.4.4.m1.1">
              <semantics id="S5.T2.4.4.4.4.m1.1a">
               <msup id="S5.T2.4.4.4.4.m1.1.1" xref="S5.T2.4.4.4.4.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.4.4.4.4.m1.1.1.2" xref="S5.T2.4.4.4.4.m1.1.1.2a.cmml">
                 64.0
                </mtext>
                <mo id="S5.T2.4.4.4.4.m1.1.1.3" xref="S5.T2.4.4.4.4.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.4.m1.1b">
                <apply id="S5.T2.4.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.4.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.4.4.4.4.m1.1.1.1.cmml" xref="S5.T2.4.4.4.4.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.4.4.4.4.m1.1.1.2a.cmml" xref="S5.T2.4.4.4.4.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.4.4.4.4.m1.1.1.2.cmml" xref="S5.T2.4.4.4.4.m1.1.1.2">
                   64.0
                  </mtext>
                 </ci>
                 <times id="S5.T2.4.4.4.4.m1.1.1.3.cmml" xref="S5.T2.4.4.4.4.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.4.4.4.4.m1.1c">
                \textbf{64.0}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.5.5.5.5">
             <math alttext="\textbf{80.8}^{*}" class="ltx_Math" display="inline" id="S5.T2.5.5.5.5.m1.1">
              <semantics id="S5.T2.5.5.5.5.m1.1a">
               <msup id="S5.T2.5.5.5.5.m1.1.1" xref="S5.T2.5.5.5.5.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.5.5.5.5.m1.1.1.2" xref="S5.T2.5.5.5.5.m1.1.1.2a.cmml">
                 80.8
                </mtext>
                <mo id="S5.T2.5.5.5.5.m1.1.1.3" xref="S5.T2.5.5.5.5.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.5.m1.1b">
                <apply id="S5.T2.5.5.5.5.m1.1.1.cmml" xref="S5.T2.5.5.5.5.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.5.5.5.5.m1.1.1.1.cmml" xref="S5.T2.5.5.5.5.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.5.5.5.5.m1.1.1.2a.cmml" xref="S5.T2.5.5.5.5.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.5.5.5.5.m1.1.1.2.cmml" xref="S5.T2.5.5.5.5.m1.1.1.2">
                   80.8
                  </mtext>
                 </ci>
                 <times id="S5.T2.5.5.5.5.m1.1.1.3.cmml" xref="S5.T2.5.5.5.5.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.5.5.5.5.m1.1c">
                \textbf{80.8}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.6.6.6.6">
             <math alttext="\textbf{76.2}^{*}" class="ltx_Math" display="inline" id="S5.T2.6.6.6.6.m1.1">
              <semantics id="S5.T2.6.6.6.6.m1.1a">
               <msup id="S5.T2.6.6.6.6.m1.1.1" xref="S5.T2.6.6.6.6.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.6.6.6.6.m1.1.1.2" xref="S5.T2.6.6.6.6.m1.1.1.2a.cmml">
                 76.2
                </mtext>
                <mo id="S5.T2.6.6.6.6.m1.1.1.3" xref="S5.T2.6.6.6.6.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.6.6.6.6.m1.1b">
                <apply id="S5.T2.6.6.6.6.m1.1.1.cmml" xref="S5.T2.6.6.6.6.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.6.6.6.6.m1.1.1.1.cmml" xref="S5.T2.6.6.6.6.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.6.6.6.6.m1.1.1.2a.cmml" xref="S5.T2.6.6.6.6.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.6.6.6.6.m1.1.1.2.cmml" xref="S5.T2.6.6.6.6.m1.1.1.2">
                   76.2
                  </mtext>
                 </ci>
                 <times id="S5.T2.6.6.6.6.m1.1.1.3.cmml" xref="S5.T2.6.6.6.6.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.6.6.6.6.m1.1c">
                \textbf{76.2}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.7.7.7">
             <math alttext="\textbf{83.0}^{*}" class="ltx_Math" display="inline" id="S5.T2.7.7.7.7.m1.1">
              <semantics id="S5.T2.7.7.7.7.m1.1a">
               <msup id="S5.T2.7.7.7.7.m1.1.1" xref="S5.T2.7.7.7.7.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.7.7.7.7.m1.1.1.2" xref="S5.T2.7.7.7.7.m1.1.1.2a.cmml">
                 83.0
                </mtext>
                <mo id="S5.T2.7.7.7.7.m1.1.1.3" xref="S5.T2.7.7.7.7.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.7.7.7.7.m1.1b">
                <apply id="S5.T2.7.7.7.7.m1.1.1.cmml" xref="S5.T2.7.7.7.7.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.7.7.7.7.m1.1.1.1.cmml" xref="S5.T2.7.7.7.7.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.7.7.7.7.m1.1.1.2a.cmml" xref="S5.T2.7.7.7.7.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.7.7.7.7.m1.1.1.2.cmml" xref="S5.T2.7.7.7.7.m1.1.1.2">
                   83.0
                  </mtext>
                 </ci>
                 <times id="S5.T2.7.7.7.7.m1.1.1.3.cmml" xref="S5.T2.7.7.7.7.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.7.7.7.7.m1.1c">
                \textbf{83.0}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T2.10.10.10.14">
             <span class="ltx_text ltx_font_bold" id="S5.T2.10.10.10.14.1">
              78.9
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.8.8.8.8">
             <math alttext="\textbf{73.4}^{*}" class="ltx_Math" display="inline" id="S5.T2.8.8.8.8.m1.1">
              <semantics id="S5.T2.8.8.8.8.m1.1a">
               <msup id="S5.T2.8.8.8.8.m1.1.1" xref="S5.T2.8.8.8.8.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.8.8.8.8.m1.1.1.2" xref="S5.T2.8.8.8.8.m1.1.1.2a.cmml">
                 73.4
                </mtext>
                <mo id="S5.T2.8.8.8.8.m1.1.1.3" xref="S5.T2.8.8.8.8.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.8.8.8.8.m1.1b">
                <apply id="S5.T2.8.8.8.8.m1.1.1.cmml" xref="S5.T2.8.8.8.8.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.8.8.8.8.m1.1.1.1.cmml" xref="S5.T2.8.8.8.8.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.8.8.8.8.m1.1.1.2a.cmml" xref="S5.T2.8.8.8.8.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.8.8.8.8.m1.1.1.2.cmml" xref="S5.T2.8.8.8.8.m1.1.1.2">
                   73.4
                  </mtext>
                 </ci>
                 <times id="S5.T2.8.8.8.8.m1.1.1.3.cmml" xref="S5.T2.8.8.8.8.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.8.8.8.8.m1.1c">
                \textbf{73.4}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.9.9.9.9">
             <math alttext="\textbf{77.2}^{*}" class="ltx_Math" display="inline" id="S5.T2.9.9.9.9.m1.1">
              <semantics id="S5.T2.9.9.9.9.m1.1a">
               <msup id="S5.T2.9.9.9.9.m1.1.1" xref="S5.T2.9.9.9.9.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.9.9.9.9.m1.1.1.2" xref="S5.T2.9.9.9.9.m1.1.1.2a.cmml">
                 77.2
                </mtext>
                <mo id="S5.T2.9.9.9.9.m1.1.1.3" xref="S5.T2.9.9.9.9.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.9.9.9.9.m1.1b">
                <apply id="S5.T2.9.9.9.9.m1.1.1.cmml" xref="S5.T2.9.9.9.9.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.9.9.9.9.m1.1.1.1.cmml" xref="S5.T2.9.9.9.9.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.9.9.9.9.m1.1.1.2a.cmml" xref="S5.T2.9.9.9.9.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.9.9.9.9.m1.1.1.2.cmml" xref="S5.T2.9.9.9.9.m1.1.1.2">
                   77.2
                  </mtext>
                 </ci>
                 <times id="S5.T2.9.9.9.9.m1.1.1.3.cmml" xref="S5.T2.9.9.9.9.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.9.9.9.9.m1.1c">
                \textbf{77.2}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.10.10.10.10">
             <math alttext="\textbf{73.4}^{*}" class="ltx_Math" display="inline" id="S5.T2.10.10.10.10.m1.1">
              <semantics id="S5.T2.10.10.10.10.m1.1a">
               <msup id="S5.T2.10.10.10.10.m1.1.1" xref="S5.T2.10.10.10.10.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T2.10.10.10.10.m1.1.1.2" xref="S5.T2.10.10.10.10.m1.1.1.2a.cmml">
                 73.4
                </mtext>
                <mo id="S5.T2.10.10.10.10.m1.1.1.3" xref="S5.T2.10.10.10.10.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T2.10.10.10.10.m1.1b">
                <apply id="S5.T2.10.10.10.10.m1.1.1.cmml" xref="S5.T2.10.10.10.10.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T2.10.10.10.10.m1.1.1.1.cmml" xref="S5.T2.10.10.10.10.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T2.10.10.10.10.m1.1.1.2a.cmml" xref="S5.T2.10.10.10.10.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T2.10.10.10.10.m1.1.1.2.cmml" xref="S5.T2.10.10.10.10.m1.1.1.2">
                   73.4
                  </mtext>
                 </ci>
                 <times id="S5.T2.10.10.10.10.m1.1.1.3.cmml" xref="S5.T2.10.10.10.10.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T2.10.10.10.10.m1.1c">
                \textbf{73.4}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
           </tr>
          </tbody>
         </table>
        </span>
       </div>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_table">
         Table 2:
        </span>
        Comparison of COLA and baselines in zero-shot stance detection task. Best scores are in bold. * denotes COLA improves the best baseline at
        <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S5.T2.12.m1.1">
         <semantics id="S5.T2.12.m1.1b">
          <mrow id="S5.T2.12.m1.1.1" xref="S5.T2.12.m1.1.1.cmml">
           <mi id="S5.T2.12.m1.1.1.2" xref="S5.T2.12.m1.1.1.2.cmml">
            p
           </mi>
           <mo id="S5.T2.12.m1.1.1.1" xref="S5.T2.12.m1.1.1.1.cmml">
            &lt;
           </mo>
           <mn id="S5.T2.12.m1.1.1.3" xref="S5.T2.12.m1.1.1.3.cmml">
            0.05
           </mn>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S5.T2.12.m1.1c">
           <apply id="S5.T2.12.m1.1.1.cmml" xref="S5.T2.12.m1.1.1">
            <lt id="S5.T2.12.m1.1.1.1.cmml" xref="S5.T2.12.m1.1.1.1">
            </lt>
            <ci id="S5.T2.12.m1.1.1.2.cmml" xref="S5.T2.12.m1.1.1.2">
             ùëù
            </ci>
            <cn id="S5.T2.12.m1.1.1.3.cmml" type="float" xref="S5.T2.12.m1.1.1.3">
             0.05
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T2.12.m1.1d">
           p&lt;0.05
          </annotation>
         </semantics>
        </math>
        with paired t-test.
       </figcaption>
      </figure>
      <figure class="ltx_table" id="S5.T3">
       <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.2" style="width:389.4pt;height:129.6pt;vertical-align:-0.0pt;">
        <span class="ltx_transformed_inner" style="transform:translate(-48.7pt,16.2pt) scale(0.8,0.8) ;">
         <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.2.2">
          <thead class="ltx_thead">
           <tr class="ltx_tr" id="S5.T3.2.2.3.1">
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.2.2.3.1.1" rowspan="2">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.1.1">
              Category
             </span>
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.2.2.3.1.2" rowspan="2">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.2.1">
              Model
             </span>
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="6" id="S5.T3.2.2.3.1.3">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.3.1">
              SEM16(%)
             </span>
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T3.2.2.3.1.4">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.4.1">
              WT-WT(%)
             </span>
            </th>
           </tr>
           <tr class="ltx_tr" id="S5.T3.2.2.4.2">
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.1">
             DT
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.2">
             HC
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.3">
             FM
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.4">
             LA
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.5">
             A
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S5.T3.2.2.4.2.6">
             CC
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.7">
             CA
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.8">
             CE
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.9">
             AC
            </th>
            <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T3.2.2.4.2.10">
             AH
            </th>
           </tr>
          </thead>
          <tbody class="ltx_tbody">
           <tr class="ltx_tr" id="S5.T3.2.2.5.1">
            <td class="ltx_td ltx_border_r ltx_border_t" id="S5.T3.2.2.5.1.1">
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.2.2.5.1.2">
             BiCond
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.3">
             59.0
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.4">
             56.1
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.5">
             52.9
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.6">
             61.2
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.7">
             55.3
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.2.2.5.1.8">
             35.6
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.9">
             71.1
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.10">
             72.3
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.11">
             72.6
            </td>
            <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.5.1.12">
             72.0
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T3.2.2.6.2">
            <td class="ltx_td ltx_border_r" id="S5.T3.2.2.6.2.1">
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.6.2.2">
             BERT
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.3">
             57.9
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.4">
             61.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.5">
             59.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.6">
             63.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.7">
             60.7
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.6.2.8">
             38.8
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.9">
             73.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.10">
             73.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.11">
             76.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.6.2.12">
             75.5
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T3.2.2.7.3">
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.7.3.1">
             In-target Labeled Data
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.7.3.2">
             CrossNet
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.3">
             60.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.4">
             60.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.5">
             55.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.6">
             61.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.7">
             56.4
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.7.3.8">
             40.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.9">
             71.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.10">
             71.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.11">
             73.8
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.7.3.12">
             72.5
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T3.2.2.8.4">
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.8.4.1">
             Dependent Methods
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.8.4.2">
             ATT-LSTM
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.3">
             55.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.4">
             59.8
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.5">
             55.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.6">
             62.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.7">
             55.9
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.8.4.8">
             39.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.9">
             72.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.10">
             71.4
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.11">
             74.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.8.4.12">
             73.5
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T3.2.2.9.5">
            <td class="ltx_td ltx_border_r" id="S5.T3.2.2.9.5.1">
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.9.5.2">
             ASGCN
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.3">
             58.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.4">
             61.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.5">
             58.7
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.6">
             63.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.7">
             59.5
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.9.5.8">
             40.6
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.9">
             72.2
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.10">
             72.9
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.11">
             75.1
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.9.5.12">
             74.3
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T3.2.2.10.6">
            <td class="ltx_td ltx_border_r" id="S5.T3.2.2.10.6.1">
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.10.6.2">
             TPDG
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.3">
             63.0
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.4">
             73.4
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.5">
             67.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.6">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.10.6.6.1">
              74.7
             </span>
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.7">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.10.6.7.1">
              64.7
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.2.2.10.6.8">
             42.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.9">
             79.3
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.10">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.10.6.10.1">
              77.6
             </span>
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.11">
             81.5
            </td>
            <td class="ltx_td ltx_align_center" id="S5.T3.2.2.10.6.12">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.10.6.12.1">
              80.2
             </span>
            </td>
           </tr>
           <tr class="ltx_tr" id="S5.T3.2.2.2">
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.2.2.2.3">
             Zero-shot Method
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.2.2.2.4">
             COLA(ours)
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.1.1">
             <math alttext="\textbf{71.2}^{*}" class="ltx_Math" display="inline" id="S5.T3.1.1.1.1.m1.1">
              <semantics id="S5.T3.1.1.1.1.m1.1a">
               <msup id="S5.T3.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T3.1.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.1.m1.1.1.2a.cmml">
                 71.2
                </mtext>
                <mo id="S5.T3.1.1.1.1.m1.1.1.3" xref="S5.T3.1.1.1.1.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.m1.1b">
                <apply id="S5.T3.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T3.1.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T3.1.1.1.1.m1.1.1.2a.cmml" xref="S5.T3.1.1.1.1.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T3.1.1.1.1.m1.1.1.2.cmml" xref="S5.T3.1.1.1.1.m1.1.1.2">
                   71.2
                  </mtext>
                 </ci>
                 <times id="S5.T3.1.1.1.1.m1.1.1.3.cmml" xref="S5.T3.1.1.1.1.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.m1.1c">
                \textbf{71.2}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.5">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.2.5.1">
              75.9
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.6">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.2.6.1">
              69.1
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.7">
             71.0
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.8">
             62.3
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.2.2.2.2">
             <math alttext="\textbf{64.0}^{*}" class="ltx_Math" display="inline" id="S5.T3.2.2.2.2.m1.1">
              <semantics id="S5.T3.2.2.2.2.m1.1a">
               <msup id="S5.T3.2.2.2.2.m1.1.1" xref="S5.T3.2.2.2.2.m1.1.1.cmml">
                <mtext class="ltx_mathvariant_bold" id="S5.T3.2.2.2.2.m1.1.1.2" xref="S5.T3.2.2.2.2.m1.1.1.2a.cmml">
                 64.0
                </mtext>
                <mo id="S5.T3.2.2.2.2.m1.1.1.3" xref="S5.T3.2.2.2.2.m1.1.1.3.cmml">
                 ‚àó
                </mo>
               </msup>
               <annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.m1.1b">
                <apply id="S5.T3.2.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.2.m1.1.1">
                 <csymbol cd="ambiguous" id="S5.T3.2.2.2.2.m1.1.1.1.cmml" xref="S5.T3.2.2.2.2.m1.1.1">
                  superscript
                 </csymbol>
                 <ci id="S5.T3.2.2.2.2.m1.1.1.2a.cmml" xref="S5.T3.2.2.2.2.m1.1.1.2">
                  <mtext class="ltx_mathvariant_bold" id="S5.T3.2.2.2.2.m1.1.1.2.cmml" xref="S5.T3.2.2.2.2.m1.1.1.2">
                   64.0
                  </mtext>
                 </ci>
                 <times id="S5.T3.2.2.2.2.m1.1.1.3.cmml" xref="S5.T3.2.2.2.2.m1.1.1.3">
                 </times>
                </apply>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.m1.1c">
                \textbf{64.0}^{*}
               </annotation>
              </semantics>
             </math>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.9">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.2.9.1">
              80.8
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.10">
             76.2
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.11">
             <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.2.11.1">
              83.0
             </span>
            </td>
            <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.2.2.2.12">
             78.9
            </td>
           </tr>
          </tbody>
         </table>
        </span>
       </div>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_table">
         Table 3:
        </span>
        Comparison of zero-shot COLA and baselines fully trained on labeled data for the in-target stance detection task. Best scores are in bold. * denotes COLA improves the best baseline at
        <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S5.T3.4.m1.1">
         <semantics id="S5.T3.4.m1.1b">
          <mrow id="S5.T3.4.m1.1.1" xref="S5.T3.4.m1.1.1.cmml">
           <mi id="S5.T3.4.m1.1.1.2" xref="S5.T3.4.m1.1.1.2.cmml">
            p
           </mi>
           <mo id="S5.T3.4.m1.1.1.1" xref="S5.T3.4.m1.1.1.1.cmml">
            &lt;
           </mo>
           <mn id="S5.T3.4.m1.1.1.3" xref="S5.T3.4.m1.1.1.3.cmml">
            0.05
           </mn>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S5.T3.4.m1.1c">
           <apply id="S5.T3.4.m1.1.1.cmml" xref="S5.T3.4.m1.1.1">
            <lt id="S5.T3.4.m1.1.1.1.cmml" xref="S5.T3.4.m1.1.1.1">
            </lt>
            <ci id="S5.T3.4.m1.1.1.2.cmml" xref="S5.T3.4.m1.1.1.2">
             ùëù
            </ci>
            <cn id="S5.T3.4.m1.1.1.3.cmml" type="float" xref="S5.T3.4.m1.1.1.3">
             0.05
            </cn>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T3.4.m1.1d">
           p&lt;0.05
          </annotation>
         </semantics>
        </math>
        with paired t-test.
       </figcaption>
      </figure>
     </li>
     <li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       ‚Ä¢
      </span>
      <div class="ltx_para" id="S5.I1.i1.p1">
       <p class="ltx_p" id="S5.I1.i1.p1.1">
        Our method outperforms the state-of-the-art zero-shot stance detection approaches across the majority of metrics. On most metrics across three datasets, our model demonstrates statistically significant improvements over the best baseline. For the CC and LA targets in the SEM16 dataset, our approach achieves substantial gains over the best baseline, with absolute increases in
        <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S5.I1.i1.p1.1.m1.1">
         <semantics id="S5.I1.i1.p1.1.m1.1a">
          <msub id="S5.I1.i1.p1.1.m1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.cmml">
           <mi id="S5.I1.i1.p1.1.m1.1.1.2" xref="S5.I1.i1.p1.1.m1.1.1.2.cmml">
            F
           </mi>
           <mrow id="S5.I1.i1.p1.1.m1.1.1.3" xref="S5.I1.i1.p1.1.m1.1.1.3.cmml">
            <mi id="S5.I1.i1.p1.1.m1.1.1.3.2" xref="S5.I1.i1.p1.1.m1.1.1.3.2.cmml">
             a
            </mi>
            <mo id="S5.I1.i1.p1.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S5.I1.i1.p1.1.m1.1.1.3.1.cmml">
             ‚Äã
            </mo>
            <mi id="S5.I1.i1.p1.1.m1.1.1.3.3" xref="S5.I1.i1.p1.1.m1.1.1.3.3.cmml">
             v
            </mi>
            <mo id="S5.I1.i1.p1.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.I1.i1.p1.1.m1.1.1.3.1.cmml">
             ‚Äã
            </mo>
            <mi id="S5.I1.i1.p1.1.m1.1.1.3.4" xref="S5.I1.i1.p1.1.m1.1.1.3.4.cmml">
             g
            </mi>
           </mrow>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.m1.1b">
           <apply id="S5.I1.i1.p1.1.m1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S5.I1.i1.p1.1.m1.1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1">
             subscript
            </csymbol>
            <ci id="S5.I1.i1.p1.1.m1.1.1.2.cmml" xref="S5.I1.i1.p1.1.m1.1.1.2">
             ùêπ
            </ci>
            <apply id="S5.I1.i1.p1.1.m1.1.1.3.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3">
             <times id="S5.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3.1">
             </times>
             <ci id="S5.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3.2">
              ùëé
             </ci>
             <ci id="S5.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3.3">
              ùë£
             </ci>
             <ci id="S5.I1.i1.p1.1.m1.1.1.3.4.cmml" xref="S5.I1.i1.p1.1.m1.1.1.3.4">
              ùëî
             </ci>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.m1.1c">
           F_{avg}
          </annotation>
         </semantics>
        </math>
        of 15.7% and 25.1% respectively. In the WT-WT dataset, our method realizes significant improvements over the best baseline for all targets except for AH. In the VAST dataset, which comprises tens of thousands of instances, our model secures a notable absolute boost of 1.8% in the overall Macro-F1 Score. This attests to the robust zero-shot stance detection capabilities of our approach.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       ‚Ä¢
      </span>
      <div class="ltx_para" id="S5.I1.i2.p1">
       <p class="ltx_p" id="S5.I1.i2.p1.1">
        The zero-shot stance detection performance of our method is closely aligned with that of the state-of-the-art in-target stance detection techniques, even when they are fully trained on corresponding targets. On the SEM16 dataset, our approach significantly outperforms the best baseline, TPDG, on the DT and CC targets, while maintaining comparable performance on other targets. In the WT-WT dataset, our method consistently matches the performance of TPDG across all targets. Remarkably, even though these comparison methods have been extensively trained on their respective targets, our approach still sustains comparable or superior performance, underscoring our method‚Äôs strong performance.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       ‚Ä¢
      </span>
      <div class="ltx_para" id="S5.I1.i3.p1">
       <p class="ltx_p" id="S5.I1.i3.p1.1">
        Direct application of large language models may yield poor performance, especially on abstract concept targets. In the SEM16 dataset, for the targets A (
        <span class="ltx_text ltx_font_italic" id="S5.I1.i3.p1.1.1">
         Atheism
        </span>
        ) and CC (
        <span class="ltx_text ltx_font_italic" id="S5.I1.i3.p1.1.2">
         Climate Change is a Real Concern
        </span>
        ), GPT-3.5 achieves only 8.1% and 24.7% in
        <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S5.I1.i3.p1.1.m1.1">
         <semantics id="S5.I1.i3.p1.1.m1.1a">
          <msub id="S5.I1.i3.p1.1.m1.1.1" xref="S5.I1.i3.p1.1.m1.1.1.cmml">
           <mi id="S5.I1.i3.p1.1.m1.1.1.2" xref="S5.I1.i3.p1.1.m1.1.1.2.cmml">
            F
           </mi>
           <mrow id="S5.I1.i3.p1.1.m1.1.1.3" xref="S5.I1.i3.p1.1.m1.1.1.3.cmml">
            <mi id="S5.I1.i3.p1.1.m1.1.1.3.2" xref="S5.I1.i3.p1.1.m1.1.1.3.2.cmml">
             a
            </mi>
            <mo id="S5.I1.i3.p1.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S5.I1.i3.p1.1.m1.1.1.3.1.cmml">
             ‚Äã
            </mo>
            <mi id="S5.I1.i3.p1.1.m1.1.1.3.3" xref="S5.I1.i3.p1.1.m1.1.1.3.3.cmml">
             v
            </mi>
            <mo id="S5.I1.i3.p1.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.I1.i3.p1.1.m1.1.1.3.1.cmml">
             ‚Äã
            </mo>
            <mi id="S5.I1.i3.p1.1.m1.1.1.3.4" xref="S5.I1.i3.p1.1.m1.1.1.3.4.cmml">
             g
            </mi>
           </mrow>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.m1.1b">
           <apply id="S5.I1.i3.p1.1.m1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S5.I1.i3.p1.1.m1.1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1">
             subscript
            </csymbol>
            <ci id="S5.I1.i3.p1.1.m1.1.1.2.cmml" xref="S5.I1.i3.p1.1.m1.1.1.2">
             ùêπ
            </ci>
            <apply id="S5.I1.i3.p1.1.m1.1.1.3.cmml" xref="S5.I1.i3.p1.1.m1.1.1.3">
             <times id="S5.I1.i3.p1.1.m1.1.1.3.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1.3.1">
             </times>
             <ci id="S5.I1.i3.p1.1.m1.1.1.3.2.cmml" xref="S5.I1.i3.p1.1.m1.1.1.3.2">
              ùëé
             </ci>
             <ci id="S5.I1.i3.p1.1.m1.1.1.3.3.cmml" xref="S5.I1.i3.p1.1.m1.1.1.3.3">
              ùë£
             </ci>
             <ci id="S5.I1.i3.p1.1.m1.1.1.3.4.cmml" xref="S5.I1.i3.p1.1.m1.1.1.3.4">
              ùëî
             </ci>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.m1.1c">
           F_{avg}
          </annotation>
         </semantics>
        </math>
        respectively. Even with the enhanced GPT-3.5+COT, the scores are merely 10.3% and 25.2%. Across almost all datasets and metrics, the performance of simply deploying large language models significantly lags behind our proposed method. This underscores the limitations of directly using large language models for stance detection tasks, especially in handling stances towards abstract concept targets, highlighting the necessity and validity of our design.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <figure class="ltx_table" id="S5.T4">
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.1">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S5.T4.1.1.1">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T4.1.1.1.1" rowspan="2">
        <span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.1.1">
         Model
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="6" id="S5.T4.1.1.1.2">
        <span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.2.1">
         SEM16(%)
        </span>
       </th>
      </tr>
      <tr class="ltx_tr" id="S5.T4.1.2.2">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.2.1">
        DT
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.2.2">
        HC
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.2.3">
        FM
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.2.4">
        LA
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.2.5">
        A
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.2.6">
        CC
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T4.1.3.1">
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.3.1.1">
        COLA
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.1.2">
        71.2
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.1.3">
        75.9
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.1.4">
        69.1
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.1.5">
        71.0
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.1.6">
        62.3
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.1.7">
        64.0
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T4.1.4.2">
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.4.2.1">
        w/o Liguisitic Expert
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.4.2.2">
        69.1
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.4.2.3">
        74.2
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.4.2.4">
        67.8
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.4.2.5">
        67.2
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.4.2.6">
        46.0
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.4.2.7">
        62.1
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T4.1.5.3">
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.5.3.1">
        w/o Domain Specialist
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.5.3.2">
        70.4
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.5.3.3">
        75.0
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.5.3.4">
        66.5
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.5.3.5">
        60.1
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.5.3.6">
        42.4
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.5.3.7">
        58.2
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T4.1.6.4">
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.6.4.1">
        w/o Social Media Veteran
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.6.4.2">
        67.8
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.6.4.3">
        75.5
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.6.4.4">
        68.2
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.6.4.5">
        64.4
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.6.4.6">
        54.6
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.6.4.7">
        60.0
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T4.1.7.5">
       <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.7.5.1">
        w/o Multidimensional Text Analysis Stage
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.7.5.2">
        67.4
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.7.5.3">
        72.8
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.7.5.4">
        65.2
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.7.5.5">
        52.2
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.7.5.6">
        23.3
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T4.1.7.5.7">
        55.9
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T4.1.8.6">
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T4.1.8.6.1">
        w/o Reasoning-Enhanced Debating Stage
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.1.8.6.2">
        64.7
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.1.8.6.3">
        73.3
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.1.8.6.4">
        64.0
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.1.8.6.5">
        53.8
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.1.8.6.6">
        26.6
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.1.8.6.7">
        49.1
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     Experimental results of ablation study.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Ablation Study (RQ2)
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     To investigate the impact of each module in our design, we conduct ablation studies to assess the performance of our framework when each module is removed. The results are shown in Table
     <a class="ltx_ref" href="#S5.T4" title="Table 4 ‚Ä£ 5.1 Overall Performance (RQ1) ‚Ä£ 5 Experimental Results ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     , which demonstrate that every module in our framework contributes to performance enhancement. In the following, we provide a detailed description of the results.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S5.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.1
     </span>
     Study on multidimensional text analysis stage.
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS1.p1">
     <p class="ltx_p" id="S5.SS2.SSS1.p1.2">
      During the multidimensional text analysis stage, three expert agents from different domains concurrently analyze the text. We individually removed each of these experts to assess the performance of our approach. We also evaluated the performance when all expert analyses are excluded. The results show that the removal of any expert agent results in a certain degree of performance degradation. Moreover, eliminating the entire multidimensional text analysis stage leads to a significant performance drop. The most pronounced performance decline was observed for the A (
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS1.p1.2.1">
       Atheism
      </span>
      ) target. Removing the Linguistic Expert, Domain Specialist, and Social Media Veteran leads to an
      <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p1.1.m1.1">
       <semantics id="S5.SS2.SSS1.p1.1.m1.1a">
        <msub id="S5.SS2.SSS1.p1.1.m1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.cmml">
         <mi id="S5.SS2.SSS1.p1.1.m1.1.1.2" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml">
          F
         </mi>
         <mrow id="S5.SS2.SSS1.p1.1.m1.1.1.3" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.cmml">
          <mi id="S5.SS2.SSS1.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.2.cmml">
           a
          </mi>
          <mo id="S5.SS2.SSS1.p1.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S5.SS2.SSS1.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.3.cmml">
           v
          </mi>
          <mo id="S5.SS2.SSS1.p1.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S5.SS2.SSS1.p1.1.m1.1.1.3.4" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.4.cmml">
           g
          </mi>
         </mrow>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.1.m1.1b">
         <apply id="S5.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.2">
           ùêπ
          </ci>
          <apply id="S5.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.3">
           <times id="S5.SS2.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.1">
           </times>
           <ci id="S5.SS2.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.2">
            ùëé
           </ci>
           <ci id="S5.SS2.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.3">
            ùë£
           </ci>
           <ci id="S5.SS2.SSS1.p1.1.m1.1.1.3.4.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.4">
            ùëî
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.1.m1.1c">
         F_{avg}
        </annotation>
       </semantics>
      </math>
      decrease to 46.0%, 42.4%, and 54.6%, respectively. What‚Äôs more, without the multidimensional text analysis stage, the
      <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p1.2.m2.1">
       <semantics id="S5.SS2.SSS1.p1.2.m2.1a">
        <msub id="S5.SS2.SSS1.p1.2.m2.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.cmml">
         <mi id="S5.SS2.SSS1.p1.2.m2.1.1.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml">
          F
         </mi>
         <mrow id="S5.SS2.SSS1.p1.2.m2.1.1.3" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml">
          <mi id="S5.SS2.SSS1.p1.2.m2.1.1.3.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.2.cmml">
           a
          </mi>
          <mo id="S5.SS2.SSS1.p1.2.m2.1.1.3.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S5.SS2.SSS1.p1.2.m2.1.1.3.3" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.3.cmml">
           v
          </mi>
          <mo id="S5.SS2.SSS1.p1.2.m2.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S5.SS2.SSS1.p1.2.m2.1.1.3.4" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.4.cmml">
           g
          </mi>
         </mrow>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.2.m2.1b">
         <apply id="S5.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2">
           ùêπ
          </ci>
          <apply id="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3">
           <times id="S5.SS2.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.1">
           </times>
           <ci id="S5.SS2.SSS1.p1.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.2">
            ùëé
           </ci>
           <ci id="S5.SS2.SSS1.p1.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.3">
            ùë£
           </ci>
           <ci id="S5.SS2.SSS1.p1.2.m2.1.1.3.4.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.4">
            ùëî
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.2.m2.1c">
         F_{avg}
        </annotation>
       </semantics>
      </math>
      drops to a mere 23.3%. This could be attributed to the complexity of the
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS1.p1.2.2">
       Atheism
      </span>
      topic across various domains such as religion and society. These findings underscore the effectiveness of our multidimensional text analysis stage and the design of each agent therein.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.2
     </span>
     Study on reasoning-enhanced debating stage.
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS2.p1">
     <p class="ltx_p" id="S5.SS2.SSS2.p1.1">
      In the reasoning-enhanced debating phase, we introduce debates among agents with differing perspectives to augment the reasoning capabilities of our LLM-based system. We remove this stage and let the judger agent directly deduce the text‚Äôs stance from the expert agents‚Äô text analysis, aiming to verify the effectiveness of the debating design. Upon the removal of the debating stage, our method experiences a noticeable performance degradation. The most significant drops are observed for the abstract concept targets A (
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS2.p1.1.1">
       Atheism
      </span>
      ), CC (
      <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS2.p1.1.2">
       Climate Change is Real Concern
      </span>
      ), and LA (Legalization of Abortion), with the absolute
      <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p1.1.m1.1">
       <semantics id="S5.SS2.SSS2.p1.1.m1.1a">
        <msub id="S5.SS2.SSS2.p1.1.m1.1.1" xref="S5.SS2.SSS2.p1.1.m1.1.1.cmml">
         <mi id="S5.SS2.SSS2.p1.1.m1.1.1.2" xref="S5.SS2.SSS2.p1.1.m1.1.1.2.cmml">
          F
         </mi>
         <mrow id="S5.SS2.SSS2.p1.1.m1.1.1.3" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.cmml">
          <mi id="S5.SS2.SSS2.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.2.cmml">
           a
          </mi>
          <mo id="S5.SS2.SSS2.p1.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S5.SS2.SSS2.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.3.cmml">
           v
          </mi>
          <mo id="S5.SS2.SSS2.p1.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.1.cmml">
           ‚Äã
          </mo>
          <mi id="S5.SS2.SSS2.p1.1.m1.1.1.3.4" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.4.cmml">
           g
          </mi>
         </mrow>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.1.m1.1b">
         <apply id="S5.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S5.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.2">
           ùêπ
          </ci>
          <apply id="S5.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3">
           <times id="S5.SS2.SSS2.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.1">
           </times>
           <ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.2">
            ùëé
           </ci>
           <ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.3">
            ùë£
           </ci>
           <ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.4.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.4">
            ùëî
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.1.m1.1c">
         F_{avg}
        </annotation>
       </semantics>
      </math>
      declining by 35.7%, 14.9%, and 10.6%, respectively. This indicates that the reasoning-enhanced debating stage offers substantial benefits, especially when dealing with relatively abstract targets. The results validate the effectiveness of the reasoning-enhanced debating stage design.
     </p>
    </div>
    <figure class="ltx_figure" id="S5.F3">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="256" id="S5.F3.g1" src="/html/2310.10467/assets/x3.png" width="276"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 3:
      </span>
      Cases of explainations generated by our approach.
     </figcaption>
    </figure>
    <figure class="ltx_table" id="S5.T5">
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.1">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S5.T5.1.1.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S5.T5.1.1.1.1" rowspan="2">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.1.1">
          Method
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="6" id="S5.T5.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.2.1">
          SEM16(%)
         </span>
        </th>
       </tr>
       <tr class="ltx_tr" id="S5.T5.1.2.2">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.2.2.1">
         DT
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.2.2.2">
         HC
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.2.2.3">
         FM
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.2.2.4">
         LA
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.2.2.5">
         A
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T5.1.2.2.6">
         CC
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S5.T5.1.3.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T5.1.3.1.1">
         GPT-3.5
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.2">
         69.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.3">
         75.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.4">
         60.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.5">
         55.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.6">
         10.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.7">
         25.2
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T5.1.4.2">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T5.1.4.2.1">
         COLA
        </th>
        <td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.2">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.4.2.2.1">
          71.2
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.3">
         75.9
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.4">
         69.1
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.5">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.4.2.5.1">
          71.0
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.6">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.4.2.6.1">
          62.3
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.7">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.4.2.7.1">
          64.0
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T5.1.5.3">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S5.T5.1.5.3.1">
         GPT-3.5+COLA‚Äôs Explainations
        </th>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.1.5.3.2">
         69.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.1.5.3.3">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.5.3.3.1">
          77.7
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.1.5.3.4">
         <span class="ltx_text ltx_font_bold" id="S5.T5.1.5.3.4.1">
          70.7
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.1.5.3.5">
         66.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.1.5.3.6">
         61.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.1.5.3.7">
         54.5
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 5:
      </span>
      Performance of GPT-3.5 Turbo, COLA and GPT-3.5 Turbo with explainations generated by COLA. Best scores are in bold.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Study on Explainablity (RQ3)
   </h3>
   <div class="ltx_para" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     An explainable artificial intelligence (XAI) is one that offers clear insights or justifications to make its decisions comprehensible
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib7" title="">
       arrieta2020explainable
      </a>
     </cite>
     . By elucidating its decision-making processes, an XAI augments transparency and reinforces model trustability
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib16" title="">
       das2020opportunities
      </a>
     </cite>
     . Large language models inherently possess the capability to explain their outputs. By prompting them about the rationale behind their decisions, we can obtain explanations for their determinations directly. To delve deeper into the explainablility of our approach, we conduct both case studies and quantitative experiments to verify its ability to generate clear and reasonable explanations.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS3.p2">
    <p class="ltx_p" id="S5.SS3.p2.1">
     During the stance conclusion stage, we mandate the judger agent to provide outputs in a JSON format, consisting of two components: the stance and a concise explanation not exceeding 100 tokens. We conduct our experiment on the SEM16 dataset. After closely examining the generated outputs, we find that our model can provide clear explanations for its decisions. In Figure
     <a class="ltx_ref" href="#S5.F3" title="Figure 3 ‚Ä£ 5.2.2 Study on reasoning-enhanced debating stage. ‚Ä£ 5.2 Ablation Study (RQ2) ‚Ä£ 5 Experimental Results ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , we show two cases to illustrate.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS3.p3">
    <p class="ltx_p" id="S5.SS3.p3.1">
     In the first case, the tweet
     <span class="ltx_text ltx_font_italic" id="S5.SS3.p3.1.1">
      ‚ÄúThe ruling by @Scotus is a major setback for @EPA &amp; the environment. #dirtycoal‚Äù
     </span>
     agrees that climate change is a real concern. Our model detects this stance. In its generated explanation, the model discerns the mention of the EPA and the usage of the #dirtycoal tag, indicating an environmental concern. Moreover, the model perceives an emotional tone of frustration, further reflecting a pro-environmental perspective.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS3.p4">
    <p class="ltx_p" id="S5.SS3.p4.1">
     In the second case, the tweet
     <span class="ltx_text ltx_font_italic" id="S5.SS3.p4.1.1">
      ‚Äú@GovtsTheProblem This is what I see: Make way 4 ur queen peasants! Don‚Äôt touch or talk 2 her U filth! #NoHillary2016 #Benghazi‚Äù
     </span>
     portrays an opposing stance toward Hillary. Our model rationally explains its judgment from a linguistic perspective (utilization of derogatory language), a domain-specialist perspective (mentioning the Benghazi incident in a negative context), and a social media lens (the hashtag #NoHillary2016). These cases validate the model‚Äôs proficiency in generating clear and reasonable explanations.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS3.p5">
    <p class="ltx_p" id="S5.SS3.p5.1">
     To further validate our model‚Äôs ability to produce clear and logical explanations, we conduct quantitative experiments. For the SEM16 dataset, we collect explanations (from the second part of the JSON output) related to each instance‚Äôs stance generated by COLA. These explanations, along with the original text, are fed into the GPT-3.5 Turbo model. We inform the model that these explanations could be used as references for its decisions. As a result, we obtain a new set of judgments from the model. It‚Äôs evident that the performance of GPT-3.5 Turbo significantly improves by incorporating explanations generated by COLA in addition to the original text, as presented in Table
     <a class="ltx_ref" href="#S5.T5" title="Table 5 ‚Ä£ 5.2.2 Study on reasoning-enhanced debating stage. ‚Ä£ 5.2 Ablation Study (RQ2) ‚Ä£ 5 Experimental Results ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     . There is a noticeable increase for the A(
     <span class="ltx_text ltx_font_italic" id="S5.SS3.p5.1.1">
      Atheism
     </span>
     ) and CC(
     <span class="ltx_text ltx_font_italic" id="S5.SS3.p5.1.2">
      Climate Change is Real Concern
     </span>
     ) targets, with
     <math alttext="F_{avg}" class="ltx_Math" display="inline" id="S5.SS3.p5.1.m1.1">
      <semantics id="S5.SS3.p5.1.m1.1a">
       <msub id="S5.SS3.p5.1.m1.1.1" xref="S5.SS3.p5.1.m1.1.1.cmml">
        <mi id="S5.SS3.p5.1.m1.1.1.2" xref="S5.SS3.p5.1.m1.1.1.2.cmml">
         F
        </mi>
        <mrow id="S5.SS3.p5.1.m1.1.1.3" xref="S5.SS3.p5.1.m1.1.1.3.cmml">
         <mi id="S5.SS3.p5.1.m1.1.1.3.2" xref="S5.SS3.p5.1.m1.1.1.3.2.cmml">
          a
         </mi>
         <mo id="S5.SS3.p5.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S5.SS3.p5.1.m1.1.1.3.1.cmml">
          ‚Äã
         </mo>
         <mi id="S5.SS3.p5.1.m1.1.1.3.3" xref="S5.SS3.p5.1.m1.1.1.3.3.cmml">
          v
         </mi>
         <mo id="S5.SS3.p5.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S5.SS3.p5.1.m1.1.1.3.1.cmml">
          ‚Äã
         </mo>
         <mi id="S5.SS3.p5.1.m1.1.1.3.4" xref="S5.SS3.p5.1.m1.1.1.3.4.cmml">
          g
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S5.SS3.p5.1.m1.1b">
        <apply id="S5.SS3.p5.1.m1.1.1.cmml" xref="S5.SS3.p5.1.m1.1.1">
         <csymbol cd="ambiguous" id="S5.SS3.p5.1.m1.1.1.1.cmml" xref="S5.SS3.p5.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S5.SS3.p5.1.m1.1.1.2.cmml" xref="S5.SS3.p5.1.m1.1.1.2">
          ùêπ
         </ci>
         <apply id="S5.SS3.p5.1.m1.1.1.3.cmml" xref="S5.SS3.p5.1.m1.1.1.3">
          <times id="S5.SS3.p5.1.m1.1.1.3.1.cmml" xref="S5.SS3.p5.1.m1.1.1.3.1">
          </times>
          <ci id="S5.SS3.p5.1.m1.1.1.3.2.cmml" xref="S5.SS3.p5.1.m1.1.1.3.2">
           ùëé
          </ci>
          <ci id="S5.SS3.p5.1.m1.1.1.3.3.cmml" xref="S5.SS3.p5.1.m1.1.1.3.3">
           ùë£
          </ci>
          <ci id="S5.SS3.p5.1.m1.1.1.3.4.cmml" xref="S5.SS3.p5.1.m1.1.1.3.4">
           ùëî
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS3.p5.1.m1.1c">
        F_{avg}
       </annotation>
      </semantics>
     </math>
     improving by 51.6 and 29.3 points, respectively. For the HC(
     <span class="ltx_text ltx_font_italic" id="S5.SS3.p5.1.3">
      Hillary Clinton
     </span>
     ) and FM(
     <span class="ltx_text ltx_font_italic" id="S5.SS3.p5.1.4">
      Feminist Movement
     </span>
     ) targets, the results even exceed that of COLA. This further confirms our model‚Äôs strong ability in generating clear and logical explanations.
    </p>
   </div>
   <figure class="ltx_table" id="S5.T6">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.1" style="width:403.6pt;height:86.4pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-50.5pt,10.8pt) scale(0.8,0.8) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T6.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S5.T6.1.1.1.1">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.1.1.1.1.1" rowspan="2">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.1.1">
           Category
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.1.1.1.1.2" rowspan="2">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.2.1">
           Model
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S5.T6.1.1.1.1.3">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.3.1">
           Restaurant14(%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S5.T6.1.1.1.1.4">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.4.1">
           Laptop14(%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T6.1.1.1.1.5">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.5.1">
           Restaurant15(%)
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T6.1.1.2.2">
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.2.2.1">
          Accuracy
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.2.2.2">
          Macro-F1
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.2.2.3">
          Accuracy
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.2.2.4">
          Macro-F1
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.2.2.5">
          Accuracy
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.2.2.6">
          Macro-F1
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T6.1.1.3.3">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.1.1.3.3.1">
          Labeled Data
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.1.1.3.3.2">
          DGEDT
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.3.3.3">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.3.3.3.1">
           86.3
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.3.3.4">
          80.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.3.3.5">
          79.8
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.3.3.6">
          75.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.3.3.7">
          84.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.3.3.8">
          71.0
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T6.1.1.4.4">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T6.1.1.4.4.1">
          Dependent Methods
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T6.1.1.4.4.2">
          dotGCN
         </th>
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.4.4.3">
          86.2
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.4.4.4">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.4.4.4.1">
           80.5
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.4.4.5">
          81.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.4.4.6">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.4.4.6.1">
           78.1
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.4.4.7">
          85.2
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T6.1.1.4.4.8">
          72.7
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T6.1.1.5.5">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S5.T6.1.1.5.5.1" rowspan="2">
          <span class="ltx_text" id="S5.T6.1.1.5.5.1.1">
           Zero-shot Methods
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.1.1.5.5.2">
          GPT-3.5-Turbo
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.5.5.3">
          74.3
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.5.5.4">
          69.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.5.5.5">
          69.9
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.5.5.6">
          61.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.5.5.7">
          80.4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.5.5.8">
          67.7
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T6.1.1.6.6">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S5.T6.1.1.6.6.1">
          Ours
         </th>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T6.1.1.6.6.2">
          84.1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T6.1.1.6.6.3">
          77.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T6.1.1.6.6.4">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.6.6.4.1">
           81.6
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T6.1.1.6.6.5">
          77.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T6.1.1.6.6.6">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.6.6.6.1">
           85.4
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T6.1.1.6.6.7">
          <span class="ltx_text ltx_font_bold" id="S5.T6.1.1.6.6.7.1">
           74.9
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 6:
     </span>
     Performance of our framework and baselines on aspect-based sentiment analysis. Best scores are in bold.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S5.T7">
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T7.1">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S5.T7.1.1.1">
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T7.1.1.1.1">
        <span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.1.1">
         Model
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T7.1.1.1.2">
        <span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.2.1">
         Accuracy(%)
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T7.1.1.1.3">
        <span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.3.1">
         F1-Score(%)
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T7.1.2.1">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.1.1">
        Hybrid RCNN
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.1.2">
        74.8
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.2.1.3">
        59.6
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.1.3.2">
       <td class="ltx_td ltx_align_center" id="S5.T7.1.3.2.1">
        GPT-3.5 Turbo
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T7.1.3.2.2">
        67.6
       </td>
       <td class="ltx_td ltx_align_center" id="S5.T7.1.3.2.3">
        56.0
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T7.1.4.3">
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T7.1.4.3.1">
        Ours
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T7.1.4.3.2">
        <span class="ltx_text ltx_font_bold" id="S5.T7.1.4.3.2.1">
         76.5
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b" id="S5.T7.1.4.3.3">
        <span class="ltx_text ltx_font_bold" id="S5.T7.1.4.3.3.1">
         63.9
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 7:
     </span>
     Performance of our framework and baselines on persuasion prediction. Best scores are in bold.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S5.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.4
    </span>
    Study on Versatility (RQ4)
   </h3>
   <div class="ltx_para" id="S5.SS4.p1">
    <p class="ltx_p" id="S5.SS4.p1.1">
     Our proposed COLA can be summarized as an Analyst-Debater-Summarizer framework. In this section, we conduct experiments to validate that the Analyst-Debater-Summarizer framework can be applied to other text classification tasks for text analysis on web and social media, not just as an ad-hoc approach for stance detection. We perform experiments on two additional text classification tasks: aspect-based sentiment analysis and persuasion prediction. We select aspect-based sentiment analysis because it demands precise understanding of sentiments tied to specific elements in text, reflecting the detailed analysis capability of our framework. Meanwhile, persuasion prediction is chosen due to its emphasis on detecting underlying intent, highlighting COLA‚Äôs ability to adeptly handle intricate conversational dynamics commonly seen in web and social media exchanges.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS4.p2">
    <p class="ltx_p" id="S5.SS4.p2.1">
     Aspect-based sentiment analysis is to determine the sentiment polarity (
     <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.1">
      Positive
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.2">
      Negative
     </span>
     , or
     <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.3">
      Neutral
     </span>
     ) expressed towards each aspect mentioned in the text
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib36" title="">
       pontiki-etal-2014-semeval
      </a>
     </cite>
     . In this task, we modify the debater component in our original framework to engage in sentiment debates instead of stance debates, while keeping other design unchanged. We evaluate our approach‚Äôs performance on the Restaurant14 and Laptop14 datasets from SemEval14
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib36" title="">
       pontiki-etal-2014-semeval
      </a>
     </cite>
     , as well as the Restaurant15 dataset from SemEval15
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib35" title="">
       pontiki2016semeval
      </a>
     </cite>
     . We follow Chen et al.
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib14" title="">
       chen2017recurrent
      </a>
     </cite>
     and use Accuracy and Macro-F1 score as evaluation metrics. We compare our approach with state-of-the-art models that require training, namely DGEDT
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib40" title="">
       tang2020dependency
      </a>
     </cite>
     and dotGCN
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib13" title="">
       chen2022discrete
      </a>
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S5.SS4.p3">
    <p class="ltx_p" id="S5.SS4.p3.1">
     The experimental results are presented in Table
     <a class="ltx_ref" href="#S5.T6" title="Table 6 ‚Ä£ 5.3 Study on Explainablity (RQ3) ‚Ä£ 5 Experimental Results ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     . It can be observed that our zero-shot method performs comparably to the best baseline models that rely on labeled data. On the Restaurant15 dataset, our approach even outperforms the top baseline. Another crucial finding is that our approach consistently outperforms directly applying GPT-3.5 Turbo while maintaining ease of use.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS4.p4">
    <p class="ltx_p" id="S5.SS4.p4.1">
     Following Ziems et al.
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib54" title="">
       ziems2023can
      </a>
     </cite>
     , we define persuasion prediction as determining whether one party in a conversation is persuaded after the conversation ends. In this task, we replace the three experts in our original framework with two experts: a domain expert and a psychologist. They provide detailed analysis of various concepts and nouns in the conversation topic and analyze the psychological changes of the individuals involved. The debaters are modified to argue for whether a participant in the conversation has been persuaded. We use the dataset provided by Wang et al.
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib43" title="">
       wang2019persuasion
      </a>
     </cite>
     and follow their evaluation metrics, using Accuracy and Macro-F1.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS4.p5">
    <p class="ltx_p" id="S5.SS4.p5.1">
     We compare our approach with Hybrid RCNN
     <cite class="ltx_cite ltx_citemacro_cite">
      <a class="ltx_ref" href="#bib.bib43" title="">
       wang2019persuasion
      </a>
     </cite>
     and GPT-3.5 Turbo, and the results are presented in Table
     <a class="ltx_ref" href="#S5.T7" title="Table 7 ‚Ä£ 5.3 Study on Explainablity (RQ3) ‚Ä£ 5 Experimental Results ‚Ä£ Stance Detection with Collaborative Role-Infused LLM-Based Agents">
      <span class="ltx_text ltx_ref_tag">
       7
      </span>
     </a>
     . The experimental results show that our approach achieves better performance compared to the baseline and a significant improvement over GPT-3.5 Turbo.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS4.p6">
    <p class="ltx_p" id="S5.SS4.p6.1">
     The Analyst-Debater-Summarizer framework has proven to be highly successful in both aspect-based sentiment analysis and persuasion classification tasks. On a series of tasks, our zero-shot framework performs on par with state-of-the-art baselines that rely on training data and significantly outperforms direct application of GPT-3.5 Turbo. These experiments demonstrate the versatility of our approach.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.5
    </span>
    Discussions
   </h3>
   <div class="ltx_para" id="S5.SS5.p1">
    <p class="ltx_p" id="S5.SS5.p1.1">
     In the aforementioned experiment, we extensively evaluate the performance of our approach across various dimensions. From the perspective of our method‚Äôs design rationale, the ablation study confirms that every component in our approach contributes to a performance boost, indicating that the design is free of redundancy and can be considered efficacious. In comparison with existing methods, experimental evidence shows that our approach outperforms all other zero-shot methods on stance detection. Furthermore, its performance is on par with in-target stance detection methods that rely on in-target labeled data, exhibiting impressive accuracy. In addition, for two other text classification tasks related to web and social media content analysis, our method achieves results comparable to state-of-the-art baselines, underscoring its versatility. From a practical application standpoint, our method does not require additional training for the model. Instead, it can be implemented by interacting with existing large language models through APIs or other means, showcasing its strong usability. The experiments also prove that our framework can provide clear and rational explanations for its decisions, ensuring a high degree of explainability. Such generated explanations can bolster users‚Äô trust in our approach and are conducive to further analysis. Given these advantages, our method promises a broad range of applications.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion and Future Work
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this work, we harness the formidable capabilities of LLMs for advanced stance detection. We propose COLA, where multiple LLM-based agents collaborate to reach an conclusion. This method encompasses three stages: the multidimensional text analysis stage, the reasoning-enhanced debating stage, and the stance conclusion stage. Experimental results demonstrate that our approach achieves high accuracy, effectiveness, explainability, and versatility, showcasing its significant applicability.
   </p>
  </div>
  <div class="ltx_para" id="S6.p2">
   <p class="ltx_p" id="S6.p2.1">
    Our method is not without limitation. Due to the absence of real-time training data for large language models, the performance in analyzing real-time topics might be slightly compromised. For future work, we intend to incorporate a real-time updating knowledge base into the text analysis stage to enhance our framework‚Äôs capability to analyze texts that include current events. Furthermore, there remains vast potential for exploring its implementation in addressing extensive text analysis tasks on web and social media.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     Aseel Addawood, Jodi Schneider, and Masooda Bashir.
    </span>
    <span class="ltx_bibblock">
     Stance classification of twitter debates: The encryption debate as a use case.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">
      Proceedings of the 8th international conference on Social Media &amp; Society
     </span>
     , pages 1‚Äì10, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Do as i can, not as i say: Grounding language in robotic affordances.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2204.01691
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     Abeer AlDayel and Walid Magdy.
    </span>
    <span class="ltx_bibblock">
     Stance detection on social media: State of the art and trends.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">
      Information Processing &amp; Management
     </span>
     , 58(4):102597, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     Emily Allaway and Kathleen McKeown.
    </span>
    <span class="ltx_bibblock">
     Zero-shot stance detection: A dataset and model using generalized topic representations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2010.03640
     </span>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     Emily Allaway, Malavika Srikanth, and Kathleen McKeown.
    </span>
    <span class="ltx_bibblock">
     Adversarial learning for zero-shot stance detection on social media.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">
      arXiv preprint arXiv:2105.06603
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     Nora Alturayeif, Hamzah Luqman, and Moataz Ahmed.
    </span>
    <span class="ltx_bibblock">
     A systematic review of machine learning techniques for stance detection and its applications.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">
      Neural Computing and Applications
     </span>
     , 35(7):5113‚Äì5144, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     Alejandro¬†Barredo Arrieta, Natalia D√≠az-Rodr√≠guez, Javier Del¬†Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc√≠a, Sergio Gil-L√≥pez, Daniel Molina, Richard Benjamins, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Explainable artificial intelligence (xai): Concepts, taxonomies, opportunities and challenges toward responsible ai.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">
      Information fusion
     </span>
     , 58:82‚Äì115, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     Isabelle Augenstein, Tim Rockt√§schel, Andreas Vlachos, and Kalina Bontcheva.
    </span>
    <span class="ltx_bibblock">
     Stance detection with bidirectional conditional encoding.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">
      arXiv preprint arXiv:1606.05464
     </span>
     , 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     Roy Bar-Haim, Indrajit Bhattacharya, Francesco Dinuzzo, Amrita Saha, and Noam Slonim.
    </span>
    <span class="ltx_bibblock">
     Stance classification of context-dependent claims.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">
      Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers
     </span>
     , pages 251‚Äì261, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared¬†D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">
      Advances in neural information processing systems
     </span>
     , 33:1877‚Äì1901, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou.
    </span>
    <span class="ltx_bibblock">
     Large language models as tool makers.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2305.17126
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu.
    </span>
    <span class="ltx_bibblock">
     Chateval: Towards better llm-based evaluators through multi-agent debate.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">
      arXiv preprint arXiv:2308.07201
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     Chenhua Chen, Zhiyang Teng, Zhongqing Wang, and Yue Zhang.
    </span>
    <span class="ltx_bibblock">
     Discrete opinion tree induction for aspect-based sentiment analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">
      Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
     </span>
     , pages 2051‚Äì2064, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     Peng Chen, Zhongqian Sun, Lidong Bing, and Wei Yang.
    </span>
    <span class="ltx_bibblock">
     Recurrent attention network on memory for aspect sentiment analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">
      Proceedings of the 2017 conference on empirical methods in natural language processing
     </span>
     , pages 452‚Äì461, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     Costanza Conforti, Jakob Berndt, Mohammad¬†Taher Pilehvar, Chryssi Giannitsarou, Flavio Toxvaerd, and Nigel Collier.
    </span>
    <span class="ltx_bibblock">
     Will-they-won‚Äôt-they: A very large dataset for stance detection on twitter.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">
      arXiv preprint arXiv:2005.00388
     </span>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     Arun Das and Paul Rad.
    </span>
    <span class="ltx_bibblock">
     Opportunities and challenges in explainable artificial intelligence (xai): A survey.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">
      arXiv preprint arXiv:2006.11371
     </span>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
    </span>
    <span class="ltx_bibblock">
     Bert: Pre-training of deep bidirectional transformers for language understanding.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:1810.04805
     </span>
     , 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     Yilun Du, Shuang Li, Antonio Torralba, Joshua¬†B Tenenbaum, and Igor Mordatch.
    </span>
    <span class="ltx_bibblock">
     Improving factuality and reasoning in language models through multiagent debate.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">
      arXiv preprint arXiv:2305.14325
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong Wang, Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     S3: Social-network simulation system with large language model-empowered agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">
      arXiv preprint arXiv:2307.14984
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     Miha Grƒçar, Darko Cherepnalkoski, Igor Mozetiƒç, and Petra Kralj¬†Novak.
    </span>
    <span class="ltx_bibblock">
     Stance and influence of twitter users regarding the brexit referendum.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">
      Computational social networks
     </span>
     , 4:1‚Äì25, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     Tom√°s Hercig, Peter Krejzl, Barbora Hourov√°, Josef Steinberger, and Ladislav Lenc.
    </span>
    <span class="ltx_bibblock">
     Detecting stance in czech news commentaries.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">
      ITAT
     </span>
     , 176:180, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven Ka¬†Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Metagpt: Meta programming for multi-agent collaborative framework.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">
      arXiv preprint arXiv:2308.00352
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     Myungha Jang and James Allan.
    </span>
    <span class="ltx_bibblock">
     Explaining controversy on social media via stance summarization.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">
      The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval
     </span>
     , pages 1221‚Äì1224, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     Dilek K√º√ß√ºk and Fazli Can.
    </span>
    <span class="ltx_bibblock">
     Stance detection: A survey.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">
      ACM Computing Surveys (CSUR)
     </span>
     , 53(1):1‚Äì37, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     Bin Liang, Zixiao Chen, Lin Gui, Yulan He, Min Yang, and Ruifeng Xu.
    </span>
    <span class="ltx_bibblock">
     Zero-shot stance detection via contrastive learning.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">
      Proceedings of the ACM Web Conference 2022
     </span>
     , pages 2738‚Äì2747, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     Bin Liang, Yonghao Fu, Lin Gui, Min Yang, Jiachen Du, Yulan He, and Ruifeng Xu.
    </span>
    <span class="ltx_bibblock">
     Target-adaptive graph for cross-target stance detection.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">
      Proceedings of the Web Conference 2021
     </span>
     , pages 3453‚Äì3464, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi.
    </span>
    <span class="ltx_bibblock">
     Encouraging divergent thinking in large language models through multi-agent debate.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">
      arXiv preprint arXiv:2305.19118
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     Rui Liu, Zheng Lin, Yutong Tan, and Weiping Wang.
    </span>
    <span class="ltx_bibblock">
     Enhancing zero-shot and few-shot stance detection with commonsense knowledge graph.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">
      Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021
     </span>
     , pages 3152‚Äì3157, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     Nikita Lozhnikov, Leon Derczynski, and Manuel Mazzara.
    </span>
    <span class="ltx_bibblock">
     Stance prediction for russian: data and analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">
      Proceedings of 6th International Conference in Software Engineering for Defence Applications: SEDA 2018 6
     </span>
     , pages 176‚Äì186. Springer, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     Saif Mohammad, Svetlana Kiritchenko, Parinaz Sobhani, Xiaodan Zhu, and Colin Cherry.
    </span>
    <span class="ltx_bibblock">
     Semeval-2016 task 6: Detecting stance in tweets.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">
      Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016)
     </span>
     , pages 31‚Äì41, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     Saif¬†M Mohammad, Parinaz Sobhani, and Svetlana Kiritchenko.
    </span>
    <span class="ltx_bibblock">
     Stance and sentiment in tweets.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">
      ACM Transactions on Internet Technology (TOIT)
     </span>
     , 17(3):1‚Äì23, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     Varun Nair, Elliot Schumacher, Geoffrey Tso, and Anitha Kannan.
    </span>
    <span class="ltx_bibblock">
     Dera: enhancing large language model completions with dialog-enabled resolving agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2303.17071
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">
      arXiv
     </span>
     , pages 2303‚Äì08774, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     Joon¬†Sung Park, Joseph¬†C O‚ÄôBrien, Carrie¬†J Cai, Meredith¬†Ringel Morris, Percy Liang, and Michael¬†S Bernstein.
    </span>
    <span class="ltx_bibblock">
     Generative agents: Interactive simulacra of human behavior.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2304.03442
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [35]
    </span>
    <span class="ltx_bibblock">
     Maria Pontiki, Dimitris Galanis, Haris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar, Mohammed AL-Smadi, Mahmoud Al-Ayyoub, Yanyan Zhao, Bing Qin, Orph√©e De¬†Clercq, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Semeval-2016 task 5: Aspect based sentiment analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">
      ProWorkshop on Semantic Evaluation (SemEval-2016)
     </span>
     , pages 19‚Äì30. Association for Computational Linguistics, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [36]
    </span>
    <span class="ltx_bibblock">
     Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar.
    </span>
    <span class="ltx_bibblock">
     SemEval-2014 task 4: Aspect based sentiment analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">
      Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)
     </span>
     , pages 27‚Äì35, Dublin, Ireland, August 2014. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [37]
    </span>
    <span class="ltx_bibblock">
     Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Toolllm: Facilitating large language models to master 16000+ real-world apis.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2307.16789
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [38]
    </span>
    <span class="ltx_bibblock">
     Timo Schick, Jane Dwivedi-Yu, Roberto Dess√¨, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    </span>
    <span class="ltx_bibblock">
     Toolformer: Language models can teach themselves to use tools.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2302.04761
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [39]
    </span>
    <span class="ltx_bibblock">
     N¬†Shinn, F¬†Cassano, B¬†Labash, A¬†Gopinath, K¬†Narasimhan, and S¬†Yao.
    </span>
    <span class="ltx_bibblock">
     Reflexion: Language agents with verbal reinforcement learning (arxiv: 2303.11366). arxiv, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [40]
    </span>
    <span class="ltx_bibblock">
     Hao Tang, Donghong Ji, Chenliang Li, and Qiji Zhou.
    </span>
    <span class="ltx_bibblock">
     Dependency graph enhanced dual-transformer structure for aspect-based sentiment classification.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">
      Proceedings of the 58th annual meeting of the association for computational linguistics
     </span>
     , pages 6578‚Äì6588, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [41]
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Llama 2: Open foundation and fine-tuned chat models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">
      arXiv preprint arXiv:2307.09288
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [42]
    </span>
    <span class="ltx_bibblock">
     Apoorva Upadhyaya, Marco Fisichella, and Wolfgang Nejdl.
    </span>
    <span class="ltx_bibblock">
     A multi-task model for sentiment aided stance detection of climate change tweets.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">
      Proceedings of the International AAAI Conference on Web and Social Media
     </span>
     , volume¬†17, pages 854‚Äì865, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [43]
    </span>
    <span class="ltx_bibblock">
     Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen Zhang, and Zhou Yu.
    </span>
    <span class="ltx_bibblock">
     Persuasion for good: Towards a personalized persuasive dialogue system for social good.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:1906.06725
     </span>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [44]
    </span>
    <span class="ltx_bibblock">
     Yequan Wang, Minlie Huang, Xiaoyan Zhu, and Li¬†Zhao.
    </span>
    <span class="ltx_bibblock">
     Attention-based lstm for aspect-level sentiment classification.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">
      Proceedings of the 2016 conference on empirical methods in natural language processing
     </span>
     , pages 606‚Äì615, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [45]
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Maarten Bosma, Vincent¬†Y Zhao, Kelvin Guu, Adams¬†Wei Yu, Brian Lester, Nan Du, Andrew¬†M Dai, and Quoc¬†V Le.
    </span>
    <span class="ltx_bibblock">
     Finetuned language models are zero-shot learners.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">
      arXiv preprint arXiv:2109.01652
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [46]
    </span>
    <span class="ltx_bibblock">
     Penghui Wei and Wenji Mao.
    </span>
    <span class="ltx_bibblock">
     Modeling transferable topics for cross-target stance detection.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">
      Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval
     </span>
     , pages 1173‚Äì1176, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [47]
    </span>
    <span class="ltx_bibblock">
     Penghui Wei, Wenji Mao, and Daniel Zeng.
    </span>
    <span class="ltx_bibblock">
     A target-guided neural memory model for stance detection in twitter.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">
      2018 International Joint Conference on Neural Networks (IJCNN)
     </span>
     , pages 1‚Äì8. IEEE, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [48]
    </span>
    <span class="ltx_bibblock">
     Jiannan Xiang, Tianhua Tao, Yi¬†Gu, Tianmin Shu, Zirui Wang, Zichao Yang, and Zhiting Hu.
    </span>
    <span class="ltx_bibblock">
     Language models meet world models: Embodied experiences enhance language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">
      arXiv preprint arXiv:2305.10626
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [49]
    </span>
    <span class="ltx_bibblock">
     Chang Xu, C√©cile Paris, Surya Nepal, and Ross Sparks.
    </span>
    <span class="ltx_bibblock">
     Cross-target stance classification with self-attention networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">
      arXiv preprint arXiv:1805.06593
     </span>
     , 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [50]
    </span>
    <span class="ltx_bibblock">
     Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et¬†al.
    </span>
    <span class="ltx_bibblock">
     Glm-130b: An open bilingual pre-trained model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">
      arXiv preprint arXiv:2210.02414
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [51]
    </span>
    <span class="ltx_bibblock">
     Bowen Zhang, Daijun Ding, and Liwen Jing.
    </span>
    <span class="ltx_bibblock">
     How would stance detection techniques evolve after the launch of chatgpt?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">
      arXiv preprint arXiv:2212.14548
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [52]
    </span>
    <span class="ltx_bibblock">
     Bowen Zhang, Xianghua Fu, Daijun Ding, Hu¬†Huang, Yangyang Li, and Liwen Jing.
    </span>
    <span class="ltx_bibblock">
     Investigating chain-of-thought with chatgpt for stance detection on social media.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">
      arXiv preprint arXiv:2304.03087
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [53]
    </span>
    <span class="ltx_bibblock">
     Chen Zhang, Qiuchi Li, and Dawei Song.
    </span>
    <span class="ltx_bibblock">
     Aspect-based sentiment classification with aspect-specific graph convolutional networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">
      arXiv preprint arXiv:1909.03477
     </span>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [54]
    </span>
    <span class="ltx_bibblock">
     Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi Yang.
    </span>
    <span class="ltx_bibblock">
     Can large language models transform computational social science?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">
      arXiv preprint arXiv:2305.03514
     </span>
     , 2023.
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
